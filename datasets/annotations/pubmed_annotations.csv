,summary_uuid,summary,article,summ_id,system_id,nonfactual_sentence,label_type_ann1,label_type_ann2,inaccuracy_severity_ann1,inaccuracy_severity_ann2,error_type_ann1,error_type_ann2,error_factuality_ann1,error_factuality_ann2,comments_ann1,comments_ann2
0,60506d6a-75fc-4fbe-ad9f-20d6e5bd8322_gpt3_gen,"Plants possess complicated photosensory networks that monitor and respond to a wide spectrum of ambient light energies beyond the range of human vision. The spectral sensitivity of the plant light-sensors allows growth and development tailored to best fit ambient light conditions. The implementation of narrow-wavelength LED technology may benefit plant growth schema through supplementation or complete retrofitting of existing chambers. Such devices may reveal interesting interactions between light sensing systems. Recent findings demonstrate that even ""benign"" wavebands have significant influence in plant physiology in concert with red and blue light. Plant research has demonstrated that specific light wavebands may affect discrete aspects of plant physiology, such as germination, stem growth, biomass, and the transition to flowering. LED-based lighting regimes have applications to human physiology as well, and the possibility that combinatorial light regimes may help to optimize growth and control developmental transitions makes the implementation of LED technology particularly attractive to the design of controlled environments targeted to plant production for aesthetic applications or applications relevant to human nutrition."," light drives the processes of photosynthesis and plant development, and ultimately affects crop yield. the culmination of over a century of plant photobiology research shows that plants possess complicated photosensory networks that monitor and respond to a wide spectrum of ambient light energies. the spectral sensitivity of the plant light-sensors greatly exceeds the range of human vision, as light effects on physiology have been observed from energies arising from the uv-b wavebands into the near infra-red. this broad range of environmental information is processed by integrated signaling networks that tailor growth and development to best fit ambient light conditions. light sensing pathways have been dissected through use of narrow-bandwidth light sources. since individual photoreceptors are generally tuned to sense specific regions of the spectrum, narrow-bandwidth irradiation allows isolation of effects associated with a particular waveband. for instance, the phytochromes mediate responses to red and far-red light, with partial activity extended through the green, blue and near-uv wavebands. cryptochromes are required for maximal response to blue and uv-a, while the phototropins exhibit autophosphorylation when stimulated with light qualities from the blue-green interface to uv-c. other sensors share sensory overlap with the phototropins, and at least several other receptors remain to be characterized. narrow-bandwidth, research-quality light is typically generated using a broad spectrum source filtered through an infra-red heat sink and several layers of acetate theatre filters or colored plastic. fluorescent lamps also are used, as they emit three principle light qualities that can be readily filtered to obtain narrow-bandwidth light. led light has been used principally in studies of phytochrome reversibility, as switchable red and far-red led arrays are commercially available. many reports have demonstrated the utility of red/far-red led sources in modulating phytochrome responses during de-etiolation, modulation of root growth, root greening and senescence. led technology has been incorporated into lighting regimes to modulate plant growth and development for decades as acute supplementation of sunlight or as the basis of plant growth in commercial chambers. additionally, led-generated light is well-suited for small growth chambers and other applications where a significant fluence rate is required, but little physical space is available for conventional lamps. the practical aspects of led lighting make them particularly well-suited for space applications where light treatments need to be precise and reliable with little heat radiation and low weight. leds may also be especially useful in retrofitting incandescent or fluorescent growth chambers for terrestrial applications. there is a need for a light source that may facilitate plant growth in a chamber environment, yet still allow for dynamic variation in light quality and quantity for experimental studies. such devices may reveal interesting interactions between light sensing systems. recent findings demonstrate that even ""benign"" wavebands have significant influence in plant physiology in concert with red and blue light. in this report we detail the design and construction of a compact led light array for use in plant research. these light sources utilize norlux hex-led arrays and are capable of delivering – μmol m- s- of combined red, green, and/or blue light. the design allows precise fluence-rate control of individual wavebands, allowing growth of plants under different combinations of light energies. these designs are the same as those used to generate plant-growth data in a number of recent studies of red, blue and green light interaction. two designs are presented in figures the first is a plan that may be suitable for use in the laboratory or classroom for fewer than one thousand dollars. the second depicts an expandable system that may be appropriate for large growth chambers. together the two plans presented represent tested and proven designs to introduce efficient lighting to chambers where light quality, quantity, duration and mixture can be readily controlled.  the advent of new semiconductor technologies has inspired a marked decrease in the price of led-based devices. an increased number of consumer-grade products have become available to the researcher, and now these new tools may be integrated into various light-research applications. the goal of this work is to provide an interface between research needs and new technology. with this, the best-available research tools may be implemented by researchers without a significant investment in development. the plans presented herein offer two options for led light source construction, based on the need of an experimental illumination tool or requirement for large-area irradiation. led-based lighting regimes are being adopted by municipalities and medical facilities for their consistent, low-power, low-maintenance output. however, one of the most important practical applications of this technology is in the design for lighting regimes to support plant growth. it is of great interest to not only to foster plant growth, but to control plant growth. basic plant research has demonstrated that specific light wavebands may affect discrete aspects of plant physiology, such as germination, stem growth, biomass and the transition to flowering. the supplementation of specific wavebands or skewing of overall spectrum may help modulate the progression of these developmental events. the possibility that combinatorial light regimes may help to optimize growth and control developmental transitions makes the implementation of led technology particularly attractive to the design of controlled environments targeted to plant production for aesthetic applications, or applications relevant to human nutrition. if spectral quality alone can delay or hasten the floral transition it may have profound effects on modulating the delivery of nursery goods or perhaps affect the availability of consumable produce in a finite, controlled environment. this attribute alone makes led lighting a compelling platform for specific plant growth routines, such as those proposed for long-term inhabitation of space. since humans rely specifically on vegetative parts or reproductive parts of plants for nutrition, it is critical to develop systems which impart control of the progression of plant development to affect plant output toward the particular needs of humans. the implementation of narrow-wavelength led technology may benefit plant growth schema through supplementation or complete retrofitting of existing chambers. its compact design may replace existing infrastructure with long-life and consistent output. here, antiquated lamp systems, replete with toxic, inefficient fluors, may be refitted with efficient light sources that require little to no maintenance with comparable light output. although previously unattainable without substantial engineering, the geometry of the systems provided in this report brings led technology to the average plant biology laboratory. despite their vast advantages over conventional lighting systems, the led arrays described in this report offer opportunities for improvement and expansion. larger installations require close attention to array density, as the fluence rate of rgb hex led lights decays significantly toward the edges of the irradiation area. careful arrangement modified to the application lessens the frequency of ""hotspots"" or other gradients of light intensities under the light fixture. it is impossible to eliminate all variability under the arrays under all fluence rates and light combinations. the spacing of hex units in individual systems needs to be carefully tailored for the specific application. another potential improvement would be to integrate par sensors into the system to provide irradiance feedback and adjust light intensity through a computer-aided regulatory circuit. this would allow the user to enter a specific irradiance value for the desired wavelength and would compensate for changes in led output that occur over time and with temperature changes in the ambient environment. this system has been developed using leds emitting three principal wavebands. the clear extrapolation is to add additional led types to generate additional spectrum coverage. leds currently manufactured include uv, far-red and infra-red light. from the plans presented within this report it may be possible to develop lighting systems that roughly approximate solar output by compounding the effects of multiple leds. such a system may prove especially valuable in optimizing plant physiology and may have applications to human physiology as well. the arrays described were tested for support of normal plant developmental responses. these are most conspicuous in early seedling development, as initial responses to light are rapid, robust, and have been well characterized. three responses to light, namely inhibition of stem elongation, stem growth promotion and phototropism, have been extremely well characterized and may be used to test and verify the utility of these led arrays on early plant developmental responses. three assays were conducted. first, end-point stem growth was measured in plants grown under three fluence rates of red or blue light. red and blue light strongly inhibit early stem elongation through the phytochrome and cryptochrome systems, respectively. the results of two independent fluence-rate/response experiments using over seedlings are shown in figure 5a and 5b. figure 5a shows the height of seedlings grown for h under constant blue light and figure 5b shows the effect of the same treatment with red light. the cry and phyb mutants are presented as controls. the data show that constant blue or red light inhibit seedling elongation in a manner roughly proportional to fluence rate. inhibition is detectable even at low fluence rate, leading to a strong inhibition of stem growth elongation. the results of these trials mirror the previously published results, suggesting that the led arrays described herein act in a manner similar to those used previously. while phytochromes and cryptochrome effects are salient as stem growth inhibition after days of growth in constant light, other rapid responses involve other light sensors and can be measured on the order of minutes rather than days. contrary to the effects of red and blue, a short single pulse of green light stimulates rapid elongation of the hypocotyl in the dark-grown seedling. the response persists in all photomorphogenic mutants, it occurs when plants are grown in constant dim red light, and growth promotion is the opposite of what occurs when seedlings are irradiated with red or blue light. this evidence renders it difficult to conveniently ascribe this response to any of the known light sensors, and it is likely being mediated by a separate green-sensitive transduction pathway. figure 5c, shows the results of independent seedlings treated with green light from the norlux hex arrays, compared to previously published data. seedlings irradiated with a short, single pulse of green light begin to grow rapidly within min, attaining 140% of their dark rate before growth rate declines to dark levels after an hour. the results are highly similar to published findings, again indicating that norlux hex arrays are a suitable alternative to other led or fluorescent light sources. phototropism is the rapid curvature of the hypocotyl toward a unilateral light source. in arabidopsis phototropism is blue light induced and is mediated by the phototropins, autophosphorylating serine-threonine kinases associated with the plasma membrane. the response is exquisitely sensitive to blue light. here wild-type seedlings were irradiated from the side while being imaged in 5-minute intervals with an infra-red ccd camera. the degree of curvature was monitored over two hours and compared to previous results. the results indicate that the rapid response of phototropism is very similar between the arrays designed in this study and those produced commercially.  as the availability of new technologies increases, research programs are challenged with the need to retool their capabilities to exploit their potential. since many of these new technologies are electronic and/or computer related, a certain degree of technical prowess is required to move ideas from the drawing board to application. the development costs of these technologies may be significant. this report offers two clearly applicable models of led light source development that may be implemented in the study of plant growth and output, helping to narrow the long-term challenges of illumination to support plant growth. these designs allow the fine control of specific wavebands shown to influence plant growth and development. such designs represent the first step in defining conditions that will optimize, or perhaps even control, plant growth and development. the light sources used in this report sustain normal plant early developmental responses, suggesting that they are an appropriate substitute for, or complement to, other plant illumination solutions. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
1,60506d6a-75fc-4fbe-ad9f-20d6e5bd8322_flant5_gen,This paper describes the design and construction of a compact led light source for use in plant research.," light drives the processes of photosynthesis and plant development, and ultimately affects crop yield. the culmination of over a century of plant photobiology research shows that plants possess complicated photosensory networks that monitor and respond to a wide spectrum of ambient light energies. the spectral sensitivity of the plant light-sensors greatly exceeds the range of human vision, as light effects on physiology have been observed from energies arising from the uv-b wavebands into the near infra-red. this broad range of environmental information is processed by integrated signaling networks that tailor growth and development to best fit ambient light conditions. light sensing pathways have been dissected through use of narrow-bandwidth light sources. since individual photoreceptors are generally tuned to sense specific regions of the spectrum, narrow-bandwidth irradiation allows isolation of effects associated with a particular waveband. for instance, the phytochromes mediate responses to red and far-red light, with partial activity extended through the green, blue and near-uv wavebands. cryptochromes are required for maximal response to blue and uv-a, while the phototropins exhibit autophosphorylation when stimulated with light qualities from the blue-green interface to uv-c. other sensors share sensory overlap with the phototropins, and at least several other receptors remain to be characterized. narrow-bandwidth, research-quality light is typically generated using a broad spectrum source filtered through an infra-red heat sink and several layers of acetate theatre filters or colored plastic. fluorescent lamps also are used, as they emit three principle light qualities that can be readily filtered to obtain narrow-bandwidth light. led light has been used principally in studies of phytochrome reversibility, as switchable red and far-red led arrays are commercially available. many reports have demonstrated the utility of red/far-red led sources in modulating phytochrome responses during de-etiolation, modulation of root growth, root greening and senescence. led technology has been incorporated into lighting regimes to modulate plant growth and development for decades as acute supplementation of sunlight or as the basis of plant growth in commercial chambers. additionally, led-generated light is well-suited for small growth chambers and other applications where a significant fluence rate is required, but little physical space is available for conventional lamps. the practical aspects of led lighting make them particularly well-suited for space applications where light treatments need to be precise and reliable with little heat radiation and low weight. leds may also be especially useful in retrofitting incandescent or fluorescent growth chambers for terrestrial applications. there is a need for a light source that may facilitate plant growth in a chamber environment, yet still allow for dynamic variation in light quality and quantity for experimental studies. such devices may reveal interesting interactions between light sensing systems. recent findings demonstrate that even ""benign"" wavebands have significant influence in plant physiology in concert with red and blue light. in this report we detail the design and construction of a compact led light array for use in plant research. these light sources utilize norlux hex-led arrays and are capable of delivering – μmol m- s- of combined red, green, and/or blue light. the design allows precise fluence-rate control of individual wavebands, allowing growth of plants under different combinations of light energies. these designs are the same as those used to generate plant-growth data in a number of recent studies of red, blue and green light interaction. two designs are presented in figures the first is a plan that may be suitable for use in the laboratory or classroom for fewer than one thousand dollars. the second depicts an expandable system that may be appropriate for large growth chambers. together the two plans presented represent tested and proven designs to introduce efficient lighting to chambers where light quality, quantity, duration and mixture can be readily controlled.  the advent of new semiconductor technologies has inspired a marked decrease in the price of led-based devices. an increased number of consumer-grade products have become available to the researcher, and now these new tools may be integrated into various light-research applications. the goal of this work is to provide an interface between research needs and new technology. with this, the best-available research tools may be implemented by researchers without a significant investment in development. the plans presented herein offer two options for led light source construction, based on the need of an experimental illumination tool or requirement for large-area irradiation. led-based lighting regimes are being adopted by municipalities and medical facilities for their consistent, low-power, low-maintenance output. however, one of the most important practical applications of this technology is in the design for lighting regimes to support plant growth. it is of great interest to not only to foster plant growth, but to control plant growth. basic plant research has demonstrated that specific light wavebands may affect discrete aspects of plant physiology, such as germination, stem growth, biomass and the transition to flowering. the supplementation of specific wavebands or skewing of overall spectrum may help modulate the progression of these developmental events. the possibility that combinatorial light regimes may help to optimize growth and control developmental transitions makes the implementation of led technology particularly attractive to the design of controlled environments targeted to plant production for aesthetic applications, or applications relevant to human nutrition. if spectral quality alone can delay or hasten the floral transition it may have profound effects on modulating the delivery of nursery goods or perhaps affect the availability of consumable produce in a finite, controlled environment. this attribute alone makes led lighting a compelling platform for specific plant growth routines, such as those proposed for long-term inhabitation of space. since humans rely specifically on vegetative parts or reproductive parts of plants for nutrition, it is critical to develop systems which impart control of the progression of plant development to affect plant output toward the particular needs of humans. the implementation of narrow-wavelength led technology may benefit plant growth schema through supplementation or complete retrofitting of existing chambers. its compact design may replace existing infrastructure with long-life and consistent output. here, antiquated lamp systems, replete with toxic, inefficient fluors, may be refitted with efficient light sources that require little to no maintenance with comparable light output. although previously unattainable without substantial engineering, the geometry of the systems provided in this report brings led technology to the average plant biology laboratory. despite their vast advantages over conventional lighting systems, the led arrays described in this report offer opportunities for improvement and expansion. larger installations require close attention to array density, as the fluence rate of rgb hex led lights decays significantly toward the edges of the irradiation area. careful arrangement modified to the application lessens the frequency of ""hotspots"" or other gradients of light intensities under the light fixture. it is impossible to eliminate all variability under the arrays under all fluence rates and light combinations. the spacing of hex units in individual systems needs to be carefully tailored for the specific application. another potential improvement would be to integrate par sensors into the system to provide irradiance feedback and adjust light intensity through a computer-aided regulatory circuit. this would allow the user to enter a specific irradiance value for the desired wavelength and would compensate for changes in led output that occur over time and with temperature changes in the ambient environment. this system has been developed using leds emitting three principal wavebands. the clear extrapolation is to add additional led types to generate additional spectrum coverage. leds currently manufactured include uv, far-red and infra-red light. from the plans presented within this report it may be possible to develop lighting systems that roughly approximate solar output by compounding the effects of multiple leds. such a system may prove especially valuable in optimizing plant physiology and may have applications to human physiology as well. the arrays described were tested for support of normal plant developmental responses. these are most conspicuous in early seedling development, as initial responses to light are rapid, robust, and have been well characterized. three responses to light, namely inhibition of stem elongation, stem growth promotion and phototropism, have been extremely well characterized and may be used to test and verify the utility of these led arrays on early plant developmental responses. three assays were conducted. first, end-point stem growth was measured in plants grown under three fluence rates of red or blue light. red and blue light strongly inhibit early stem elongation through the phytochrome and cryptochrome systems, respectively. the results of two independent fluence-rate/response experiments using over seedlings are shown in figure 5a and 5b. figure 5a shows the height of seedlings grown for h under constant blue light and figure 5b shows the effect of the same treatment with red light. the cry and phyb mutants are presented as controls. the data show that constant blue or red light inhibit seedling elongation in a manner roughly proportional to fluence rate. inhibition is detectable even at low fluence rate, leading to a strong inhibition of stem growth elongation. the results of these trials mirror the previously published results, suggesting that the led arrays described herein act in a manner similar to those used previously. while phytochromes and cryptochrome effects are salient as stem growth inhibition after days of growth in constant light, other rapid responses involve other light sensors and can be measured on the order of minutes rather than days. contrary to the effects of red and blue, a short single pulse of green light stimulates rapid elongation of the hypocotyl in the dark-grown seedling. the response persists in all photomorphogenic mutants, it occurs when plants are grown in constant dim red light, and growth promotion is the opposite of what occurs when seedlings are irradiated with red or blue light. this evidence renders it difficult to conveniently ascribe this response to any of the known light sensors, and it is likely being mediated by a separate green-sensitive transduction pathway. figure 5c, shows the results of independent seedlings treated with green light from the norlux hex arrays, compared to previously published data. seedlings irradiated with a short, single pulse of green light begin to grow rapidly within min, attaining 140% of their dark rate before growth rate declines to dark levels after an hour. the results are highly similar to published findings, again indicating that norlux hex arrays are a suitable alternative to other led or fluorescent light sources. phototropism is the rapid curvature of the hypocotyl toward a unilateral light source. in arabidopsis phototropism is blue light induced and is mediated by the phototropins, autophosphorylating serine-threonine kinases associated with the plasma membrane. the response is exquisitely sensitive to blue light. here wild-type seedlings were irradiated from the side while being imaged in 5-minute intervals with an infra-red ccd camera. the degree of curvature was monitored over two hours and compared to previous results. the results indicate that the rapid response of phototropism is very similar between the arrays designed in this study and those produced commercially.  as the availability of new technologies increases, research programs are challenged with the need to retool their capabilities to exploit their potential. since many of these new technologies are electronic and/or computer related, a certain degree of technical prowess is required to move ideas from the drawing board to application. the development costs of these technologies may be significant. this report offers two clearly applicable models of led light source development that may be implemented in the study of plant growth and output, helping to narrow the long-term challenges of illumination to support plant growth. these designs allow the fine control of specific wavebands shown to influence plant growth and development. such designs represent the first step in defining conditions that will optimize, or perhaps even control, plant growth and development. the light sources used in this report sustain normal plant early developmental responses, suggesting that they are an appropriate substitute for, or complement to, other plant illumination solutions. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
2,ddc221f3-d5cf-4e74-bd75-25e7b3333537_gpt3_gen,"The article discusses the construction of a comprehensive Escherichia coli orf collection in a gateway® entry vector, which represents orfs of 94% of all protein-coding genes, and its utility in comparative functional genomic studies. The availability of complete collections of easily moveable cloned orfs facilitates functional studies in multiple species in parallel, even at the level of whole proteomes. The e. coli orfeome was compared to all other bacterial orfeomes that are available as gateway-compatible clones to determine its use as a model for pathogenic bacteria. The article also discusses the verification of the functionality of the entry clones by two different downstream applications, recombinant protein production in E. coli and protein interactions by the yeast two-hybrid assay. The e. coli orfeome was compared to previously generated s. aureus and s. pneumoniae collections to systematically test protein-protein interactions to determine which interactions are conserved. The study of these interactions not only demonstrated differences between the species tested but also showed another advantage of such a comparative approach."," high-throughput dna sequencing has increased the number of genome sequences to over bacterial species from which we can infer their proteomes and often major parts of their metabolism and regulatory pathways. a systems level understanding of cells, however, will require the functional characterization of these proteins and how they work together. in recent years, a growing number of efforts have used high throughput assays to catalog gene expression, protein interactions, localization and metabolic activities. for many of these studies, the first step is to identify and then clone all the open reading frames encoded by the genome of the organism. here we describe the construction of a comprehensive escherichia coli orf collection in a gateway® entry vector. the library represents orfs or 94% of all protein-coding genes. the gateway® system facilitates the transfer of orfs into a large range of expression vectors that are suitable for downstream studies. here we demonstrate the utility of the e. coli orfeome by comparing it to other available microbial orfeomes and by testing a set of protein-protein interactions among species. the complete genome sequence of escherichia coli k- encodes protein-coding orfs. kitagawa et al. previously cloned all the e. coli orfs into an expression vector creating n-terminal 6xhis and c-terminal gfp fusions. however, the aska library cannot be used to flexibly transfer orfs into other expression vectors. libraries of all open reading frames cloned into highly flexible vectors will be needed to take full advantage of the information found in any genome sequence. we transferred the aska library into an gateway® entry vector by sfii restriction enzyme cloning. about e. coli clones which were not present in the aska library or which were not successfully cloned from the aska library into the gateway® entry vector were cloned directly by gateway® recombination. the entry clone library was then validated by dna sequencing. the resulting library represents orfs. the clone collection is freely available to academic users. the e. coli entry clone library lacks start and stop codons and is thus compatible with both n-terminal and c-terminal expression clone constructions. the clones from the entry vectors can be easily shuttled into different gateway-compatible expression vectors of many types in a high-throughput fashion.  e. coli as a model for comparative genomics and biology e. coli k- has led basic life science research for more than half a century due to its easy manipulation and its safety as a non-pathogenic organism. we wondered to what extent it can also serve as model for pathogenic bacteria and compared the e. coli orfeome to all other bacterial orfeomes that are available as gateway-compatible clones. figure 1b shows how many e. coli genes have orthologs in these species including vibrio cholerae, yersinia pestis, streptococcus pneumoniae and others. for example, over 80% of e. coli cogs are conserved in pseudomonas aeruginosa. cogs represent conserved protein families and provide a standard way to compare gene sets. we can safely assume that the general molecular function of these e. coli proteins should be similar or identical to these homologues in other bacterial species. however, we cannot easily predict whether small changes in sequence will change the function or specificity of proteins. the availability of complete collections of easily moveable cloned orfs facilitates functional studies in multiple species in parallel, even at the level of whole proteomes. as of today, gateway® clone collections are available for at least bacterial species including strains of staphylococcus aureus. cogs should also facilitate comparative analysis, given that many of them are present in species for which orfeomes are available. for example, cogs are present in at least four of the species for which orfeomes are available. the e. coli orfeome for protein expression we verified the functionality of the entry clones by two different downstream applications. first, we tested recombinant protein production in e. coli by randomly selecting ten entry clones from the library that were subsequently cloned into the gateway® gst-fusion expression vector pdest-gst. the expression clones were transformed into the bl protein expression strain of e. coli and after induction of protein expression with iptg, the cells were lysed in sample buffer and analyzed by western blot. second, we tested protein interactions by the yeast two hybrid assay. about entry clones which are known to be involved in bacterial motility and chemotaxis were cloned into two different yeast two-hybrid expression vector systems and 90× = protein pair were tested for protein-protein interactions, resulting in protein-protein interactions. the e. coli orfeome for functional genomics and protein interaction analysis the availability of orfeome collections will greatly facilitate comparative functional genomic studies. an example of this is to compare protein-protein interactions among multiple species in order to determine which interactions are conserved. here we used the e. coli orf collection as well as previously generated s. aureus and s. pneumoniae collections to systematically test, by yeast two-hybrid, whether the recently described protein-protein interactions between the essential e. coli gene products ygjd, yjee and yeaz are conserved in these gram-positive pathogens. these three proteins were selected as an interesting case study because they are highly conserved, essential, and of unknown function. the yjee, yeaz, and ygjd genes are highly conserved throughout eubacterial genomes while ygjd orthologs are also found throughout the archaea and eukaryotes. we found all the interactions that handford et al. reported but there were significant differences between species. for example, yjee and yeaz from e. coli, but not from s. aureus or s. pneumoniae, interacted. the functions of these genes remain poorly understood. in e. coli, yeaz is able to proteolyse ygjd while yjee, an atpase, competes with ygjd for binding to yeaz. the inability of yjee to interact with yeaz in s. aureus and s. pneumoniae may indicate differences in the regulation of the ygjd-yeaz complex in these species. our study of these interactions not only demonstrated differences between the species tested but also showed another advantage of such a comparative approach: the s. pneumoniae yjee as well as the the s. aureus ygjd protein autoactivated the reporter genes when fused to the gal dna binding domain. this property affects approximately 10% of bait proteins in yeast two-hybrid assays. however, while the s. aureus ygjd bait is autoactivating, ygjd of e. coli and s. pneumoniae are not. hence, comparative assays may offer one strategy for circumventing limitations of the yeast two-hybrid method. additionally, by revealing which interactions are evolutionarily conserved, such comparative studies will greatly enhance our ability to interpret the conserved biological functions of the interacting proteins, and also the computational analysis of high-throughput protein-protein interaction datasets. for example, crystal structures are available for all three interacting proteins, but only one from e. coli, namely yeaz. in order to obtain more information for model building and functional interactions, we expanded our test set beyond e. coli and tested the interactions among ygjd, yeaz, and yjee in five different species, including h. pylori and r. prowazekii. in addition to the expected intraspecies interactions, interspecies interactions were observed. the s. aureus yeaz protein associated with the products of the e. coli and s. pneumoniae orthologs of ygjd while the s. pneumoniae yeaz protein was able to interact with h. pylori ygjd. this last interaction was particularly unexpected as yeaz is not conserved in h. pylori, and suggests the possibility that the functions of yeaz may be performed by another protein in this species. given the availability of orfeomes for more than a dozen species, such comparative analyses can now be carried out quite easily. more importantly, additional biochemical or genetic studies can be done in e. coli for which extensive resources, including deletion strains and comprehensive databases, are available. for instance, our e. coli clones could be used to complement mutants in other species, which would demonstrate their functional equivalence.  in conjunction with other clone sets and the vast amount of genomics and proteomics data from e. coli, the gateway-orfeome will be another highly useful resource for the e. coli functional genomics community. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
3,ddc221f3-d5cf-4e74-bd75-25e7b3333537_flant5_gen,Gateway® clone collections are a powerful tool for comparative functional genomics and protein interaction analysis.," high-throughput dna sequencing has increased the number of genome sequences to over bacterial species from which we can infer their proteomes and often major parts of their metabolism and regulatory pathways. a systems level understanding of cells, however, will require the functional characterization of these proteins and how they work together. in recent years, a growing number of efforts have used high throughput assays to catalog gene expression, protein interactions, localization and metabolic activities. for many of these studies, the first step is to identify and then clone all the open reading frames encoded by the genome of the organism. here we describe the construction of a comprehensive escherichia coli orf collection in a gateway® entry vector. the library represents orfs or 94% of all protein-coding genes. the gateway® system facilitates the transfer of orfs into a large range of expression vectors that are suitable for downstream studies. here we demonstrate the utility of the e. coli orfeome by comparing it to other available microbial orfeomes and by testing a set of protein-protein interactions among species. the complete genome sequence of escherichia coli k- encodes protein-coding orfs. kitagawa et al. previously cloned all the e. coli orfs into an expression vector creating n-terminal 6xhis and c-terminal gfp fusions. however, the aska library cannot be used to flexibly transfer orfs into other expression vectors. libraries of all open reading frames cloned into highly flexible vectors will be needed to take full advantage of the information found in any genome sequence. we transferred the aska library into an gateway® entry vector by sfii restriction enzyme cloning. about e. coli clones which were not present in the aska library or which were not successfully cloned from the aska library into the gateway® entry vector were cloned directly by gateway® recombination. the entry clone library was then validated by dna sequencing. the resulting library represents orfs. the clone collection is freely available to academic users. the e. coli entry clone library lacks start and stop codons and is thus compatible with both n-terminal and c-terminal expression clone constructions. the clones from the entry vectors can be easily shuttled into different gateway-compatible expression vectors of many types in a high-throughput fashion.  e. coli as a model for comparative genomics and biology e. coli k- has led basic life science research for more than half a century due to its easy manipulation and its safety as a non-pathogenic organism. we wondered to what extent it can also serve as model for pathogenic bacteria and compared the e. coli orfeome to all other bacterial orfeomes that are available as gateway-compatible clones. figure 1b shows how many e. coli genes have orthologs in these species including vibrio cholerae, yersinia pestis, streptococcus pneumoniae and others. for example, over 80% of e. coli cogs are conserved in pseudomonas aeruginosa. cogs represent conserved protein families and provide a standard way to compare gene sets. we can safely assume that the general molecular function of these e. coli proteins should be similar or identical to these homologues in other bacterial species. however, we cannot easily predict whether small changes in sequence will change the function or specificity of proteins. the availability of complete collections of easily moveable cloned orfs facilitates functional studies in multiple species in parallel, even at the level of whole proteomes. as of today, gateway® clone collections are available for at least bacterial species including strains of staphylococcus aureus. cogs should also facilitate comparative analysis, given that many of them are present in species for which orfeomes are available. for example, cogs are present in at least four of the species for which orfeomes are available. the e. coli orfeome for protein expression we verified the functionality of the entry clones by two different downstream applications. first, we tested recombinant protein production in e. coli by randomly selecting ten entry clones from the library that were subsequently cloned into the gateway® gst-fusion expression vector pdest-gst. the expression clones were transformed into the bl protein expression strain of e. coli and after induction of protein expression with iptg, the cells were lysed in sample buffer and analyzed by western blot. second, we tested protein interactions by the yeast two hybrid assay. about entry clones which are known to be involved in bacterial motility and chemotaxis were cloned into two different yeast two-hybrid expression vector systems and 90× = protein pair were tested for protein-protein interactions, resulting in protein-protein interactions. the e. coli orfeome for functional genomics and protein interaction analysis the availability of orfeome collections will greatly facilitate comparative functional genomic studies. an example of this is to compare protein-protein interactions among multiple species in order to determine which interactions are conserved. here we used the e. coli orf collection as well as previously generated s. aureus and s. pneumoniae collections to systematically test, by yeast two-hybrid, whether the recently described protein-protein interactions between the essential e. coli gene products ygjd, yjee and yeaz are conserved in these gram-positive pathogens. these three proteins were selected as an interesting case study because they are highly conserved, essential, and of unknown function. the yjee, yeaz, and ygjd genes are highly conserved throughout eubacterial genomes while ygjd orthologs are also found throughout the archaea and eukaryotes. we found all the interactions that handford et al. reported but there were significant differences between species. for example, yjee and yeaz from e. coli, but not from s. aureus or s. pneumoniae, interacted. the functions of these genes remain poorly understood. in e. coli, yeaz is able to proteolyse ygjd while yjee, an atpase, competes with ygjd for binding to yeaz. the inability of yjee to interact with yeaz in s. aureus and s. pneumoniae may indicate differences in the regulation of the ygjd-yeaz complex in these species. our study of these interactions not only demonstrated differences between the species tested but also showed another advantage of such a comparative approach: the s. pneumoniae yjee as well as the the s. aureus ygjd protein autoactivated the reporter genes when fused to the gal dna binding domain. this property affects approximately 10% of bait proteins in yeast two-hybrid assays. however, while the s. aureus ygjd bait is autoactivating, ygjd of e. coli and s. pneumoniae are not. hence, comparative assays may offer one strategy for circumventing limitations of the yeast two-hybrid method. additionally, by revealing which interactions are evolutionarily conserved, such comparative studies will greatly enhance our ability to interpret the conserved biological functions of the interacting proteins, and also the computational analysis of high-throughput protein-protein interaction datasets. for example, crystal structures are available for all three interacting proteins, but only one from e. coli, namely yeaz. in order to obtain more information for model building and functional interactions, we expanded our test set beyond e. coli and tested the interactions among ygjd, yeaz, and yjee in five different species, including h. pylori and r. prowazekii. in addition to the expected intraspecies interactions, interspecies interactions were observed. the s. aureus yeaz protein associated with the products of the e. coli and s. pneumoniae orthologs of ygjd while the s. pneumoniae yeaz protein was able to interact with h. pylori ygjd. this last interaction was particularly unexpected as yeaz is not conserved in h. pylori, and suggests the possibility that the functions of yeaz may be performed by another protein in this species. given the availability of orfeomes for more than a dozen species, such comparative analyses can now be carried out quite easily. more importantly, additional biochemical or genetic studies can be done in e. coli for which extensive resources, including deletion strains and comprehensive databases, are available. for instance, our e. coli clones could be used to complement mutants in other species, which would demonstrate their functional equivalence.  in conjunction with other clone sets and the vast amount of genomics and proteomics data from e. coli, the gateway-orfeome will be another highly useful resource for the e. coli functional genomics community. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
4,c16217ef-0bbb-4d17-bc6f-affb4607664d_gpt3_gen,"The article discusses the challenge of estimating divergence time of protein sequences for phylogenetic tree reconstruction, which is important in various subsequent analyses such as orthology inference. The early models focused on nucleotides, but more advanced models for protein evolution estimate parameters from protein sequence alignments, such as the Dayhoff matrices series. However, potential errors inherent in the experimental data can magnify with extrapolation, and it is questionable whether substitution probabilities observed on closely related sequences can accurately reflect the evolution of more distantly related sequences. The article presents a novel correction-based distance estimator called Scoredist, which applies a correction function to an observed reduction in normalized score, rather than to observed differences as other correction-based methods, allowing the popular Blosum matrix series to be used. Scoredist is found to be a more robust estimator for different data sources and evolutionary models compared to other distance estimators, with the main advantages of computational simplicity and high accuracy."," estimating divergence time of protein sequences is one of the fundamental problems in bioinformatics. evolutionary distance estimates are used by many of the most commonly used phylogenetic tree reconstruction algorithms. in current research, phylogenetic trees are used for many types of subsequent analysis, e.g. orthology inference. early models for sequence evolution focussed on nucleotides. they commonly employ markov chains and assume independent evolution at every site. each of the four nucleotides is identified by one state and the substitution probability is modelled as a state transition probability from one state to another. in the most straightforward approach, the same state transition probability is assigned to every substitution. subsequent models take account of more nucleotide specific properties, e.g. transitional and transversional substitutions as well as gc content. these more advanced approaches are bound to nucleotide sequences and cannot be directly used with protein sequences. markov chain models for protein evolution differ from nucleotide approaches in their larger number of states and transitions for which parameters need to be estimated. the protein sequence jukes-cantor model assigns the same probability to each substitution and is hence a rather poor approximation. this method essentially takes the observed differences between two sequences and corrects this value to the estimated evolutionary distance using a logarithmic function. other similar methods exist that also correct observed differences, e.g. kimura's method. although they produce rather inaccurate distance estimates, correction-based distance estimators are popular because of their simplicity. more advanced protein evolution models estimate parameters from protein sequence alignments. assuming the same substitutions for closely and distantly related sequences leads to the construction of the dayhoff matrix series. following this approach, it suffices to collect data from alignments of closely related sequences to build an evolutionary model of amino acid substitution. dayhoff and co-workers introduced the term percent accepted mutation, which denotes a commonly used measure for evolutionary distance between two aligned sequences. in other words, two sequences at a distance of pam are related to each other by substitutions per position on average. as substitution is a stochastic process, some positions will experience multiple substitutions while others will experience none. it is also possible that secondary substitutions at one site will result in the original residue, making the evolutionary steps invisible. this is in essence the reason why estimating evolutionary distance is so hard – multiple substitutions cannot be observed directly. an evolutionary distance of pam corresponds roughly to 80% observed differences. the term pam is found in literature for both the matrix series given by dayhoff et al. as well as for evolutionary distance unit. in this publication we refer to the matrices as dayhoff matrices and reserve the term pam for distance units. there are two major shortcomings connected with the derivation of the dayhoff matrices. first, potential errors inherent in the experimental data will be magnified by extrapolation. additionally, it is questionable whether substitution probabilities observed on closely related sequences can accurately reflect the evolution of more distantly related sequences. the efforts of researchers since the publication of the dayhoff matrices have led to several other matrix series, sharing the idea of an underlying markov chain. they differ in terms of the data they are built upon and account for the above-mentioned shortcomings in various ways. the approach behind the blosum matrices is different from dayhoff's evolutionary model. whereas the markov model assumes that any transition probability matrix may be derived from another matrix in the same series, the blosum matrices do not imply any evolutionary time. there is no direct mathematical relationship between matrices in the blosum series. sequences with identities above a given identity cutoff are clustered and used to derive score matrices. the blosum matrices are known as a good general-purpose choice. especially, blosum is frequently chosen for the alignment of sequences.  we here introduce scoredist, a novel correction-based distance estimator for protein sequences. it applies a correction function to an observed reduction in normalised score, rather than to observed differences as other correction-based methods. this gives a better estimate of the divergence in the well-established pam measure and allows the popular blosum matrix series to be used. other matrices could in principle be used, but the blosum matrix has proved to be the most universal. scoredist distance estimates are calculated directly by a simple equation and do not require cumbersome computational approximations, which is needed for e.g. maximum likelihood and expected distance estimates. additional calibration opens the possibility to make scoredist tuned to other evolutionary models. in order to evaluate our novel protein distance estimator scoredist against other estimators, we generated a large testset of artificial sequence alignments. simulation is the only way to exactly know an alignment's evolutionary distance. the substitutions were made by rose according to an evolutionary model that can be chosen arbitrarily. it is to be expected that a distance estimator based on a particular evolutionary model will perform optimally on a testset generated with the same model. we therefore generated testsets using four different matrix series: dayhoff, mv, jtt, and wag. for each model, alignments were created for evolutionary distances between and pam units, i.e. alignments for each distance. the scoredist, maximum likelihood, and expected distance estimators can all be tuned towards a particular evolutionary model. we therefore used three evolutionary models which were also used to generate the testsets for these distance estimators, and use a shorthand to refer to these as ""method-model"". for instance, maximum likelihood using the mv model is denoted ml-mv. the jukes-cantor and kimura estimators can not be tuned to a specific model but were tested on all four datasets. the jukes-cantor and kimura correction methods are generally less accurate than scoredist and ml estimators. in some cases they reached higher accuracy than scoredist and ml trained on the ""wrong"" model. for instance, on the dayhoff testset kimura was better than scoredist-mv and ml-mv, and on the mv testset jukes-cantor was better than scoredist and ml trained on dayhoff or jtt. however, jukes-cantor and kimura never came near the scoredist and ml accuracy when trained on the ""right"" model. in a real situation, it is of course not known which evolutionary model is most appropriate. therefore, taking the average rmsd values for each training model reveals the generality and robustness of the method on different testsets. the average accuracy of scoredist is consistently better than for ml, and jukes-cantor and kimura are even further behind. implementation the scoredist estimator was implemented in belvu, which is a general-purpose multiple alignment viewer that allows basic alignment editing. belvu can calculate and display phylogenetic trees. the tree reconstruction can be based on scoredist or other common correction-based distance estimators available within belvu. multiple alignments can be coloured in belvu according to conservation using average blosum score in the column, or by residue-specific colours. user-specified cutoffs can be employed to fine-tune the display. belvu has a range of functions for sorting, colouring, marking up, and printing alignments. in figure the alignment is coloured according to conservation, and sorted according to the tree. the effect of distance correction with scoredist is illustrated. belvu can also be utilised for batch mode operations on the multiple alignment, or for producing distance matrices or phylogenetic trees without graphical output. it is available for the most common unix operating systems and can be obtained from. a windows version exists but is less frequently maintained. see for instructions, and for information on the stockholm format, which is used by the pfam project. discussion our analysis was based on four different evolutionary models – dayhoff, mv, jtt and wag. we chose these because they represent the spectrum of models well. the only tuning done in the scoredist method is the estimation of the calibration factor c. this factor can be seen as a scaling factor for the logarithm base in equation that needs to be set empirically. the difference between scoredist and ml becomes particularly apparent in the mv dataset. there are several hypotheses for this behaviour. the dayhoff matrices were constructed with the limited data available at the time. given the substantial increase of research output in this field particularly during the last decade, it is not surprising that the müller-vingron model reports substantially other results than the dayhoff and jtt matrices. additionally, the calibration factor c can also be interpreted as measure for the similarity of the respective models. following this argument, jtt and dayhoff are more akin given a Δc ≈. the mv model is more distant to both jtt and dayhoff. the expected distance estimator generally overestimates distances. for instance, among dayhoff-calibrated estimators on the mv testset, expected distance is more than pam rmsd units poorer than the best method scoredist. similar values are observed for jtt calibrated estimators. generally, mv-trained estimators are prone to underestimate evolutionary distances. in combination with the ed higher distance estimation, this rather fortuitously leads to good results for ed – mv. however, the scope of this research was to identify a robust method that performs well on various data sources. an estimator which is highly sensitive to the data source or possible incorrect calibration is of less value. the best single estimator was jtt-calibrated scoredist. if the method per se is measured by averaging over all calibrations and testsets, scoredist receives, ed, and ml pam rmsd units. this highlights scoredist as the most robust estimator, with the distance between scoredist and ed being fold the difference between ed and ml. we here only present scoredist results using blosum for calculating the score σ between two sequences. in principle one could use some other score matrix, but we found that this had little effect on the results. since the goal was to make a general-purpose method, blosum was an obvious choice. the key to scoredist is the usage of scores rather than identities, and the choice of somewhat arbitrary parameters is not of primary concern. at present, gaps in the alignments are not included in the scoredist calculation. traditionally, gaps have been difficult to embody in evolutionary models. in the models used here, they are at best crudely modelled by treating every gap equally. an inherent problem is that the probabilities for insertions and deletions are not necessarily synchronized with the substitution probabilities. some protein families are more prone to indels than others, hence it is hard to make a generalizable model that suits all protein types. we have experimented with affine gap penalties in the scoredist method, but this resulted in decreased accuracy. we therefore do not recommend using gaps to estimate protein distances.  we have developed the score matrix based distance estimator scoredist for aligned protein sequences. its main advantages are computational simplicity and high robustness. most other distance estimators produce good results for certain evolutionary models but perform poorly on others. the maximum likelihood and expected distance were found to overfit their estimates to the evolutionary model so much that the results on testsets generated with other models suffered heavily. the correction-based methods jukes-cantor and kimura also favoured a particular evolutionary model, but were not competitively accurate on any testset. it seems that scoredist achieved the best compromise between accuracy and generalization power. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
5,c16217ef-0bbb-4d17-bc6f-affb4607664d_flant5_gen,We present a novel correction-based distance estimator for aligned protein sequences. It uses a score matrix rather than observed differences as other correction-based methods do. This gives a better estimate of the divergence in the well-established pam measure and allows the popular blosum matrix series to be used.," estimating divergence time of protein sequences is one of the fundamental problems in bioinformatics. evolutionary distance estimates are used by many of the most commonly used phylogenetic tree reconstruction algorithms. in current research, phylogenetic trees are used for many types of subsequent analysis, e.g. orthology inference. early models for sequence evolution focussed on nucleotides. they commonly employ markov chains and assume independent evolution at every site. each of the four nucleotides is identified by one state and the substitution probability is modelled as a state transition probability from one state to another. in the most straightforward approach, the same state transition probability is assigned to every substitution. subsequent models take account of more nucleotide specific properties, e.g. transitional and transversional substitutions as well as gc content. these more advanced approaches are bound to nucleotide sequences and cannot be directly used with protein sequences. markov chain models for protein evolution differ from nucleotide approaches in their larger number of states and transitions for which parameters need to be estimated. the protein sequence jukes-cantor model assigns the same probability to each substitution and is hence a rather poor approximation. this method essentially takes the observed differences between two sequences and corrects this value to the estimated evolutionary distance using a logarithmic function. other similar methods exist that also correct observed differences, e.g. kimura's method. although they produce rather inaccurate distance estimates, correction-based distance estimators are popular because of their simplicity. more advanced protein evolution models estimate parameters from protein sequence alignments. assuming the same substitutions for closely and distantly related sequences leads to the construction of the dayhoff matrix series. following this approach, it suffices to collect data from alignments of closely related sequences to build an evolutionary model of amino acid substitution. dayhoff and co-workers introduced the term percent accepted mutation, which denotes a commonly used measure for evolutionary distance between two aligned sequences. in other words, two sequences at a distance of pam are related to each other by substitutions per position on average. as substitution is a stochastic process, some positions will experience multiple substitutions while others will experience none. it is also possible that secondary substitutions at one site will result in the original residue, making the evolutionary steps invisible. this is in essence the reason why estimating evolutionary distance is so hard – multiple substitutions cannot be observed directly. an evolutionary distance of pam corresponds roughly to 80% observed differences. the term pam is found in literature for both the matrix series given by dayhoff et al. as well as for evolutionary distance unit. in this publication we refer to the matrices as dayhoff matrices and reserve the term pam for distance units. there are two major shortcomings connected with the derivation of the dayhoff matrices. first, potential errors inherent in the experimental data will be magnified by extrapolation. additionally, it is questionable whether substitution probabilities observed on closely related sequences can accurately reflect the evolution of more distantly related sequences. the efforts of researchers since the publication of the dayhoff matrices have led to several other matrix series, sharing the idea of an underlying markov chain. they differ in terms of the data they are built upon and account for the above-mentioned shortcomings in various ways. the approach behind the blosum matrices is different from dayhoff's evolutionary model. whereas the markov model assumes that any transition probability matrix may be derived from another matrix in the same series, the blosum matrices do not imply any evolutionary time. there is no direct mathematical relationship between matrices in the blosum series. sequences with identities above a given identity cutoff are clustered and used to derive score matrices. the blosum matrices are known as a good general-purpose choice. especially, blosum is frequently chosen for the alignment of sequences.  we here introduce scoredist, a novel correction-based distance estimator for protein sequences. it applies a correction function to an observed reduction in normalised score, rather than to observed differences as other correction-based methods. this gives a better estimate of the divergence in the well-established pam measure and allows the popular blosum matrix series to be used. other matrices could in principle be used, but the blosum matrix has proved to be the most universal. scoredist distance estimates are calculated directly by a simple equation and do not require cumbersome computational approximations, which is needed for e.g. maximum likelihood and expected distance estimates. additional calibration opens the possibility to make scoredist tuned to other evolutionary models. in order to evaluate our novel protein distance estimator scoredist against other estimators, we generated a large testset of artificial sequence alignments. simulation is the only way to exactly know an alignment's evolutionary distance. the substitutions were made by rose according to an evolutionary model that can be chosen arbitrarily. it is to be expected that a distance estimator based on a particular evolutionary model will perform optimally on a testset generated with the same model. we therefore generated testsets using four different matrix series: dayhoff, mv, jtt, and wag. for each model, alignments were created for evolutionary distances between and pam units, i.e. alignments for each distance. the scoredist, maximum likelihood, and expected distance estimators can all be tuned towards a particular evolutionary model. we therefore used three evolutionary models which were also used to generate the testsets for these distance estimators, and use a shorthand to refer to these as ""method-model"". for instance, maximum likelihood using the mv model is denoted ml-mv. the jukes-cantor and kimura estimators can not be tuned to a specific model but were tested on all four datasets. the jukes-cantor and kimura correction methods are generally less accurate than scoredist and ml estimators. in some cases they reached higher accuracy than scoredist and ml trained on the ""wrong"" model. for instance, on the dayhoff testset kimura was better than scoredist-mv and ml-mv, and on the mv testset jukes-cantor was better than scoredist and ml trained on dayhoff or jtt. however, jukes-cantor and kimura never came near the scoredist and ml accuracy when trained on the ""right"" model. in a real situation, it is of course not known which evolutionary model is most appropriate. therefore, taking the average rmsd values for each training model reveals the generality and robustness of the method on different testsets. the average accuracy of scoredist is consistently better than for ml, and jukes-cantor and kimura are even further behind. implementation the scoredist estimator was implemented in belvu, which is a general-purpose multiple alignment viewer that allows basic alignment editing. belvu can calculate and display phylogenetic trees. the tree reconstruction can be based on scoredist or other common correction-based distance estimators available within belvu. multiple alignments can be coloured in belvu according to conservation using average blosum score in the column, or by residue-specific colours. user-specified cutoffs can be employed to fine-tune the display. belvu has a range of functions for sorting, colouring, marking up, and printing alignments. in figure the alignment is coloured according to conservation, and sorted according to the tree. the effect of distance correction with scoredist is illustrated. belvu can also be utilised for batch mode operations on the multiple alignment, or for producing distance matrices or phylogenetic trees without graphical output. it is available for the most common unix operating systems and can be obtained from. a windows version exists but is less frequently maintained. see for instructions, and for information on the stockholm format, which is used by the pfam project. discussion our analysis was based on four different evolutionary models – dayhoff, mv, jtt and wag. we chose these because they represent the spectrum of models well. the only tuning done in the scoredist method is the estimation of the calibration factor c. this factor can be seen as a scaling factor for the logarithm base in equation that needs to be set empirically. the difference between scoredist and ml becomes particularly apparent in the mv dataset. there are several hypotheses for this behaviour. the dayhoff matrices were constructed with the limited data available at the time. given the substantial increase of research output in this field particularly during the last decade, it is not surprising that the müller-vingron model reports substantially other results than the dayhoff and jtt matrices. additionally, the calibration factor c can also be interpreted as measure for the similarity of the respective models. following this argument, jtt and dayhoff are more akin given a Δc ≈. the mv model is more distant to both jtt and dayhoff. the expected distance estimator generally overestimates distances. for instance, among dayhoff-calibrated estimators on the mv testset, expected distance is more than pam rmsd units poorer than the best method scoredist. similar values are observed for jtt calibrated estimators. generally, mv-trained estimators are prone to underestimate evolutionary distances. in combination with the ed higher distance estimation, this rather fortuitously leads to good results for ed – mv. however, the scope of this research was to identify a robust method that performs well on various data sources. an estimator which is highly sensitive to the data source or possible incorrect calibration is of less value. the best single estimator was jtt-calibrated scoredist. if the method per se is measured by averaging over all calibrations and testsets, scoredist receives, ed, and ml pam rmsd units. this highlights scoredist as the most robust estimator, with the distance between scoredist and ed being fold the difference between ed and ml. we here only present scoredist results using blosum for calculating the score σ between two sequences. in principle one could use some other score matrix, but we found that this had little effect on the results. since the goal was to make a general-purpose method, blosum was an obvious choice. the key to scoredist is the usage of scores rather than identities, and the choice of somewhat arbitrary parameters is not of primary concern. at present, gaps in the alignments are not included in the scoredist calculation. traditionally, gaps have been difficult to embody in evolutionary models. in the models used here, they are at best crudely modelled by treating every gap equally. an inherent problem is that the probabilities for insertions and deletions are not necessarily synchronized with the substitution probabilities. some protein families are more prone to indels than others, hence it is hard to make a generalizable model that suits all protein types. we have experimented with affine gap penalties in the scoredist method, but this resulted in decreased accuracy. we therefore do not recommend using gaps to estimate protein distances.  we have developed the score matrix based distance estimator scoredist for aligned protein sequences. its main advantages are computational simplicity and high robustness. most other distance estimators produce good results for certain evolutionary models but perform poorly on others. the maximum likelihood and expected distance were found to overfit their estimates to the evolutionary model so much that the results on testsets generated with other models suffered heavily. the correction-based methods jukes-cantor and kimura also favoured a particular evolutionary model, but were not competitively accurate on any testset. it seems that scoredist achieved the best compromise between accuracy and generalization power. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
6,2b69de95-f83c-4508-8242-2f9a6b1f393a_gpt3_gen,"Phage display libraries are used for antibody screening and production. The study focuses on high resolution melt curve analysis (HRMA) to visualize clonal diversity and the enrichment of clones after vhh-selection from a llama non-immune phage display library. HRMA is a better method than traditional fingerprinting as it is more efficient in determining clonal similarity, simpler, and requires only PCR, a DNA dye, and melting instrumentation. HRMA is suitable for a wide variety of applications, including determining methylation status of genomic regions and clone diversity in a single-chain fv phage library."," phage display libraries consist of small antibody fragments cloned into a display phage vector, allowing efficient antibody screening and production in a bacterial system. traditional antibodies are composed of a heavy- and a light-chain that need to recombine in a tetramer for the formation of a functional antibody. because most of these random recombinations will yield non-functional antibodies, when produced as recombinant fragments in e. coli, isolation of effective antibodies demands extremely large phage libraries. camelidae have, next to conventional antibodies, dimeric heavy chain antibodies that lack light chains. the variable domain of the hcab has a single binding domain with a specificity and affinity similar to conventional antibodies. in a phage display library, each phage displays a different antigen-binding domain on its surface. to isolate specific antibodies, phage particles from a library are bound to an antigen, recovered and used to infect fresh bacteria. subsequently, phages go through several rounds of epitope binding and re-infection resulting in an enrichment of binding phages. a perfect experiment will ultimately yield groups of phages, each encoding a different antibody directed against the starting antigen. the set of phages can be used together as'polyclonal phages', individual phages as'monoclonal phages'. after selection, individual vhh clones are characterized to determine their specificity by elisa and their diversity by fingerprinting/sequencing. although ultimate identification is done using clone-insert nucleotide sequencing, pre-sequence fingerprinting is performed to reduce cost. phage display clones are usually analysed using restriction digestion of pcr amplified vhh insert, followed by agarose gel-electrophoresis. however, this methodology is time consuming, labour intensive, has limited resolution and is not effective for the analysis of a large number of clones. in the current study, we developed a protocol using high resolution melt curve analysis to visualise clonal diversity and study enrichment of clones after vhh-selection from a llama non-immune phage display library. unlike the traditional application for melt curve analysis, where base pair differences are detected through a change in melt temperature of a fully base-paired hybrid and mismatched hybrids, the current study uses differences in melt curve shape and the tm of each melt curve to identify template nucleotide sequence similarities within a large group of unlike pcr fragments. similar melt curve shapes represent similar dna sequences and melt curves can be automatically and efficiently grouped using the available hrma software.  after two rounds of selection against an epitope spanning the first amino acids of the huntingtin protein, phages were picked and elisa showed positive and negative wells. an optical density of or higher was considered a positive result while the negative control was less than. clone diversity was investigated using both hrma and hinfi restriction digestion of pcr-amplified clone inserts. as expected, since the pcr fragments had an average size of bp, hrma showed a wide range of melt profiles often containing multiple melting domains per fragment representing differences in nucleotide sequence. representative results from independent hrma analyses are shown in figure a comparison of the elisa and hrma results are shown in figure only the elisa-positive clones are represented in this figure. there was a complete agreement of elisa-positive and elisa-negative clones with hrma analysis. the elisa-positive clones belonged to different groups, the largest group contained clones, one group clones, one group clones, and groups contained a unique clone. of the remaining clones that showed a negative elisa, clones could not be analysed by hrma because of a low pcr yield and/or low quality melting. the remaining clones could be grouped into different groups, consisting of one large group of clones and three groups of and clones, respectively. the remaining groups all contained clones or less. all groups identified by restriction digestion fingerprinting were also identified by hrma. groups could overall be confirmed by nucleotide sequence analysis and pcr fragments were approximately bp in length ranging from to bp with a tm of either or 86°c and a g/c content of or 54%. the most common fragment length was bp with a tm of 86°c and a g/c content of 54%. fragments with these characteristics were present in the majority of groups assigned by the software. as can be seen in figure hrma even identified one additional group that was not seen with fingerprinting. however, as can be seen in the red hrma group in figure occasionally, elisa results and hrma results did not agree with restriction digestion results. sequencing showed that the red clone with the different digestion pattern was bp different from the other clones in this hrma group. these changes were outside the vhh encoding region and thus did not affect vhh binding characteristics. however, this bp difference did change a hinfi restriction site resulting in a different restriction pattern. discussion hrma has been used routinely for mutation scanning on patient samples with small fragments of equal size that differ only or a few nucleotides in sequence. the temperature at which the probe-template hybrid melts, distinguishes between fully base-paired hybrids from mismatched hybrids. in the current study, we developed a protocol using hrma to identify clonal origin of vhh fragments selected from a phage display library as an alternative for dna fingerprinting. the protocol uses the differences in melt curve shape and tm of each melt curve to identify template nucleotide sequence similarities within a large group of samples. although the software used for hrma was originally designed to detect bp differences between two small fragments, our results demonstrate that it is also capable of accurately analysing melt curves from longer unlike pcr fragments. hrma is a very efficient technique to obtain a quick overview and determine if clone selection was successful. from a successful selection experiment one expects several recurring clones. when all clones are different, no enrichment has taken place and clone selection has probably failed, when all clones are identical, the success is probably also doubtful. when the elisa negative clones contain a large recurrent set, these clones might either be well-growing but have low-affinity/are non-specific or high affinity clones that somehow fail to produce enough vhh in order to obtain a positive elisa signal. hrma is also suitable to follow clone selection; initially one expects all clones to be different, with larger clone sets emerging in later rounds of selection. when comparing hrma to digestion analysis of the vhh fragments, hrma analysis is a more sensitive and efficient method to determine clonal similarity. all groups identified with restriction digestion fingerprinting could also be identified by hrma and were overall confirmed by sequence analysis. it is a simple and rapid method taking only two and a half hours to complete after pcr amplification. furthermore, it is inexpensive, requiring only pcr, a dna dye, and melting instrumentation. in the current study we have used the lightcycler for the final pcr amplification and melt curve analysis, however, any block cycler can be used for amplification and the subsequent melt analysis could then be performed with other high-resolution melting devices such as the lightscanner. multiple samples can be analysed simultaneously and groups can be assigned in an automated manner.  hrma is very efficient to obtain a quick overview and determine if clone selection was successful. similar groups of clones identified by restriction digestion fingerprinting were also identified by hrma and were confirmed by nucleotide sequence analysis. hrma is suitable for a wide variety of applications where verification and/or analysis of clonal diversity is essential, including determining clone diversity in a single-chain fv phage library, analysis of clones obtained after in vitro mutagenesis, cdna clones to determine allelic expression and clones to determine methylation status of genomic regions. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
7,2b69de95-f83c-4508-8242-2f9a6b1f393a_flant5_gen,High resolution melt curve analysis (hrma) is a simple and efficient method to identify clonal origin of vhh fragments selected from a phage display library as an alternative for dna fingerprinting.," phage display libraries consist of small antibody fragments cloned into a display phage vector, allowing efficient antibody screening and production in a bacterial system. traditional antibodies are composed of a heavy- and a light-chain that need to recombine in a tetramer for the formation of a functional antibody. because most of these random recombinations will yield non-functional antibodies, when produced as recombinant fragments in e. coli, isolation of effective antibodies demands extremely large phage libraries. camelidae have, next to conventional antibodies, dimeric heavy chain antibodies that lack light chains. the variable domain of the hcab has a single binding domain with a specificity and affinity similar to conventional antibodies. in a phage display library, each phage displays a different antigen-binding domain on its surface. to isolate specific antibodies, phage particles from a library are bound to an antigen, recovered and used to infect fresh bacteria. subsequently, phages go through several rounds of epitope binding and re-infection resulting in an enrichment of binding phages. a perfect experiment will ultimately yield groups of phages, each encoding a different antibody directed against the starting antigen. the set of phages can be used together as'polyclonal phages', individual phages as'monoclonal phages'. after selection, individual vhh clones are characterized to determine their specificity by elisa and their diversity by fingerprinting/sequencing. although ultimate identification is done using clone-insert nucleotide sequencing, pre-sequence fingerprinting is performed to reduce cost. phage display clones are usually analysed using restriction digestion of pcr amplified vhh insert, followed by agarose gel-electrophoresis. however, this methodology is time consuming, labour intensive, has limited resolution and is not effective for the analysis of a large number of clones. in the current study, we developed a protocol using high resolution melt curve analysis to visualise clonal diversity and study enrichment of clones after vhh-selection from a llama non-immune phage display library. unlike the traditional application for melt curve analysis, where base pair differences are detected through a change in melt temperature of a fully base-paired hybrid and mismatched hybrids, the current study uses differences in melt curve shape and the tm of each melt curve to identify template nucleotide sequence similarities within a large group of unlike pcr fragments. similar melt curve shapes represent similar dna sequences and melt curves can be automatically and efficiently grouped using the available hrma software.  after two rounds of selection against an epitope spanning the first amino acids of the huntingtin protein, phages were picked and elisa showed positive and negative wells. an optical density of or higher was considered a positive result while the negative control was less than. clone diversity was investigated using both hrma and hinfi restriction digestion of pcr-amplified clone inserts. as expected, since the pcr fragments had an average size of bp, hrma showed a wide range of melt profiles often containing multiple melting domains per fragment representing differences in nucleotide sequence. representative results from independent hrma analyses are shown in figure a comparison of the elisa and hrma results are shown in figure only the elisa-positive clones are represented in this figure. there was a complete agreement of elisa-positive and elisa-negative clones with hrma analysis. the elisa-positive clones belonged to different groups, the largest group contained clones, one group clones, one group clones, and groups contained a unique clone. of the remaining clones that showed a negative elisa, clones could not be analysed by hrma because of a low pcr yield and/or low quality melting. the remaining clones could be grouped into different groups, consisting of one large group of clones and three groups of and clones, respectively. the remaining groups all contained clones or less. all groups identified by restriction digestion fingerprinting were also identified by hrma. groups could overall be confirmed by nucleotide sequence analysis and pcr fragments were approximately bp in length ranging from to bp with a tm of either or 86°c and a g/c content of or 54%. the most common fragment length was bp with a tm of 86°c and a g/c content of 54%. fragments with these characteristics were present in the majority of groups assigned by the software. as can be seen in figure hrma even identified one additional group that was not seen with fingerprinting. however, as can be seen in the red hrma group in figure occasionally, elisa results and hrma results did not agree with restriction digestion results. sequencing showed that the red clone with the different digestion pattern was bp different from the other clones in this hrma group. these changes were outside the vhh encoding region and thus did not affect vhh binding characteristics. however, this bp difference did change a hinfi restriction site resulting in a different restriction pattern. discussion hrma has been used routinely for mutation scanning on patient samples with small fragments of equal size that differ only or a few nucleotides in sequence. the temperature at which the probe-template hybrid melts, distinguishes between fully base-paired hybrids from mismatched hybrids. in the current study, we developed a protocol using hrma to identify clonal origin of vhh fragments selected from a phage display library as an alternative for dna fingerprinting. the protocol uses the differences in melt curve shape and tm of each melt curve to identify template nucleotide sequence similarities within a large group of samples. although the software used for hrma was originally designed to detect bp differences between two small fragments, our results demonstrate that it is also capable of accurately analysing melt curves from longer unlike pcr fragments. hrma is a very efficient technique to obtain a quick overview and determine if clone selection was successful. from a successful selection experiment one expects several recurring clones. when all clones are different, no enrichment has taken place and clone selection has probably failed, when all clones are identical, the success is probably also doubtful. when the elisa negative clones contain a large recurrent set, these clones might either be well-growing but have low-affinity/are non-specific or high affinity clones that somehow fail to produce enough vhh in order to obtain a positive elisa signal. hrma is also suitable to follow clone selection; initially one expects all clones to be different, with larger clone sets emerging in later rounds of selection. when comparing hrma to digestion analysis of the vhh fragments, hrma analysis is a more sensitive and efficient method to determine clonal similarity. all groups identified with restriction digestion fingerprinting could also be identified by hrma and were overall confirmed by sequence analysis. it is a simple and rapid method taking only two and a half hours to complete after pcr amplification. furthermore, it is inexpensive, requiring only pcr, a dna dye, and melting instrumentation. in the current study we have used the lightcycler for the final pcr amplification and melt curve analysis, however, any block cycler can be used for amplification and the subsequent melt analysis could then be performed with other high-resolution melting devices such as the lightscanner. multiple samples can be analysed simultaneously and groups can be assigned in an automated manner.  hrma is very efficient to obtain a quick overview and determine if clone selection was successful. similar groups of clones identified by restriction digestion fingerprinting were also identified by hrma and were confirmed by nucleotide sequence analysis. hrma is suitable for a wide variety of applications where verification and/or analysis of clonal diversity is essential, including determining clone diversity in a single-chain fv phage library, analysis of clones obtained after in vitro mutagenesis, cdna clones to determine allelic expression and clones to determine methylation status of genomic regions. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
8,354d288f-40b5-4e23-a454-51844f568685_gpt3_gen,"The use of azole antifungal drugs in agriculture may lead to the development of cross-resistance to these drugs in human pathogenic fungi, including Aspergillus fumigatus. The study found that exposure to prochloraz, an azole commonly used in agriculture, led to the emergence of cross-resistance to medical triazoles in A. fumigatus, as well as morphological colony changes. The resistance was stable even after the removal of selective pressure, suggesting the development of a resistance mechanism. The study calls for increased surveillance and efforts to find safer compounds to use in agriculture to avoid compromising the efficacy of clinical azoles in the future."," the ubiquitous saprophytic mould aspergillus fumigatus is known to cause a spectrum of diseases in humans, including allergic syndromes, noninvasive infections, and invasive aspergillosis, a condition associated with significant morbidity and mortality.a. fumigatus is one of the human pathogenic fungi that have a natural habitat in the environment, including soil and plants. some members of the azole drug class, which includes voriconazole and posaconazole, have been shown to be effective in the treatment of invasive aspergillosis, and for a long time, azole resistance among clinical a. fumigatus isolates was considered to be an uncommon finding. however, multiazole resistance is emerging and is increasingly recognized as a cause of treatment failure. in agriculture, thousands of tons of azoles are sold annually for the purpose of plant protection, either to prevent or to control fungal growth that can cause extensive loss of crops or to ease the problem of postharvest spoilage of plants and fruits. the mechanism of action of all azoles - irrespectively of their chemical structure and variable biological properties - is based on its interference with the activity of fungal lanosterol alpha-demethylase, an enzyme encoded by cyp51a gene in a. fumigatus that is responsible for the transformation of lanosterol in ergosterol, an essential component of the fungal cytoplasmatic membrane. the inhibition of ergosterol formation results in cell membrane disorganization and impairment of fungal growth. therefore, azoles are considered fungistatic rather than fungicidal, and it is well known that a strong and persistent antimicrobial pressure can lead to the selection of resistant clones, particularly if the drug effect is static rather than microbicidal. since azoles are the mainstay treatment for both human and agricultural fungal diseases, a major concern is the predictable emergence of cross-resistance to clinical a. fumigatus isolates that is already observed in several countries, driven by the massive use of azole fungicides in agriculture, which have the same mechanism of action as those used in humans. the aim of our study was to investigate whether prochloraz, an azole extensively used in agriculture, could be associated with the development of cross-resistance to clinical azoles among a. fumigatus.  the three isolates developed a progressive increment of pcz minimal inhibitory concentrations value. in addition, a concomitant increase of the mic of vrc, pos and itraconazole was also observed. during the induction assay, mic of pcz increased times from day until day concerning the clinical azoles, cross-resistance was developed since all isolates changed from a susceptible to a resistant phenotype, according to meletiadis and colleagues. a. fumigatus isolates to prochloraz and clinical azoles a. fumigatus pcz, prochloraz; vrc, voriconazole; pos, posaconazole; itz, itraconazole; flc, fluconazole; Ø, mic after 30 days of culture in the absence of pcz. there are several studies that have characterized azole resistance in a. fumigatus, and most recently some addressed the possible cross-resistance between environmental and medical azoles. our study demonstrated the time frame between the introduction of a widely used agricultural antifungal and the emergence of cross-resistance to medical triazoles. during the induction assay, we found that besides the emergence of cross-resistance, pcz exposure caused marked morphological colony changes, both macroscopically and microscopically. macroscopic modification of the pigmentation of a. fumigatus colonies, changing from the original green colour to white was remarkable at the beginning of the assay. with the increase of mic values of pcz the colonies became scarcer, smaller and totally white. microscopic examination showed a progressive absence of conidiation: the original strain showed normal microscopic features regarding conidiation while almost white colonies showed nearly complete absence of conidiation. the totally white mycelia corresponded solely to hyphae and immature little conidiophore structures without conidia. these changes in pigmentation and in conidiation as a consequence of exposure to azoles have already been reported. varanasi and colleagues speculate that azoles may bind to a phytochrome-like regulatory molecule inhibiting the initiation and subsequent development of conidiophores in aspergillus species. such mechanism of action could also explain the different levels of inhibition displayed by other tested azoles and why echinocandins and polyenes did not show this effect. notably, such morphological changes may be responsible for laboratorial diagnostic misidentification of the fungal genus/species. the high mic values for pcz that were achieved in vitro maintained stable following removal of the selective pressure of the drug. for vrc, the mic value decreased only after 30 days of incubation without the selective pressure, changing the susceptibility phenotype from resistant to intermediate. for pos, the developed mic value also decreased but not enough to change the phenotype of resistance. regarding itz, for both lmf and lmn it was observed the complete reversibility of the resistant phenotype in the absence of pcz, ie, the mic reverted to the initial value. however, strain lmf had, since day zero, itz mic of 2 mg/l, which falls in resistant category. in all the isolates conidiation reappeared together with the typical green colour of mature colonies following the removal of pcz. since pcz was responsible for the emergence of stable resistance to itself and to very important medical triazoles in a. fumigatus, a resistance mechanism may have been developed. previous reports describe cyp51a mutation, efflux pump overexpression and/or target upregulation as the main mechanisms responsible for such resistance. a clonal expansion of isolates harbouring the tr34/l98h mutation has been reported across several countries. interestingly, besides the fact that these resistant isolates are less genetically variable than susceptible ones, no impact on fitness was observed. the phenotypic results and the stability of the developed resistance herein reported suggest the same. future studies aiming to assess the underlying molecular resistance mechanisms, not only from these induced resistant strains but also from isolates with naturally high mic values to pcz and resistant to medical azoles without previous in vitro induction, will certainly be our next step. meanwhile, our study suggests that the abuse of azole antifungals in nature may cause serious human health problems since azole-resistance and cross-resistance has the potential to further compromise the efficacy of clinical azoles in the future. furthermore, we can speculate that the exposure of clinically relevant moulds other than a. fumigatus to agricultural azoles may also be associated with the emergence of cross-resistance to clinical azoles. several compounds are being tested in order to find new antifungal alternatives, anticipating the possible loss of efficacy of clinical azoles. on the other hand, efforts should be made to find safer compounds to use in agriculture.  in order to assess the real dimension of aspergillus resistance, a susceptibility test should be performed in all isolates from patients with aspergillus infection. moreover, for patients with severe infection initial combination therapy may be considered in geographical areas with high prevalence of environmental azole resistant isolates. ultimately, surveillance studies in both clinical and in environment settings should be conducted in order to provide updated local data regarding susceptibility profiles. ",pubmed_generic,GPT 3.5,"The study found that exposure to prochloraz, an azole commonly used in agriculture, led to the emergence of cross-resistance to medical triazoles in A. fumigatus, as well as morphological colony changes.",non_factual,factual,minor,,intrinsic,,,,,
9,354d288f-40b5-4e23-a454-51844f568685_flant5_gen,"pcz, an azole extensively used in agriculture, is associated with the emergence of cross-resistance to clinical azoles among a. fumigatus isolates."," the ubiquitous saprophytic mould aspergillus fumigatus is known to cause a spectrum of diseases in humans, including allergic syndromes, noninvasive infections, and invasive aspergillosis, a condition associated with significant morbidity and mortality.a. fumigatus is one of the human pathogenic fungi that have a natural habitat in the environment, including soil and plants. some members of the azole drug class, which includes voriconazole and posaconazole, have been shown to be effective in the treatment of invasive aspergillosis, and for a long time, azole resistance among clinical a. fumigatus isolates was considered to be an uncommon finding. however, multiazole resistance is emerging and is increasingly recognized as a cause of treatment failure. in agriculture, thousands of tons of azoles are sold annually for the purpose of plant protection, either to prevent or to control fungal growth that can cause extensive loss of crops or to ease the problem of postharvest spoilage of plants and fruits. the mechanism of action of all azoles - irrespectively of their chemical structure and variable biological properties - is based on its interference with the activity of fungal lanosterol alpha-demethylase, an enzyme encoded by cyp51a gene in a. fumigatus that is responsible for the transformation of lanosterol in ergosterol, an essential component of the fungal cytoplasmatic membrane. the inhibition of ergosterol formation results in cell membrane disorganization and impairment of fungal growth. therefore, azoles are considered fungistatic rather than fungicidal, and it is well known that a strong and persistent antimicrobial pressure can lead to the selection of resistant clones, particularly if the drug effect is static rather than microbicidal. since azoles are the mainstay treatment for both human and agricultural fungal diseases, a major concern is the predictable emergence of cross-resistance to clinical a. fumigatus isolates that is already observed in several countries, driven by the massive use of azole fungicides in agriculture, which have the same mechanism of action as those used in humans. the aim of our study was to investigate whether prochloraz, an azole extensively used in agriculture, could be associated with the development of cross-resistance to clinical azoles among a. fumigatus.  the three isolates developed a progressive increment of pcz minimal inhibitory concentrations value. in addition, a concomitant increase of the mic of vrc, pos and itraconazole was also observed. during the induction assay, mic of pcz increased times from day until day concerning the clinical azoles, cross-resistance was developed since all isolates changed from a susceptible to a resistant phenotype, according to meletiadis and colleagues. a. fumigatus isolates to prochloraz and clinical azoles a. fumigatus pcz, prochloraz; vrc, voriconazole; pos, posaconazole; itz, itraconazole; flc, fluconazole; Ø, mic after 30 days of culture in the absence of pcz. there are several studies that have characterized azole resistance in a. fumigatus, and most recently some addressed the possible cross-resistance between environmental and medical azoles. our study demonstrated the time frame between the introduction of a widely used agricultural antifungal and the emergence of cross-resistance to medical triazoles. during the induction assay, we found that besides the emergence of cross-resistance, pcz exposure caused marked morphological colony changes, both macroscopically and microscopically. macroscopic modification of the pigmentation of a. fumigatus colonies, changing from the original green colour to white was remarkable at the beginning of the assay. with the increase of mic values of pcz the colonies became scarcer, smaller and totally white. microscopic examination showed a progressive absence of conidiation: the original strain showed normal microscopic features regarding conidiation while almost white colonies showed nearly complete absence of conidiation. the totally white mycelia corresponded solely to hyphae and immature little conidiophore structures without conidia. these changes in pigmentation and in conidiation as a consequence of exposure to azoles have already been reported. varanasi and colleagues speculate that azoles may bind to a phytochrome-like regulatory molecule inhibiting the initiation and subsequent development of conidiophores in aspergillus species. such mechanism of action could also explain the different levels of inhibition displayed by other tested azoles and why echinocandins and polyenes did not show this effect. notably, such morphological changes may be responsible for laboratorial diagnostic misidentification of the fungal genus/species. the high mic values for pcz that were achieved in vitro maintained stable following removal of the selective pressure of the drug. for vrc, the mic value decreased only after 30 days of incubation without the selective pressure, changing the susceptibility phenotype from resistant to intermediate. for pos, the developed mic value also decreased but not enough to change the phenotype of resistance. regarding itz, for both lmf and lmn it was observed the complete reversibility of the resistant phenotype in the absence of pcz, ie, the mic reverted to the initial value. however, strain lmf had, since day zero, itz mic of 2 mg/l, which falls in resistant category. in all the isolates conidiation reappeared together with the typical green colour of mature colonies following the removal of pcz. since pcz was responsible for the emergence of stable resistance to itself and to very important medical triazoles in a. fumigatus, a resistance mechanism may have been developed. previous reports describe cyp51a mutation, efflux pump overexpression and/or target upregulation as the main mechanisms responsible for such resistance. a clonal expansion of isolates harbouring the tr34/l98h mutation has been reported across several countries. interestingly, besides the fact that these resistant isolates are less genetically variable than susceptible ones, no impact on fitness was observed. the phenotypic results and the stability of the developed resistance herein reported suggest the same. future studies aiming to assess the underlying molecular resistance mechanisms, not only from these induced resistant strains but also from isolates with naturally high mic values to pcz and resistant to medical azoles without previous in vitro induction, will certainly be our next step. meanwhile, our study suggests that the abuse of azole antifungals in nature may cause serious human health problems since azole-resistance and cross-resistance has the potential to further compromise the efficacy of clinical azoles in the future. furthermore, we can speculate that the exposure of clinically relevant moulds other than a. fumigatus to agricultural azoles may also be associated with the emergence of cross-resistance to clinical azoles. several compounds are being tested in order to find new antifungal alternatives, anticipating the possible loss of efficacy of clinical azoles. on the other hand, efforts should be made to find safer compounds to use in agriculture.  in order to assess the real dimension of aspergillus resistance, a susceptibility test should be performed in all isolates from patients with aspergillus infection. moreover, for patients with severe infection initial combination therapy may be considered in geographical areas with high prevalence of environmental azole resistant isolates. ultimately, surveillance studies in both clinical and in environment settings should be conducted in order to provide updated local data regarding susceptibility profiles. ",pubmed_generic,Flan T5,"pcz, an azole extensively used in agriculture, is associated with the emergence of cross-resistance to clinical azoles among a. fumigatus isolates.",non_factual,factual,minor,,intrinsic,,,,,
10,fb4bae9d-538b-4327-9584-4c04144198d1_gpt3_gen,"Feline herpesvirus is a common virus in cats that can cause respiratory and ocular diseases, including loss of sight. Vaccinations can reduce symptoms, but severe disease can still occur in young kittens without immunity. Antiviral drugs have been tested for their effectiveness in reducing plaque numbers, and the acyclic nucleoside phosphonate -9-adenine appears to be the most efficient. Additionally, these drugs can reduce the size of herpesvirus-induced plaques, which could potentially limit lesions in vivo. A comparative study of six antiviral drugs found that ganciclovir, pmedap, and cidofovir were the most potent inhibitors of feline herpesvirus replication in CRFK cells, making them potential candidates for treating infections in cats. Safety studies are necessary to determine the drugs' effects in live cats."," feline herpesvirus, an alphaherpesvirus, is one of the most common viruses among cats. infection is associated with respiratory disorders and ocular disease, including keratitis, conjunctivitis, corneal sequestration, keratoconjunctivitis and, ultimately, loss of sight. the severity of clinical symptoms induced by fhv- infection can be reduced by vaccination. however, especially in young kittens that have not yet reached the age of vaccination, but already lost maternal immunity, severe disease may still occur. once these kittens have developed lesions, recurrent disease and virus excretion may occur upon reactivation at later age. in order to control disease in these cases, treatment with an effective antiviral drug would be helpful. several antiviral drugs have already been tested for their efficacy to inhibit fhv- replication by means of a classical plaque number reduction assay. based on the ic or concentration needed to reduce plaque number with %, especially the acyclic nucleoside phosphonate -9-adenine seems very efficient. also, the anp cidofovir as well as the nucleoside analogues ganciclovir, penciclovir, idoxuridine, trifluridine and vidarabine are efficient in reducing the number of fhv-1-induced plaques in vitro. acyclovir and foscarnet, although of proven value against human herpesviruses, have low efficacy against the formation of plaques by fhv-. besides by reducing the number of plaques, as described above, antiviral agents may also exert an effect by reducing the size of herpesvirus-induced plaques. reduction in plaque size may be a potential parameter for the ability of an antiviral agent to restrict the size of macroscopic lesions in vivo. up till now, no studies have addressed the efficacy of antiviral agents to limit the size of fhv-1-induced plaques. the aim of the present study was to compare the efficacy of six antiviral drugs against fhv- in vitro. parameters used to measure efficacy were the ability to limit fhv-1-induced plaque number ) as well as plaque size ) in crandell-rees feline kidney cells.  effect of the antiviral drugs on plaque number no significant variation in plaque number was observed between fhv-1-inoculated cells incubated with various concentrations of roswell park memorial institute - medium and the untreated control. effect of the antiviral drugs on plaque size it is known that marked differences may occur in plaque size when fhv- is grown in vitro. therefore, data obtained in the plaque size assay were subjected to an f-test to examine whether the variation in plaque size between samples was significantly different from the variation in plaque size within a sample. or, in other words, the f-test was used to answer the question whether variation in plaque size was merely an artefact or whether it was related to the use of antiviral drugs. it was found that all antiviral drugs exhibited a significant effect on plaque size. using a post-hoc lsd-test it was demonstrated that the reduction in plaque size was significant for all drugs at all concentrations when compared with the untreated control. the variation in plaque size observed in fhv-1-inoculated cells incubated with various concentrations of rpmi was not significantly different from the variation in plaque size observed in the untreated control. effect of the antiviral drugs on the viability of crfk cells it was found that when crfk cells were cultivated in the presence of 2% rpmi or more, that the relative viability of the cells was significantly lower in comparison with untreated crfk cells incubated with complete medium. in order to determine whether the antiviral products exerted a cytotoxic effect we, therefore, compared the mean relative viability of crfk cells incubated with antiviral products with the mean relative viability of crfk cells incubated with the corresponding concentration of rpmi. acyclovir exerted no significant effect on the viability of crfk cells up till a concentration of μg/ml, ganciclovir up till a concentration of μg/ml, cidofovir up till a concentration of μg/ml, foscarnet up till a concentration of μg/ml, adefovir up till a concentration of μg/ml and pmedap up till a concentration of μg/ml. these concentrations amply exceeded the ic and the ic for all drugs, demonstrating that none of the products were toxic for crfk cells at antiviral concentrations. discussion over the years, an impressive array of antiviral agents has been developed for the treatment of human herpesvirus infections. many of these agents have already been studied for their efficacy against fhv-. in the present study the efficacy of a selection of six antiviral drugs against fhv- was compared in crfk cells using two different parameters, i.e. reduction in plaque number and reduction in plaque size. our study demonstrates that the efficacy of the drugs to reduce the number of plaques can be ranked as follows: ganciclovir → pmedap → cidofovir → adefovir → foscarnet → acyclovir. the results for ganciclovir and cidofovir are similar to those obtained by maggs and clarke, who compared the ability of four antiviral drugs to reduce the number of plaques in crfk cells. they found an ic of μm for ganciclovir and of μm for cidovir. concerning the activity of foscarnet and acyclovir, our results are slightly different from those obtained by maggs and clarke. the latter authors found a lower activity for foscarnet μm or relative antiviral efficacy ) and a higher activity for acyclovir μm or relative antiviral efficacy ). also, other authors obtained variable results on the activity of acyclovir against fhv- with ic values ranging from to μm. a potential explanation for the observed variation may be related to the virus strain. indeed, in a comparative study of nasisse et al., the ic for acyclovir in crfk cells varied almost 2-fold depending on the fhv- strain used. also, there may be inter-test variation involved. while both testing the activity of acyclovir against fhv- strain on crfk cells, nasisse et al. reported a markedly higher ic than maggs and clarke. antiviral agents not only reduce the number of herpesvirus-induced plaques, they also contribute in the reduction of plaque size. our study is the first that addressed the ability of antiviral agents to reduce the size of fhv-1-induced plaques. ranking the drugs following their relative ability to reduce plaque size resulted in cidofovir → ganciclovir → pmedap → adefovir → foscarnet → acyclovir, which is an almost exactly equivalent ranking as that for plaque number data. the latter demonstrates that measuring plaque size is a useful and complementary means of assessing antiviral efficacy. interestingly, for all six drugs it was found that the concentration needed to reduce plaque size was notably lower than that needed to reduce plaque number. the most remarkable effect was observed for cidofovir. its ic was 30-times lower than its ic. for ganciclovir, the ic was 8-times lower. for the other four drugs, a to 5-times lower concentration was required to reduce plaque size with 50% when compared with the ic. the relevance of this finding in view of protection of cats against fhv-1-induced disease remains to be determined. however, as already speculated by mikloska and cunningham, reduction of plaque size in vitro may be a potential parameter for the ability of an antiviral agent to restrict the size of virus-induced lesions in vivo. the ability of adefovir to inhibit fhv- replication was found to differ markedly from pmedap. this seems rather surprising since both drugs, which belong to the class of acyclic nucleoside phosphonates, are closely related and share a similar antiviral mechanism that relies on the inhibition of viral dna polymerase by the corresponding active diphosphate derivatives. a possible explanation could be a difference in uptake of the drugs by crfk cells. however, kramata and downey found that cellular uptake did not significantly differ between adefovir and pmedap in a human t-lymphoblastoid cell line ccrf-cem. alternatively, viral dna polymerase may have a higher sensitivity for the pmedap diphosphate derivatives than for adefovir diphosphate derivatives, similar as described for cellular dna polymerase. also, there may be a variation in intracellular stability of each drug metabolite as observed for other antiviral drugs. it seems unlikely that the efficiency of phosphorylation by cellular enzymes and, consequently, the amounts of the active diphosphates differ. for both drugs, phosphorylation is catalyzed by mitochondrial and cytosolic isoenzymes of amp kinase. none of the products were toxic for crfk cells at antiviral concentrations. however, the results of the cytotoxicity assay cannot simply be extrapolated to the cat itself, as sensitivity of host cells to a certain drug may differ from those of a continuous cell line. for example, while we were unable to detect a significant effect of cidofovir on the viability of crfk cells up to a concentration of μg/ml, sandmeyer and colleagues reported cytotoxic effects at a concentration of μg/ml in a primary cell culture of feline corneal epithelial cells. also, adefovir exerted no cytotoxic effects in our in vitro study, but when applied in cats for the treatment of feline infectious peritonitis virus or feline leukaemia virus, severe haematological side effects were observed. this highlights the need for extensive safety studies in the cat.  from our study, it can be concluded that measuring reduction in plaque number and plaque size are two valuable and complementary means of assessing the efficacy of an antiviral drug. by using these parameters for six selected antiviral drugs, we found that ganciclovir, pmedap, and cidofovir are most potent inhibitors of fhv- replication in crfk cells. therefore, they may be valuable candidates for the treatment of fhv- infection in cats. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
11,fb4bae9d-538b-4327-9584-4c04144198d1_flant5_gen,Efficacy of antiviral drugs against feline herpesvirus in vitro.," feline herpesvirus, an alphaherpesvirus, is one of the most common viruses among cats. infection is associated with respiratory disorders and ocular disease, including keratitis, conjunctivitis, corneal sequestration, keratoconjunctivitis and, ultimately, loss of sight. the severity of clinical symptoms induced by fhv- infection can be reduced by vaccination. however, especially in young kittens that have not yet reached the age of vaccination, but already lost maternal immunity, severe disease may still occur. once these kittens have developed lesions, recurrent disease and virus excretion may occur upon reactivation at later age. in order to control disease in these cases, treatment with an effective antiviral drug would be helpful. several antiviral drugs have already been tested for their efficacy to inhibit fhv- replication by means of a classical plaque number reduction assay. based on the ic or concentration needed to reduce plaque number with %, especially the acyclic nucleoside phosphonate -9-adenine seems very efficient. also, the anp cidofovir as well as the nucleoside analogues ganciclovir, penciclovir, idoxuridine, trifluridine and vidarabine are efficient in reducing the number of fhv-1-induced plaques in vitro. acyclovir and foscarnet, although of proven value against human herpesviruses, have low efficacy against the formation of plaques by fhv-. besides by reducing the number of plaques, as described above, antiviral agents may also exert an effect by reducing the size of herpesvirus-induced plaques. reduction in plaque size may be a potential parameter for the ability of an antiviral agent to restrict the size of macroscopic lesions in vivo. up till now, no studies have addressed the efficacy of antiviral agents to limit the size of fhv-1-induced plaques. the aim of the present study was to compare the efficacy of six antiviral drugs against fhv- in vitro. parameters used to measure efficacy were the ability to limit fhv-1-induced plaque number ) as well as plaque size ) in crandell-rees feline kidney cells.  effect of the antiviral drugs on plaque number no significant variation in plaque number was observed between fhv-1-inoculated cells incubated with various concentrations of roswell park memorial institute - medium and the untreated control. effect of the antiviral drugs on plaque size it is known that marked differences may occur in plaque size when fhv- is grown in vitro. therefore, data obtained in the plaque size assay were subjected to an f-test to examine whether the variation in plaque size between samples was significantly different from the variation in plaque size within a sample. or, in other words, the f-test was used to answer the question whether variation in plaque size was merely an artefact or whether it was related to the use of antiviral drugs. it was found that all antiviral drugs exhibited a significant effect on plaque size. using a post-hoc lsd-test it was demonstrated that the reduction in plaque size was significant for all drugs at all concentrations when compared with the untreated control. the variation in plaque size observed in fhv-1-inoculated cells incubated with various concentrations of rpmi was not significantly different from the variation in plaque size observed in the untreated control. effect of the antiviral drugs on the viability of crfk cells it was found that when crfk cells were cultivated in the presence of 2% rpmi or more, that the relative viability of the cells was significantly lower in comparison with untreated crfk cells incubated with complete medium. in order to determine whether the antiviral products exerted a cytotoxic effect we, therefore, compared the mean relative viability of crfk cells incubated with antiviral products with the mean relative viability of crfk cells incubated with the corresponding concentration of rpmi. acyclovir exerted no significant effect on the viability of crfk cells up till a concentration of μg/ml, ganciclovir up till a concentration of μg/ml, cidofovir up till a concentration of μg/ml, foscarnet up till a concentration of μg/ml, adefovir up till a concentration of μg/ml and pmedap up till a concentration of μg/ml. these concentrations amply exceeded the ic and the ic for all drugs, demonstrating that none of the products were toxic for crfk cells at antiviral concentrations. discussion over the years, an impressive array of antiviral agents has been developed for the treatment of human herpesvirus infections. many of these agents have already been studied for their efficacy against fhv-. in the present study the efficacy of a selection of six antiviral drugs against fhv- was compared in crfk cells using two different parameters, i.e. reduction in plaque number and reduction in plaque size. our study demonstrates that the efficacy of the drugs to reduce the number of plaques can be ranked as follows: ganciclovir → pmedap → cidofovir → adefovir → foscarnet → acyclovir. the results for ganciclovir and cidofovir are similar to those obtained by maggs and clarke, who compared the ability of four antiviral drugs to reduce the number of plaques in crfk cells. they found an ic of μm for ganciclovir and of μm for cidovir. concerning the activity of foscarnet and acyclovir, our results are slightly different from those obtained by maggs and clarke. the latter authors found a lower activity for foscarnet μm or relative antiviral efficacy ) and a higher activity for acyclovir μm or relative antiviral efficacy ). also, other authors obtained variable results on the activity of acyclovir against fhv- with ic values ranging from to μm. a potential explanation for the observed variation may be related to the virus strain. indeed, in a comparative study of nasisse et al., the ic for acyclovir in crfk cells varied almost 2-fold depending on the fhv- strain used. also, there may be inter-test variation involved. while both testing the activity of acyclovir against fhv- strain on crfk cells, nasisse et al. reported a markedly higher ic than maggs and clarke. antiviral agents not only reduce the number of herpesvirus-induced plaques, they also contribute in the reduction of plaque size. our study is the first that addressed the ability of antiviral agents to reduce the size of fhv-1-induced plaques. ranking the drugs following their relative ability to reduce plaque size resulted in cidofovir → ganciclovir → pmedap → adefovir → foscarnet → acyclovir, which is an almost exactly equivalent ranking as that for plaque number data. the latter demonstrates that measuring plaque size is a useful and complementary means of assessing antiviral efficacy. interestingly, for all six drugs it was found that the concentration needed to reduce plaque size was notably lower than that needed to reduce plaque number. the most remarkable effect was observed for cidofovir. its ic was 30-times lower than its ic. for ganciclovir, the ic was 8-times lower. for the other four drugs, a to 5-times lower concentration was required to reduce plaque size with 50% when compared with the ic. the relevance of this finding in view of protection of cats against fhv-1-induced disease remains to be determined. however, as already speculated by mikloska and cunningham, reduction of plaque size in vitro may be a potential parameter for the ability of an antiviral agent to restrict the size of virus-induced lesions in vivo. the ability of adefovir to inhibit fhv- replication was found to differ markedly from pmedap. this seems rather surprising since both drugs, which belong to the class of acyclic nucleoside phosphonates, are closely related and share a similar antiviral mechanism that relies on the inhibition of viral dna polymerase by the corresponding active diphosphate derivatives. a possible explanation could be a difference in uptake of the drugs by crfk cells. however, kramata and downey found that cellular uptake did not significantly differ between adefovir and pmedap in a human t-lymphoblastoid cell line ccrf-cem. alternatively, viral dna polymerase may have a higher sensitivity for the pmedap diphosphate derivatives than for adefovir diphosphate derivatives, similar as described for cellular dna polymerase. also, there may be a variation in intracellular stability of each drug metabolite as observed for other antiviral drugs. it seems unlikely that the efficiency of phosphorylation by cellular enzymes and, consequently, the amounts of the active diphosphates differ. for both drugs, phosphorylation is catalyzed by mitochondrial and cytosolic isoenzymes of amp kinase. none of the products were toxic for crfk cells at antiviral concentrations. however, the results of the cytotoxicity assay cannot simply be extrapolated to the cat itself, as sensitivity of host cells to a certain drug may differ from those of a continuous cell line. for example, while we were unable to detect a significant effect of cidofovir on the viability of crfk cells up to a concentration of μg/ml, sandmeyer and colleagues reported cytotoxic effects at a concentration of μg/ml in a primary cell culture of feline corneal epithelial cells. also, adefovir exerted no cytotoxic effects in our in vitro study, but when applied in cats for the treatment of feline infectious peritonitis virus or feline leukaemia virus, severe haematological side effects were observed. this highlights the need for extensive safety studies in the cat.  from our study, it can be concluded that measuring reduction in plaque number and plaque size are two valuable and complementary means of assessing the efficacy of an antiviral drug. by using these parameters for six selected antiviral drugs, we found that ganciclovir, pmedap, and cidofovir are most potent inhibitors of fhv- replication in crfk cells. therefore, they may be valuable candidates for the treatment of fhv- infection in cats. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
12,e8522a3a-9db4-410c-9303-3405d1fc2ba3_gpt3_gen,"The article discusses the challenges of accurately classifying multiple types of cancers using gene expression profiling and proposes a new learning method called the paired-samples test algorithm (PST), which is based on the jackknife method. PST is designed for solving multi-category problems under a one-versus-rest scheme with limited training data sets and addresses potential mislabeling by predicting training samples together with the training data set. The proposed method was evaluated on two benchmark data sets and showed improved prediction accuracy, especially when t-statistics were used for primary feature selection. The study highlights the importance of assessing uncertainty in cancer type predictions and proposes a relative confidence criterion, called r, which provides insight into potential weaknesses of classifiers or heterogeneity in a given tumor type. Future work will consider combining r and the prediction probability to make a better score for type determination."," the use of gene expression profiling for the classification of human cancers has been widely investigated. previous works were successful in predicting tumor types in the context of binary problems. many algorithms for feature extraction and sample classification have been proposed. more recently, a method for addressing the potential mislabeling in the training set was proposed for binary classification of cancer samples. as there are over a hundred types of cancers, and potentially even more subtypes, it is essential to develop multi-category methodologies for molecular classification for any practical application. multi-category prediction can be achieved using binary classification algorithms via the one-versus-one and/or one-versus-rest partition of the training data set. however, in a cancer type prediction, multi-category problems proved to be more challenging than simple binary problems, and the reported results were less than satisfactory. on one hand, when the available resource is limited and the sample size of a given category is small, classifiers based on the ovr partition of the data set potentially suffer from severe over-fitting, leading to low predictive ability and robustness. furthermore, the substantial noise introduced by implementing the numerous classifiers under an ovo scheme and the asymmetric training sets caused by ovr partitioning of the data will inevitably weaken the classification system. on the other hand, the effects of biological and technical noise together with the genetic heterogeneity of samples within a clinically defined tumor class decrease the predictive power in a multiple setting. in disease diagnostic, a measurement of confidence or uncertainty reported with the type determination is always desirable. however, some well-established statistical criteria often become less credible and of little biological meaning for highly heterogeneous cancer types, especially in the context of multiple cancer types. a potential reason is that the winning classifier used to discriminate one cancer type from others could be weak or unstable due to limited training samples. although this phenomenon was alluded to in previous studies, it has not received appropriate attention. figure presents a graphical illustration of the problem. using an ovr binary classifier, all samples of a homogeneous cancer type were classified correctly and with high confidence. all other cancer type samples in the group have probabilities of being cancer type a close to zero. however, the situation was very different when a heterogeneous cancer class was considered. in fact, some samples of cancer b type had classification probability lower than. such low classification probability could lead to misdiagnosis if a hard classification rule is applied. it is possible that such low probability is due to the weakness of the classifier that is established with a highly heterogeneous training set. the jackknife is a well known, non-parametric method often used for estimating the sampling distribution of a statistic. given a sample dataset and a desired statistic, the jackknife works by computing the desired statistic with an element removed from the equation. the process is repeated for each element in the dataset. the application in cancer classification with gene expression profiling has been reported in the context of binary problems. in that study, the individual maximum difference subsets of genes identified from a set of jackknife subsets of samples were aggregated to generate the ""overall mdss"" in order to return the expected classification. in other words, jackknife was used for feature selection rather than for training multiple sub-classifiers. in this study, a new learning method called paired-samples test algorithm, which is based on the jackknife method, was used to classify multiple tumor types using gene expression data. the proposed method is designed for solving multi-category problems under an ovr scheme with a very limited training data set, and it is similar to the bootstrap aggregating procedure, which proved to be helpful in improving weak classifiers. in order to get a relative measurement of uncertainty in the prediction of a sample category, the training sample being removed each time was predicted together with the training samples. the procedure was implemented in a parsimonious way, making its integration with a computationally intensive algorithm, such as the stochastic, regulation-based binary regression, feasible. the performance of the proposed method was evaluated under several scenarios of gene selection criteria using two well known and challenging datasets: the gcm and nci datasets containing and cancer tumor types, respectively.  determination of the optimum number of genes to be used by the classification algorithm is usually a difficult task that depends on several factors, including the classification algorithms and the complexity of the data set. for the used binary regression algorithm, previous studies have shown that a feature set of one to two hundred top genes is adequate for a simple two category problem. in this study, the size of the feature set used was or genes for the gcm dataset and or genes for the nci dataset. gcm data the prediction accuracy of the validation samples, using different gene selection procedures, is summarized in figure the results showed that fold change and penalized t-statistic based methods for feature selection outperformed the t-statistic-based procedure. in most cases, the application of pst improved the prediction accuracy or maintained the high accuracies that had been obtained prior to its application, except in the scenario of genes and penalized t-statistic. the largest improvement occurred when genes were considered using different feature selection criteria, resulting in an increase in accuracy ranging from % to %. the combination of genes, fold change-based feature selection and pst had the highest prediction accuracy of %. additionally, almost 50% of the % incorrectly classified samples had their true tumor type predicted as the second possible classification in this scenario. it should be noted that while the largest improvements were seemingly coming from the weaker gene selection mechanisms, the application of pst made the binary regression algorithm more robust in relation to the gene selection methods and the size of the gene set to be used. these prediction results are, in general, better than those obtained by several previous studies using the same data set. using a recursive feature elimination procedure and a support vector machine classification algorithm, ramaswamy et al. obtained their best result with tumors correctly predicted among the test samples, corresponding to an accuracy of 78%. using a feature selection algorithm based on the overlaps of gene expression values between different classes in conjunction with the covering classification algorithm, a modification of the k-nn method, bagirov et al. achieved a prediction accuracy of around 80%. based on the concept of gene interaction, antonov et al proposed a maximal margin linear programming procedure that combines linear programming and svm. using mama, only eight test samples were misclassified. although slightly superior to our method in the overall accuracy, the lack of information about confusion profiles of the prediction and the secondary classification of non-correctly predicted samples make the direct comparison between both methods difficult. recently, sheng and tan reported a prediction accuracy of around 83% by using error correcting out codes, svm and a recursive feature elimination procedure. the output coding based approach is very costly in implementation and the result was highly sensitive to the decoding functions and the length of the random code. a in parenthesis are the assigned tumor types for the misclassified samples. it is possible that the superiority of the proposed method over svm and other learning algorithms could be related to the difference in gene selection methods used in this study and by ramaswamy et al and bagirov et al. however, our preliminary work as well as readily available information demonstrated that svm outperformed k-nn, nn, pnn and the decision tree in general does not support such a claim. in fact, the highest accuracies obtained using svm occurred when 200- genes were selected based on fc, t-statistics, penalized t-statistics and non-parametric anova, ranging from % to %. these were well below the results obtained using our approach. as indicated in table it seems that some tumor types are easily predicted. for example, ly, ut, me and csn tumors had 100% prediction accuracy using all three methods. meanwhile, other types, such as br, had a high misclassification rate ranging from to 75%, indicating potential excess heterogeneity. additionally, the profile of misclassified samples was very different between the four studies. in fact, among the four br tumors, two were misclassified as ov and pa in ramaswamy et al, three were misclassified as lu, lu and bl in bagirov et al, and three were misclassified as le, pa, and ut in the current study. to further validate the results behind the use of the independent test samples, a four-fold cross validation was conducted for the training samples. the results of this validation are presented in figure in most scenarios, the prediction accuracy was improved when the proposed jackknife method was used. the highest value was %, which was achieved from several combinations of the gene selection method and gene number, including the case of fc-based gene selection and genes. this accuracy value was similar to the best performance of % obtained using the independent test samples, and it is % higher than the accuracy obtained by ramaswamy et al.the np-anova feature selection performed marginally better in the cross validation than in the independent test with the highest prediction accuracy of %. ppp rediction uncertainty uncertainty of the correctly classified test samples from the best result is graphically presented in figure among these samples, eight tumors had high f and nearly 3/ of the tumors had their prediction confidence <. for the classification algorithm used in this study, f was defined as the aggregate probability that the test sample t belongs to the assigned tumor type. in this context, considering f alone makes the current prediction results seem unexpected. however, when taking r values into account, confidence measurement, or f, appears to be in better agreement with the results of this study. of those samples with lower prediction confidence, the majority had their r between - and, suggesting that their lower prediction confidences were mainly due to the potential weakness of the classifiers and/or some moderate heterogeneity. in addition, the profile of the four metastatic prostate samples was interesting. although they were predicted with 100% accuracy, their relative confidences were low. this suggests the metastatic tumors can be distinguished from the primary tumors of the same type by using the proposed relative confidence criterion. nci data there were no independent test samples in the nci dataset. consequently, ten-fold cross validation was conducted as in statnikov et al. the results are summarized in figure in most scenarios, the prediction accuracy ranged from % to %. the improvement due to the use of the pst algorithm was not as significant as with the gcm data. a modest improvement was observed when the number of used genes was relative small. one explanation is that, because some tumor types had a very limited number of samples available for training the classifiers, holding out one sample from the training set as is required for the implementation of pst sharpened sample shortage and weakened the trained classifiers. nevertheless, the prediction accuracy obtained was comparable to the best reported results using this dataset. according to statnikov et al., svm-based methods performed much better than k-nn, pnn and other non-svm methods with an accuracy ranging from % to %. furthermore, it was evident from our study that breast cancer samples were unpredictable. this result is consistent with ross et al, in which the br samples could not be clustered together. the reason could be that the br samples contained estrogen positive and estrogen negative subtypes.  in cancer type predictions, multi-category problems have proven to be more challenging than binary cases, not only in the classification accuracy but also in the assessment of uncertainty. in this paper, a jackknife-like classification method, called paired-samples test algorithm, was proposed and applied to two bench datasets of multiple tumor types. the results showed that the proposed method has improved the prediction accuracy of test samples in the gcm dataset, especially when t-statistics were used for primary feature selection. for the nci dataset, improvement was observed only when the number of used genes was relative small. these improvements made the binary regression algorithm more robust to gene selection and the number of genes used. the core idea of the proposed method is to repeatedly test a certain known tumor type with a blind test sample while withholding an associated training sample; in this way, not only can the prediction be made but also the relative confidence r of the prediction can be accessed by measuring the difference between the prediction probability of the test sample and the corresponding value of the withheld training sample. r provided insight into the sources of the uncertainty in the statistical classification by revealing the loss in confidence due to the utilization of weak classifiers or heterogeneity in a given tumor type. it is possible to combine the measurement f and r to make a better score for type determination. our continuous work will consider this possibility in regards to penalizing a negative r value. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
13,e8522a3a-9db4-410c-9303-3405d1fc2ba3_flant5_gen,"a jackknife-like classification method, called paired-samples test algorithm, was proposed and applied to two bench datasets of multiple tumor types. the results showed that the proposed method has improved the prediction accuracy of test samples in the gcm dataset, especially when t-statistics were used for primary feature selection. in most cases, the application of pst improved the prediction accuracy or maintained the high accuracies that had been obtained prior to its application. the combination of genes, fold change-based feature selection and pst had the highest prediction accuracy of %. additionally, almost 50% of the % incorrectly classified samples had their true tumor type predicted as the second possible classification in this scenario."," the use of gene expression profiling for the classification of human cancers has been widely investigated. previous works were successful in predicting tumor types in the context of binary problems. many algorithms for feature extraction and sample classification have been proposed. more recently, a method for addressing the potential mislabeling in the training set was proposed for binary classification of cancer samples. as there are over a hundred types of cancers, and potentially even more subtypes, it is essential to develop multi-category methodologies for molecular classification for any practical application. multi-category prediction can be achieved using binary classification algorithms via the one-versus-one and/or one-versus-rest partition of the training data set. however, in a cancer type prediction, multi-category problems proved to be more challenging than simple binary problems, and the reported results were less than satisfactory. on one hand, when the available resource is limited and the sample size of a given category is small, classifiers based on the ovr partition of the data set potentially suffer from severe over-fitting, leading to low predictive ability and robustness. furthermore, the substantial noise introduced by implementing the numerous classifiers under an ovo scheme and the asymmetric training sets caused by ovr partitioning of the data will inevitably weaken the classification system. on the other hand, the effects of biological and technical noise together with the genetic heterogeneity of samples within a clinically defined tumor class decrease the predictive power in a multiple setting. in disease diagnostic, a measurement of confidence or uncertainty reported with the type determination is always desirable. however, some well-established statistical criteria often become less credible and of little biological meaning for highly heterogeneous cancer types, especially in the context of multiple cancer types. a potential reason is that the winning classifier used to discriminate one cancer type from others could be weak or unstable due to limited training samples. although this phenomenon was alluded to in previous studies, it has not received appropriate attention. figure presents a graphical illustration of the problem. using an ovr binary classifier, all samples of a homogeneous cancer type were classified correctly and with high confidence. all other cancer type samples in the group have probabilities of being cancer type a close to zero. however, the situation was very different when a heterogeneous cancer class was considered. in fact, some samples of cancer b type had classification probability lower than. such low classification probability could lead to misdiagnosis if a hard classification rule is applied. it is possible that such low probability is due to the weakness of the classifier that is established with a highly heterogeneous training set. the jackknife is a well known, non-parametric method often used for estimating the sampling distribution of a statistic. given a sample dataset and a desired statistic, the jackknife works by computing the desired statistic with an element removed from the equation. the process is repeated for each element in the dataset. the application in cancer classification with gene expression profiling has been reported in the context of binary problems. in that study, the individual maximum difference subsets of genes identified from a set of jackknife subsets of samples were aggregated to generate the ""overall mdss"" in order to return the expected classification. in other words, jackknife was used for feature selection rather than for training multiple sub-classifiers. in this study, a new learning method called paired-samples test algorithm, which is based on the jackknife method, was used to classify multiple tumor types using gene expression data. the proposed method is designed for solving multi-category problems under an ovr scheme with a very limited training data set, and it is similar to the bootstrap aggregating procedure, which proved to be helpful in improving weak classifiers. in order to get a relative measurement of uncertainty in the prediction of a sample category, the training sample being removed each time was predicted together with the training samples. the procedure was implemented in a parsimonious way, making its integration with a computationally intensive algorithm, such as the stochastic, regulation-based binary regression, feasible. the performance of the proposed method was evaluated under several scenarios of gene selection criteria using two well known and challenging datasets: the gcm and nci datasets containing and cancer tumor types, respectively.  determination of the optimum number of genes to be used by the classification algorithm is usually a difficult task that depends on several factors, including the classification algorithms and the complexity of the data set. for the used binary regression algorithm, previous studies have shown that a feature set of one to two hundred top genes is adequate for a simple two category problem. in this study, the size of the feature set used was or genes for the gcm dataset and or genes for the nci dataset. gcm data the prediction accuracy of the validation samples, using different gene selection procedures, is summarized in figure the results showed that fold change and penalized t-statistic based methods for feature selection outperformed the t-statistic-based procedure. in most cases, the application of pst improved the prediction accuracy or maintained the high accuracies that had been obtained prior to its application, except in the scenario of genes and penalized t-statistic. the largest improvement occurred when genes were considered using different feature selection criteria, resulting in an increase in accuracy ranging from % to %. the combination of genes, fold change-based feature selection and pst had the highest prediction accuracy of %. additionally, almost 50% of the % incorrectly classified samples had their true tumor type predicted as the second possible classification in this scenario. it should be noted that while the largest improvements were seemingly coming from the weaker gene selection mechanisms, the application of pst made the binary regression algorithm more robust in relation to the gene selection methods and the size of the gene set to be used. these prediction results are, in general, better than those obtained by several previous studies using the same data set. using a recursive feature elimination procedure and a support vector machine classification algorithm, ramaswamy et al. obtained their best result with tumors correctly predicted among the test samples, corresponding to an accuracy of 78%. using a feature selection algorithm based on the overlaps of gene expression values between different classes in conjunction with the covering classification algorithm, a modification of the k-nn method, bagirov et al. achieved a prediction accuracy of around 80%. based on the concept of gene interaction, antonov et al proposed a maximal margin linear programming procedure that combines linear programming and svm. using mama, only eight test samples were misclassified. although slightly superior to our method in the overall accuracy, the lack of information about confusion profiles of the prediction and the secondary classification of non-correctly predicted samples make the direct comparison between both methods difficult. recently, sheng and tan reported a prediction accuracy of around 83% by using error correcting out codes, svm and a recursive feature elimination procedure. the output coding based approach is very costly in implementation and the result was highly sensitive to the decoding functions and the length of the random code. a in parenthesis are the assigned tumor types for the misclassified samples. it is possible that the superiority of the proposed method over svm and other learning algorithms could be related to the difference in gene selection methods used in this study and by ramaswamy et al and bagirov et al. however, our preliminary work as well as readily available information demonstrated that svm outperformed k-nn, nn, pnn and the decision tree in general does not support such a claim. in fact, the highest accuracies obtained using svm occurred when 200- genes were selected based on fc, t-statistics, penalized t-statistics and non-parametric anova, ranging from % to %. these were well below the results obtained using our approach. as indicated in table it seems that some tumor types are easily predicted. for example, ly, ut, me and csn tumors had 100% prediction accuracy using all three methods. meanwhile, other types, such as br, had a high misclassification rate ranging from to 75%, indicating potential excess heterogeneity. additionally, the profile of misclassified samples was very different between the four studies. in fact, among the four br tumors, two were misclassified as ov and pa in ramaswamy et al, three were misclassified as lu, lu and bl in bagirov et al, and three were misclassified as le, pa, and ut in the current study. to further validate the results behind the use of the independent test samples, a four-fold cross validation was conducted for the training samples. the results of this validation are presented in figure in most scenarios, the prediction accuracy was improved when the proposed jackknife method was used. the highest value was %, which was achieved from several combinations of the gene selection method and gene number, including the case of fc-based gene selection and genes. this accuracy value was similar to the best performance of % obtained using the independent test samples, and it is % higher than the accuracy obtained by ramaswamy et al.the np-anova feature selection performed marginally better in the cross validation than in the independent test with the highest prediction accuracy of %. ppp rediction uncertainty uncertainty of the correctly classified test samples from the best result is graphically presented in figure among these samples, eight tumors had high f and nearly 3/ of the tumors had their prediction confidence <. for the classification algorithm used in this study, f was defined as the aggregate probability that the test sample t belongs to the assigned tumor type. in this context, considering f alone makes the current prediction results seem unexpected. however, when taking r values into account, confidence measurement, or f, appears to be in better agreement with the results of this study. of those samples with lower prediction confidence, the majority had their r between - and, suggesting that their lower prediction confidences were mainly due to the potential weakness of the classifiers and/or some moderate heterogeneity. in addition, the profile of the four metastatic prostate samples was interesting. although they were predicted with 100% accuracy, their relative confidences were low. this suggests the metastatic tumors can be distinguished from the primary tumors of the same type by using the proposed relative confidence criterion. nci data there were no independent test samples in the nci dataset. consequently, ten-fold cross validation was conducted as in statnikov et al. the results are summarized in figure in most scenarios, the prediction accuracy ranged from % to %. the improvement due to the use of the pst algorithm was not as significant as with the gcm data. a modest improvement was observed when the number of used genes was relative small. one explanation is that, because some tumor types had a very limited number of samples available for training the classifiers, holding out one sample from the training set as is required for the implementation of pst sharpened sample shortage and weakened the trained classifiers. nevertheless, the prediction accuracy obtained was comparable to the best reported results using this dataset. according to statnikov et al., svm-based methods performed much better than k-nn, pnn and other non-svm methods with an accuracy ranging from % to %. furthermore, it was evident from our study that breast cancer samples were unpredictable. this result is consistent with ross et al, in which the br samples could not be clustered together. the reason could be that the br samples contained estrogen positive and estrogen negative subtypes.  in cancer type predictions, multi-category problems have proven to be more challenging than binary cases, not only in the classification accuracy but also in the assessment of uncertainty. in this paper, a jackknife-like classification method, called paired-samples test algorithm, was proposed and applied to two bench datasets of multiple tumor types. the results showed that the proposed method has improved the prediction accuracy of test samples in the gcm dataset, especially when t-statistics were used for primary feature selection. for the nci dataset, improvement was observed only when the number of used genes was relative small. these improvements made the binary regression algorithm more robust to gene selection and the number of genes used. the core idea of the proposed method is to repeatedly test a certain known tumor type with a blind test sample while withholding an associated training sample; in this way, not only can the prediction be made but also the relative confidence r of the prediction can be accessed by measuring the difference between the prediction probability of the test sample and the corresponding value of the withheld training sample. r provided insight into the sources of the uncertainty in the statistical classification by revealing the loss in confidence due to the utilization of weak classifiers or heterogeneity in a given tumor type. it is possible to combine the measurement f and r to make a better score for type determination. our continuous work will consider this possibility in regards to penalizing a negative r value. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
14,063cf922-6e0b-454e-a56f-4a31804cb9d4_flant5_gen,mst typing is a new pcr-sequencing-based genotyping method for the detection of cross-contamination with m. tuberculosis in the laboratory.," the isolation of mycobacterium tuberculosis complex organisms from clinical specimens collected from suspected patients serves as the gold standard for the proper diagnosis of tuberculosis in the laboratory. however, false-positive cultures have been reported that result from the cross-contamination of specimens via a contaminated bronchoscope or, more often, by laboratory cross-contamination. the latter situation has been reported at a frequency ranging from % to 3% of m. tuberculosis. laboratory cross-contamination should be suspected when m. tuberculosis is cultured from a smear-negative specimen processed in the same batch as a culture from a smear-positive specimen. the factors that increase the likelihood of cross-contamination include instances when only one of several specimens from the same patient is culture-positive and instances when the clinician is considering a diagnosis other than tuberculosis, which the clinician believes to be more likely based on clinical observations. such false-positives resulting from cross-contaminated specimens are disadvantageous since, besides resulting in a misdiagnosis, they result in unnecessary treatment and delay further diagnostic investigations in an effort to derive a definitive and correct diagnosis. finally, these false-positive cultures lead to an overestimation of the incidence and prevalence of tuberculosis in humans. a definitive demonstration of cross-contamination can be derived from precise molecular analyses of m. tuberculosis isolates. m. tuberculosis isolates harbouring identical genotypes are regarded as clones and are thus epidemiologically linked. the most widely used technique for determining the genotype of m. tuberculosis is a technique known as is6110-restriction fragment length polymorphism analysis. rflp analysis requires a large amount of biological material and, thus, poses a risk to laboratory workers due to the harmful nature of this pathogen. moreover, the latter method requires a substantial amount of time due to the fastidious nature of m. tuberculosis. more importantly from, a strictly technical perspective, is6110-rflp analysis does a poor job of indicating the presence of m. tuberculosis when these organisms contain only a few copies of the is sequence. recently, the variable number tandem repeat pcr-based technique and the mycobacterial interspersed repetitive unit technique have proven to be reliable methods for the resolution of cross-contamination events. we herein report the application of a new pcr-sequencing-based genotyping method, known as multispacer sequence typing, for determining whether specimens have been cross-contaminated with m. tuberculosis in the laboratory. case report a 60-year-old man was admitted for an examination to determine whether he had interstitial pneumonia. the patient had been previously hospitalised for two weeks at a different location with symptoms that included shortness of breath, a fever of °c, and a kg loss of weight within the past month. at the aforementioned hospital, a chest radiograph indicated the presence of bilateral interstitial pneumonia. subsequent microbiological investigations, including ziehl-neelsen staining and a pcr-based assay to test for the presence of m. tuberculosis on expectoration, indicated that there were no signs of such an infection. the patient was then transferred to our department for further evaluation. clinical examination of the patient verified both a body temperature of – °c and dyspnoea with 90% oxygen saturation under l/min oxygen. the medical history of the patient was unremarkable, except for previous treatment for arterial hypertension. the total body tomodensitometry indicated the presence of nodules in both lungs, in the mediastinal lymph nodes, and in a right axilar lymph node. the pertinent laboratory assays were performed and indicated a value of leucocytes/ml with 76% polymorphonuclear cells and platelets/ml. the erythrocyte sedimentation rate was determined to be mm for the first hour. the lactate dehydrogenase level was iu/ml, the gamma gt level was iu/ml, the bilirubin concentration was μmol/l, the ast level was iu/l, and the alt level was shown to be iu/l. it was suspected that the patient had already begun to develop pulmonary tuberculosis and thus was recommended to receive anti-tuberculosis therapy since it was reported that m. tuberculosis was isolated from an expectoration that was collected days prior during the first hospital visit. due to the observation that the patient's respiratory status had worsened, the patient was admitted into an intensive care unit for a period of four days. the results of direct microscopic examinations using gram and ziehl-neelsen staining of a surgical lung biopsy were negative. this sample, cultured in bactec and in 5% blood agar in slant tubes, remained sterile after a two-month incubation period. subsequent histological examination discovered large b-cell lymphoma and further assessments confirmed that the patient had stage iv lymphoma that involved the lung, liver, and bone marrow. the patient then received the appropriate anti-lymphoma therapy.  our investigation revealed isolation of a total of six m. tuberculosis strains from a laboratory that performed analyses for six different patients within a 2-week period before and after the isolation of m. tuberculosis from the index patient. all isolates were recovered from respiratory tract specimens and identified as m. tuberculosis by phenotypic methods and the etr-d sequencing method. isolate tub was recovered from a specimen received and handled on april 27th, while isolate tub was recovered from a specimen received on may 3rd, but handled for setting in culture on may 4th. isolate tub was recovered from a specimen received and handled on may 4th, while isolates tub tub and tub were recovered from specimens received and handled on may 8th. ziehl-neelsen staining was performed on all six specimens and the subsequent analyses revealed the presence of acid-fast bacilli for all samples with the exception of the specimen collected from index patient c, which exhibited no acid-fast bacillus. epidemiological investigation indicated that patients a, d, and e resided in the same ward, whereas no epidemiological link was found between the other three patients, including index patient c. eight intergenic spacers were pcr amplified for each of the six m. tuberculosis isolates and yielded pcr products of the expected sizes. sequences derived from these pcr products were combined and assembled for each of the six isolates. mst analysis was completed within four working days. analysis of the sequence combinations determined three new genetic profiles, including profile st which characterized the three isolates derived from patients a, d, and e; profile st which characterized the two isolates derived from patient b and the index patient c; and profile st which was discovered in the isolate derived from patient f. these new profiles resulted from a novel combination of the following spacer alleles: the st profile combined alleles 1/mst 1/mst 1/mst 2/mst 1/mst 3/mst 4/mst and allele 4/mst13; the st profile combined alleles 1/mst 1/mst 2/mst 2/mst 1/mst 3/mst 4/mst and allele 4/mst13; and the st profile combined alleles 1/mst 1/mst 1/mst 1/mst 3/mst 3/mst 4/mst and allele 4/mst the profiles for st st and st have been added to our free and accessible mst database http://ifr timone.univ-mrs.fr/mst_mtuberculosis/mst. mst genotyping data were assumed to be authentic based on the observations that the pcr-negative controls remained negative, coupled with the observation that all pcr products were of the predicted size. moreover, analysis of the spacer sequences edited in this work identified three new profiles, clearly indicating that amplicons did not result from laboratory contamination as a consequence of previous experiments. the mst genotyping data provided evidence to support epidemiological and clinical data that confirmed laboratory cross-contamination. specifically, one profile comprised three isolates recovered from epidemiologically-linked patients, whereas a different profile characterized only one isolate from a specimen collected from an unrelated patient f. the profile st was discovered for two m. tuberculosis isolates obtained from the index patient c and one unrelated patient b. microscopic examination of a respiratory tract specimen collected from patient b indicated the presence of acid-fast bacilli, while the same analysis performed for a specimen from the respiratory tract of the index patient c showed no indication of acid-fast bacilli. both of the latter two specimens were handled in the same laboratory, on the same day, and within the same batch of sample preparations, which explains the observation that the specimen recovered from the index patient was contaminated by the specimen collected from patient b. such a situation has been previously observed in cases of laboratory cross-contamination. interestingly, the frequency of false-positive cultures has been shown to be higher for laboratories that do not process high numbers of specimens, as was the case in the present report. as an example, in the laboratory setting, cross-contamination events may occur in the safety cabinet when a smear-positive specimen is handled in parallel with a smear-negative specimen, or during the phenotypic identification of isolates during the niacin test. cross-contamination of respiratory tract specimens by the avirulent m. tuberculosis h37ra reference strain has also been reported. the mst method, which was used in this study in addition to the more commonly used vntr/miru typing method, requires a relatively small amount of sample dna from the patient. in contrast to the conventional is6110-rflp method, which requires a relatively large amount of dna, both the mst and the vntr/miru typing methods require only small dna samples as they are based on pcr amplification of selected genomic regions. the fact that such a small amount of material is handled during these aforementioned procedures is an obvious advantage, since it limits the risk of exposure of laboratory personnel to a dangerous pathogen. since the mst method is based on sequence analysis, is reproducible and is easily exchangeable, we propose and offer a free and accessible m. tuberculosis mst database so that microbiologists may compare the spacer sequence profiles they obtain with previously determined profiles for m. tuberculosis. the requirement for sequence analysis may limit the diffusion of mst to those laboratories that are equipped with an automatic sequencer, which is not a commonality in most laboratories, especially those in resource-limited countries. since mst uses pcr amplification as the first experimental step, it has the advantage of being applicable to dna extracts from inactivated mycobacterial cultures shortly after they are shown to be positive. the mst results were obtained in four working days. a similar, yet slightly longer delay of days between initial analysis and interpretation of results was recently reported when using the vntr/miru method. in contrast, the conventional is technique provided results in a median time of days. the delay period required to complete the mst analysis is certainly short enough to contribute to the interpretation of laboratory data that may have a significant clinical impact on patients.  our report confirms the importance of rapid identification of cross-contamination. indeed, the misdiagnosed patient received unnecessary anti-tuberculosis therapy and the final correct diagnosis was slightly delayed. mst typing proved to be an efficient new tool for the detection of cross-contamination with m. tuberculosis. in addition, mst results may be obtained within a few days, which significantly improves the quality of laboratory processing and, therefore, the quality of medical care for the patient. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
15,063cf922-6e0b-454e-a56f-4a31804cb9d4_gpt3_gen,"Mycobacterium tuberculosis isolation from clinical specimens is the gold standard for diagnosing tuberculosis, but false-positive cultures due to laboratory cross-contamination can lead to misdiagnoses and unnecessary treatments. A new PCR-sequencing-based genotyping method, known as multispacer sequence typing (MST), has been developed to determine if specimens have been contaminated with M. tuberculosis in the laboratory. A case report in which MST was applied showed that patients need rapid identification of cross-contamination to avoid unnecessary anti-tuberculosis therapy and improve the quality of medical care. The development of MST has shortened the delay period required to complete M. tuberculosis analysis and offers a new tool for detecting cross-contamination."," the isolation of mycobacterium tuberculosis complex organisms from clinical specimens collected from suspected patients serves as the gold standard for the proper diagnosis of tuberculosis in the laboratory. however, false-positive cultures have been reported that result from the cross-contamination of specimens via a contaminated bronchoscope or, more often, by laboratory cross-contamination. the latter situation has been reported at a frequency ranging from % to 3% of m. tuberculosis. laboratory cross-contamination should be suspected when m. tuberculosis is cultured from a smear-negative specimen processed in the same batch as a culture from a smear-positive specimen. the factors that increase the likelihood of cross-contamination include instances when only one of several specimens from the same patient is culture-positive and instances when the clinician is considering a diagnosis other than tuberculosis, which the clinician believes to be more likely based on clinical observations. such false-positives resulting from cross-contaminated specimens are disadvantageous since, besides resulting in a misdiagnosis, they result in unnecessary treatment and delay further diagnostic investigations in an effort to derive a definitive and correct diagnosis. finally, these false-positive cultures lead to an overestimation of the incidence and prevalence of tuberculosis in humans. a definitive demonstration of cross-contamination can be derived from precise molecular analyses of m. tuberculosis isolates. m. tuberculosis isolates harbouring identical genotypes are regarded as clones and are thus epidemiologically linked. the most widely used technique for determining the genotype of m. tuberculosis is a technique known as is6110-restriction fragment length polymorphism analysis. rflp analysis requires a large amount of biological material and, thus, poses a risk to laboratory workers due to the harmful nature of this pathogen. moreover, the latter method requires a substantial amount of time due to the fastidious nature of m. tuberculosis. more importantly from, a strictly technical perspective, is6110-rflp analysis does a poor job of indicating the presence of m. tuberculosis when these organisms contain only a few copies of the is sequence. recently, the variable number tandem repeat pcr-based technique and the mycobacterial interspersed repetitive unit technique have proven to be reliable methods for the resolution of cross-contamination events. we herein report the application of a new pcr-sequencing-based genotyping method, known as multispacer sequence typing, for determining whether specimens have been cross-contaminated with m. tuberculosis in the laboratory. case report a 60-year-old man was admitted for an examination to determine whether he had interstitial pneumonia. the patient had been previously hospitalised for two weeks at a different location with symptoms that included shortness of breath, a fever of °c, and a kg loss of weight within the past month. at the aforementioned hospital, a chest radiograph indicated the presence of bilateral interstitial pneumonia. subsequent microbiological investigations, including ziehl-neelsen staining and a pcr-based assay to test for the presence of m. tuberculosis on expectoration, indicated that there were no signs of such an infection. the patient was then transferred to our department for further evaluation. clinical examination of the patient verified both a body temperature of – °c and dyspnoea with 90% oxygen saturation under l/min oxygen. the medical history of the patient was unremarkable, except for previous treatment for arterial hypertension. the total body tomodensitometry indicated the presence of nodules in both lungs, in the mediastinal lymph nodes, and in a right axilar lymph node. the pertinent laboratory assays were performed and indicated a value of leucocytes/ml with 76% polymorphonuclear cells and platelets/ml. the erythrocyte sedimentation rate was determined to be mm for the first hour. the lactate dehydrogenase level was iu/ml, the gamma gt level was iu/ml, the bilirubin concentration was μmol/l, the ast level was iu/l, and the alt level was shown to be iu/l. it was suspected that the patient had already begun to develop pulmonary tuberculosis and thus was recommended to receive anti-tuberculosis therapy since it was reported that m. tuberculosis was isolated from an expectoration that was collected days prior during the first hospital visit. due to the observation that the patient's respiratory status had worsened, the patient was admitted into an intensive care unit for a period of four days. the results of direct microscopic examinations using gram and ziehl-neelsen staining of a surgical lung biopsy were negative. this sample, cultured in bactec and in 5% blood agar in slant tubes, remained sterile after a two-month incubation period. subsequent histological examination discovered large b-cell lymphoma and further assessments confirmed that the patient had stage iv lymphoma that involved the lung, liver, and bone marrow. the patient then received the appropriate anti-lymphoma therapy.  our investigation revealed isolation of a total of six m. tuberculosis strains from a laboratory that performed analyses for six different patients within a 2-week period before and after the isolation of m. tuberculosis from the index patient. all isolates were recovered from respiratory tract specimens and identified as m. tuberculosis by phenotypic methods and the etr-d sequencing method. isolate tub was recovered from a specimen received and handled on april 27th, while isolate tub was recovered from a specimen received on may 3rd, but handled for setting in culture on may 4th. isolate tub was recovered from a specimen received and handled on may 4th, while isolates tub tub and tub were recovered from specimens received and handled on may 8th. ziehl-neelsen staining was performed on all six specimens and the subsequent analyses revealed the presence of acid-fast bacilli for all samples with the exception of the specimen collected from index patient c, which exhibited no acid-fast bacillus. epidemiological investigation indicated that patients a, d, and e resided in the same ward, whereas no epidemiological link was found between the other three patients, including index patient c. eight intergenic spacers were pcr amplified for each of the six m. tuberculosis isolates and yielded pcr products of the expected sizes. sequences derived from these pcr products were combined and assembled for each of the six isolates. mst analysis was completed within four working days. analysis of the sequence combinations determined three new genetic profiles, including profile st which characterized the three isolates derived from patients a, d, and e; profile st which characterized the two isolates derived from patient b and the index patient c; and profile st which was discovered in the isolate derived from patient f. these new profiles resulted from a novel combination of the following spacer alleles: the st profile combined alleles 1/mst 1/mst 1/mst 2/mst 1/mst 3/mst 4/mst and allele 4/mst13; the st profile combined alleles 1/mst 1/mst 2/mst 2/mst 1/mst 3/mst 4/mst and allele 4/mst13; and the st profile combined alleles 1/mst 1/mst 1/mst 1/mst 3/mst 3/mst 4/mst and allele 4/mst the profiles for st st and st have been added to our free and accessible mst database http://ifr timone.univ-mrs.fr/mst_mtuberculosis/mst. mst genotyping data were assumed to be authentic based on the observations that the pcr-negative controls remained negative, coupled with the observation that all pcr products were of the predicted size. moreover, analysis of the spacer sequences edited in this work identified three new profiles, clearly indicating that amplicons did not result from laboratory contamination as a consequence of previous experiments. the mst genotyping data provided evidence to support epidemiological and clinical data that confirmed laboratory cross-contamination. specifically, one profile comprised three isolates recovered from epidemiologically-linked patients, whereas a different profile characterized only one isolate from a specimen collected from an unrelated patient f. the profile st was discovered for two m. tuberculosis isolates obtained from the index patient c and one unrelated patient b. microscopic examination of a respiratory tract specimen collected from patient b indicated the presence of acid-fast bacilli, while the same analysis performed for a specimen from the respiratory tract of the index patient c showed no indication of acid-fast bacilli. both of the latter two specimens were handled in the same laboratory, on the same day, and within the same batch of sample preparations, which explains the observation that the specimen recovered from the index patient was contaminated by the specimen collected from patient b. such a situation has been previously observed in cases of laboratory cross-contamination. interestingly, the frequency of false-positive cultures has been shown to be higher for laboratories that do not process high numbers of specimens, as was the case in the present report. as an example, in the laboratory setting, cross-contamination events may occur in the safety cabinet when a smear-positive specimen is handled in parallel with a smear-negative specimen, or during the phenotypic identification of isolates during the niacin test. cross-contamination of respiratory tract specimens by the avirulent m. tuberculosis h37ra reference strain has also been reported. the mst method, which was used in this study in addition to the more commonly used vntr/miru typing method, requires a relatively small amount of sample dna from the patient. in contrast to the conventional is6110-rflp method, which requires a relatively large amount of dna, both the mst and the vntr/miru typing methods require only small dna samples as they are based on pcr amplification of selected genomic regions. the fact that such a small amount of material is handled during these aforementioned procedures is an obvious advantage, since it limits the risk of exposure of laboratory personnel to a dangerous pathogen. since the mst method is based on sequence analysis, is reproducible and is easily exchangeable, we propose and offer a free and accessible m. tuberculosis mst database so that microbiologists may compare the spacer sequence profiles they obtain with previously determined profiles for m. tuberculosis. the requirement for sequence analysis may limit the diffusion of mst to those laboratories that are equipped with an automatic sequencer, which is not a commonality in most laboratories, especially those in resource-limited countries. since mst uses pcr amplification as the first experimental step, it has the advantage of being applicable to dna extracts from inactivated mycobacterial cultures shortly after they are shown to be positive. the mst results were obtained in four working days. a similar, yet slightly longer delay of days between initial analysis and interpretation of results was recently reported when using the vntr/miru method. in contrast, the conventional is technique provided results in a median time of days. the delay period required to complete the mst analysis is certainly short enough to contribute to the interpretation of laboratory data that may have a significant clinical impact on patients.  our report confirms the importance of rapid identification of cross-contamination. indeed, the misdiagnosed patient received unnecessary anti-tuberculosis therapy and the final correct diagnosis was slightly delayed. mst typing proved to be an efficient new tool for the detection of cross-contamination with m. tuberculosis. in addition, mst results may be obtained within a few days, which significantly improves the quality of laboratory processing and, therefore, the quality of medical care for the patient. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
16,ebafe064-6100-44ad-8221-b04070c14d82_flant5_gen,"nlmt is a marker of rems regulation. at sleep onset, the epochs of low muscle tone represent an early manifestation of rems. reduced nrems pressure associated with enhanced homeostatic and circadian rems drive in the morning can account for the higher frequency of sorems episodes and epochs of nlmt in morning sleep than in night sleep."," rem sleep is characterised by rapid eye movements, a mixed frequency, low amplitude eeg, and a low submental muscle tone with phasic twitches. at the transition from non-rem sleep to rems these three features do not appear synchronously. the emg level may decrease prior to the occurrence of the two other markers, and may also persist for some time after the end of rems. nrems with low muscle tone was observed not only before and after rems but also at sleep onset in a selective rems deprivation study. nlmt was enhanced by total sleep deprivation and selective rems deprivation. it was proposed that epochs of nlmt could be correlates of rems and therefore serve as markers of rems regulation. the aim of the present study was to further investigate the relationship between nlmt and rems by analysing the first h of a 4-h nocturnal sleep episode and a subsequent 3-h daytime sleep episode.  rems latency and sorems episodes rems latency showed a unimodal distribution with a maximum at min during night sleep and a bimodal distribution with modes at and min and a trough at min during morning sleep. one single sleep onset rems episode occurred at night, while a total of sorems episodes were observed during morning sleep. at night, rems latencies ranged from to minutes. the four longest latencies were from a single individual with a'skipped' first rems episode in all four nights. in the morning, rems latencies ranged from to minutes. the duration of nrems episodes following a sorems episode ranged from to min; this range is comparable to that of rems latencies at night. seven of subjects showed sorems episodes in all four morning sleep episodes, one subject in three, three in two and three in one episode. only two subjects had no sorems episode. episodes of nlmt epochs of nrems with low muscle tone are illustrated for one subject. the latency to the first appearance of nlmt showed a bimodal distribution with modes at and min in night sleep. the first mode was centred at sleep onset and the second mode was situated in the proximity of rems onset. the distribution closely resembled the distribution of rems latencies in morning sleep. a unimodal distribution with a mode at min was observed in morning sleep. epochs of nlmt were more frequent in morning sleep than in the first hours of night sleep. in night sleep, episodes of nlmt at sleep onset were observed. the one subject with four'skipped' first rems episodes at night showed neither sorems episodes nor episodes of nlmt at sleep onset. the other subject without sorems episodes had no episode of nlmt at sleep onset at night but three in the morning. in of the morning sleep episodes without sorems, episodes of nlmt at sleep onset were observed. their length was similar in night and morning sleep. slow wave activity the mean time course of swa during night and morning sleep is plotted in fig. mean swa in the first nrems episode of morning sleep was lower than in the first nrems episode of night sleep. slow-wave energy of the first nrems episode was also lower in the morning than at night. simulations of process s were performed to test whether the changes in swa were in accordance with the two-process model of sleep regulation. process s represents the homeostatic process of sleep regulation. its time course was derived from eeg swa. the simulations were based on a regular sleep-wake schedule followed by a h sleep episode at night and a h daytime sleep episode. the time constants corresponded to those used in daan et al.. the simulations revealed a reduced level of s at sleep onset in the morning compared with the level at sleep onset at night. for night sleep, a close correspondence between empirical swa and the simulated level of s was observed. in the first nrems episode of morning sleep, however, the predicted level of s was above the empirical values. sleep variables derived from visual scoring waking after sleep onset, the duration and percentage of rems and stage were higher in the morning than at night, whereas the amount of stages and was lower. sleep latency was shorter in the morning than at night, whereas rems latency did not differ if sorems was excluded. total sleep time, sleep efficiency, and movement time did not differ between night and morning sleep episodes. cycle and episode duration sleep cycle duration did not differ between night and morning sleep. rems episodes, however, were longer and nrems episodes shorter in morning sleep than in night sleep. discussion episodes of nlmt the present study aimed at clarifying the relationship between a particular feature of nrems, nlmt, and rems regulation by analysing restricted nocturnal sleep and subsequent daytime sleep. the results provide evidence that nlmt is determined by rems propensity. nlmt occurred more frequently in morning sleep than in night sleep. in morning sleep, the latency to the first epoch of nlmt showed a unimodal distribution. in night sleep, a bimodal pattern prevailed with modes at sleep onset and in the proximity of rems onset. this distribution corresponds to that of rems latency in morning sleep. it is also similar to the pattern that had been observed in a selective rems deprivation protocol. the duration of the episodes of nlmt at sleep onset was slightly longer than the duration of sorems episodes and their latency was shorter. low muscle tone usually precedes and outlasts rems. from these results, we conclude that nlmt may represent a window for sorems. if the episodes of nlmt at sleep onset would just represent the normal wake-sleep transition then muscle tone would be expected to gradually decrease. as illustrated in figure both decrease and increase of muscle activity at sleep onset were typically rather sudden. no specific eeg markers were found to accompany episodes of nlmt as revealed by gross visual inspection. when nrems and rems were considered together, 86% of the morning sleep episodes, but only 37% of the night sleep episodes started with low muscle tone. in morning sleep both the circadian drive and the reduced nrems pressure contributed to a high rems propensity. low muscle tone may be considered a rems marker irrespective of the manifestation of this sleep state and epochs of low muscle tone at sleep onset may reflect the early appearance of rems. if the drive for rems is low, nlmt may be the only manifestation of this sleep state. nlmt may therefore be regarded as a facet of rems regulation as previously proposed. in that study, selective rems deprivation increased nlmt in recovery sleep and nlmt was higher in daytime sleep than in the baseline night. in our study, the number of episodes of nlmt increased, in parallel to sorems and rems, in morning sleep compared to night sleep. the present findings challenge the concept of discrete states and favours the concept of interleaved states. our hypothesis could, for instance, further be tested in a forced desynchrony protocol that allows to separate homeostatic and circadian components. low muscle tone is required to score rems. when speaking of muscle tone or emg, sleep researchers usually refer to recordings of submental or mental muscle activity, which has a state-specific tone. one has to keep in mind that the muscle tone of trunk and limb muscles shows a different pattern than the muscle tone of head and neck muscles: the reduced tonic level during sleep remains rather stable throughout the night without further decrease in rems. cells in the medial brainstem reticular formation are thought to control motor movement. they are active during waking and rems while during nrems their activity is reduced. during rems motoneurons in the brainstem are tonically inhibited although central motor systems are highly active. motoneuron hyperpolarisation and ensuing loss of muscle tone are due to a combination of disfacilitation and inhibition by the co-ordinated action of gaba and glycine release onto the motoneurons and concomitant decrease of norepinephrine and serotonin release onto them. if our assumption is correct, then the activity of the motoneurons during episodes of nlmt should show a similar pattern as seen during rems. sorems the high number of sorems episodes in morning sleep showed that this phenomenon is common in experimental protocols and illustrates that there may indeed be a rems window at sleep onset. sorems episodes and increased amounts of rems were reported for subjects sleeping in the morning after a night with or without sleep. in a time-free environment and in a forced desynchrony protocol, sorems occurred at a circadian phase corresponding to morning sleep. their number decreased in naps scheduled throughout daytime hours. after spontaneous wakefulness in a long scotoperiod protocol, sorems episodes were more frequent in the early morning hours. not only circadian factors but also nrems pressure influences sorems propensity. thus sleep initiated at 7: h after total sleep deprivation did not result in increased rems. in the present study, sorems and rems were enhanced in morning sleep by the high circadian drive and the reduced nrems propensity. the preceding restricted nocturnal sleep episode not only reduced nrems propensity but also induced a partial rems deprivation, as a large portion of rems occurs in the second half of the night. the shorter sleep latency in the morning than at night may be due to the increased rems propensity. slow wave activity simulations with the two-process model of sleep regulation revealed a close correspondence between empirical swa and the level of s for night sleep. however, the empirical values of swa were below the predicted level of s in the first nrems episode of morning sleep. this discrepancy between the data and the model is in accordance with findings of beersma and co-workers who reported reduced intensity of nrems under conditions of increased rems pressure. as already discussed, the 4-h sleep episode in the previous night decreased nrems pressure, which did not increase again up to the level of night sleep because the time between the night and the morning sleep episode was too short. concomitantly, the sleep restriction and the circadian phase increased rems pressure. thus, increased rems propensity appears to inhibit the full manifestation of swa in morning sleep. therefore not only a high nrems pressure impedes rems, but also high rems drive lowers nrems intensity. thus, swa represented in the model by process s is not just dependent on sleep-wake history, but additionally on the balance between nrems and rems pressure.  we conclude that nlmt is a marker of homeostatic and circadian rems regulation. at sleep onset, the epochs of low muscle tone represent an early manifestation of rems. reduced nrems pressure associated with enhanced homeostatic and circadian rems drive in the morning can account for the higher frequency of sorems episodes and epochs of nlmt in morning sleep than in night sleep. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
17,ebafe064-6100-44ad-8221-b04070c14d82_gpt3_gen,"The article discusses the relationship between non-rapid eye movement sleep (NREM) and rapid eye movement sleep (REM), specifically focusing on NREM episodes with low muscle tone (NLMT) as a potential marker of REM regulation. The study found that NLMT is more frequent in morning sleep than in night sleep, and that it may represent an early manifestation of REM. The study also found that episodes of small or skipped REM sleep (SOREMS) were more frequent in morning sleep, likely due to increased circadian drive and reduced NREM pressure. Finally, simulations using a two-process model of sleep regulation suggested that increased REM drive can inhibit the full manifestation of slow wave activity, which is typically associated with NREM sleep."," rem sleep is characterised by rapid eye movements, a mixed frequency, low amplitude eeg, and a low submental muscle tone with phasic twitches. at the transition from non-rem sleep to rems these three features do not appear synchronously. the emg level may decrease prior to the occurrence of the two other markers, and may also persist for some time after the end of rems. nrems with low muscle tone was observed not only before and after rems but also at sleep onset in a selective rems deprivation study. nlmt was enhanced by total sleep deprivation and selective rems deprivation. it was proposed that epochs of nlmt could be correlates of rems and therefore serve as markers of rems regulation. the aim of the present study was to further investigate the relationship between nlmt and rems by analysing the first h of a 4-h nocturnal sleep episode and a subsequent 3-h daytime sleep episode.  rems latency and sorems episodes rems latency showed a unimodal distribution with a maximum at min during night sleep and a bimodal distribution with modes at and min and a trough at min during morning sleep. one single sleep onset rems episode occurred at night, while a total of sorems episodes were observed during morning sleep. at night, rems latencies ranged from to minutes. the four longest latencies were from a single individual with a'skipped' first rems episode in all four nights. in the morning, rems latencies ranged from to minutes. the duration of nrems episodes following a sorems episode ranged from to min; this range is comparable to that of rems latencies at night. seven of subjects showed sorems episodes in all four morning sleep episodes, one subject in three, three in two and three in one episode. only two subjects had no sorems episode. episodes of nlmt epochs of nrems with low muscle tone are illustrated for one subject. the latency to the first appearance of nlmt showed a bimodal distribution with modes at and min in night sleep. the first mode was centred at sleep onset and the second mode was situated in the proximity of rems onset. the distribution closely resembled the distribution of rems latencies in morning sleep. a unimodal distribution with a mode at min was observed in morning sleep. epochs of nlmt were more frequent in morning sleep than in the first hours of night sleep. in night sleep, episodes of nlmt at sleep onset were observed. the one subject with four'skipped' first rems episodes at night showed neither sorems episodes nor episodes of nlmt at sleep onset. the other subject without sorems episodes had no episode of nlmt at sleep onset at night but three in the morning. in of the morning sleep episodes without sorems, episodes of nlmt at sleep onset were observed. their length was similar in night and morning sleep. slow wave activity the mean time course of swa during night and morning sleep is plotted in fig. mean swa in the first nrems episode of morning sleep was lower than in the first nrems episode of night sleep. slow-wave energy of the first nrems episode was also lower in the morning than at night. simulations of process s were performed to test whether the changes in swa were in accordance with the two-process model of sleep regulation. process s represents the homeostatic process of sleep regulation. its time course was derived from eeg swa. the simulations were based on a regular sleep-wake schedule followed by a h sleep episode at night and a h daytime sleep episode. the time constants corresponded to those used in daan et al.. the simulations revealed a reduced level of s at sleep onset in the morning compared with the level at sleep onset at night. for night sleep, a close correspondence between empirical swa and the simulated level of s was observed. in the first nrems episode of morning sleep, however, the predicted level of s was above the empirical values. sleep variables derived from visual scoring waking after sleep onset, the duration and percentage of rems and stage were higher in the morning than at night, whereas the amount of stages and was lower. sleep latency was shorter in the morning than at night, whereas rems latency did not differ if sorems was excluded. total sleep time, sleep efficiency, and movement time did not differ between night and morning sleep episodes. cycle and episode duration sleep cycle duration did not differ between night and morning sleep. rems episodes, however, were longer and nrems episodes shorter in morning sleep than in night sleep. discussion episodes of nlmt the present study aimed at clarifying the relationship between a particular feature of nrems, nlmt, and rems regulation by analysing restricted nocturnal sleep and subsequent daytime sleep. the results provide evidence that nlmt is determined by rems propensity. nlmt occurred more frequently in morning sleep than in night sleep. in morning sleep, the latency to the first epoch of nlmt showed a unimodal distribution. in night sleep, a bimodal pattern prevailed with modes at sleep onset and in the proximity of rems onset. this distribution corresponds to that of rems latency in morning sleep. it is also similar to the pattern that had been observed in a selective rems deprivation protocol. the duration of the episodes of nlmt at sleep onset was slightly longer than the duration of sorems episodes and their latency was shorter. low muscle tone usually precedes and outlasts rems. from these results, we conclude that nlmt may represent a window for sorems. if the episodes of nlmt at sleep onset would just represent the normal wake-sleep transition then muscle tone would be expected to gradually decrease. as illustrated in figure both decrease and increase of muscle activity at sleep onset were typically rather sudden. no specific eeg markers were found to accompany episodes of nlmt as revealed by gross visual inspection. when nrems and rems were considered together, 86% of the morning sleep episodes, but only 37% of the night sleep episodes started with low muscle tone. in morning sleep both the circadian drive and the reduced nrems pressure contributed to a high rems propensity. low muscle tone may be considered a rems marker irrespective of the manifestation of this sleep state and epochs of low muscle tone at sleep onset may reflect the early appearance of rems. if the drive for rems is low, nlmt may be the only manifestation of this sleep state. nlmt may therefore be regarded as a facet of rems regulation as previously proposed. in that study, selective rems deprivation increased nlmt in recovery sleep and nlmt was higher in daytime sleep than in the baseline night. in our study, the number of episodes of nlmt increased, in parallel to sorems and rems, in morning sleep compared to night sleep. the present findings challenge the concept of discrete states and favours the concept of interleaved states. our hypothesis could, for instance, further be tested in a forced desynchrony protocol that allows to separate homeostatic and circadian components. low muscle tone is required to score rems. when speaking of muscle tone or emg, sleep researchers usually refer to recordings of submental or mental muscle activity, which has a state-specific tone. one has to keep in mind that the muscle tone of trunk and limb muscles shows a different pattern than the muscle tone of head and neck muscles: the reduced tonic level during sleep remains rather stable throughout the night without further decrease in rems. cells in the medial brainstem reticular formation are thought to control motor movement. they are active during waking and rems while during nrems their activity is reduced. during rems motoneurons in the brainstem are tonically inhibited although central motor systems are highly active. motoneuron hyperpolarisation and ensuing loss of muscle tone are due to a combination of disfacilitation and inhibition by the co-ordinated action of gaba and glycine release onto the motoneurons and concomitant decrease of norepinephrine and serotonin release onto them. if our assumption is correct, then the activity of the motoneurons during episodes of nlmt should show a similar pattern as seen during rems. sorems the high number of sorems episodes in morning sleep showed that this phenomenon is common in experimental protocols and illustrates that there may indeed be a rems window at sleep onset. sorems episodes and increased amounts of rems were reported for subjects sleeping in the morning after a night with or without sleep. in a time-free environment and in a forced desynchrony protocol, sorems occurred at a circadian phase corresponding to morning sleep. their number decreased in naps scheduled throughout daytime hours. after spontaneous wakefulness in a long scotoperiod protocol, sorems episodes were more frequent in the early morning hours. not only circadian factors but also nrems pressure influences sorems propensity. thus sleep initiated at 7: h after total sleep deprivation did not result in increased rems. in the present study, sorems and rems were enhanced in morning sleep by the high circadian drive and the reduced nrems propensity. the preceding restricted nocturnal sleep episode not only reduced nrems propensity but also induced a partial rems deprivation, as a large portion of rems occurs in the second half of the night. the shorter sleep latency in the morning than at night may be due to the increased rems propensity. slow wave activity simulations with the two-process model of sleep regulation revealed a close correspondence between empirical swa and the level of s for night sleep. however, the empirical values of swa were below the predicted level of s in the first nrems episode of morning sleep. this discrepancy between the data and the model is in accordance with findings of beersma and co-workers who reported reduced intensity of nrems under conditions of increased rems pressure. as already discussed, the 4-h sleep episode in the previous night decreased nrems pressure, which did not increase again up to the level of night sleep because the time between the night and the morning sleep episode was too short. concomitantly, the sleep restriction and the circadian phase increased rems pressure. thus, increased rems propensity appears to inhibit the full manifestation of swa in morning sleep. therefore not only a high nrems pressure impedes rems, but also high rems drive lowers nrems intensity. thus, swa represented in the model by process s is not just dependent on sleep-wake history, but additionally on the balance between nrems and rems pressure.  we conclude that nlmt is a marker of homeostatic and circadian rems regulation. at sleep onset, the epochs of low muscle tone represent an early manifestation of rems. reduced nrems pressure associated with enhanced homeostatic and circadian rems drive in the morning can account for the higher frequency of sorems episodes and epochs of nlmt in morning sleep than in night sleep. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
18,407b7f1a-b5ef-4dbc-a799-103e9cb21f49_gpt3_gen,"Freezing lesions to the developing cortical plate in rats result in local and distal anatomical and physiological changes, including hyperexcitability around the point of disruption, deviation of axonal projections from targets in the hemisphere contralateral to the pathology, and changes in thalamo-cortical connectivity. The presence of microgyria resulting from such lesions has been associated with rapid auditory processing impairments in rats, suggesting a possible link to human dyslexia through similar auditory processing disruptions. Focal injury on postnatal day 1 during neuronal migration appears to exert more pronounced and long-term behavioral and neuroanatomical effects compared to injury occurring after the completion of neuronal migration. The reductions in corpus callosum volume in rats with microgyria are consistent with the reductions in brain weight and cortical volume previously reported. Decreased corpus callosum volume may represent an additional marker for the timing and long-term behavioral outcome of cortical developmental pathology in humans."," freezing lesions to the developing cortical plate result in a cascade of local and distal anatomical and physiological changes, including hyperexcitability around the point of disruption, deviation of axonal projections from targets in the hemisphere contralateral to the pathology, and changes in thalamo-cortical connectivity. freezing lesions induced on postnatal day and p in rats resemble human four-layer microgyria. moreover, the presence of microgyria has been associated with rapid auditory processing impairments in rats. given evidence that disruptions in auditory processing may contribute to disruptions in language development, human microgyria could relate to human dyslexia, at least in part, through similar auditory processing disruptions. previous research indicates that injury to developing cortex during peak periods of neuronal migration results in greater decreases in brain weight and cortical volume as compared to injury occurring beyond the cessation of neuronal migration in rats. in fact, focal freezing lesions on p do not lead to significant decreases in brain weight, or cortical volume, nor the formation of four-layer microgyria as seen in p and lesion cases. surprisingly, focal injury on p or does lead to deficits in processing brief gaps in white noise as measured during the juvenile period, regardless of the presence/absence of microgyria or changes in cortical volume/brain weight observed. however, when rapid auditory processing was assessed in adult rats, only subjects with lesions induced on p were found to exhibit persistent rapid auditory processing deficits. these data suggested that despite early behavioral impairments seen with focal lesions on p1- cortical disruption specifically during neuronal migration appears to exert more pronounced and long-term behavioral and neuroanatomical effects as compared to injury occurring after the completion of neuronal migration. in terms of human research, neuromorphometric studies investigating the effects of developmental pathology on long-term behavioral outcome are scarce. however, recent studies suggest a link between early cortical developmental malformations and learning-related cognitive impairments on corpus callosum volume in rats previously assessed for auditory processing, brain weight and cortical volume. we predicted that changes in corpus callosum volume would correspond with the profile of change previously seen for brain weight and cortical volume, and that these changes would in turn reflect long-term behavioral outcome.  post mortem histological analysis revealed no evidence of cortical damage in any of the sham subjects. post mortem analysis showed the presence of double bilateral microgyria only in the p and p lesion groups. the p lesion group, which received comparable freezing lesion treatments relative to the p and p groups, did not show evidence of microgyria. however, the p lesion group did show some disrupted cortical lamination in areas of cortex directly underlying the probe application points. lesions were seen mostly in sensorimotor cortex, with some extension into frontal, temporal, or occipital cortices. the majority of double lesions in p and p conditions appeared as one continuous severe microgyric lesion. however, the p group showed a pattern of disruption that was centered on the specific areas of probe application. this pattern appeared as four relatively small distinct pockets of displaced cortical lamination resulting from the freezing insults. corpus callosum volume a univariate anova was computed for corpus callosum volume, using age at treatment and treatment as fixed factors. results showed a significant main effect of treatment on corpus callosum volume, with lesion subjects showing significantly smaller callosal volumes as compared to shams. an age at treatment × treatment interaction was also found for corpus callosum volume, indicating that corpus callosum volumes were smaller as the age of injury decreased from p to p among lesion subjects, simple effects analyses revealed significant differences between p and p, and p and p, subjects. there was no significant difference between p and p lesion subjects. however, unlike the p lesion group, p subjects did show a significant reduction in corpus callosum volume compared to shams, indicating an overall reduction in corpus callosum volume similar to, but not as great as, the reduction seen in the p lesion condition. discussion the current findings show that focal bilateral freezing lesions to the developing cortex result in differential reductions in corpus callosum volume as a function of the timing of the insult. results show an age of treatment by treatment interaction, indicating that as the age at injury moves from p to p the corpus callosum becomes smaller. this progressive decrease in corpus callosum volume is evidenced by smaller callosal volumes in p versus p lesion, and p lesion versus sham subjects. although the cause of these changes is unknown, the current results add to previous studies showing reduced cortico-cortical and thalamo-cortical connectivity, along with reductions in cortical volume and brain weight, resulting from p lesion-induced microgyria. as previously reported for the subjects in the current analysis, brain weight and cortical volume decrease as a function of the age at which injury occurs. specifically, p induced lesion subjects had the smallest cortex and brain weight compared to shams, followed by p and then the p lesion group. all of these data taken together suggest that changes in corpus callosum volume, in addition to cortical volume and brain weight, may represent an important clinical marker for the timing of cortical developmental pathology, which may contribute to some aspects of learning impairment. moreover, the current report provides increased support for the hypothesis that early injury to developing cortex can have marked effects on the volume of various structures directly and indirectly related to the point of disruption. we previously reported that p focal injury to cortex led to long-term impairment in processing short but not long duration gaps in white noise using a startle response paradigm. further, prior to the current analysis all subjects received a total of days of silent gap/reflex modification testing. during the juvenile period, all subjects in the current brain assessment received days of silent gap testing, in addition to days of silent gap testing in adulthood. briefly, acoustic testing involved the placement of rats on a load cell platform while a pseudo randomized set of variable duration silent gaps was presented in continuous db broadband white noise prior to a db startle eliciting noise burst. detection of the silent gap cue elicited a reduction in the startle response relative to an uncued trial, where no gap preceded the startle burst. importantly, subjects with the largest reduction in corpus callosum volume, as seen in the current analysis, showed the worst long-term behavioral outcome. specifically, p lesion subjects continued to show impairments in 2– ms silent gap detection after p whereas p and p lesion groups no longer showed the robust pattern of impairment. it is important to note that all of the subjects evaluated in the current study received the same testing experience prior to sacrifice. further, the nature of reflex modification insured that alternative strategies could not be used as with more complex maze learning or operant conditioning tasks. while the possibility exists that behavioral testing effected the brains of the three lesion groups or shams differently, the fact that p and sham subjects did not differ in corpus callosum volume suggests that age at injury was an important factor in determining long-term neuromorphological profiles across groups. further, even with repeated behavioral testing these results are especially important within the clinical context. however, future studies will seek to determine the effects of different types of experience on key anatomical markers, such as corpus callosum volume. although the results of the current study do not address the causal mechanisms underlying auditory processing impairments, they may represent an additional marker for the presence of developmental pathology which might be involved in the appearance of human learning impairments such as dyslexia,, as well as cortical developmental malformations. in recent years, as neuroimaging has become more accessible to researchers, the corpus callosum has gained increased attention as a target for possible pathology underlying developmental learning impairments. however, sampling in these studies is frequently limited to young adults and there is often little information regarding the timing or occurrence of pre/pari natal insults. therefore, the use of rodent models of focal cortical injury such as the one presented here may help identify possible windows during brain development at which particular structures are more susceptible to degradation, which in turn could lead to more pronounced long term behavioral pathology. the present data supports the notion that assessment of colossal morphology in populations at risk for neurodevelopmental pathologies, may help identify whether and when injury occurred, as well as predict potential long-term behavioral outcomes.  the reductions in corpus callosum volume in the p and lesion groups are consistent with the reductions in brain weight and cortical volume previously reported for microgyric rats. current results suggest that disruption to the cortical plate during early postnatal development may lead to more widely dispersed neurovolumetric anomalies and subsequent behavioral impairments, compared with injury that occurs later in development. further, these results suggest that in a human clinical setting decreased corpus callosum volume may represent an additional marker for long-term behavioral outcome. ",pubmed_generic,GPT 3.5,Decreased corpus callosum volume may represent an additional marker for the timing and long-term behavioral outcome of cortical developmental pathology in humans.,factual,factual,,,,,,,Accurate,
19,407b7f1a-b5ef-4dbc-a799-103e9cb21f49_flant5_gen,p focal injury to the developing cortex results in differential reductions in corpus callosum volume as a function of the timing of the insult.," freezing lesions to the developing cortical plate result in a cascade of local and distal anatomical and physiological changes, including hyperexcitability around the point of disruption, deviation of axonal projections from targets in the hemisphere contralateral to the pathology, and changes in thalamo-cortical connectivity. freezing lesions induced on postnatal day and p in rats resemble human four-layer microgyria. moreover, the presence of microgyria has been associated with rapid auditory processing impairments in rats. given evidence that disruptions in auditory processing may contribute to disruptions in language development, human microgyria could relate to human dyslexia, at least in part, through similar auditory processing disruptions. previous research indicates that injury to developing cortex during peak periods of neuronal migration results in greater decreases in brain weight and cortical volume as compared to injury occurring beyond the cessation of neuronal migration in rats. in fact, focal freezing lesions on p do not lead to significant decreases in brain weight, or cortical volume, nor the formation of four-layer microgyria as seen in p and lesion cases. surprisingly, focal injury on p or does lead to deficits in processing brief gaps in white noise as measured during the juvenile period, regardless of the presence/absence of microgyria or changes in cortical volume/brain weight observed. however, when rapid auditory processing was assessed in adult rats, only subjects with lesions induced on p were found to exhibit persistent rapid auditory processing deficits. these data suggested that despite early behavioral impairments seen with focal lesions on p1- cortical disruption specifically during neuronal migration appears to exert more pronounced and long-term behavioral and neuroanatomical effects as compared to injury occurring after the completion of neuronal migration. in terms of human research, neuromorphometric studies investigating the effects of developmental pathology on long-term behavioral outcome are scarce. however, recent studies suggest a link between early cortical developmental malformations and learning-related cognitive impairments on corpus callosum volume in rats previously assessed for auditory processing, brain weight and cortical volume. we predicted that changes in corpus callosum volume would correspond with the profile of change previously seen for brain weight and cortical volume, and that these changes would in turn reflect long-term behavioral outcome.  post mortem histological analysis revealed no evidence of cortical damage in any of the sham subjects. post mortem analysis showed the presence of double bilateral microgyria only in the p and p lesion groups. the p lesion group, which received comparable freezing lesion treatments relative to the p and p groups, did not show evidence of microgyria. however, the p lesion group did show some disrupted cortical lamination in areas of cortex directly underlying the probe application points. lesions were seen mostly in sensorimotor cortex, with some extension into frontal, temporal, or occipital cortices. the majority of double lesions in p and p conditions appeared as one continuous severe microgyric lesion. however, the p group showed a pattern of disruption that was centered on the specific areas of probe application. this pattern appeared as four relatively small distinct pockets of displaced cortical lamination resulting from the freezing insults. corpus callosum volume a univariate anova was computed for corpus callosum volume, using age at treatment and treatment as fixed factors. results showed a significant main effect of treatment on corpus callosum volume, with lesion subjects showing significantly smaller callosal volumes as compared to shams. an age at treatment × treatment interaction was also found for corpus callosum volume, indicating that corpus callosum volumes were smaller as the age of injury decreased from p to p among lesion subjects, simple effects analyses revealed significant differences between p and p, and p and p, subjects. there was no significant difference between p and p lesion subjects. however, unlike the p lesion group, p subjects did show a significant reduction in corpus callosum volume compared to shams, indicating an overall reduction in corpus callosum volume similar to, but not as great as, the reduction seen in the p lesion condition. discussion the current findings show that focal bilateral freezing lesions to the developing cortex result in differential reductions in corpus callosum volume as a function of the timing of the insult. results show an age of treatment by treatment interaction, indicating that as the age at injury moves from p to p the corpus callosum becomes smaller. this progressive decrease in corpus callosum volume is evidenced by smaller callosal volumes in p versus p lesion, and p lesion versus sham subjects. although the cause of these changes is unknown, the current results add to previous studies showing reduced cortico-cortical and thalamo-cortical connectivity, along with reductions in cortical volume and brain weight, resulting from p lesion-induced microgyria. as previously reported for the subjects in the current analysis, brain weight and cortical volume decrease as a function of the age at which injury occurs. specifically, p induced lesion subjects had the smallest cortex and brain weight compared to shams, followed by p and then the p lesion group. all of these data taken together suggest that changes in corpus callosum volume, in addition to cortical volume and brain weight, may represent an important clinical marker for the timing of cortical developmental pathology, which may contribute to some aspects of learning impairment. moreover, the current report provides increased support for the hypothesis that early injury to developing cortex can have marked effects on the volume of various structures directly and indirectly related to the point of disruption. we previously reported that p focal injury to cortex led to long-term impairment in processing short but not long duration gaps in white noise using a startle response paradigm. further, prior to the current analysis all subjects received a total of days of silent gap/reflex modification testing. during the juvenile period, all subjects in the current brain assessment received days of silent gap testing, in addition to days of silent gap testing in adulthood. briefly, acoustic testing involved the placement of rats on a load cell platform while a pseudo randomized set of variable duration silent gaps was presented in continuous db broadband white noise prior to a db startle eliciting noise burst. detection of the silent gap cue elicited a reduction in the startle response relative to an uncued trial, where no gap preceded the startle burst. importantly, subjects with the largest reduction in corpus callosum volume, as seen in the current analysis, showed the worst long-term behavioral outcome. specifically, p lesion subjects continued to show impairments in 2– ms silent gap detection after p whereas p and p lesion groups no longer showed the robust pattern of impairment. it is important to note that all of the subjects evaluated in the current study received the same testing experience prior to sacrifice. further, the nature of reflex modification insured that alternative strategies could not be used as with more complex maze learning or operant conditioning tasks. while the possibility exists that behavioral testing effected the brains of the three lesion groups or shams differently, the fact that p and sham subjects did not differ in corpus callosum volume suggests that age at injury was an important factor in determining long-term neuromorphological profiles across groups. further, even with repeated behavioral testing these results are especially important within the clinical context. however, future studies will seek to determine the effects of different types of experience on key anatomical markers, such as corpus callosum volume. although the results of the current study do not address the causal mechanisms underlying auditory processing impairments, they may represent an additional marker for the presence of developmental pathology which might be involved in the appearance of human learning impairments such as dyslexia,, as well as cortical developmental malformations. in recent years, as neuroimaging has become more accessible to researchers, the corpus callosum has gained increased attention as a target for possible pathology underlying developmental learning impairments. however, sampling in these studies is frequently limited to young adults and there is often little information regarding the timing or occurrence of pre/pari natal insults. therefore, the use of rodent models of focal cortical injury such as the one presented here may help identify possible windows during brain development at which particular structures are more susceptible to degradation, which in turn could lead to more pronounced long term behavioral pathology. the present data supports the notion that assessment of colossal morphology in populations at risk for neurodevelopmental pathologies, may help identify whether and when injury occurred, as well as predict potential long-term behavioral outcomes.  the reductions in corpus callosum volume in the p and lesion groups are consistent with the reductions in brain weight and cortical volume previously reported for microgyric rats. current results suggest that disruption to the cortical plate during early postnatal development may lead to more widely dispersed neurovolumetric anomalies and subsequent behavioral impairments, compared with injury that occurs later in development. further, these results suggest that in a human clinical setting decreased corpus callosum volume may represent an additional marker for long-term behavioral outcome. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
20,c180bdb9-7901-480d-8074-3c8faa2e5b83_flant5_gen,"a simple, efficient method for the production and purification of active human renin."," the renin-angiotensin system is a hormone system that regulates blood pressure and extracellular volume in the body. the ras sequentially processes angiotensinogen to angiotensin ii, a peptide hormone that is a potent vasoconstrictor. inhibition of ras components has been used successfully in the treatment of hypertension, heart failure and end organ damage. renin catalyzes the first and rate-limiting step of the ras cascade and renin is specific for angiotensinogen. blockade of ang ii production by direct inhibition of renin has long been a therapeutic goal. early renin inhibitors, such as enalkiren and remikiren, were effective in blood pressure lowering. however, due to poor oral bioavailability, duration of action, and high costs of synthesis, these early peptidomimetic inhibitors never progressed to pivotal clinical studies. continued clinical interest in renin has led to the recent approval of the first renin inhibitor, aliskiren, a non-peptidic inhibitor of renin, which has generated an interest in finding newer renin inhibitors with improved profiles. renin is a member of the aspartic acid protease family. the human renin gene encodes for a protein consisting of amino acids. it is proteolytically processed and secreted as a residue zymogen, prorenin, which contains a amino acid propeptide. the propeptide serves as an autoinhibitory domain that controls the enzyme activity. the pro segment must be removed to generate mature, fully active renin. prorenin is synthesized principally by juxtaglomerular cells in the wall of the afferent arteriole of the kidney and is released into the bloodstream. renin was first purified from animal tissues, including submaxillary glands and kidneys. yields were generally very low. for instance, yokosawa et al obtained only μg of pure renin from kg of non-cancerous autopsied human kidneys. using recombinant techniques, renin has been expressed and purified from eukaryotic cell lines including cho cells, mouse l- cells, sf insect cells and damp cells. active renin had also been over-expressed in escherichia coli and successfully refolded. in order to supply enzyme to support our structure-based design efforts, we developed an efficient system for renin production and purification in amounts sufficient to support routine x-ray crystallography. herein, we report a simple procedure for renin expression and purification that exploits the affinity of glycosylated renin for con a. generally, multi-milligram quantities of material can be prepared from the conditioned medium of hek cell culture. the active renin protein prepared has been used successfully to support activity assays and to generate high resolution crystal complexes with bound inhibitors.  the recombinant human renin gene was transfected into the human kidney cell line, hek- a clonal cell line expressing significant levels of prorenin was prepared by limiting dilution. analysis of the conditioned media of multiple clones identified a single clone that was scaled and transferred to growth in a hollow fiber bioreactor. this line was subsequently adapted to growth in serum free media. the recombinant human prorenin was constitutively secreted into the medium with concomitant removal of the aminoacid long n-terminal signal peptide. although serum-free medium was used to grow the cells, the small amounts of other proteins were found as contaminants. prorenin has two n-linked glycosylation sites and. the glycosylated prorenin has reasonable affinity for con a and this interaction was used to purify the protein to high purity in a single step. to our surprise, the major contaminating protein, bsa, did not bind to the con a resin. the bovine serum had been used in the culture medium initially when the cell line was adapted to the serum-free medium and bsa was a major component. therefore, the con a chromatography is more like a step of prorenin enrichment and any major contaminants were removed subsequently with cation exchange chromatography. after the hollow fiber bioreactor system was set up for the prorenin expression, the conditioned medium was collected, about ml a day, which was pooled and loaded onto the con a column. for one typical manageable purification experiment, 250– ml containing approximately mg proteins was used. the column was washed until the baseline was stabilized. in order to improve the yields, the column was ""soaked and then eluted"" with the buffer containing d-methyl-mannopyranoside at the low flow rate. usually, two or three cycles of the soaking/eluting were applied in order to maximize the recovery. the volume of the pooled materials containing mainly prorenin was reduced to approximately ml by the millipore ultrafiltration device, followed by activation and further purification. no other detectable endogenous con a binding proteins were observed by coomasie stained sds-page gels. the con a material was converted to active renin by digestion with trypsin. trypsin cleaves after residue arg conditions were optimized using different temperature, time and amounts of trypsin. the final conditions were described in the experimental section and provide mild proteolysis for quantitative conversion of prorenin to active renin. prolonged trypsin treatment did not appear to result in any internal cleavage of the protein, and generally one hour incubation at 4°c with trypsin afforded a complete conversion from prorenin to renin indicating that the propeptide trypsin-cleavage site was accessible. after digestion, trypsin was removed with trypsin-inhibitor agarose beads. any other contaminants or misfolded renin proteins were removed with cation exchange chromatography. approximately 60–70% of the total proteins were removed at this step. the final step of purification involved with a size exclusion column, resulting in a purified activated renin of >98% purity, as estimated by the reducing sds-page analysis. the conversion of prorenin to renin by trypsin results in removal of amino acids, approximately kda. because of heterogeneous nature of glycosylation, prorenin and renin migrated on the sds-page gel as broad bands of around kda and kda, respectively. the proteins were analyzed by the n-terminal sequencing and mass spectrometry for further characterization of the proteolytic activation. the n-terminal sequence analysis confirmed that the first residues of the mature renin were ltlgxt and verified the complete removal of the propeptide. the x represents the asparagine residue which is a glycosylation site. mass spectrometry analysis indicated that glycosylation of renin added from to kda to the molecular weight, based on the calculated dna-deduced amino acid sequence. the discrepancy of molecular weights might be related to variations in growth conditions and reagents from batch to batch because of the heterogeneous nature of glycosylation. the sugar moieties were removable by endoglycosidase h treatment only in partially denatured proteins under conditions of 1% sds at 37°c overnight. in our crystallization studies and biological assays, the sugar moieties were not removed. typically, 1– mg of protein could be obtained from one batch of purification using approximately – ml starting conditioned medium, depending on cell well-being, growth conditions and other procedural irregularities. *the representative major molecular weight peak from several batch of samples. the activated renin was characterized in a functional assay. the catalytic activity was measured using the commercially available substrate, dabcyl-γabu-ile-his-pro-phe-his-leu-val-ile-his-thr-edans, which is based on the angiotensinogen sequence. velocity of reaction was initially followed by hplc and exhibited hyperbolic dependence on substrate concentration consistent with michaelis-menten kinetics with an apparent km of μm. this value is similar to the km of μm reported in the literature based on the fret assay. the catalytic efficiency of recombinant rennin was determined using the dabcyl-edans substrate. the enzyme had a second order rate constant of × m-1s- this value is close to the published catalytic efficiency of × m-1s- and × m-1s- for the cleavage of angiotensinogen tetradecapeptide by purified human renin. enzymatic activity of the recombinant human renin was measured in a ph-rate profile. activity was measured between ph and in ph units. the maximum activity was observed at ph, similar to purified human renin. the peak and the shoulder of the ph profile were similar to those observed for purified human renin cleaving partially purified human angiotensinogen with the maxima at ~ and. several well characterized inhibitors of human renin were tested with the recombinant enzyme. these inhibitors included commercially available statines and the small molecule inhibitor aliskiren. pepstatin a is a potent inhibitor of several aspartic proteases including cathepsin e, cathepsin d and hiv protease. human renin is poorly inhibited by pepstatin a, while porcine renin exhibits sub-micromolar inhibition constants with this compound. the recombinant human renin was inhibited by pepstatin a with an ic of ± μm, similar to literature values. sr is a pepstatin analog that inhibits human plasma renin activity with the ic of nm. the compound is potent against purified recombinant human renin with an ic of ± nm the recombinant renin was also inhibited by aliskiren, a potent human renin inhibitor currently marketed for hypertension as tekturna. aliskiren is selective for human renin with a reported ic of nm. in our hands, ic value for recombinant human renin was ± nm. the recombinant renin is indistinguishable from renin purified from human sources and stable after long term storage at -80°c. the material is suitable for functional assays and x-ray crystallography. the material had been used to generate > renin inhibitor complexes ranging from Å– Å resolution. a typical experiment is shown with vtp. vtp is a weak inhibitor of ic nm. co-crystals of this compound were obtained by the hanging drop method. these crystals diffracted at Å. this complex can be used for soaking studies with potent inhibitors, which readily displace vtp generating high quality crystals. details on the structural solutions of vtp and additional structures will be reported separately.  this present work describes a simple, efficient method for the production and purification of active human renin. recombinant renin can be generated in milligram quantities via a simple activation/purification sequence. biochemical properties of the recombinant human renin are indistinguishable from those reported in the literature for purified enzyme. renin inhibitors were active against the recombinant enzyme with potencies very similar to the inhibition constants measured for purified human renin. the material is highly pure and is suitable for supporting activity assays and structural biology efforts. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
21,c180bdb9-7901-480d-8074-3c8faa2e5b83_gpt3_gen,"The article describes a simple and efficient method for producing and purifying active human renin, an enzyme involved in regulating blood pressure and extracellular volume in the body. The recombinant renin generated using this method has similar biochemical properties to purified enzyme and can be used for activity assays and structural biology efforts. Renin inhibitors, such as aliskiren, are also effective against the recombinant enzyme."," the renin-angiotensin system is a hormone system that regulates blood pressure and extracellular volume in the body. the ras sequentially processes angiotensinogen to angiotensin ii, a peptide hormone that is a potent vasoconstrictor. inhibition of ras components has been used successfully in the treatment of hypertension, heart failure and end organ damage. renin catalyzes the first and rate-limiting step of the ras cascade and renin is specific for angiotensinogen. blockade of ang ii production by direct inhibition of renin has long been a therapeutic goal. early renin inhibitors, such as enalkiren and remikiren, were effective in blood pressure lowering. however, due to poor oral bioavailability, duration of action, and high costs of synthesis, these early peptidomimetic inhibitors never progressed to pivotal clinical studies. continued clinical interest in renin has led to the recent approval of the first renin inhibitor, aliskiren, a non-peptidic inhibitor of renin, which has generated an interest in finding newer renin inhibitors with improved profiles. renin is a member of the aspartic acid protease family. the human renin gene encodes for a protein consisting of amino acids. it is proteolytically processed and secreted as a residue zymogen, prorenin, which contains a amino acid propeptide. the propeptide serves as an autoinhibitory domain that controls the enzyme activity. the pro segment must be removed to generate mature, fully active renin. prorenin is synthesized principally by juxtaglomerular cells in the wall of the afferent arteriole of the kidney and is released into the bloodstream. renin was first purified from animal tissues, including submaxillary glands and kidneys. yields were generally very low. for instance, yokosawa et al obtained only μg of pure renin from kg of non-cancerous autopsied human kidneys. using recombinant techniques, renin has been expressed and purified from eukaryotic cell lines including cho cells, mouse l- cells, sf insect cells and damp cells. active renin had also been over-expressed in escherichia coli and successfully refolded. in order to supply enzyme to support our structure-based design efforts, we developed an efficient system for renin production and purification in amounts sufficient to support routine x-ray crystallography. herein, we report a simple procedure for renin expression and purification that exploits the affinity of glycosylated renin for con a. generally, multi-milligram quantities of material can be prepared from the conditioned medium of hek cell culture. the active renin protein prepared has been used successfully to support activity assays and to generate high resolution crystal complexes with bound inhibitors.  the recombinant human renin gene was transfected into the human kidney cell line, hek- a clonal cell line expressing significant levels of prorenin was prepared by limiting dilution. analysis of the conditioned media of multiple clones identified a single clone that was scaled and transferred to growth in a hollow fiber bioreactor. this line was subsequently adapted to growth in serum free media. the recombinant human prorenin was constitutively secreted into the medium with concomitant removal of the aminoacid long n-terminal signal peptide. although serum-free medium was used to grow the cells, the small amounts of other proteins were found as contaminants. prorenin has two n-linked glycosylation sites and. the glycosylated prorenin has reasonable affinity for con a and this interaction was used to purify the protein to high purity in a single step. to our surprise, the major contaminating protein, bsa, did not bind to the con a resin. the bovine serum had been used in the culture medium initially when the cell line was adapted to the serum-free medium and bsa was a major component. therefore, the con a chromatography is more like a step of prorenin enrichment and any major contaminants were removed subsequently with cation exchange chromatography. after the hollow fiber bioreactor system was set up for the prorenin expression, the conditioned medium was collected, about ml a day, which was pooled and loaded onto the con a column. for one typical manageable purification experiment, 250– ml containing approximately mg proteins was used. the column was washed until the baseline was stabilized. in order to improve the yields, the column was ""soaked and then eluted"" with the buffer containing d-methyl-mannopyranoside at the low flow rate. usually, two or three cycles of the soaking/eluting were applied in order to maximize the recovery. the volume of the pooled materials containing mainly prorenin was reduced to approximately ml by the millipore ultrafiltration device, followed by activation and further purification. no other detectable endogenous con a binding proteins were observed by coomasie stained sds-page gels. the con a material was converted to active renin by digestion with trypsin. trypsin cleaves after residue arg conditions were optimized using different temperature, time and amounts of trypsin. the final conditions were described in the experimental section and provide mild proteolysis for quantitative conversion of prorenin to active renin. prolonged trypsin treatment did not appear to result in any internal cleavage of the protein, and generally one hour incubation at 4°c with trypsin afforded a complete conversion from prorenin to renin indicating that the propeptide trypsin-cleavage site was accessible. after digestion, trypsin was removed with trypsin-inhibitor agarose beads. any other contaminants or misfolded renin proteins were removed with cation exchange chromatography. approximately 60–70% of the total proteins were removed at this step. the final step of purification involved with a size exclusion column, resulting in a purified activated renin of >98% purity, as estimated by the reducing sds-page analysis. the conversion of prorenin to renin by trypsin results in removal of amino acids, approximately kda. because of heterogeneous nature of glycosylation, prorenin and renin migrated on the sds-page gel as broad bands of around kda and kda, respectively. the proteins were analyzed by the n-terminal sequencing and mass spectrometry for further characterization of the proteolytic activation. the n-terminal sequence analysis confirmed that the first residues of the mature renin were ltlgxt and verified the complete removal of the propeptide. the x represents the asparagine residue which is a glycosylation site. mass spectrometry analysis indicated that glycosylation of renin added from to kda to the molecular weight, based on the calculated dna-deduced amino acid sequence. the discrepancy of molecular weights might be related to variations in growth conditions and reagents from batch to batch because of the heterogeneous nature of glycosylation. the sugar moieties were removable by endoglycosidase h treatment only in partially denatured proteins under conditions of 1% sds at 37°c overnight. in our crystallization studies and biological assays, the sugar moieties were not removed. typically, 1– mg of protein could be obtained from one batch of purification using approximately – ml starting conditioned medium, depending on cell well-being, growth conditions and other procedural irregularities. *the representative major molecular weight peak from several batch of samples. the activated renin was characterized in a functional assay. the catalytic activity was measured using the commercially available substrate, dabcyl-γabu-ile-his-pro-phe-his-leu-val-ile-his-thr-edans, which is based on the angiotensinogen sequence. velocity of reaction was initially followed by hplc and exhibited hyperbolic dependence on substrate concentration consistent with michaelis-menten kinetics with an apparent km of μm. this value is similar to the km of μm reported in the literature based on the fret assay. the catalytic efficiency of recombinant rennin was determined using the dabcyl-edans substrate. the enzyme had a second order rate constant of × m-1s- this value is close to the published catalytic efficiency of × m-1s- and × m-1s- for the cleavage of angiotensinogen tetradecapeptide by purified human renin. enzymatic activity of the recombinant human renin was measured in a ph-rate profile. activity was measured between ph and in ph units. the maximum activity was observed at ph, similar to purified human renin. the peak and the shoulder of the ph profile were similar to those observed for purified human renin cleaving partially purified human angiotensinogen with the maxima at ~ and. several well characterized inhibitors of human renin were tested with the recombinant enzyme. these inhibitors included commercially available statines and the small molecule inhibitor aliskiren. pepstatin a is a potent inhibitor of several aspartic proteases including cathepsin e, cathepsin d and hiv protease. human renin is poorly inhibited by pepstatin a, while porcine renin exhibits sub-micromolar inhibition constants with this compound. the recombinant human renin was inhibited by pepstatin a with an ic of ± μm, similar to literature values. sr is a pepstatin analog that inhibits human plasma renin activity with the ic of nm. the compound is potent against purified recombinant human renin with an ic of ± nm the recombinant renin was also inhibited by aliskiren, a potent human renin inhibitor currently marketed for hypertension as tekturna. aliskiren is selective for human renin with a reported ic of nm. in our hands, ic value for recombinant human renin was ± nm. the recombinant renin is indistinguishable from renin purified from human sources and stable after long term storage at -80°c. the material is suitable for functional assays and x-ray crystallography. the material had been used to generate > renin inhibitor complexes ranging from Å– Å resolution. a typical experiment is shown with vtp. vtp is a weak inhibitor of ic nm. co-crystals of this compound were obtained by the hanging drop method. these crystals diffracted at Å. this complex can be used for soaking studies with potent inhibitors, which readily displace vtp generating high quality crystals. details on the structural solutions of vtp and additional structures will be reported separately.  this present work describes a simple, efficient method for the production and purification of active human renin. recombinant renin can be generated in milligram quantities via a simple activation/purification sequence. biochemical properties of the recombinant human renin are indistinguishable from those reported in the literature for purified enzyme. renin inhibitors were active against the recombinant enzyme with potencies very similar to the inhibition constants measured for purified human renin. the material is highly pure and is suitable for supporting activity assays and structural biology efforts. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
22,c6820589-a011-434f-bbb1-68f680b21e06_flant5_gen,a surveillance study of macrolide susceptibility of invasive pneumococcal disease in germany between and," streptococcus pneumoniae is a leading pathogen in bacterial pneumonia, sepsis and meningitis in humans worldwide. in many european countries the rate of resistance of s. pneumoniae to macrolides has exceeded that of penicillin. concerning penicillin, it has been described that treatment of patients with nonmeningeal invasive pneumococcal infections with nonsusceptible isolates was not associated with higher mortality rates. in new penicillin breakpoints for s. pneumoniae were published by the clsi, differentiating meningitis and non-meningitis cases of invasive pneumococcal disease. their impact on susceptibility categorisation in germany was described previously by our group. however, for macrolides an increased risk of macrolide failure has been reported for pneumococcal isolates nonsusceptible in vitro. the aim of this study was to evaluate macrolide susceptibility of all isolates of s. pneumoniae with ipd that were sent to the german national reference center for streptococci between and and to evaluate potential trends in nonsusceptibility over time. the description of serotype specific resistance, was a major aim of the study. the study was undertaken against the background of the recent observation of declining macrolide resistance rates especially among german children. methods study design the nrcs has conducted surveillance for invasive pneumococcal disease in germany since a population- and laboratory-based approach was used to collect data on invasive pneumococcal disease among children < years and adults ≥ years in germany. isolates were sent to the nrcs by diagnostic microbiological laboratories throughout germany on a voluntary basis. cases from january to december were included in this study. a case of ipd was defined by the isolation of s. pneumoniae from a normally sterile site. microbiological investigations isolates were identified by standard procedures including bile solubility and optochin sensitivity. minimal inhibitory concentrations testing was performed using the broth microdilution method as recommended by the clinical and laboratory standards institute. macrolide resistance was investigated using erythromycin or clarithromycin, in which testing with erythromycin was replaced by clarithromycin over the years. isolates were tested both for erythromycin and clarithromycin. the susceptible, intermediate, and resistant breakpoints were ≤,, and ≥ μg/ml, both for erythromycin and clarithromycin. streptococcus pneumoniae atcc was used as a control strain. statistical analysis all categorical data were expressed as frequencies. to analyse a severe increase or decrease over time the cochran-armitage test was used. the overall significance level was adjusted using the bonferroni correction to account for the problem of multiple testing. due to tests p-values ≤ were considered as statistically significant test results. all statistical analyses were conducted using sas version..  in total, isolates from invasive pneumococcal disease were collected between january and december the number of cases for each year vary between and. data on macrolide susceptibility were available for isolates, whereas isolates originated from adults, isolates were from children. the overall nonsusceptibility rate of all isolates was %. higher resistance rates were observed among children than among adults. sero i%, intermediate isolates in percent; r%, resistant isolates in percent; s%, susceptible isolates in percent; n, number of isolates tested. total † represents the number of isolates collected from both children and adults. total ‡ represents the serotype distribution in percent in relation to the number of ipd isolates serotyped. others* includes the serotypes: 15f, 18b, 7c, 10f, 11b, 35a,,, 24a, 28f, 35c,, 22a,, 7a, 24b, 25f,,, 7b, 17a,,,,. the sampling source related nonsusceptibility is shown in table highest nonsusceptibility rates were observed for pharyngeal isolates, pericardium and mastoid. nonsusceptibility rates for csf and blood were % and %, respectively. the serotype distribution broken down to the sampling source is shown in table for blood, csf and bal serotype is most prevalent, whereas for pleural fluid serotypes and are most often found. sero only sampling sites with ≥ isolates were included in this table. nt: nontypeable; n: number of isolates tested. others* includes the serotypes: rough, 9l, 23b,, 18f, 12a,, 28a, 35b, 10b, 15f, 18b, 12b, 33b, 7c, 10f, 11b, 11f, 35a, 7a, 19c,,, 24a, 28f, 35c,, 19b, 22a,,, 7b, 24b, 25f,,, 17a,,,. as for the childhood ipd isolates in the first year of this study, % were intermediate and % resistant to macrolides. maximum nonsusceptibility rates during the period under study were observed in, while in % of isolates were intermediate and % resistant. ipd isolates obtained from adults were intermediate in % and resistant in % in maximum nonsusceptibility rates were observed in as well. nonsusceptibility rates in were % and %. the increase in macrolide nonsusceptibility from to was statistically significant for children and adults, as well as the decrease from to. concerning the intermediate resistant isolates no significant trends were observed, adults; 2005-2008: children, adults ). detailed results of the macrolide susceptibility testing are shown in figure the mics of all invasive isolates are illustrated in figure overall, the leading serotypes were serotypes,, 7f, and 23f. a ranking of serotype specific macrolide nonsusceptibility of ipd isolates is shown in table serotype was by far the most resistant serotype, followed by serotypes rough, 19b,, 6b, 15a, 19f, and 19a. however, absolute numbers for rough, 19b and were very low. serotypes contributing considerably to pneumococcal macrolide nonsusceptibility by combination of frequency among invasive isolates and relatively high macrolide nonsusceptibility are especially serotypes 6b, 19f, 19a, 9v and 23f. the development of nonsusceptibility of these serotypes over the years is shown in figure the nonsusceptibility among serotype isolates increases considerably over the years up to around 80%. for serotype 19f a significant increase in nonsusceptibility was observed as well. no significant trends were found for serotypes 6b, 9v, 19a and 23f. the peak in nonsusceptibility among 7-, 10- and 13-valent serotypes in adults from to correlates to an increased incidence of serotype during that time. generally, the rate of resistance is higher among the vaccine serotypes than among the non vaccine serotypes. the proportion of nonsusceptible 7-valent vaccine serotypes remained largely constant from to among children. among the non pcv serotypes the rate of nonsusceptibility is lower. concerning adults, an increase of isolates sent to the nrcs can be noticed. the fraction of nonsusceptible isolates has declined during the last years among 7-valent vaccine serotypes after a notable increase from to. discussion and  this paper presents the results of years of surveillance for macrolide susceptibility of invasive pneumococcal disease in germany. the prevalence of antibiotic-resistant s. pneumoniae continues to increase worldwide but varies widely between countries. in europe, high resistance rates for macrolides have been reported from france, spain, italy and belgium. pneumococcal macrolide resistance rates reported from germany were low. nevertheless, a continuous and statistically significant increase of macrolide nonsusceptibility could be observed after publication of these studies, reaching maximum values in. the relatively high rate of variation in resistance among childhood isolates during the first years of the study is presumably due to the low number of cases, and a suspected bias for resistant isolates among the centers sending the isolates. since a considerable and statistically significant decrease especially for childhood nonsusceptibility has been noticed. these data are similar to those recently reported from spain, where a reduction of erythromycin nonsusceptibility from % in to % in has been described. an increased awareness of ipd among adults has been observed since this correlates to the general recommendation of pneumococcal conjugate vaccination for children < years in germany at the end of july and an increased interest in serotype information of ipd. furthermore, in january an internet based laboratory sentinel system was established in germany, which enables participating laboratories to transfer anonymised basic patient information on a voluntary basis. compared to children, only a minor reduction of nonsusceptibility has been observed among adults from to, although this reduction was also statistically significant. possible reasons for the decrease in macrolide nonsusceptibility include a reduced macrolide consumption due to the rising resistance rates, as well as the general recommendation of pneumococcal conjugate vaccination for children < years in germany at the end of july since the introduction of the vaccine a considerable decrease of serotypes included in the 7-valent pneumococcal conjugate vaccine has been observed among german children, but also among adults, which is partly due to the association of serotypes with age. the antibiotic prescribing practices, which are thought to be among the most significant drivers for the spread of pneumococcal resistance, differ vastly between european countries. a decrease in the use of macrolides has been reported for instance in spain, portugal, belgium, slovenia and taiwan. the influence of a decreased macrolide consumption on macrolide susceptibility is discussed controversially. in spain a relation between the decrease in macrolide consumption and the decrease in erythromycin non-susceptibility among children could be shown, while this effect was absent among the adult population, probably due to the increase in non-vaccine serotypes such as 19a. reports from other countries showed no decrease in macrolide nonsusceptibility following a reduced macrolide consumption. besides the total macrolide consumption, the influence of long lasting macrolides, which may increase even in times of decreasing total macrolide consumption, is discussed to be a cause of the macrolide nonsusceptibility. besides antibiotics, pneumococcal conjugate vaccination is another important factor associated with changes in macrolide susceptibility. in our study, high rates of serotype specific resistance among the more frequent serotypes were observed among the serotypes 6b, 19f and 23f, in particular. these results are in line with results from germany published previously by the nrcs for invasive and respiratory tract isolates and comparable to results reported from several european countries. notably, a statistically significant trend in increasing macrolide resistance was seen for serotypes and 19f. however, since both serotypes are included in the pneumococcal conjugate vaccines, a future reduction of these serotypes can be expected. the low rate of macrolide nonsusceptibility among isolates not serotyped corresponds to the fact, that high resistance levels were a main trigger for initiation of serotyping during the early years of this study, when consistent serotyping of all isolates was not conducted due to excessive costs. in spite of all these observations, because the impact of preventive and therapeutic strategies on pneumococcal evolution not only depends on, but also influences the serotype distribution, when normal temporal and regional variations of serotype distribution are taken into consideration, future developments remain difficult to predict. ongoing nationwide surveillance is necessary to observe further developments of pneumococcal macrolide resistance in germany. authors' contributions mi performed the analysis and drafted the manuscript. cm performed the statistical analysis. mi, rrr and ml participated in the laboratory analyses. mi, rrr and ml conceived the study. all authors read and approved the final manuscript. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
23,c6820589-a011-434f-bbb1-68f680b21e06_gpt3_gen,"The article discusses the results of a study on the macrolide susceptibility of isolates of Streptococcus pneumoniae with invasive pneumococcal disease (IPD) in Germany between 2004 and 2013. The study found that macrolide resistance rates have been increasing, particularly for certain serotypes, but have recently decreased, potentially due to reduced macrolide consumption and pneumococcal conjugate vaccination. The authors emphasize the need for ongoing surveillance to monitor resistance rates and the impact of preventative and therapeutic strategies on pneumococcal evolution."," streptococcus pneumoniae is a leading pathogen in bacterial pneumonia, sepsis and meningitis in humans worldwide. in many european countries the rate of resistance of s. pneumoniae to macrolides has exceeded that of penicillin. concerning penicillin, it has been described that treatment of patients with nonmeningeal invasive pneumococcal infections with nonsusceptible isolates was not associated with higher mortality rates. in new penicillin breakpoints for s. pneumoniae were published by the clsi, differentiating meningitis and non-meningitis cases of invasive pneumococcal disease. their impact on susceptibility categorisation in germany was described previously by our group. however, for macrolides an increased risk of macrolide failure has been reported for pneumococcal isolates nonsusceptible in vitro. the aim of this study was to evaluate macrolide susceptibility of all isolates of s. pneumoniae with ipd that were sent to the german national reference center for streptococci between and and to evaluate potential trends in nonsusceptibility over time. the description of serotype specific resistance, was a major aim of the study. the study was undertaken against the background of the recent observation of declining macrolide resistance rates especially among german children. methods study design the nrcs has conducted surveillance for invasive pneumococcal disease in germany since a population- and laboratory-based approach was used to collect data on invasive pneumococcal disease among children < years and adults ≥ years in germany. isolates were sent to the nrcs by diagnostic microbiological laboratories throughout germany on a voluntary basis. cases from january to december were included in this study. a case of ipd was defined by the isolation of s. pneumoniae from a normally sterile site. microbiological investigations isolates were identified by standard procedures including bile solubility and optochin sensitivity. minimal inhibitory concentrations testing was performed using the broth microdilution method as recommended by the clinical and laboratory standards institute. macrolide resistance was investigated using erythromycin or clarithromycin, in which testing with erythromycin was replaced by clarithromycin over the years. isolates were tested both for erythromycin and clarithromycin. the susceptible, intermediate, and resistant breakpoints were ≤,, and ≥ μg/ml, both for erythromycin and clarithromycin. streptococcus pneumoniae atcc was used as a control strain. statistical analysis all categorical data were expressed as frequencies. to analyse a severe increase or decrease over time the cochran-armitage test was used. the overall significance level was adjusted using the bonferroni correction to account for the problem of multiple testing. due to tests p-values ≤ were considered as statistically significant test results. all statistical analyses were conducted using sas version..  in total, isolates from invasive pneumococcal disease were collected between january and december the number of cases for each year vary between and. data on macrolide susceptibility were available for isolates, whereas isolates originated from adults, isolates were from children. the overall nonsusceptibility rate of all isolates was %. higher resistance rates were observed among children than among adults. sero i%, intermediate isolates in percent; r%, resistant isolates in percent; s%, susceptible isolates in percent; n, number of isolates tested. total † represents the number of isolates collected from both children and adults. total ‡ represents the serotype distribution in percent in relation to the number of ipd isolates serotyped. others* includes the serotypes: 15f, 18b, 7c, 10f, 11b, 35a,,, 24a, 28f, 35c,, 22a,, 7a, 24b, 25f,,, 7b, 17a,,,,. the sampling source related nonsusceptibility is shown in table highest nonsusceptibility rates were observed for pharyngeal isolates, pericardium and mastoid. nonsusceptibility rates for csf and blood were % and %, respectively. the serotype distribution broken down to the sampling source is shown in table for blood, csf and bal serotype is most prevalent, whereas for pleural fluid serotypes and are most often found. sero only sampling sites with ≥ isolates were included in this table. nt: nontypeable; n: number of isolates tested. others* includes the serotypes: rough, 9l, 23b,, 18f, 12a,, 28a, 35b, 10b, 15f, 18b, 12b, 33b, 7c, 10f, 11b, 11f, 35a, 7a, 19c,,, 24a, 28f, 35c,, 19b, 22a,,, 7b, 24b, 25f,,, 17a,,,. as for the childhood ipd isolates in the first year of this study, % were intermediate and % resistant to macrolides. maximum nonsusceptibility rates during the period under study were observed in, while in % of isolates were intermediate and % resistant. ipd isolates obtained from adults were intermediate in % and resistant in % in maximum nonsusceptibility rates were observed in as well. nonsusceptibility rates in were % and %. the increase in macrolide nonsusceptibility from to was statistically significant for children and adults, as well as the decrease from to. concerning the intermediate resistant isolates no significant trends were observed, adults; 2005-2008: children, adults ). detailed results of the macrolide susceptibility testing are shown in figure the mics of all invasive isolates are illustrated in figure overall, the leading serotypes were serotypes,, 7f, and 23f. a ranking of serotype specific macrolide nonsusceptibility of ipd isolates is shown in table serotype was by far the most resistant serotype, followed by serotypes rough, 19b,, 6b, 15a, 19f, and 19a. however, absolute numbers for rough, 19b and were very low. serotypes contributing considerably to pneumococcal macrolide nonsusceptibility by combination of frequency among invasive isolates and relatively high macrolide nonsusceptibility are especially serotypes 6b, 19f, 19a, 9v and 23f. the development of nonsusceptibility of these serotypes over the years is shown in figure the nonsusceptibility among serotype isolates increases considerably over the years up to around 80%. for serotype 19f a significant increase in nonsusceptibility was observed as well. no significant trends were found for serotypes 6b, 9v, 19a and 23f. the peak in nonsusceptibility among 7-, 10- and 13-valent serotypes in adults from to correlates to an increased incidence of serotype during that time. generally, the rate of resistance is higher among the vaccine serotypes than among the non vaccine serotypes. the proportion of nonsusceptible 7-valent vaccine serotypes remained largely constant from to among children. among the non pcv serotypes the rate of nonsusceptibility is lower. concerning adults, an increase of isolates sent to the nrcs can be noticed. the fraction of nonsusceptible isolates has declined during the last years among 7-valent vaccine serotypes after a notable increase from to. discussion and  this paper presents the results of years of surveillance for macrolide susceptibility of invasive pneumococcal disease in germany. the prevalence of antibiotic-resistant s. pneumoniae continues to increase worldwide but varies widely between countries. in europe, high resistance rates for macrolides have been reported from france, spain, italy and belgium. pneumococcal macrolide resistance rates reported from germany were low. nevertheless, a continuous and statistically significant increase of macrolide nonsusceptibility could be observed after publication of these studies, reaching maximum values in. the relatively high rate of variation in resistance among childhood isolates during the first years of the study is presumably due to the low number of cases, and a suspected bias for resistant isolates among the centers sending the isolates. since a considerable and statistically significant decrease especially for childhood nonsusceptibility has been noticed. these data are similar to those recently reported from spain, where a reduction of erythromycin nonsusceptibility from % in to % in has been described. an increased awareness of ipd among adults has been observed since this correlates to the general recommendation of pneumococcal conjugate vaccination for children < years in germany at the end of july and an increased interest in serotype information of ipd. furthermore, in january an internet based laboratory sentinel system was established in germany, which enables participating laboratories to transfer anonymised basic patient information on a voluntary basis. compared to children, only a minor reduction of nonsusceptibility has been observed among adults from to, although this reduction was also statistically significant. possible reasons for the decrease in macrolide nonsusceptibility include a reduced macrolide consumption due to the rising resistance rates, as well as the general recommendation of pneumococcal conjugate vaccination for children < years in germany at the end of july since the introduction of the vaccine a considerable decrease of serotypes included in the 7-valent pneumococcal conjugate vaccine has been observed among german children, but also among adults, which is partly due to the association of serotypes with age. the antibiotic prescribing practices, which are thought to be among the most significant drivers for the spread of pneumococcal resistance, differ vastly between european countries. a decrease in the use of macrolides has been reported for instance in spain, portugal, belgium, slovenia and taiwan. the influence of a decreased macrolide consumption on macrolide susceptibility is discussed controversially. in spain a relation between the decrease in macrolide consumption and the decrease in erythromycin non-susceptibility among children could be shown, while this effect was absent among the adult population, probably due to the increase in non-vaccine serotypes such as 19a. reports from other countries showed no decrease in macrolide nonsusceptibility following a reduced macrolide consumption. besides the total macrolide consumption, the influence of long lasting macrolides, which may increase even in times of decreasing total macrolide consumption, is discussed to be a cause of the macrolide nonsusceptibility. besides antibiotics, pneumococcal conjugate vaccination is another important factor associated with changes in macrolide susceptibility. in our study, high rates of serotype specific resistance among the more frequent serotypes were observed among the serotypes 6b, 19f and 23f, in particular. these results are in line with results from germany published previously by the nrcs for invasive and respiratory tract isolates and comparable to results reported from several european countries. notably, a statistically significant trend in increasing macrolide resistance was seen for serotypes and 19f. however, since both serotypes are included in the pneumococcal conjugate vaccines, a future reduction of these serotypes can be expected. the low rate of macrolide nonsusceptibility among isolates not serotyped corresponds to the fact, that high resistance levels were a main trigger for initiation of serotyping during the early years of this study, when consistent serotyping of all isolates was not conducted due to excessive costs. in spite of all these observations, because the impact of preventive and therapeutic strategies on pneumococcal evolution not only depends on, but also influences the serotype distribution, when normal temporal and regional variations of serotype distribution are taken into consideration, future developments remain difficult to predict. ongoing nationwide surveillance is necessary to observe further developments of pneumococcal macrolide resistance in germany. authors' contributions mi performed the analysis and drafted the manuscript. cm performed the statistical analysis. mi, rrr and ml participated in the laboratory analyses. mi, rrr and ml conceived the study. all authors read and approved the final manuscript. ",pubmed_generic,GPT 3.5,The article discusses the results of a study on the macrolide susceptibility of isolates of Streptococcus pneumoniae with invasive pneumococcal disease (IPD) in Germany between 2004 and 2013.,factual,non_factual,,minor,,extrinsic,,factual,,Dates are not mentioned in the article . 
24,62c46fc7-05d6-419d-864f-fec1f9c8cd76_gpt3_gen,"The article discusses the challenges associated with studying gene function in vivo using gene knock-out technology. In some cases, constitutive gene deletion is either lethal or deleterious for embryonic development, making it necessary to induce gene deletion in a tissue-specific or time-specific manner. The article outlines the use of the cre-lox recombination system for tissue-specific gene knock-out models and highlights the issue of incomplete deletion due to variability in cre recombinase expression. The conventional approach to determine the ratio of 1lox to 2lox alleles is southern blotting, which has several limitations. The article presents a probe-based real-time PCR protocol that allows accurate quantification of 1lox/2lox allele ratios in genomic DNA and can be used for all models using Cre-lox mediated gene recombination. The article also discusses potential pitfalls, particularly when using Sybr Green-based protocols. The article presents an example of the protocol’s use in conditional deletion of DNA methyltransferase 3a in tumorigenesis in mice. The assay was able to measure 1lox/2lox allele ratios using small amounts of DNA and was shown to be highly reproducible and accurate. The article concludes that the probe-based real-time PCR assay is a highly attractive alternative to conventional southern blotting and can detect small differences in 1lox/2lox allele ratios with improved specificity."," gene knock out technology is widely used to study gene function in vivo, however in some cases constitutive gene deletion is either lethal or deleterious for embryonic development precluding analysis of the adult organism. in these instances it is necessary to induce gene deletion in a tissue specific or time specific manner. tissue specific gene knock out models are most often constructed using the cre-lox recombination system. for this, the sequence of interest is flanked by loxp sites and conditional deletion is achieved by tissue specific expression of the cre recombinase enzyme. due to variability in cre recombinase expression however, deletion of the gene of interest is frequently incomplete. in such cases the tissue of interest would consist of a mixture of cells containing either the functional allele or the truncated allele. clearly, the ratio of 2lox containing cells to 1lox containing cells can have a profound impact on the outcome of the experiment. also, in many cases the ratio of these two cell types can change over time, particularly in regenerating tissues, causing additional variability in the phentotype. in the worst case the presence of cells with the functional 2lox allele can fully mask the effect of the gene deletion. for example if tumors are detected following the conditional deletion of a tumor relevant enzyme it is possible that such tumors are formed by residual 2lox cells. therefore to better understand the phenotype of such experiments it is imperative to accurately measure the relative presence of 1lox and 2lox alleles at various time points of the study. the conventional approach to determine the ratio of 1lox to 2lox alleles is southern blotting. this method however is time consuming, requires large amounts of dna and has a relatively low sensitivity and low dynamic range. therefore alternative methods such as competitive endpoint pcr and emlpa have also been used. however since many laboratories routinely use real-time pcr for quantitative rna or dna sequence analysis we decided to develop a real-time pcr based assay to measure 1lox/2lox allele ratios. we here present a universally applicable probe based real-time pcr protocol that allows accurate quantification of 1lox/2lox allele ratios in genomic dna. this assay is conveniently adaptable to all models using cre-lox mediated gene recombination. in addition we demonstrate and discuss potential pitfalls in particular when using sybr green based protocols.  to evaluate the role of dna methyltransferase 3a in tumorigenesis we induced conditional deletion of dnmt3a ) in intestinal epithelial cells of apc mice using a cre recombinase transgene under control of the modified fatty acid binding protein promoter ). as published previously, fabpl4× at -132-cre mediated gene deletion in epithelial cells of the intestinal tract is incomplete. it was therefore necessary to quantify the ratio of the functional dnmt3a 2lox allele and the truncated dnmt3a 1lox allele in the intestinal mucosa and in intestinal tumors of transgenic mice. to allow processing of large sample numbers with small amounts of dna we tested whether 1lox/2lox allele ratios could be measured using a real-time pcr based assay testing of sybr green based real-time pcr for analysis of conditional gene deletion to allow analysis of gene deletion using sybr green based real-time pcr we designed primers allowing specific amplification of the 1lox and 2lox allele repectively. as illustrated in figure 1a positioning of the 2lox specific primers is comparatively easy because they can be placed anywhere within the potentially deleted region. however it has to be considered that in some cases the excised gene fragment can persist, particularly in non-proliferating tissue after initiation of cre expression. therefore in such cases - in tissues with low mitotic activity and shortly after induction of cre expression - 2lox primer placement in analogy to figure 2a might be preferable. when designing 1lox specific primers, care has to be taken to place them within unique genomic sequences flanking the remaining loxp site of the truncated 1lox allele. however, when following this approach to quantify conditional dnmt3a deletion in our mice we noted the continuous presence of a double peak in the melting curve of the 1lox reaction. this double peak persisted even when choosing different annealing temperatures, multiple alternative primer pairs for the 1lox reaction, different primer concentrations and different dna concentrations. since the presence of two peaks in the melting curve of sybr green based real-time pcr assays frequently indicates the presence of two different amplicons we analyzed the resulting pcr product using both gel electrophoresis and capillary electrophoresis. surprisingly, although we had observed two peaks in the melting curve analysis, we could identify only one distinctive pcr product. furthermore when we size selected the pcr product using gel purification to exclude primers and alternative products and repeated the melting curve analysis we reproduced the same double peak, suggesting that the amplified sequence itself was responsible for this aberrant signal. a possible explanation for this observation is that the palindromic loxp sequence motif could serve as a core motif that promotes annealing of sense/sense and antisense/antisense strands or possibly the formation of hairpins. such hybridization products/hairpins would have a lower melting temperature than antisense/sense hybrids and therefore contribute to a second peak in melting curve analysis. since the melting curve is critical for quality control in sybr green assays, data with an aberrant double peak are frequently excluded from further analysis. our example illustrates that sybr green based assays are not only limited by possible amplification and measurement of nonspecific pcr products but are also potentially affected by alternate re-annealing or secondary structures of the specific pcr product itself. in agreement with our own data, difficulties with sybr green based analysis of 1lox/2lox allele ratios have also been reported independently. to resolve such potential difficulties of sybr green based analysis of loxp containing sequences we therefore developed an alternative assay to quantify 1lox/2lox allele ratios using a probe based real-time pcr approach. our aim was to establish a universal probe that could be used for all reactions and models of cre-lox mediated gene deletion such that only the flanking primer sequences need to be adapted. such an assay would combine the convenience of a sybr green based assay with the specificity of a probe based assay. testing of probe based real-time pcr for analysis of conditional gene deletion to establish a probe based assay for the 1lox and 2lox reaction respectively we selected a hydrolysis probe that specifically binds to the loxp site itself and designed primers flanking the loxp site as illustrated in figure 2a. the use of a probe covering the loxp site allowed us to use the same probe for both the 1lox and lox reaction. to generate allele specific standards that would allow us to validate the assay and test its accuracy we cloned 1lox and 2lox specific pcr products into a ta vector and verified resulting clones by sequencing. to generate standards for real-time pcr we then released allele specific fragments by restriction digest and mixed the fragments at variable molar ratios. the resulting 1lox/2lox standards were verified using capillary electrophoresis, which confirmed the expected ratios. to determine the relative efficiency of the 1lox and 2lox specific real-time pcr reaction and to detect possible interference between the two alleles we conducted real-time pcr using 1: dilutions of the above mentioned fragment mixtures. as illustrated in figure 2c we observed a linear correlation between the crossing point and log concentration data for both reactions, with all data points close to the curve, indicating that the efficiency of both reactions was not affected by variable admixtures of the other allele. to further test the accuracy of the real-time pcr assay we conducted quantitive pcr, using incremental standards ranging from 9/ to 1/ and calculated allele ratios from the measured data. as summarized in figure 3a the 1lox/2lox allele ratios as determined by the probe based real-time pcr assay closely reflected allele ratios measured by capillary electrophoresis and the expected allele ratios. testing of probe based real-time pcr for analysis of cre-lox recombination in fabpl4× at -132-cre transgenic mice after establishing the accuracy of the method we measured conditional deletion of dnmt3a in intestinal epithelial cells of fabpl4× at -132-cre transgenic mice. for this we harvested intestinal epithelial cells from the proximal, middle and distal third of the small intestine of dnmt3a, fabpl4× at -132-cre mice and measured 1lox/2lox allele ratios using real-time pcr. as shown in figure 3d we detected a low deletion efficiency in the proximal small intestine and increasing deletion efficiency in the distal small intestine, with the 1lox/2lox allele ratio varying from to approximately respectively. importantly the data of the two cre+ mice were highly similar and the variation within the sample replicates was very low, confirming the reproducibility of the method. also, these results are in good agreement with published data on the same fabpl4× at -132-cre strain using northern blotting and immunohistochemistry, which further confirms the utility of the assay. discussion real-time pcr is clearly preferable to southern blotting when attempting to quantify conditional gene deletion: real-time pcr offers a higher sensitivity, requires significantly smaller dna samples and requires much less processing time. this is particularly useful when allele ratios have to be measured in small samples at several time points, such as in conditional deletion experiments involving hematopoetic stem cells. surprisingly, only one study formally evaluated this technical approach, however without testing the ability of the method to detect small changes in allele ratios. in principle either sybr green based protocols or probe based protocols can be used for real-time pcr. sybr green based assays are very popular because of the relatively low cost and the convenient implementation requiring primer design only. however, as illustrated by our example, it appears that sybr green based protocols for quantification of conditional gene deletion, are potentially complicated by the palindromic sequence of the loxp site. we show that pcr products containing this sequence, such as the 1lox specific pcr product, can generate double peaks during melting curve analysis, likely due to alternate product hybridization, which can complicate quality control of the reaction. in such cases it is uncertain whether the double peak reflects the presence of an additional nonspecific pcr product or not. we therefore suggest that it is generally preferable to use a probe based real-time pcr approach, which avoids such erroneous signals and offers improved specificity. the hydrolysis probe established in our protocol, that is used for analysis of both alleles, recognizes the loxp site itself and is therefore universally applicable to any assay measuring 1lox/2lox allele ratios. to adapt the assay to other conditional alleles it is therefore only necessary to place primer pairs in the unique genomic sequence flanking the loxp sites. our data support the notion that such probe based real-time pcr analysis allows reproducible and accurate measurement of 1lox/2lox allele ratios with small amounts of dna and is therefore a highly attractive alternative to conventional southern blotting.  our results suggest that probe based real-time pcr can accurately detect small differences in 1lox/2lox allele ratios with improved specificity. our protocol requires the use of one probe only for all reactions. this probe is directed against the loxp site itself and is therefore universally applicable to any assay analyzing cre-lox recombination efficiency, such that only the primer sequences have to be adapted. our assay therefore combines the convenience of sybr green based analysis with the specificity of probe based analysis and is applicable to all models of cre-lox mediated conditional gene deletion. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
25,62c46fc7-05d6-419d-864f-fec1f9c8cd76_flant5_gen,We present a universally applicable probe based real-time pcr protocol that allows accurate quantification of 1lox/2lox allele ratios in genomic dna.," gene knock out technology is widely used to study gene function in vivo, however in some cases constitutive gene deletion is either lethal or deleterious for embryonic development precluding analysis of the adult organism. in these instances it is necessary to induce gene deletion in a tissue specific or time specific manner. tissue specific gene knock out models are most often constructed using the cre-lox recombination system. for this, the sequence of interest is flanked by loxp sites and conditional deletion is achieved by tissue specific expression of the cre recombinase enzyme. due to variability in cre recombinase expression however, deletion of the gene of interest is frequently incomplete. in such cases the tissue of interest would consist of a mixture of cells containing either the functional allele or the truncated allele. clearly, the ratio of 2lox containing cells to 1lox containing cells can have a profound impact on the outcome of the experiment. also, in many cases the ratio of these two cell types can change over time, particularly in regenerating tissues, causing additional variability in the phentotype. in the worst case the presence of cells with the functional 2lox allele can fully mask the effect of the gene deletion. for example if tumors are detected following the conditional deletion of a tumor relevant enzyme it is possible that such tumors are formed by residual 2lox cells. therefore to better understand the phenotype of such experiments it is imperative to accurately measure the relative presence of 1lox and 2lox alleles at various time points of the study. the conventional approach to determine the ratio of 1lox to 2lox alleles is southern blotting. this method however is time consuming, requires large amounts of dna and has a relatively low sensitivity and low dynamic range. therefore alternative methods such as competitive endpoint pcr and emlpa have also been used. however since many laboratories routinely use real-time pcr for quantitative rna or dna sequence analysis we decided to develop a real-time pcr based assay to measure 1lox/2lox allele ratios. we here present a universally applicable probe based real-time pcr protocol that allows accurate quantification of 1lox/2lox allele ratios in genomic dna. this assay is conveniently adaptable to all models using cre-lox mediated gene recombination. in addition we demonstrate and discuss potential pitfalls in particular when using sybr green based protocols.  to evaluate the role of dna methyltransferase 3a in tumorigenesis we induced conditional deletion of dnmt3a ) in intestinal epithelial cells of apc mice using a cre recombinase transgene under control of the modified fatty acid binding protein promoter ). as published previously, fabpl4× at -132-cre mediated gene deletion in epithelial cells of the intestinal tract is incomplete. it was therefore necessary to quantify the ratio of the functional dnmt3a 2lox allele and the truncated dnmt3a 1lox allele in the intestinal mucosa and in intestinal tumors of transgenic mice. to allow processing of large sample numbers with small amounts of dna we tested whether 1lox/2lox allele ratios could be measured using a real-time pcr based assay testing of sybr green based real-time pcr for analysis of conditional gene deletion to allow analysis of gene deletion using sybr green based real-time pcr we designed primers allowing specific amplification of the 1lox and 2lox allele repectively. as illustrated in figure 1a positioning of the 2lox specific primers is comparatively easy because they can be placed anywhere within the potentially deleted region. however it has to be considered that in some cases the excised gene fragment can persist, particularly in non-proliferating tissue after initiation of cre expression. therefore in such cases - in tissues with low mitotic activity and shortly after induction of cre expression - 2lox primer placement in analogy to figure 2a might be preferable. when designing 1lox specific primers, care has to be taken to place them within unique genomic sequences flanking the remaining loxp site of the truncated 1lox allele. however, when following this approach to quantify conditional dnmt3a deletion in our mice we noted the continuous presence of a double peak in the melting curve of the 1lox reaction. this double peak persisted even when choosing different annealing temperatures, multiple alternative primer pairs for the 1lox reaction, different primer concentrations and different dna concentrations. since the presence of two peaks in the melting curve of sybr green based real-time pcr assays frequently indicates the presence of two different amplicons we analyzed the resulting pcr product using both gel electrophoresis and capillary electrophoresis. surprisingly, although we had observed two peaks in the melting curve analysis, we could identify only one distinctive pcr product. furthermore when we size selected the pcr product using gel purification to exclude primers and alternative products and repeated the melting curve analysis we reproduced the same double peak, suggesting that the amplified sequence itself was responsible for this aberrant signal. a possible explanation for this observation is that the palindromic loxp sequence motif could serve as a core motif that promotes annealing of sense/sense and antisense/antisense strands or possibly the formation of hairpins. such hybridization products/hairpins would have a lower melting temperature than antisense/sense hybrids and therefore contribute to a second peak in melting curve analysis. since the melting curve is critical for quality control in sybr green assays, data with an aberrant double peak are frequently excluded from further analysis. our example illustrates that sybr green based assays are not only limited by possible amplification and measurement of nonspecific pcr products but are also potentially affected by alternate re-annealing or secondary structures of the specific pcr product itself. in agreement with our own data, difficulties with sybr green based analysis of 1lox/2lox allele ratios have also been reported independently. to resolve such potential difficulties of sybr green based analysis of loxp containing sequences we therefore developed an alternative assay to quantify 1lox/2lox allele ratios using a probe based real-time pcr approach. our aim was to establish a universal probe that could be used for all reactions and models of cre-lox mediated gene deletion such that only the flanking primer sequences need to be adapted. such an assay would combine the convenience of a sybr green based assay with the specificity of a probe based assay. testing of probe based real-time pcr for analysis of conditional gene deletion to establish a probe based assay for the 1lox and 2lox reaction respectively we selected a hydrolysis probe that specifically binds to the loxp site itself and designed primers flanking the loxp site as illustrated in figure 2a. the use of a probe covering the loxp site allowed us to use the same probe for both the 1lox and lox reaction. to generate allele specific standards that would allow us to validate the assay and test its accuracy we cloned 1lox and 2lox specific pcr products into a ta vector and verified resulting clones by sequencing. to generate standards for real-time pcr we then released allele specific fragments by restriction digest and mixed the fragments at variable molar ratios. the resulting 1lox/2lox standards were verified using capillary electrophoresis, which confirmed the expected ratios. to determine the relative efficiency of the 1lox and 2lox specific real-time pcr reaction and to detect possible interference between the two alleles we conducted real-time pcr using 1: dilutions of the above mentioned fragment mixtures. as illustrated in figure 2c we observed a linear correlation between the crossing point and log concentration data for both reactions, with all data points close to the curve, indicating that the efficiency of both reactions was not affected by variable admixtures of the other allele. to further test the accuracy of the real-time pcr assay we conducted quantitive pcr, using incremental standards ranging from 9/ to 1/ and calculated allele ratios from the measured data. as summarized in figure 3a the 1lox/2lox allele ratios as determined by the probe based real-time pcr assay closely reflected allele ratios measured by capillary electrophoresis and the expected allele ratios. testing of probe based real-time pcr for analysis of cre-lox recombination in fabpl4× at -132-cre transgenic mice after establishing the accuracy of the method we measured conditional deletion of dnmt3a in intestinal epithelial cells of fabpl4× at -132-cre transgenic mice. for this we harvested intestinal epithelial cells from the proximal, middle and distal third of the small intestine of dnmt3a, fabpl4× at -132-cre mice and measured 1lox/2lox allele ratios using real-time pcr. as shown in figure 3d we detected a low deletion efficiency in the proximal small intestine and increasing deletion efficiency in the distal small intestine, with the 1lox/2lox allele ratio varying from to approximately respectively. importantly the data of the two cre+ mice were highly similar and the variation within the sample replicates was very low, confirming the reproducibility of the method. also, these results are in good agreement with published data on the same fabpl4× at -132-cre strain using northern blotting and immunohistochemistry, which further confirms the utility of the assay. discussion real-time pcr is clearly preferable to southern blotting when attempting to quantify conditional gene deletion: real-time pcr offers a higher sensitivity, requires significantly smaller dna samples and requires much less processing time. this is particularly useful when allele ratios have to be measured in small samples at several time points, such as in conditional deletion experiments involving hematopoetic stem cells. surprisingly, only one study formally evaluated this technical approach, however without testing the ability of the method to detect small changes in allele ratios. in principle either sybr green based protocols or probe based protocols can be used for real-time pcr. sybr green based assays are very popular because of the relatively low cost and the convenient implementation requiring primer design only. however, as illustrated by our example, it appears that sybr green based protocols for quantification of conditional gene deletion, are potentially complicated by the palindromic sequence of the loxp site. we show that pcr products containing this sequence, such as the 1lox specific pcr product, can generate double peaks during melting curve analysis, likely due to alternate product hybridization, which can complicate quality control of the reaction. in such cases it is uncertain whether the double peak reflects the presence of an additional nonspecific pcr product or not. we therefore suggest that it is generally preferable to use a probe based real-time pcr approach, which avoids such erroneous signals and offers improved specificity. the hydrolysis probe established in our protocol, that is used for analysis of both alleles, recognizes the loxp site itself and is therefore universally applicable to any assay measuring 1lox/2lox allele ratios. to adapt the assay to other conditional alleles it is therefore only necessary to place primer pairs in the unique genomic sequence flanking the loxp sites. our data support the notion that such probe based real-time pcr analysis allows reproducible and accurate measurement of 1lox/2lox allele ratios with small amounts of dna and is therefore a highly attractive alternative to conventional southern blotting.  our results suggest that probe based real-time pcr can accurately detect small differences in 1lox/2lox allele ratios with improved specificity. our protocol requires the use of one probe only for all reactions. this probe is directed against the loxp site itself and is therefore universally applicable to any assay analyzing cre-lox recombination efficiency, such that only the primer sequences have to be adapted. our assay therefore combines the convenience of sybr green based analysis with the specificity of probe based analysis and is applicable to all models of cre-lox mediated conditional gene deletion. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
26,f10e4e1d-1b57-4a4a-8ded-90bbdad85182_gpt3_gen,"The development of high-throughput genomic technologies has led to an increase in the amount of gene expression data, which necessitates computational and mathematical techniques to analyze the massive datasets and model gene regulatory networks. Two popular approaches for inferring gene regulatory networks from expression data are probabilistic boolean networks (PBN) and dynamic bayesian networks (DBN). Both methods have been used to reconstruct gene regulatory networks, but DBN has been found to be better suited for characterizing time series gene expression data while PBN is more useful for studying the logical interactions of genes without specific details. A comparison of PBN and DBN approaches was performed using a biological time-series dataset to construct a Drosophila gene network, and the results showed that both methods had good performances, with DBN identifying more gene interactions and giving better recall than PBN."," the development of high-throughput genomic technologies, makes it possible to study dependencies and regulation among genes on a genome-wide scale. in last decade, the amount of gene expression data has increased rapidly necessitating development of computational methods and mathematical techniques to analyze the resulting massive data sets. in order to understand the functioning of cellular organisms, why complicated response patterns to stressors are observed, and provide a hypothesis for experimental verification, it is necessary to model gene regulatory networks. currently, clustering, classification and visualization methods are used for reconstruction or inference of gene regulatory networks from gene expression data sets. these methods generally group genes based on the similarity of expression patterns. based on large-scale microarray data retrieved from biological experiments, many computational approaches have been proposed to reconstruct genetic regulatory networks, such as boolean networks, differential equations, bayesian networks and neural networks. among these approaches, boolean network methods and bayesian network methods have drawn the most interest in the field of systems biology. much recent work has been done to reconstruct gene regulatory networks from expression data using bayesian networks and dynamic bayesian network. bayesian network approaches have been used in modeling genetic regulatory networks because of its probabilistic nature. however, drawbacks of bayesian network approaches include failure to capture temporal information and modeling of cyclic networks. dbn is better suited for characterizing time series gene expression data than the static version. perrin et al. used a stochastic machine learning method to model gene interactions and it was capable of handling missing variables. zou et al. presented a dbn-based approach, in which the number of potential regulators is limited to reduce search space. yu et al. developed a simulation approach to improve dbn inference algorithms, especially in the context of limited quantities of biological data. in, xing and wu proposed a higher order markov dbn to model multiple time units in a delayed gene regulatory network. recently, likelihood maximization algorithms such as the expectation-maximization algorithm have been used to infer hidden parameters and deal with missing data. the boolean network model, originally introduced by kauffman is also very useful to infer gene regulatory networks because it can monitor the dynamic behaviour in complicated systems based on large amounts of gene expression data. one of the main objectives of boolean network models is to study the logical interactions of genes without knowing specific details. in a boolean network, the target gene is predicted by other genes through a boolean function. a probabilistic boolean network, first introduced by shmulevich et al. in is the stochastic extension of boolean network. it consists of a family of boolean networks, each of which corresponds to a contextual condition determined by variables outside the model. as models of genetic regulatory networks, the pbn method has been further developed by several authors. in, a model for random gene perturbations was developed to derive an explicit formula for the transition probabilities in the new pbn model. in, intervention is treated via external control variables in a context-sensitive pbn by extending the results for instantaneously random pbn in several directions. some learning approaches for pbn have also been explored. considering the same joint probability distribution over common variables, several fundamental relationships of two model classes have been discussed in. in this paper, two important computational approaches for modeling gene regulatory networks, pbn and dbn, are compared using a biological time-series dataset from the drosophila interaction database to construct a drosophila gene network. we present the pbn and dbn approaches and grn construction methods used and discuss the performance of the two approaches in constructing grns.  a real biological time series data set was used to compare pbn and dbn approaches for modeling gene regulatory networks. the raw data was preprocessed in the same way as given in. there were gene samples with time points available in drosophila melanogaster genes network through the four stages of the life cycle: embryonic, larval, pupal and adulthood. an example network of drosophila muscle development is given in, in which muscle-specific protein is treated as hub gene in their inferred network. we used a different subset of the genes which participate in the development of muscle. particularly, mlp84b and other genes which contribute to larval somatic muscle development were used to infer gene regulatory networks. the d. melanogaster gene muscle lim protein at 84b has also been known in flybase as lim it encodes a product with putative protein binding involved in myogenesis which is a component of the cytoplasm. it is expressed in the embryo. table shows the scores of mlp84b interacting with other related genes. here, we first selected genes to infer grns using pbn and dbn. the constructed grns are shown in figure there exists interactions totally within this small larval somatic muscle network. and interactions in the network have been successful identified. most interactions between mlp84b and genes with high confidence have been inferred. more comparison results of pbn and dbn are given in table where n is the number of nodes in network and e the number of edges among the nodes. pbn means that there are nodes and edges in that pbn simulation. to analyze the effect of network size on the inference accuracy, four combinations,,, and, were considered for inferring gene network. for each combination, we randomly selected five subsets of genes of the same numbers of genes and edges from the drosophila gene network. for each subset genes, we inferred a gene network and retrieved the number of correct edges ce, miss errors me, and false alarm errors fe. for each combination, the average and range of ce, me and fe were calculated, as given in table a correct edge is the one that exists in a real network and is successfully identified by the inference methods. miss error is defined as the edge between two genes that exists in a real network, but the inference algorithms miss or make wrong orientations. false alarm error is the edge that the inference algorithms create but does not exist in the real network. we used the benchmark measures recall r and precision p to evaluate performances of inference algorithms for pbn and dbn. while different definitions for recall and precision exist, in this paper, r is defined as ce/ and p is represented as ce/. the selection of subset genes in network was based on the current existing gene interactions and network diagram in the drosophila genes network. the results in table show that for the same case, dbn reduces miss errors but increases false alarms errors slightly. for all cases, dbn can identify more corrected edges than pbn and hence improve recall. the precision of dbn is better in three cases but worse in one case than pbn. for both pbn and dbn methods, recall and precision decrease if the number of genes increases. one can see that if more genes are selected for inferring grns, the network contains more edges and it is more difficult to successfully identify the interactions among genes. while the dbn method can give better recall of identifying genetic network interactions, it is more time-consuming than pbn. discussion it is challenging to infer grns from time series gene expression data. among thousands of genes, each gene interacts with one or more other genes directly or indirectly through complex dynamic and nonlinear relationships, time series data used to infer genetic networks have low-sample size compared to the number of genes, and gene expression data may contain a substantial amount of noise. different approaches may have different performances for different datasets. moreover, inference accuracy depends not only upon models but also on inference schemes. in this paper, we only select two representative inference algorithms for pbn and dbn to model the grns, respectively. it is desirable to perform a more comprehensive evaluation of the two approaches with different inference methods and to develop the more robust algorithm and techniques to improve the accuracy of inferring grns.  pbn-based and dbn-based methods were used for inferring grns from drosophila time series dataset with time points obtained from the drosophila interaction database. the results showed that accuracy in terms of recall and precision can be improved if a smaller subset of genes is selected for inferring grns. both pbn and dbn approaches had good performance in modeling the gene regulatory networks. in all tested cases, dbn identified more gene interactions and gave better recall than pbn. the accuracy of inferring grns was not only dependent upon the model selection but also relied on the particular inference algorithms that were selected for implementation. different inference schemes may be applied to improve accuracy and performance. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
27,f10e4e1d-1b57-4a4a-8ded-90bbdad85182_flant5_gen,"pbn and dbn approaches for modeling gene regulatory networks are compared using a biological time-series dataset from the drosophila interaction database to construct a drosophila gene network. we present the pbn and dbn approaches and grn construction methods used and discuss the performance of the two approaches in constructing grns. a real biological time series data set was used to compare pbn and dbn approaches for modeling gene regulatory networks. the raw data was preprocessed in the same way as given in. there were gene samples with time points available in drosophila melanogaster genes network through the four stages of the life cycle: embryonic, larval, pupal and adulthood. an example network of drosophila muscle development is given in, in which muscle-specific protein is treated as hub gene in their inferred network. here, we first selected genes to infer grns using pbn and dbn. the constructed grns are shown in figure there exists interactions totally within this small larval somatic muscle network. and interactions in the network have been successful identified. more comparison results of pbn and dbn are given in table where n is the number of nodes in network and e the number of edges among the nodes. pbn means that there are nodes and edges in that pbn simulation. to analyze the effect of network size on the inference accuracy, four combinations, were considered for inferring gene network. for each combination, we randomly selected five subsets of genes of the same numbers of genes and edges from the drosophila gene network. for each subset genes, we inferred a gene network and retrieved the number of correct edges ce, miss errors me, and false alarms errors fe. for all tested cases, dbn can identify more gene interactions and gave better recall than pbn."," the development of high-throughput genomic technologies, makes it possible to study dependencies and regulation among genes on a genome-wide scale. in last decade, the amount of gene expression data has increased rapidly necessitating development of computational methods and mathematical techniques to analyze the resulting massive data sets. in order to understand the functioning of cellular organisms, why complicated response patterns to stressors are observed, and provide a hypothesis for experimental verification, it is necessary to model gene regulatory networks. currently, clustering, classification and visualization methods are used for reconstruction or inference of gene regulatory networks from gene expression data sets. these methods generally group genes based on the similarity of expression patterns. based on large-scale microarray data retrieved from biological experiments, many computational approaches have been proposed to reconstruct genetic regulatory networks, such as boolean networks, differential equations, bayesian networks and neural networks. among these approaches, boolean network methods and bayesian network methods have drawn the most interest in the field of systems biology. much recent work has been done to reconstruct gene regulatory networks from expression data using bayesian networks and dynamic bayesian network. bayesian network approaches have been used in modeling genetic regulatory networks because of its probabilistic nature. however, drawbacks of bayesian network approaches include failure to capture temporal information and modeling of cyclic networks. dbn is better suited for characterizing time series gene expression data than the static version. perrin et al. used a stochastic machine learning method to model gene interactions and it was capable of handling missing variables. zou et al. presented a dbn-based approach, in which the number of potential regulators is limited to reduce search space. yu et al. developed a simulation approach to improve dbn inference algorithms, especially in the context of limited quantities of biological data. in, xing and wu proposed a higher order markov dbn to model multiple time units in a delayed gene regulatory network. recently, likelihood maximization algorithms such as the expectation-maximization algorithm have been used to infer hidden parameters and deal with missing data. the boolean network model, originally introduced by kauffman is also very useful to infer gene regulatory networks because it can monitor the dynamic behaviour in complicated systems based on large amounts of gene expression data. one of the main objectives of boolean network models is to study the logical interactions of genes without knowing specific details. in a boolean network, the target gene is predicted by other genes through a boolean function. a probabilistic boolean network, first introduced by shmulevich et al. in is the stochastic extension of boolean network. it consists of a family of boolean networks, each of which corresponds to a contextual condition determined by variables outside the model. as models of genetic regulatory networks, the pbn method has been further developed by several authors. in, a model for random gene perturbations was developed to derive an explicit formula for the transition probabilities in the new pbn model. in, intervention is treated via external control variables in a context-sensitive pbn by extending the results for instantaneously random pbn in several directions. some learning approaches for pbn have also been explored. considering the same joint probability distribution over common variables, several fundamental relationships of two model classes have been discussed in. in this paper, two important computational approaches for modeling gene regulatory networks, pbn and dbn, are compared using a biological time-series dataset from the drosophila interaction database to construct a drosophila gene network. we present the pbn and dbn approaches and grn construction methods used and discuss the performance of the two approaches in constructing grns.  a real biological time series data set was used to compare pbn and dbn approaches for modeling gene regulatory networks. the raw data was preprocessed in the same way as given in. there were gene samples with time points available in drosophila melanogaster genes network through the four stages of the life cycle: embryonic, larval, pupal and adulthood. an example network of drosophila muscle development is given in, in which muscle-specific protein is treated as hub gene in their inferred network. we used a different subset of the genes which participate in the development of muscle. particularly, mlp84b and other genes which contribute to larval somatic muscle development were used to infer gene regulatory networks. the d. melanogaster gene muscle lim protein at 84b has also been known in flybase as lim it encodes a product with putative protein binding involved in myogenesis which is a component of the cytoplasm. it is expressed in the embryo. table shows the scores of mlp84b interacting with other related genes. here, we first selected genes to infer grns using pbn and dbn. the constructed grns are shown in figure there exists interactions totally within this small larval somatic muscle network. and interactions in the network have been successful identified. most interactions between mlp84b and genes with high confidence have been inferred. more comparison results of pbn and dbn are given in table where n is the number of nodes in network and e the number of edges among the nodes. pbn means that there are nodes and edges in that pbn simulation. to analyze the effect of network size on the inference accuracy, four combinations,,, and, were considered for inferring gene network. for each combination, we randomly selected five subsets of genes of the same numbers of genes and edges from the drosophila gene network. for each subset genes, we inferred a gene network and retrieved the number of correct edges ce, miss errors me, and false alarm errors fe. for each combination, the average and range of ce, me and fe were calculated, as given in table a correct edge is the one that exists in a real network and is successfully identified by the inference methods. miss error is defined as the edge between two genes that exists in a real network, but the inference algorithms miss or make wrong orientations. false alarm error is the edge that the inference algorithms create but does not exist in the real network. we used the benchmark measures recall r and precision p to evaluate performances of inference algorithms for pbn and dbn. while different definitions for recall and precision exist, in this paper, r is defined as ce/ and p is represented as ce/. the selection of subset genes in network was based on the current existing gene interactions and network diagram in the drosophila genes network. the results in table show that for the same case, dbn reduces miss errors but increases false alarms errors slightly. for all cases, dbn can identify more corrected edges than pbn and hence improve recall. the precision of dbn is better in three cases but worse in one case than pbn. for both pbn and dbn methods, recall and precision decrease if the number of genes increases. one can see that if more genes are selected for inferring grns, the network contains more edges and it is more difficult to successfully identify the interactions among genes. while the dbn method can give better recall of identifying genetic network interactions, it is more time-consuming than pbn. discussion it is challenging to infer grns from time series gene expression data. among thousands of genes, each gene interacts with one or more other genes directly or indirectly through complex dynamic and nonlinear relationships, time series data used to infer genetic networks have low-sample size compared to the number of genes, and gene expression data may contain a substantial amount of noise. different approaches may have different performances for different datasets. moreover, inference accuracy depends not only upon models but also on inference schemes. in this paper, we only select two representative inference algorithms for pbn and dbn to model the grns, respectively. it is desirable to perform a more comprehensive evaluation of the two approaches with different inference methods and to develop the more robust algorithm and techniques to improve the accuracy of inferring grns.  pbn-based and dbn-based methods were used for inferring grns from drosophila time series dataset with time points obtained from the drosophila interaction database. the results showed that accuracy in terms of recall and precision can be improved if a smaller subset of genes is selected for inferring grns. both pbn and dbn approaches had good performance in modeling the gene regulatory networks. in all tested cases, dbn identified more gene interactions and gave better recall than pbn. the accuracy of inferring grns was not only dependent upon the model selection but also relied on the particular inference algorithms that were selected for implementation. different inference schemes may be applied to improve accuracy and performance. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
28,20871c95-7859-49b1-9670-fb1ae129dc35_flant5_gen,We describe a fieldable genotyping method for b. anthracis and y. pestis using agilent bioanalyzer.," bacillus anthracis is a gram-positive spore-forming bacillus that causes anthrax. this bacterium is commonly found in soil and is responsible for diseases of herbivores and other mammals including humans. anthrax is still endemic in many countries, middle east, africa, north, central and south america, as well as other areas of the world. the site of entry determines different forms of anthrax, cutaneous, gastrointestinal, and inhalation; the latter form is highly fatal, with a mortality rate of up to 80% in the absence of an adequate antimicrobial therapy. yersinia pestis is a gram-negative bacterium, etiological agent of plague. the bacterium is transmitted by fleas or aerosols, causing different forms of plague: bubonic, septicemic or pneumonic. y.pestis is often associated with the wellknown black death plague of the middle ages, a pandemic that had killed a third of european population in the 14th and 15th centuries, but approximately human cases still occur worldwide each year. primary pneumonic plague is rapidly progressive and virulent, and, as inhalation anthrax, with a mortality rate close to 100% in the absence of a timely treatment. y. pestis and b. anthracis are both considered serious threats and potential bioterrorism agents because of their evaluation as bioweapons by soviet union and united states laboratories during the past decades. above all, b. anthracis gained renewed attention in when letters containing anthrax spores were mailed causing the death of five persons and infecting others, while probably hundreds of people were exposed to infectious spores. both agents are classified by the us centre for disease control and prevention in the bioterrorism disease agent list as category a microrganism, the most dangerous ones, because of easy dissemination and transmission, high mortality and impact to public health. b. anthracis and y. pestis both show very low intraspecies genetic diversity, making very challenging the rapid and accurate differentiation among individual biovars and strains. nevertheless, finding a way to differenziate the strains by molecular genotyping, remains essential for discrimination between naturally occurring versus intentional outbreaks. the importance of forensic microbiology, as this field is know called, was demonstrated during the events, and previously by tokyo and sverdlovsk incidents. finally genetic characterization of isolates allows to increase information about worldwide bacterial distribution and epidemiology. standard genotyping methods require either highly discriminative but heavy, and relatively expensive devices such as automated capillary electrophoresis devices, or cheaper, easy to use but more time consuming and with lower resolution power such as agarose gels. a new miniaturized platform for quantification and separation of nucleic acid molecules, agilent bioanalyzer, has shown accuracy, precision and high feasibility along with speed and moderate cost reagents. this platform is based on microfluidic technology and allows to analyze dna samples in minutes. the device, also called ""lab on a chip"", integrates multiple functions onto a single apparatus, so that sample dispensing, separation, detection and analysis are performed on the same support. along with limited weight and size, the above features make the instrument ideal for field use and other on-site investigations. agilent can also be easily used by low-expertise staff. a similar system was previously employed to study the genetic variability of bcla gene for strain discrimination within the bacillus cereus group. in this paper we evaluate this approach for genotyping analysis of the two major biothreat agents.  experimental design in order to validate this platform, we compared the data produced by the agilent bioanalyzer to agarose gel based data and capillary gel based data. ten y. pestis and thirty-nine b. anthracis strains were genotyped using previously described sets of vntr loci. these previously genotyped strains were chosen to be representative of allelic variability within the two species. briefly, these genotypes are from strains with the largest genetic distance, encompassing most of the observed allele variation. the vntr markers amplified for bacterial genotyping, were arranged into pcr multiplex reactions either for b. anthracis or y. pestis. this allowed us to use a single dna chip for each strain. after pcr amplification μl of each reaction was loaded into 12-wells chip. primer concentrations were experimentally adjusted to obtain a balanced amplification of different fragments. this optimization was facilitated using the quantification data supplied by the bioanalyzer. the vast majority of data produced by agilent were not accurate. the discrepancies between observed and expected fragment size are, presumably, the result of abnormal migration patterns of some repetitive sequences into electrophoretic matrix. in order to check if the offset was reproducible, we tested interchip and intrachip variability in markers containing the smallest repeat units, for which incorrect allelic calling is more probable. the samples were run in triplicate on the same and on different chips, and size data compared. in general, it was observed a low level of inter-intrachip variability. for example, for b. anthracis cg marker, we observed ± for allele and ± for allele to correctly convert the agilent dna fragment size estimates into repeat copy numbers, it was necessary to establish conversion tables containing bioanalyzer fragment sizes as well as actual sizes corresponding to repeats unit numbers, as previously reported. * modified primer set once these reproducible offset values are taken into account, the mlva assay as run on the agilent exhibited concordant results with previous typing results for b. anthracis and y. pestis. we were able to resolve closely sized dna fragments, and the analyzed samples showed concordance either with interchip repetitions or with expected size data. these data, used for upgma cluster analysis, generate dendrograms with linkage distance perfectly identical to those previously obtained by standard methodologies. for each individual strain the agilent assay is completed in about minutes after pcr amplification. for a single strain to be genotyped, this time is significantly lower than hours described in previous assay. genotyping b. anthracis with the 25-loci mlva to fit all the loci into a 12-wells chip the b. anthracis loci were combined into triplex, duplex and singleplex pcr amplifications. the arrangement of different loci in the same multiplex is such as to avoid overlapping of vntr markers size ranges. for four b. anthracis loci multiplexing was impossible, because of the large allele size range. primer sequences were as described in, loci combination and final primers concentrations are reported in table under these conditions, we were able to amplify each expected fragment, and the software could identify amplicon size. the offset values for all loci and alleles were measured and are presented in tables and for chromosomal markers, reproducibility of the observed data allowed correct assignment of each allele for every locus. however, for plasmid markers, since their shorter repeat unit and pcr product size compared to the chromosomal ones, we observed variability not exceeding one single additional base for each allele in repeated runs. even with this additional base, correct assignment could be reproducibly done for the plasmid loci. genotyping y. pestis with the 25-loci mlva to fit all the loci into chip wells the y. pestis markers were grouped into duplex and one triplex. the majority of primer sequences were as described in but for y. pestis markers new primer pairs were redesigned to allow multiplexing. thus, final amplicon size was increased to avoid any possible overlap with other different loci into the new multiplexed reactions. for y. pestis markers, we observed variability up to two bases and, as previously described for b. anthracis, discrepancies not exceeding 25% of the repeat unit size. discussion the intentional release of anthrax spores by mail in in the united states caused the death of five persons by inhalation anthrax and publicly demonstrated the bioweapon-associated threat, of which only the community of biodefence experts was previously aware. this increased the demands for a better genetic characterization of bioterrorism agents, in order to distinguish between natural outbreaks and/or intentional release of micro-organisms, and to help trace back the origin of an aggression. we have here evaluated the agilent ""lab on a chip"" platform for genotyping of b. anthracis and y. pestis strains on. this assay runs in minutes one multiplexed pcr reactions chip, genotyping a single isolate at a time. for this reason this system is faster compared to automated sequencing devices, either slab gel or capillary based when a single strain has to be genotyped. given the possibility to compare different chip runs in different times this device can immediately show identities or diversities between new isolates compared to already characterized ones. moreover it has shown a high degree of automation either for amplicon separation or for digital output of results. compared to previous genotyping methods, the bionalyzer is more effective than standard ethidium bromide slab gel electrophoresis, giving reproducible, precise and more sensible output for the shortest repeat units. since no fluorescent primers are required the assay is cheaper to maintain than ceq or other sequencing machines. a rough estimation of the total cost of a loci assay indicates that genotyping on this equipment is at least four to ten times less expensive than a capillary system assay, at low to medium throughput level. the equipment itself is cheaper, and both consumables and equipment can be stored for a long period of time and activated when needed. finally, the results are comparable to those obtained by automated sequencers. this platform appears particularly useful when response time is the critical factor. we propose therefore such a system as a method suitable for high resolution identification of biothreat agents. to date this system is the most effective genotyping technology available for on-site investigations. also, this platform may be used for fast quality-checking of type collection, and dna preparations for biosecurity and strain accountability purposes. typing data produced by the mlva approach can be easily compared using shared internet databases, as illustrated for instance in.  in this paper we describe a fieldable genotyping method for b. anthracis and y. pestis. this method is an adaptation on agilent bioanalyzer of previously described loci mlva. the system was validated by characterizing thirty-nine b. anthracis and ten y. pestis isolates, demonstrating to be, for a single genotyping, more rapid than traditional methods. the transfer on a new platform maintains reproducibility and precision to unambigously identify alleles. this method is shown to be a valid alternative to standard genotyping techniques for field characterization of important biothreat agents. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
29,20871c95-7859-49b1-9670-fb1ae129dc35_gpt3_gen,"The article discusses the threat posed by Bacillus anthracis and Yersinia pestis, two bacteria that are considered potential bioterrorism agents due to their high mortality rates and ability to spread easily. These bacteria are difficult to differentiate among individual strains, making it challenging to distinguish naturally occurring outbreaks from intentional ones. The article presents a new miniaturized platform called the Agilent Bioanalyzer, which is based on microfluidic technology and allows for the quantification and separation of nucleic acid molecules. The platform has been evaluated for genotyping analysis of both bacteria and has shown accuracy, precision, high feasibility, speed, and moderate cost reagents. The system is more effective than standard methods for genotyping, while also being faster, cheaper, and more practical for on-site investigations. It is useful for identifying and characterizing biothreat agents, improving biosecurity, and increasing information about worldwide bacterial epidemiology."," bacillus anthracis is a gram-positive spore-forming bacillus that causes anthrax. this bacterium is commonly found in soil and is responsible for diseases of herbivores and other mammals including humans. anthrax is still endemic in many countries, middle east, africa, north, central and south america, as well as other areas of the world. the site of entry determines different forms of anthrax, cutaneous, gastrointestinal, and inhalation; the latter form is highly fatal, with a mortality rate of up to 80% in the absence of an adequate antimicrobial therapy. yersinia pestis is a gram-negative bacterium, etiological agent of plague. the bacterium is transmitted by fleas or aerosols, causing different forms of plague: bubonic, septicemic or pneumonic. y.pestis is often associated with the wellknown black death plague of the middle ages, a pandemic that had killed a third of european population in the 14th and 15th centuries, but approximately human cases still occur worldwide each year. primary pneumonic plague is rapidly progressive and virulent, and, as inhalation anthrax, with a mortality rate close to 100% in the absence of a timely treatment. y. pestis and b. anthracis are both considered serious threats and potential bioterrorism agents because of their evaluation as bioweapons by soviet union and united states laboratories during the past decades. above all, b. anthracis gained renewed attention in when letters containing anthrax spores were mailed causing the death of five persons and infecting others, while probably hundreds of people were exposed to infectious spores. both agents are classified by the us centre for disease control and prevention in the bioterrorism disease agent list as category a microrganism, the most dangerous ones, because of easy dissemination and transmission, high mortality and impact to public health. b. anthracis and y. pestis both show very low intraspecies genetic diversity, making very challenging the rapid and accurate differentiation among individual biovars and strains. nevertheless, finding a way to differenziate the strains by molecular genotyping, remains essential for discrimination between naturally occurring versus intentional outbreaks. the importance of forensic microbiology, as this field is know called, was demonstrated during the events, and previously by tokyo and sverdlovsk incidents. finally genetic characterization of isolates allows to increase information about worldwide bacterial distribution and epidemiology. standard genotyping methods require either highly discriminative but heavy, and relatively expensive devices such as automated capillary electrophoresis devices, or cheaper, easy to use but more time consuming and with lower resolution power such as agarose gels. a new miniaturized platform for quantification and separation of nucleic acid molecules, agilent bioanalyzer, has shown accuracy, precision and high feasibility along with speed and moderate cost reagents. this platform is based on microfluidic technology and allows to analyze dna samples in minutes. the device, also called ""lab on a chip"", integrates multiple functions onto a single apparatus, so that sample dispensing, separation, detection and analysis are performed on the same support. along with limited weight and size, the above features make the instrument ideal for field use and other on-site investigations. agilent can also be easily used by low-expertise staff. a similar system was previously employed to study the genetic variability of bcla gene for strain discrimination within the bacillus cereus group. in this paper we evaluate this approach for genotyping analysis of the two major biothreat agents.  experimental design in order to validate this platform, we compared the data produced by the agilent bioanalyzer to agarose gel based data and capillary gel based data. ten y. pestis and thirty-nine b. anthracis strains were genotyped using previously described sets of vntr loci. these previously genotyped strains were chosen to be representative of allelic variability within the two species. briefly, these genotypes are from strains with the largest genetic distance, encompassing most of the observed allele variation. the vntr markers amplified for bacterial genotyping, were arranged into pcr multiplex reactions either for b. anthracis or y. pestis. this allowed us to use a single dna chip for each strain. after pcr amplification μl of each reaction was loaded into 12-wells chip. primer concentrations were experimentally adjusted to obtain a balanced amplification of different fragments. this optimization was facilitated using the quantification data supplied by the bioanalyzer. the vast majority of data produced by agilent were not accurate. the discrepancies between observed and expected fragment size are, presumably, the result of abnormal migration patterns of some repetitive sequences into electrophoretic matrix. in order to check if the offset was reproducible, we tested interchip and intrachip variability in markers containing the smallest repeat units, for which incorrect allelic calling is more probable. the samples were run in triplicate on the same and on different chips, and size data compared. in general, it was observed a low level of inter-intrachip variability. for example, for b. anthracis cg marker, we observed ± for allele and ± for allele to correctly convert the agilent dna fragment size estimates into repeat copy numbers, it was necessary to establish conversion tables containing bioanalyzer fragment sizes as well as actual sizes corresponding to repeats unit numbers, as previously reported. * modified primer set once these reproducible offset values are taken into account, the mlva assay as run on the agilent exhibited concordant results with previous typing results for b. anthracis and y. pestis. we were able to resolve closely sized dna fragments, and the analyzed samples showed concordance either with interchip repetitions or with expected size data. these data, used for upgma cluster analysis, generate dendrograms with linkage distance perfectly identical to those previously obtained by standard methodologies. for each individual strain the agilent assay is completed in about minutes after pcr amplification. for a single strain to be genotyped, this time is significantly lower than hours described in previous assay. genotyping b. anthracis with the 25-loci mlva to fit all the loci into a 12-wells chip the b. anthracis loci were combined into triplex, duplex and singleplex pcr amplifications. the arrangement of different loci in the same multiplex is such as to avoid overlapping of vntr markers size ranges. for four b. anthracis loci multiplexing was impossible, because of the large allele size range. primer sequences were as described in, loci combination and final primers concentrations are reported in table under these conditions, we were able to amplify each expected fragment, and the software could identify amplicon size. the offset values for all loci and alleles were measured and are presented in tables and for chromosomal markers, reproducibility of the observed data allowed correct assignment of each allele for every locus. however, for plasmid markers, since their shorter repeat unit and pcr product size compared to the chromosomal ones, we observed variability not exceeding one single additional base for each allele in repeated runs. even with this additional base, correct assignment could be reproducibly done for the plasmid loci. genotyping y. pestis with the 25-loci mlva to fit all the loci into chip wells the y. pestis markers were grouped into duplex and one triplex. the majority of primer sequences were as described in but for y. pestis markers new primer pairs were redesigned to allow multiplexing. thus, final amplicon size was increased to avoid any possible overlap with other different loci into the new multiplexed reactions. for y. pestis markers, we observed variability up to two bases and, as previously described for b. anthracis, discrepancies not exceeding 25% of the repeat unit size. discussion the intentional release of anthrax spores by mail in in the united states caused the death of five persons by inhalation anthrax and publicly demonstrated the bioweapon-associated threat, of which only the community of biodefence experts was previously aware. this increased the demands for a better genetic characterization of bioterrorism agents, in order to distinguish between natural outbreaks and/or intentional release of micro-organisms, and to help trace back the origin of an aggression. we have here evaluated the agilent ""lab on a chip"" platform for genotyping of b. anthracis and y. pestis strains on. this assay runs in minutes one multiplexed pcr reactions chip, genotyping a single isolate at a time. for this reason this system is faster compared to automated sequencing devices, either slab gel or capillary based when a single strain has to be genotyped. given the possibility to compare different chip runs in different times this device can immediately show identities or diversities between new isolates compared to already characterized ones. moreover it has shown a high degree of automation either for amplicon separation or for digital output of results. compared to previous genotyping methods, the bionalyzer is more effective than standard ethidium bromide slab gel electrophoresis, giving reproducible, precise and more sensible output for the shortest repeat units. since no fluorescent primers are required the assay is cheaper to maintain than ceq or other sequencing machines. a rough estimation of the total cost of a loci assay indicates that genotyping on this equipment is at least four to ten times less expensive than a capillary system assay, at low to medium throughput level. the equipment itself is cheaper, and both consumables and equipment can be stored for a long period of time and activated when needed. finally, the results are comparable to those obtained by automated sequencers. this platform appears particularly useful when response time is the critical factor. we propose therefore such a system as a method suitable for high resolution identification of biothreat agents. to date this system is the most effective genotyping technology available for on-site investigations. also, this platform may be used for fast quality-checking of type collection, and dna preparations for biosecurity and strain accountability purposes. typing data produced by the mlva approach can be easily compared using shared internet databases, as illustrated for instance in.  in this paper we describe a fieldable genotyping method for b. anthracis and y. pestis. this method is an adaptation on agilent bioanalyzer of previously described loci mlva. the system was validated by characterizing thirty-nine b. anthracis and ten y. pestis isolates, demonstrating to be, for a single genotyping, more rapid than traditional methods. the transfer on a new platform maintains reproducibility and precision to unambigously identify alleles. this method is shown to be a valid alternative to standard genotyping techniques for field characterization of important biothreat agents. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
30,9ba3696a-bfeb-4e92-a16a-9d301168bf27_flant5_gen,We present an estimator for the covariance of distances estimated from pairwise alignments.," the estimation of evolutionary distances between gene/protein sequences is one of the most important problems in molecular evolution. in particular, it lies at the heart of most phylogenetic tree construction methods. the estimation of such distances is a two step process: first, homologous characters are identified, then the distances are estimated from the character substitution patterns. the most accurate matching of homologous characters is obtained by multiple sequence alignments. indeed, by considering all sequences simultaneously, msas yield a consistent and in principle optimal grouping of the homologous characters. unfortunately, msas are hard to compute optimally, and thus are in practice computed using heuristics. alternatively, the sequences can be analyzed exclusively on the basis of pairs of sequences, using an algorithm such as smith-waterman that yields optimal pairwise alignments. this approach is often taken by large-scale comparative genomics analysis such as mips, oma or roundup, which analyze the sequences pairwise due to computational constraints. once the homologous characters are identified, the second step of distance estimation can proceed. the method of choice is a maximum likelihood estimation based on some model of evolution. there too, the distances can either be estimated simultaneously from all sequences using a combination of tree topology inference and joint optimization of all branches, or pairwise, by estimating the distances between every pair of sequences. joint estimation requires msas, while pairwise distance estimation can be done from either opas or from the pairwise alignments induced by an msa. fig. provides an overview of the different approaches. in all cases, the estimation of evolutionary distances is subject to inference uncertainty, which is commonly quantified by their variances and covariances. indeed, the distance variance information can be used to build confidence intervals around the estimate; covariances of pairs of distances can be used to build the confidence intervals of combinations of distances. examples of applications include generalized least squares phylogenetic tree building construction of confidence sets of trees, test for monophyly using likelihood ratios, comparison of evolutionary distances for orthology inference, or distance-based lateral gene transfer detection variance estimates are provided by ml theory in both joint and pairwise distances estimation. however, ml theory only provides covariance estimates if all distances are estimated jointly. covariance estimates for distances computed from ipas in the context of specific parametric substitution models have been reported by hasegawa et al. and bulmer, and were generalized by susko to all markovian models of evolution. furthermore, the covariance of distances from ipas can also be estimated through bootstrapping. as for the covariance of distances obtained from opas, the main difficulty in computing them is that, since sequence pairs are aligned individually, they usually have inconsistencies in their inference of the homologous characters. thus, the alignments cannot be partitioned in consistent ""columns"" of characters, and neither susko's method nor resampling approaches such as bootstrapping can be applied. indeed, in the case of analyses relying exclusively on pairwise comparison and distance estimation, i.e. where no msa computation can be afforded, we are not aware of any previously published estimator for the covariance of distances estimates from pairwise alignments. we have shown in a previous article a numerical approximation for the constrained case of the covariance of two opa distances involving a common sequence, for empirical substitution models such as pam or jtt. in this article, we present an estimator for the covariance of ml distances estimated from opas that works on triplets and quartets of sequences. this solves the problem of sets of sequences of arbitrary size, because each covariance involves at most four sequences at a time. thus, the full covariance matrix is naturally obtained through quartet analysis. we analyze the performances of the estimator in terms of bias and variance. finally, we compare the results obtained on triplets of sequences to our previous work.  in the following, we present and analyze the performances of the estimator for the covariance of two distances. for this purpose, it is informative to analyze the results separately for the following three different underlying topological relations, illustrated in fig. 2: case of dependence the two distances are estimated between four distinct sequences, and they have some evolution in common. with such an evolutionary history, the two distances estimates covary positively. case of independence the two distances are estimated between four distinct sequences, but they have no evolution in common. this case is informative, because a central assumption in most evolutionary models is that evolution on different branches is independent. with no branch in common, the distances should not covary. thus, such a topology can be used to test the estimators as negative control. case of triplet the two distances involve a common sequence, and have some evolution in common. this case is of special interest, because we have previously presented an alternate estimator for this particular case using a different approach. thus, we can compare our results to this approach, hereafter called ""the numerical approximation"". note that the covariances are estimated using the same algorithm in all three cases: we only distinguish them from each another for the purpose of this analysis. to assess the performance of the covariance estimator, it was compared against the monte carlo covariance estimator. in short, each point shown in the figures was obtained from sets of sequences mutated along a random quartet subtree of the tree of life. that way, the evaluation is based on tree samples that are distributed as closely as possible to real biological data. to account for gene families with varying rates, each quartet was scaled with a random factor uniformly distributed between and note that results corresponding to very large distance constitute extreme cases; for instance, when sequences are pam units apart, each position has, on average, mutated times. fig. 3a shows the mean of our estimator versus the monte carlo estimator in nine scatterplots arising from combining the topologies mentioned above with three different sequence lengths. in the case of dependence, the first row, we see that our estimator lies in about 80% of the cases within the 95% confidence interval of the monte carlo estimator. in the case of independence, both estimators are close to zero, though our estimator shows a minor upward bias in some cases. the third row gives the result of both the covariance estimator introduced here, as well as the numerical approximation from our previous study. here, we see that though the former performs well in cases of lower covariance values, it shows a clear downward bias in cases of larger covariances. the numerical approximation does not present any apparent sign of bias, which is hardly surprising, given that it was obtained through regression. what is however surprising, is that, given its simple structure, it performs better than the covariance estimator, which takes into account more data and is backed by a more detailed model. it is instructive to compare the absolute bias of the covariance estimator to the well-known ml variance estimator. as can be seen in fig. 3b, the ml variance is also biased for high variance values. we conjecture that this is mainly due to mis-aligned positions, which cause model violations in the parameter estimation. this problem is also likely to affect the covariance estimator. even more directly, the ml variance estimator is a factor in the expression of the covariance estimator, so any error in the ml variance is propagated to the covariance estimator. at this point, improving the ml estimator for cases of high divergence is likely to require better alignments, or an explicit modeling of the mis-aligned positions, which is beyond the scope of the present work. further, to put the bias of the covariance estimator into perspective, we compared it to the standard deviation of the estimator. fig. presents the bias and standard deviation as function of the average number of anchors for sequence length of the anchors are the positions that are consistently aligned in the opas involved. both bias and standard deviation strongly depend on the fraction of anchors, which can be thought of as a measure of alignment quality. fig. depicts the dependency between percentage of anchors and average distance. as one would expect, the fraction of anchors decreases as divergence increases. for a fraction of anchor positions below 60%, the average of the two distances involved in the covariance computation is always greater than pam. in fig. we first consider the bias and standard deviation for the case of dependence. when the fraction of anchor positions is above 60%, the bias is far smaller than the standard deviation, and is therefore likely to have little negative impact in practice. in the case of triplets, the bias exceeds the standard deviation already when the fraction of anchors is about 80%. the ml variance estimator has this transition around 75% of anchors. in the case of independence, where we expect our covariance estimator to be zero, its bias is always much smaller than its standard deviation. most applications of the covariance estimator involve the covariance matrix. let a^ be an approximation to the matrix a. we refer to ||aˆ−a||2||a|| as the relative error in a^, where ||·|| denotes the two-norm. fig. shows the relative error of the × variance-covariance matrices computed with the ml variance estimator in the diagonal entries and our covariance estimator in the off-diagonal entries, and the same × matrices with only diagonal entries. the plots show that for the dependence case the the matrices with both covariance and ml variance estimators have a equal or lower relative error than the matrices with the ml variance only, except for a few cases in the region with a high fraction of anchors. in the triplet case, the variance-covariance matrices have always lower error then variance matrices. finally, in the case of independence, the matrices with covariance do not always have lower relative error, but this is expected, because the true covariance is null in this special case.  we have presented a method to estimate the covariances of distances estimated from pairwise alignments. it does not require the construction of msas, which are hard to compute and therefore are only approximated in practice. furthermore, it does not rely on phylogenetic trees as it is the case with covariance estimation from joint ml, or in covariance estimation methods that model the covariances as a function of shared branch lengths. tree building is not only a costly process, but is also subject to inference errors. the accuracy of our estimator is comparable to the ml variance estimator. both estimators are biased but in both cases the bias is, for distances below pam, far smaller than their standard deviation. the bias of the covariance estimator becomes worse with declining percentage of anchors. these biases arise because the alignment positions under scrutiny do not constitute an unbiased subsample of the true homologous positions. note that misaligned positions are likely to affect distances from msas too. a solution to this problem would lead to better distance estimates in the first place. in the meanwhile, it is probably best to issue a warning if the percentage of anchors falls below some threshold. the estimation of evolutionary distances is a very important process in molecular evolution, and therefore the covariance estimator presented here will be of use for various applications, such as the construction of gls trees on opa distances, the construction of confidence sets of trees based on the gls test statistic, relative-rate tests, distance-based lateral gene transfer detection, and in general in any process that needs to estimate confidence of distance combinations. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
31,9ba3696a-bfeb-4e92-a16a-9d301168bf27_gpt3_gen,"The estimation of evolutionary distances between gene/protein sequences is critical in molecular evolution and is used to construct phylogenetic trees. The process involves identifying homologous characters and estimating distances from character substitution patterns. Multiple sequence alignments (MSAs) yield the most accurate matching of homologous characters but are hard to compute optimally and are often computed using heuristics. Alternatively, sequences can be analyzed using pairwise algorithms such as Smith-Waterman, which yield optimal pairwise alignments. Once homologous characters are identified, the distances are estimated using a maximum likelihood estimation based on some model of evolution. However, the estimation of evolutionary distances is subject to inference uncertainty, which is commonly quantified by their variances and covariances. This article presents an estimator for the covariance of maximum likelihood distances estimated from pairwise alignments that works on triplets and quartets of sequences, solving the problem of sets of sequences of arbitrary size because each covariance involves at most four sequences at a time. The performances of the estimator in terms of bias and variance are analyzed. This estimator will be of use for various applications, such as the construction of generalized least squares trees on opa distances, the construction of confidence sets of trees based on the gls test statistic, relative-rate tests, distance-based lateral gene transfer detection, and in general in any process that needs to estimate confidence of distance combinations."," the estimation of evolutionary distances between gene/protein sequences is one of the most important problems in molecular evolution. in particular, it lies at the heart of most phylogenetic tree construction methods. the estimation of such distances is a two step process: first, homologous characters are identified, then the distances are estimated from the character substitution patterns. the most accurate matching of homologous characters is obtained by multiple sequence alignments. indeed, by considering all sequences simultaneously, msas yield a consistent and in principle optimal grouping of the homologous characters. unfortunately, msas are hard to compute optimally, and thus are in practice computed using heuristics. alternatively, the sequences can be analyzed exclusively on the basis of pairs of sequences, using an algorithm such as smith-waterman that yields optimal pairwise alignments. this approach is often taken by large-scale comparative genomics analysis such as mips, oma or roundup, which analyze the sequences pairwise due to computational constraints. once the homologous characters are identified, the second step of distance estimation can proceed. the method of choice is a maximum likelihood estimation based on some model of evolution. there too, the distances can either be estimated simultaneously from all sequences using a combination of tree topology inference and joint optimization of all branches, or pairwise, by estimating the distances between every pair of sequences. joint estimation requires msas, while pairwise distance estimation can be done from either opas or from the pairwise alignments induced by an msa. fig. provides an overview of the different approaches. in all cases, the estimation of evolutionary distances is subject to inference uncertainty, which is commonly quantified by their variances and covariances. indeed, the distance variance information can be used to build confidence intervals around the estimate; covariances of pairs of distances can be used to build the confidence intervals of combinations of distances. examples of applications include generalized least squares phylogenetic tree building construction of confidence sets of trees, test for monophyly using likelihood ratios, comparison of evolutionary distances for orthology inference, or distance-based lateral gene transfer detection variance estimates are provided by ml theory in both joint and pairwise distances estimation. however, ml theory only provides covariance estimates if all distances are estimated jointly. covariance estimates for distances computed from ipas in the context of specific parametric substitution models have been reported by hasegawa et al. and bulmer, and were generalized by susko to all markovian models of evolution. furthermore, the covariance of distances from ipas can also be estimated through bootstrapping. as for the covariance of distances obtained from opas, the main difficulty in computing them is that, since sequence pairs are aligned individually, they usually have inconsistencies in their inference of the homologous characters. thus, the alignments cannot be partitioned in consistent ""columns"" of characters, and neither susko's method nor resampling approaches such as bootstrapping can be applied. indeed, in the case of analyses relying exclusively on pairwise comparison and distance estimation, i.e. where no msa computation can be afforded, we are not aware of any previously published estimator for the covariance of distances estimates from pairwise alignments. we have shown in a previous article a numerical approximation for the constrained case of the covariance of two opa distances involving a common sequence, for empirical substitution models such as pam or jtt. in this article, we present an estimator for the covariance of ml distances estimated from opas that works on triplets and quartets of sequences. this solves the problem of sets of sequences of arbitrary size, because each covariance involves at most four sequences at a time. thus, the full covariance matrix is naturally obtained through quartet analysis. we analyze the performances of the estimator in terms of bias and variance. finally, we compare the results obtained on triplets of sequences to our previous work.  in the following, we present and analyze the performances of the estimator for the covariance of two distances. for this purpose, it is informative to analyze the results separately for the following three different underlying topological relations, illustrated in fig. 2: case of dependence the two distances are estimated between four distinct sequences, and they have some evolution in common. with such an evolutionary history, the two distances estimates covary positively. case of independence the two distances are estimated between four distinct sequences, but they have no evolution in common. this case is informative, because a central assumption in most evolutionary models is that evolution on different branches is independent. with no branch in common, the distances should not covary. thus, such a topology can be used to test the estimators as negative control. case of triplet the two distances involve a common sequence, and have some evolution in common. this case is of special interest, because we have previously presented an alternate estimator for this particular case using a different approach. thus, we can compare our results to this approach, hereafter called ""the numerical approximation"". note that the covariances are estimated using the same algorithm in all three cases: we only distinguish them from each another for the purpose of this analysis. to assess the performance of the covariance estimator, it was compared against the monte carlo covariance estimator. in short, each point shown in the figures was obtained from sets of sequences mutated along a random quartet subtree of the tree of life. that way, the evaluation is based on tree samples that are distributed as closely as possible to real biological data. to account for gene families with varying rates, each quartet was scaled with a random factor uniformly distributed between and note that results corresponding to very large distance constitute extreme cases; for instance, when sequences are pam units apart, each position has, on average, mutated times. fig. 3a shows the mean of our estimator versus the monte carlo estimator in nine scatterplots arising from combining the topologies mentioned above with three different sequence lengths. in the case of dependence, the first row, we see that our estimator lies in about 80% of the cases within the 95% confidence interval of the monte carlo estimator. in the case of independence, both estimators are close to zero, though our estimator shows a minor upward bias in some cases. the third row gives the result of both the covariance estimator introduced here, as well as the numerical approximation from our previous study. here, we see that though the former performs well in cases of lower covariance values, it shows a clear downward bias in cases of larger covariances. the numerical approximation does not present any apparent sign of bias, which is hardly surprising, given that it was obtained through regression. what is however surprising, is that, given its simple structure, it performs better than the covariance estimator, which takes into account more data and is backed by a more detailed model. it is instructive to compare the absolute bias of the covariance estimator to the well-known ml variance estimator. as can be seen in fig. 3b, the ml variance is also biased for high variance values. we conjecture that this is mainly due to mis-aligned positions, which cause model violations in the parameter estimation. this problem is also likely to affect the covariance estimator. even more directly, the ml variance estimator is a factor in the expression of the covariance estimator, so any error in the ml variance is propagated to the covariance estimator. at this point, improving the ml estimator for cases of high divergence is likely to require better alignments, or an explicit modeling of the mis-aligned positions, which is beyond the scope of the present work. further, to put the bias of the covariance estimator into perspective, we compared it to the standard deviation of the estimator. fig. presents the bias and standard deviation as function of the average number of anchors for sequence length of the anchors are the positions that are consistently aligned in the opas involved. both bias and standard deviation strongly depend on the fraction of anchors, which can be thought of as a measure of alignment quality. fig. depicts the dependency between percentage of anchors and average distance. as one would expect, the fraction of anchors decreases as divergence increases. for a fraction of anchor positions below 60%, the average of the two distances involved in the covariance computation is always greater than pam. in fig. we first consider the bias and standard deviation for the case of dependence. when the fraction of anchor positions is above 60%, the bias is far smaller than the standard deviation, and is therefore likely to have little negative impact in practice. in the case of triplets, the bias exceeds the standard deviation already when the fraction of anchors is about 80%. the ml variance estimator has this transition around 75% of anchors. in the case of independence, where we expect our covariance estimator to be zero, its bias is always much smaller than its standard deviation. most applications of the covariance estimator involve the covariance matrix. let a^ be an approximation to the matrix a. we refer to ||aˆ−a||2||a|| as the relative error in a^, where ||·|| denotes the two-norm. fig. shows the relative error of the × variance-covariance matrices computed with the ml variance estimator in the diagonal entries and our covariance estimator in the off-diagonal entries, and the same × matrices with only diagonal entries. the plots show that for the dependence case the the matrices with both covariance and ml variance estimators have a equal or lower relative error than the matrices with the ml variance only, except for a few cases in the region with a high fraction of anchors. in the triplet case, the variance-covariance matrices have always lower error then variance matrices. finally, in the case of independence, the matrices with covariance do not always have lower relative error, but this is expected, because the true covariance is null in this special case.  we have presented a method to estimate the covariances of distances estimated from pairwise alignments. it does not require the construction of msas, which are hard to compute and therefore are only approximated in practice. furthermore, it does not rely on phylogenetic trees as it is the case with covariance estimation from joint ml, or in covariance estimation methods that model the covariances as a function of shared branch lengths. tree building is not only a costly process, but is also subject to inference errors. the accuracy of our estimator is comparable to the ml variance estimator. both estimators are biased but in both cases the bias is, for distances below pam, far smaller than their standard deviation. the bias of the covariance estimator becomes worse with declining percentage of anchors. these biases arise because the alignment positions under scrutiny do not constitute an unbiased subsample of the true homologous positions. note that misaligned positions are likely to affect distances from msas too. a solution to this problem would lead to better distance estimates in the first place. in the meanwhile, it is probably best to issue a warning if the percentage of anchors falls below some threshold. the estimation of evolutionary distances is a very important process in molecular evolution, and therefore the covariance estimator presented here will be of use for various applications, such as the construction of gls trees on opa distances, the construction of confidence sets of trees based on the gls test statistic, relative-rate tests, distance-based lateral gene transfer detection, and in general in any process that needs to estimate confidence of distance combinations. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
32,32a6aca3-63d4-491b-810e-31fdcb20d87a_flant5_gen,"Physical exercise mitigates autophagy, attenuates apoptosis and promotes neurogenesis in the peri-infarct region after transient middle cerebral artery occlusion in rats."," ischemic stroke is a major cause of neurological disability and a big burden on the family and society. regaining function can significantly reduce dependence and improve the quality of life of stroke survivors. ischemic stroke has a very complex pathophysiology. in addition to irreversible neuronal damage, ischemia also triggers cellular processes for neuronal repair involving remaining neurons. apoptosis and necrosis are two vital types of cell death in ischemic brain injury. recently, autophagic cell death has been reported as a third type of cell death in ischemic tissue. autophagy is a lysosomal pathway for recycling of organelles and long-lived proteins. in the course of autophagy, autophagosomes or autophagic vacuoles, are formed to sequester cytoplasmic constituents. the autophagosomes fuse with lysosomes to digest the contents for recycling. physiologically, autophagy plays a key role in adapting to nutritional deprivation and eliminating aggregated proteins. however, inappropriate activation of autophagy may lead to cell death in cerebral ischemia. although it is unclear whether autophagy prevents or contributes to apoptotic cell death, the interaction between autophagy-related and apoptosis-related proteins, suggests an interplay between apoptosis and autophagy. on the other hand, stroke also induces neurogenesis. it has been reported that newborn neurons can contribute to functional recovery after stroke. interestingly, down-regulation of either autophagy or apoptosis can increase neurogenesis after stroke. therefore, the functional outcome may be resulted from a complex interplay among autophagy, apoptosis and neurogenesis following cerebral ischemia. previously, we and others have demonstrated that physical exercise can improve functional recovery after stroke. the protective effects of physical exercise are partially associated with enhancement of neurogenesis and attenuation of apoptosis. it is necessary to investigate the effects of physical exercise on neuronal proliferation and death. although it has been proved that physical exercise can mitigate autophagy and enhance functional recovery after myocardial infarction in animals, the role of autophagy in exercise-induced functional recovery after stroke remains elusive. growth factors such as igf- also have benefitial effects on exercise-induced functional recovery in cerebral ischemia. it is also reported that up-regulation of igf- expression mitigates autophagy in some conditions. consequently, the aim of this study is to investigate the effects of physical exercise on ischemia-induced autophagy, apoptosis, neurogenesis and igf- in the peri-infarct region after transient middle cerebral artery occlusion in rats. in this study, we demonstrated that physical exercise could mitigate autophagosome accumulation, attenuate apoptosis, promote neurogenesis and igf- expression in the peri-infarct region, thus improving the functional recovery.  physical exercise improved functional recovery the effects of physical exercise on neurological function were evaluated using modified neurological severity score scale. the mnss were ±, ± and ± at and days in the exercise groups after mcao, respectively. in contrast, the mnss were ±, ±, ± and ± at and days in the control group after mcao, respectively. the repeated measures anova revealed a significant main effect of mnss at and days, an significant interaction between treatment effects and time effects at and days and a significant time effect at and days. but there was no significant difference between two groups at days after mcao. non-parametric analysis revealed that the mnss values at or days were much lower than those in control group at days, indicating a spontaneous recovery after mcao. there was no significant difference in mean arterial pressure, rectal temperature, arterial blood gas values, glucose levels and body weight. physical exercise reduced the volume of the infarct area the relative infarct volumes were %± % at days in basal control group after mcao. the relative infarct volumes were %± % and %± % in physical exercise and control group at days after mcao. the relative infarct volumes were %± % and %± % at and days in the physical exercise group after mcao, respectively. in contrast, the relative infarct volumes were %± % and % ± % at and days in the control group after mcao, respectively. in control group, the infarct volumes were significantly smaller at and days than those at days after mcao, indicating a spontaneous recovery after mcao. compared with control group, physical exercise significantly reduced the infarct volumes at and days but not at days after mcao. interestingly, the attenuation of mnss was positively correlated with the reduction of infarct volumes. these findings suggest that physical exercise reduces brain damage and improves neurological function. physical exercise mitigated autophagosomes accumulation and attenuated apoptosis in the peri-infarct region to examine the involvement of autophagosomes, immunostaining was performed using an antibody against lc there are two forms of lc3—the cytosolic and membrane-bound forms. upon induction of autophagy, the cytosolic lc3-i is conjugated to phosphatidylethanolamine to form lc3-ii and the latter then translocates to the newly formed autophagosome membrane. therefore, lc staining shows a change from diffuse cytoplasmic pattern to intense punctate labelling when autophagosome formation is induced. lc staining remained diffuse within the cytoplasm in sham-operated rats or contra-lateral hemisphere. in contrast, lc staining displayed numerous punctate dots within the cytoplasm after transient mcao. lc3-immunopositive cells reached the peak in the peri-infarct region at days after mcao and decreased thereafter. there were significant differences in the number of lc3-punctate cells between control and physical exercise groups at and days, but not at days. compared with control group, physical exercise alleviated autophagy. furthermore, the number of lc3-punctate cells was positively correlated with both neurological function scores and relative infarct volumes, suggesting that activity of autophagy is associated with ischemic cellular injury. therefore, physical exercise improves functional recovery may, at least partially, through inhibition of autophagy. the tunel-positive cells were rare in the contra-lateral hemisphere and sham-operated group after mcao. in contrast, the tunel-positive cells were evident in peri-infarct region at days and then decreased gradually from to days. there were significant differences in the number of tunel-positive cells between physical exercise group and control group at and days, suggesting that physical exercise reduces apoptotic cell death. to further investigate the demise of lc3-positive cells, double-labeled immunofluorescence staining was performed using antibodies against lc and tunel. notably, double staining showed that % of lc3-positive cells were also stained with tunel. lc3/tunel double-positive cells were significantly lower in physical exercise groups than in control group. moreover, the induction of lc3-punctate cells was positively correlated with the number of tunel-positive cells. physical exercise increased the expression of igf- and promoted neurogenesis in the peri-infarct region igf-1-positive cells were evident on ischemic side but were rarely detected on the contra-lateral hemisphere. there was no co-localization between igf- and lc3-ii. compared with control group, physical exercise increased the expression of igf- at all the observed time points. ki a proliferative marker, was used to evaluate neurogenesis in the peri-infarct region. at days after mcao, ki67-positive cells were obvious in the peri-infarct region, but were barely visible in the contra-lateral cerebrum and sham-operated group. the number of ki67-immunopositive cells in the peri-infarct region reached the peak at days and decreased thereafter. physical exercise significantly increased ki67-immunopositive cells in the peri-infarct region at, and days after mcao. discussion in the present study, we investigated the effects of physical exercise on autophagy, apoptosis and neurogenesis. we found that ischemia-induced autophagy was associated with apoptotic cell death but not with neurogenesis, suggesting a deleterious role of autophagy in brain ischemic injury. in addition to attenuating autophagy and apoptotic cell death, physical exercise also promoted igf- expression and cell proliferation, thereby improving functional recovery. the function of autophagy in exercise-mediated protection against ischemia still remains controversial. for example, in myocardial infarction, prior exercise maintains basal autophagy and protects against cardiac ischemic injury. on the other hand, post-ischemic exercise reduces the ratio of lc3ii/lc3i and improves functional recovery. it is generally believed that imbalance or excessive autophagy promotes cellular pathology and ultimately leads to cell death in cerebral ischemia. however, the relationship between autophagy and exercise-mediated neuroprotection is not clear. consistently, we found that autophagosomes were accumulated after focal cerebral ischemia. in contrast, physical exercise attenuated ischemia-induced autophagosome accumulation. the suppression of autophagy by exercise was positively associated with the recovery of neurological function and reduction of brain damage, suggesting that physical exercise may improve functional recovery from ischemic stroke, at least in part, through inhibition of autophagy. cell death, especially apoptosis, is a major contributor to neuronal damage in cerebral ischemia. the interplay between autophagy and apoptosis is very complex. autophagy can either promote or inhibit apoptosis under different conditions. interestingly, we found that tunel-positive and lc3-punctate cells were pronounced in the peri-infarct region and the number of tunel-positive cells was positively correlated with the number of lc3-punctate cells. physical exercise significantly reduced both autophagic and apoptotic cell death. given that autophagy and apoptosis can share many common death pathways. our findings suggest that autophagy may play a pathologic role in ischemic cell death whereas physical exercise may attenuate ischemia-induced brain damage through inhibition of common upstream signals for cell death. neurogenesis, particularly igf-1-mediated neurogenesis, is a major mechanism underlying beneficial effects of exercise on ischemic stroke. post-ischemic neurogenesis is a complex process involving coordination of multiple signaling pathways. it has been reported that autophagy can play opposite roles in regulating neurogenesis depending on different conditions. for example, activation of autophagy can modulate cell proliferation during neuronal development and regeneration. on the other hand, reducing autophagic activity has been shown to promote neurogenesis after ischemic stroke. in addition, igf- is also thought to have significant inhibitory actions on autophagy through activation of mammalian target of rapamycin complex. consistently, exercise significantly increased the numbers of igf-1- positive cells and ki67-labeled proliferation cells. however, lc was not co-localized with either igf- or ki- indicating that autophagy may not be directly involved in ischemia-induced neurogenesis. whether igf- plays a role in exercise-induced mitigation of atuophagy needs further investigation.  altogether, our results suggest that the benefit of physical exercise on functional recovery is associated with mitigation of autophagy, attenuation of apoptosis and enhancement of neurogenesis as evidenced by igf- expression and cell proliferation in the peri-infarct region after stroke. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
33,32a6aca3-63d4-491b-810e-31fdcb20d87a_gpt3_gen,"Ischemic stroke is a major cause of neurological disability, but regaining function can significantly reduce dependence and improve the quality of life of stroke survivors. However, ischemia triggers complex cellular processes for neuronal repair involving autophagic cell death, which can contribute to apoptosis and necrosis in the ischemic brain injury. Recent findings suggest that the benefits of physical exercise on functional recovery are associated with mitigation of autophagy, attenuation of apoptosis, and enhancement of neurogenesis through the expression of insulin-like growth factor-1 and cell proliferation in the peri-infarct region after stroke."," ischemic stroke is a major cause of neurological disability and a big burden on the family and society. regaining function can significantly reduce dependence and improve the quality of life of stroke survivors. ischemic stroke has a very complex pathophysiology. in addition to irreversible neuronal damage, ischemia also triggers cellular processes for neuronal repair involving remaining neurons. apoptosis and necrosis are two vital types of cell death in ischemic brain injury. recently, autophagic cell death has been reported as a third type of cell death in ischemic tissue. autophagy is a lysosomal pathway for recycling of organelles and long-lived proteins. in the course of autophagy, autophagosomes or autophagic vacuoles, are formed to sequester cytoplasmic constituents. the autophagosomes fuse with lysosomes to digest the contents for recycling. physiologically, autophagy plays a key role in adapting to nutritional deprivation and eliminating aggregated proteins. however, inappropriate activation of autophagy may lead to cell death in cerebral ischemia. although it is unclear whether autophagy prevents or contributes to apoptotic cell death, the interaction between autophagy-related and apoptosis-related proteins, suggests an interplay between apoptosis and autophagy. on the other hand, stroke also induces neurogenesis. it has been reported that newborn neurons can contribute to functional recovery after stroke. interestingly, down-regulation of either autophagy or apoptosis can increase neurogenesis after stroke. therefore, the functional outcome may be resulted from a complex interplay among autophagy, apoptosis and neurogenesis following cerebral ischemia. previously, we and others have demonstrated that physical exercise can improve functional recovery after stroke. the protective effects of physical exercise are partially associated with enhancement of neurogenesis and attenuation of apoptosis. it is necessary to investigate the effects of physical exercise on neuronal proliferation and death. although it has been proved that physical exercise can mitigate autophagy and enhance functional recovery after myocardial infarction in animals, the role of autophagy in exercise-induced functional recovery after stroke remains elusive. growth factors such as igf- also have benefitial effects on exercise-induced functional recovery in cerebral ischemia. it is also reported that up-regulation of igf- expression mitigates autophagy in some conditions. consequently, the aim of this study is to investigate the effects of physical exercise on ischemia-induced autophagy, apoptosis, neurogenesis and igf- in the peri-infarct region after transient middle cerebral artery occlusion in rats. in this study, we demonstrated that physical exercise could mitigate autophagosome accumulation, attenuate apoptosis, promote neurogenesis and igf- expression in the peri-infarct region, thus improving the functional recovery.  physical exercise improved functional recovery the effects of physical exercise on neurological function were evaluated using modified neurological severity score scale. the mnss were ±, ± and ± at and days in the exercise groups after mcao, respectively. in contrast, the mnss were ±, ±, ± and ± at and days in the control group after mcao, respectively. the repeated measures anova revealed a significant main effect of mnss at and days, an significant interaction between treatment effects and time effects at and days and a significant time effect at and days. but there was no significant difference between two groups at days after mcao. non-parametric analysis revealed that the mnss values at or days were much lower than those in control group at days, indicating a spontaneous recovery after mcao. there was no significant difference in mean arterial pressure, rectal temperature, arterial blood gas values, glucose levels and body weight. physical exercise reduced the volume of the infarct area the relative infarct volumes were %± % at days in basal control group after mcao. the relative infarct volumes were %± % and %± % in physical exercise and control group at days after mcao. the relative infarct volumes were %± % and %± % at and days in the physical exercise group after mcao, respectively. in contrast, the relative infarct volumes were %± % and % ± % at and days in the control group after mcao, respectively. in control group, the infarct volumes were significantly smaller at and days than those at days after mcao, indicating a spontaneous recovery after mcao. compared with control group, physical exercise significantly reduced the infarct volumes at and days but not at days after mcao. interestingly, the attenuation of mnss was positively correlated with the reduction of infarct volumes. these findings suggest that physical exercise reduces brain damage and improves neurological function. physical exercise mitigated autophagosomes accumulation and attenuated apoptosis in the peri-infarct region to examine the involvement of autophagosomes, immunostaining was performed using an antibody against lc there are two forms of lc3—the cytosolic and membrane-bound forms. upon induction of autophagy, the cytosolic lc3-i is conjugated to phosphatidylethanolamine to form lc3-ii and the latter then translocates to the newly formed autophagosome membrane. therefore, lc staining shows a change from diffuse cytoplasmic pattern to intense punctate labelling when autophagosome formation is induced. lc staining remained diffuse within the cytoplasm in sham-operated rats or contra-lateral hemisphere. in contrast, lc staining displayed numerous punctate dots within the cytoplasm after transient mcao. lc3-immunopositive cells reached the peak in the peri-infarct region at days after mcao and decreased thereafter. there were significant differences in the number of lc3-punctate cells between control and physical exercise groups at and days, but not at days. compared with control group, physical exercise alleviated autophagy. furthermore, the number of lc3-punctate cells was positively correlated with both neurological function scores and relative infarct volumes, suggesting that activity of autophagy is associated with ischemic cellular injury. therefore, physical exercise improves functional recovery may, at least partially, through inhibition of autophagy. the tunel-positive cells were rare in the contra-lateral hemisphere and sham-operated group after mcao. in contrast, the tunel-positive cells were evident in peri-infarct region at days and then decreased gradually from to days. there were significant differences in the number of tunel-positive cells between physical exercise group and control group at and days, suggesting that physical exercise reduces apoptotic cell death. to further investigate the demise of lc3-positive cells, double-labeled immunofluorescence staining was performed using antibodies against lc and tunel. notably, double staining showed that % of lc3-positive cells were also stained with tunel. lc3/tunel double-positive cells were significantly lower in physical exercise groups than in control group. moreover, the induction of lc3-punctate cells was positively correlated with the number of tunel-positive cells. physical exercise increased the expression of igf- and promoted neurogenesis in the peri-infarct region igf-1-positive cells were evident on ischemic side but were rarely detected on the contra-lateral hemisphere. there was no co-localization between igf- and lc3-ii. compared with control group, physical exercise increased the expression of igf- at all the observed time points. ki a proliferative marker, was used to evaluate neurogenesis in the peri-infarct region. at days after mcao, ki67-positive cells were obvious in the peri-infarct region, but were barely visible in the contra-lateral cerebrum and sham-operated group. the number of ki67-immunopositive cells in the peri-infarct region reached the peak at days and decreased thereafter. physical exercise significantly increased ki67-immunopositive cells in the peri-infarct region at, and days after mcao. discussion in the present study, we investigated the effects of physical exercise on autophagy, apoptosis and neurogenesis. we found that ischemia-induced autophagy was associated with apoptotic cell death but not with neurogenesis, suggesting a deleterious role of autophagy in brain ischemic injury. in addition to attenuating autophagy and apoptotic cell death, physical exercise also promoted igf- expression and cell proliferation, thereby improving functional recovery. the function of autophagy in exercise-mediated protection against ischemia still remains controversial. for example, in myocardial infarction, prior exercise maintains basal autophagy and protects against cardiac ischemic injury. on the other hand, post-ischemic exercise reduces the ratio of lc3ii/lc3i and improves functional recovery. it is generally believed that imbalance or excessive autophagy promotes cellular pathology and ultimately leads to cell death in cerebral ischemia. however, the relationship between autophagy and exercise-mediated neuroprotection is not clear. consistently, we found that autophagosomes were accumulated after focal cerebral ischemia. in contrast, physical exercise attenuated ischemia-induced autophagosome accumulation. the suppression of autophagy by exercise was positively associated with the recovery of neurological function and reduction of brain damage, suggesting that physical exercise may improve functional recovery from ischemic stroke, at least in part, through inhibition of autophagy. cell death, especially apoptosis, is a major contributor to neuronal damage in cerebral ischemia. the interplay between autophagy and apoptosis is very complex. autophagy can either promote or inhibit apoptosis under different conditions. interestingly, we found that tunel-positive and lc3-punctate cells were pronounced in the peri-infarct region and the number of tunel-positive cells was positively correlated with the number of lc3-punctate cells. physical exercise significantly reduced both autophagic and apoptotic cell death. given that autophagy and apoptosis can share many common death pathways. our findings suggest that autophagy may play a pathologic role in ischemic cell death whereas physical exercise may attenuate ischemia-induced brain damage through inhibition of common upstream signals for cell death. neurogenesis, particularly igf-1-mediated neurogenesis, is a major mechanism underlying beneficial effects of exercise on ischemic stroke. post-ischemic neurogenesis is a complex process involving coordination of multiple signaling pathways. it has been reported that autophagy can play opposite roles in regulating neurogenesis depending on different conditions. for example, activation of autophagy can modulate cell proliferation during neuronal development and regeneration. on the other hand, reducing autophagic activity has been shown to promote neurogenesis after ischemic stroke. in addition, igf- is also thought to have significant inhibitory actions on autophagy through activation of mammalian target of rapamycin complex. consistently, exercise significantly increased the numbers of igf-1- positive cells and ki67-labeled proliferation cells. however, lc was not co-localized with either igf- or ki- indicating that autophagy may not be directly involved in ischemia-induced neurogenesis. whether igf- plays a role in exercise-induced mitigation of atuophagy needs further investigation.  altogether, our results suggest that the benefit of physical exercise on functional recovery is associated with mitigation of autophagy, attenuation of apoptosis and enhancement of neurogenesis as evidenced by igf- expression and cell proliferation in the peri-infarct region after stroke. ",pubmed_generic,GPT 3.5,"Recent findings suggest that the benefits of physical exercise on functional recovery are associated with mitigation of autophagy, attenuation of apoptosis, and enhancement of neurogenesis through the expression of insulin-like growth factor-1 and cell proliferation in the peri-infarct region after stroke.",non_factual,factual,minor,,intrinsic,,,,,
34,ff62c3e3-8690-4618-b188-b98fe536ba77_gpt3_gen,"Brucella is a genus of bacteria that causes brucellosis, a disease that affects many mammals including humans. The bacteria can be classified into different species based on their host range, surface structure, genetic markers, and other features. One of the main sources of genetic diversity in Brucella is the copy number and distribution of a mobile genetic element called IS. Most Brucella species contain a specific number of IS copies, but some strains of Brucella abortus have been found to have additional copies of IS that have transposed into new sites in the genome. These polymorphisms can have both negative and positive effects, disrupting gene functions or causing beneficial changes. The causes of IS transposition are not fully understood, but host-pathogen interactions may play a role. The discovery of IS polymorphism in B. abortus field strains highlights the importance of using multiple markers for molecular typing and suggests that changes in IS distribution could affect virulence."," brucella is a genus of bacteria causing brucellosis, a zoonosis that affects a large variety of mammals and that is readily transmitted to humans. the genus includes several classical species that can be distinguished by their preferential host range, surface structure, biochemical and physiological features, and genetic markers. this classification is reflected in some degree of genetic polymorphism, one of the main sources of which is the copy number and distribution of is. b. melitensis and b. suis contain seven complete is copies. b. abortus carries six complete and one truncated is copies, b. ceti and b. pinnipedialis more than copies and b. ovis copies. is is very stable: its mobility has been demonstrated only by using a ""transposon trap"" in vitro in b. ovis and b. pinnipedialis, but not in b. melitensis and b. abortus. based on this stability, polymorphism at the alkb locus is used to differentiate b. abortus from b. melitensis, b. ovis and b. suis in the amos multiplex pcr assay. is stability is not only relevant for brucella typification: its mobility is implicated in the generation of genetic diversity and speciation, as shown by the distribution of is among the extant brucella species. here we report that is transposition and the generation of the associated polymorphism takes place in b. abortus under natural conditions, when genetic drift should be limited by the selective pressure imposed by the host.  in a previous work with b. abortus strains, it was found that two isolates displayed is profiles that were different from that typical of b. abortus field strains. this is confirmed here by the genetic profiling summarized in table and by the is southern blot presented in figure the latter shows that, while the reference strain b. abortus presented seven is711-carrying fragments, isolates b, and b b and b displayed an additional one. it is known that rb a lipopolysaccharide rough strain obtained from b. abortus by multiple in vitro passages on antibiotic containing media, harbors eight copies plus an additional one that transposed into the lipopolysaccharide wboa gene. similarly, b. abortus a strain isolated more than sixty years ago and extensively replicated in different laboratories carries eight is copies. however, the molecular weight of x-b and x-b fragments was different from those bearing the extra is copies in and rb. interestingly, whereas strain b which was isolated from the same sample as b displayed the genetic profile typical of b. abortus, strains b b and b showed an identical profile, even though they were from successive outbreaks in the same flock. these results show that it is possible to find b. abortus field isolates with different is distributions. a is profiles are shown in figure b a, b. abortus typical pattern; b, b. abortus pattern; c, b. ovis typical pattern. c b and b were isolated from the same sample. d b b and b are strains isolated from different outbreaks in the same flock. e np: not performed we characterized the insertion sites in b and b to ascertain whether they were new or already present in other brucellae. to this end, we carried out is-anchored pcr using is711-bound primers plus a decamer of %gc similar to that of the brucella genome. the resulting amplicons ranged from - kb with a similar distribution among strains, but with an additional pcr fragment for each b and b strains. considering that those fragments may contain part of the additional is copies plus their surrounding sequences, we cloned and sequenced the kb and kb dna amplicons of b and b respectively, and designed flanking primers to confirm the position of the new is copy. as predicted for the insertion of complete is copies of bp in length, specific pcr products of bp and bp were amplified. we believe that an is replicative transposition is the most plausible explanation for these results. in fact, the sequence analysis suggested that transposition had occurred by a canonical ta duplication at ytar site. in strain b this site was in an intergenic region between a lactate permease gene and bruab1_ corresponding to a bp bru-rs element, a palindromic repeat sequence that represents a putative insertion site for is. in contrast, the is extra copy in b b and b was interrupting an orf encoding a transcriptional regulator of the marr family. similarity searches showed that the b and b sites did not match with any of the is loci previously reported for b. abortus or even with the novel is sites recently described for brucella marine mammal strains, although the b site was found in b. ovis. to confirm these findings and to investigate whether these sites were also present in the genomes of the brucella species carrying a high-copy number of is we carried out pcr assays with b. ovis, b. ceti and b. pinnipedialis dnas. for the b12-specific is pcr amplifications with flanking primers yielded an is-empty locus fragment. in contrast, the pcr amplifying the b fragment yielded the predicted bp fragment in b. ovis but not in b. ceti or b. pinnipedialis. the x-b and x-b is sequences were nearly identical to that of is711_1a and depicted only changes in a few nucleotides. on the basis of the high is sequence similarity across sequenced b. abortus strains, we performed a cluster analysis between the is copies of b. abortus 9- and those additional ones found in rb b and b strains to get insight about their origin. although as expected, the analysis disclosed only low sequence dissimilarity, it suggested that the new copies might derive from is711_1a. since a previous work has shown that the is711_xa in the b. abortus alkb locus and the is711_x- in strain are identical to is711_1a, the inclusion of is711_x-b and is711_x-b in the same cluster supports the hypothesis that is711_1a is more active than other copies in the b. abortus genome and can transpose into new sites or even into sites shared with related species. is transposition can disrupt genes and produce negative polar effects, but also cause beneficial changes by remodeling genomes through long range recombination. in the case of strain b it is uncertain whether the intergenic position of is disturbs the expression of nearby genes. most is studied in detail are also located within intergenic regions showing that transposition is mostly viable when occurring into neutral sites. however, the extra is copy in b b and b interrupts a putative transcriptional regulator that is expressed during the late-logarithmic phase of growth in b. melitensis and, interestingly, these strains did not show urease activity, a factor that has been proposed to favor brucella gastrointestinal infections in mice. we investigated whether the marr mutation was involved in the urease-negative phenotype by constructing a b. abortus Δmarr mutant. this mutant displayed urease activity, suggesting that the absence of urease in b b and b is probably caused by mutation in ure genes. the fact that these urease negative marr mutant strains were repeatedly isolated from aborted fetuses for at least four years questions the relevance of this factor in placental colonization and abortion induction. research is in progress to characterize the genetic background of this urease negative phenotype.  in this report, we have provided evidence that is polymorphism occurs in b. abortus field strains. the fact that such polymorphism can take place in sites shared with related species points out the relevance of a multiple-marker approach in molecular typing of brucella species. in addition, our results suggest that the extra is copies might originate from what seems to be the most active is copy. although the environmental signals involved in the activation of the transposase remain unknown, host-pathogen interactions may play a role. further work is needed to elucidate if changes promoted by is transposition are associated with virulence fluctuations in this pathogen. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
35,ff62c3e3-8690-4618-b188-b98fe536ba77_flant5_gen,b. abortus field strains display polymorphism in the is locus and the associated polymorphism can be attributed to the activation of the transposase.," brucella is a genus of bacteria causing brucellosis, a zoonosis that affects a large variety of mammals and that is readily transmitted to humans. the genus includes several classical species that can be distinguished by their preferential host range, surface structure, biochemical and physiological features, and genetic markers. this classification is reflected in some degree of genetic polymorphism, one of the main sources of which is the copy number and distribution of is. b. melitensis and b. suis contain seven complete is copies. b. abortus carries six complete and one truncated is copies, b. ceti and b. pinnipedialis more than copies and b. ovis copies. is is very stable: its mobility has been demonstrated only by using a ""transposon trap"" in vitro in b. ovis and b. pinnipedialis, but not in b. melitensis and b. abortus. based on this stability, polymorphism at the alkb locus is used to differentiate b. abortus from b. melitensis, b. ovis and b. suis in the amos multiplex pcr assay. is stability is not only relevant for brucella typification: its mobility is implicated in the generation of genetic diversity and speciation, as shown by the distribution of is among the extant brucella species. here we report that is transposition and the generation of the associated polymorphism takes place in b. abortus under natural conditions, when genetic drift should be limited by the selective pressure imposed by the host.  in a previous work with b. abortus strains, it was found that two isolates displayed is profiles that were different from that typical of b. abortus field strains. this is confirmed here by the genetic profiling summarized in table and by the is southern blot presented in figure the latter shows that, while the reference strain b. abortus presented seven is711-carrying fragments, isolates b, and b b and b displayed an additional one. it is known that rb a lipopolysaccharide rough strain obtained from b. abortus by multiple in vitro passages on antibiotic containing media, harbors eight copies plus an additional one that transposed into the lipopolysaccharide wboa gene. similarly, b. abortus a strain isolated more than sixty years ago and extensively replicated in different laboratories carries eight is copies. however, the molecular weight of x-b and x-b fragments was different from those bearing the extra is copies in and rb. interestingly, whereas strain b which was isolated from the same sample as b displayed the genetic profile typical of b. abortus, strains b b and b showed an identical profile, even though they were from successive outbreaks in the same flock. these results show that it is possible to find b. abortus field isolates with different is distributions. a is profiles are shown in figure b a, b. abortus typical pattern; b, b. abortus pattern; c, b. ovis typical pattern. c b and b were isolated from the same sample. d b b and b are strains isolated from different outbreaks in the same flock. e np: not performed we characterized the insertion sites in b and b to ascertain whether they were new or already present in other brucellae. to this end, we carried out is-anchored pcr using is711-bound primers plus a decamer of %gc similar to that of the brucella genome. the resulting amplicons ranged from - kb with a similar distribution among strains, but with an additional pcr fragment for each b and b strains. considering that those fragments may contain part of the additional is copies plus their surrounding sequences, we cloned and sequenced the kb and kb dna amplicons of b and b respectively, and designed flanking primers to confirm the position of the new is copy. as predicted for the insertion of complete is copies of bp in length, specific pcr products of bp and bp were amplified. we believe that an is replicative transposition is the most plausible explanation for these results. in fact, the sequence analysis suggested that transposition had occurred by a canonical ta duplication at ytar site. in strain b this site was in an intergenic region between a lactate permease gene and bruab1_ corresponding to a bp bru-rs element, a palindromic repeat sequence that represents a putative insertion site for is. in contrast, the is extra copy in b b and b was interrupting an orf encoding a transcriptional regulator of the marr family. similarity searches showed that the b and b sites did not match with any of the is loci previously reported for b. abortus or even with the novel is sites recently described for brucella marine mammal strains, although the b site was found in b. ovis. to confirm these findings and to investigate whether these sites were also present in the genomes of the brucella species carrying a high-copy number of is we carried out pcr assays with b. ovis, b. ceti and b. pinnipedialis dnas. for the b12-specific is pcr amplifications with flanking primers yielded an is-empty locus fragment. in contrast, the pcr amplifying the b fragment yielded the predicted bp fragment in b. ovis but not in b. ceti or b. pinnipedialis. the x-b and x-b is sequences were nearly identical to that of is711_1a and depicted only changes in a few nucleotides. on the basis of the high is sequence similarity across sequenced b. abortus strains, we performed a cluster analysis between the is copies of b. abortus 9- and those additional ones found in rb b and b strains to get insight about their origin. although as expected, the analysis disclosed only low sequence dissimilarity, it suggested that the new copies might derive from is711_1a. since a previous work has shown that the is711_xa in the b. abortus alkb locus and the is711_x- in strain are identical to is711_1a, the inclusion of is711_x-b and is711_x-b in the same cluster supports the hypothesis that is711_1a is more active than other copies in the b. abortus genome and can transpose into new sites or even into sites shared with related species. is transposition can disrupt genes and produce negative polar effects, but also cause beneficial changes by remodeling genomes through long range recombination. in the case of strain b it is uncertain whether the intergenic position of is disturbs the expression of nearby genes. most is studied in detail are also located within intergenic regions showing that transposition is mostly viable when occurring into neutral sites. however, the extra is copy in b b and b interrupts a putative transcriptional regulator that is expressed during the late-logarithmic phase of growth in b. melitensis and, interestingly, these strains did not show urease activity, a factor that has been proposed to favor brucella gastrointestinal infections in mice. we investigated whether the marr mutation was involved in the urease-negative phenotype by constructing a b. abortus Δmarr mutant. this mutant displayed urease activity, suggesting that the absence of urease in b b and b is probably caused by mutation in ure genes. the fact that these urease negative marr mutant strains were repeatedly isolated from aborted fetuses for at least four years questions the relevance of this factor in placental colonization and abortion induction. research is in progress to characterize the genetic background of this urease negative phenotype.  in this report, we have provided evidence that is polymorphism occurs in b. abortus field strains. the fact that such polymorphism can take place in sites shared with related species points out the relevance of a multiple-marker approach in molecular typing of brucella species. in addition, our results suggest that the extra is copies might originate from what seems to be the most active is copy. although the environmental signals involved in the activation of the transposase remain unknown, host-pathogen interactions may play a role. further work is needed to elucidate if changes promoted by is transposition are associated with virulence fluctuations in this pathogen. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
36,0373c5f7-f972-4ccf-800f-b0cff07a3ca3_gpt3_gen,"Researchers have found a high prevalence of Toxoplasma gondii infection in water buffaloes in Veracruz, Mexico. The parasite can cause severe and life-threatening disease in humans, especially in immunocompromised individuals. Consumption of raw or undercooked meat from infected buffaloes may pose a risk of transmission to humans. The study also found that environmental factors, such as mean annual rainfall, were associated with the prevalence of infection in the buffaloes. These results highlight the need for further research to investigate the risk of transmission from water buffaloes to humans and to develop strategies to mitigate this risk."," toxoplasma gondii is a widely distributed parasite infecting warm-blooded animals including the water buffalo. toxoplasmosis in humans may be a severe disease affecting the lymph nodes, eyes, and central nervous system and can be life-threatening mostly in immunocompromised patients. water buffaloes are important to the economy of many countries and in mexico they represent an emerging alternative for diversified livestock production. in asia, water buffaloes are the major source of milk and milk products, and their meat is consumed by humans in several countries. in general, buffaloes, like cattle, are considered resistant to clinical toxoplasmosis and there is no valid report of isolation of viable t. gondii from buffalo meat. recently, dehkordi et al. reported isolation of viable t. gondii from milk of of buffaloes in iran, but the validity of these results has been questioned. this report has raised concerns regarding transmission of t. gondii by consuming raw products from buffaloes. we are not aware of any report of t. gondii infection in water buffaloes from mexico. the objective of this study was to determine the seroprevalence and correlates of t. gondii infection in water buffaloes raised in several municipalities in veracruz, mexico. methods water buffaloes surveyed water buffaloes from geographical regions of veracruz, mexico were sampled from september to august these water buffaloes ranged freely and grazed on natural pastures. sampling was based on accessibility to ranches raising buffaloes in the mexican state of veracruz that shares its eastern border with the gulf of mexico. water buffaloes were located in ranches throughout these municipalities: isla, juan rodriguez clara, las choapas, and sayula de alemán. a questionnaire was used to obtain the general characteristics of the buffalo herds including age, sex, weight, breed, and obstetric history. additionally, environmental data were recorded including presence of common water source shared with other animals in the ranch, cohabitation with other animals, and climatic conditions. the age of the buffaloes ranged from to 11 years old, were males, and females. three water buffalo breeds were represented: murrah, carabao, and jafarabadi. ethics statement this project was approved by the bioethics and animal welfare commission of the facultad de medicina veterinaria y zootecnia of universidad veracruzana. consent was obtained from the owners of the buffaloes. serological examination for t. gondii antibodies serum samples were obtained and stored at −20°c until tested. testing for t. gondii antibodies in the buffaloes’ sera was performed using 2-fold serial dilutions from 1: to 1: with the modified agglutination test as described by dubey and desmonts. a titer of 1: was used as cut off for seropositivity in the mat. statistical analysis statistical analysis was performed with the aid of epi info version. software. the pearson’s chi-squared test was used for comparison of the frequencies among groups. the association between the buffaloes’ characteristics and t. gondii seropositivity was assessed by multivariable analysis. the dependent variable was seropositivity to t. gondii by mat for an individual animal. independent variables included in the multivariable analysis were those with a p value ≤ in the bivariate analysis: region, municipality, altitude, mean annual temperature, mean annual rainfall, and common water source. odds ratio and 95% confidence interval were calculated by multivariate analysis using backward stepwise logistic regression analysis. the hosmer-lemeshow goodness of fit test was used to assess the fitness of the regression model. statistical significance was set at a p value of < .  antibodies to t. gondii were found in of the buffaloes with mat titers of 1: in 1: in and 1: in 9; none of the samples had a higher titer. seroprevalence of t. gondii infection was significantly higher in buffaloes in the olmeca region than in the papaloapan region. all ranches had seropositive buffaloes, and seroprevalence in buffaloes varied significantly among ranches. a correlation of t. gondii seropositivity rates and environmental characteristics is shown in table  the seroprevalence varied among municipalities. the seroprevalence of t. gondii infection was significantly higher in buffaloes at 80– meters above sea level than those at 10– meters above sea level. the seroprevalence in warm climate was similar to the one in warm-humid climate. in contrast, the seroprevalence was significantly higher in municipalities with 27°c of mean annual temperature than in those with -25°c mean annual temperature. in addition, seroprevalence varied among mean annual rainfall, the seroprevalence was significantly higher in municipalities with 1266–1650 mm of mean annual rainfall than those with 2316–2900 mm of mean annual rainfall.table seroprevalence of t. gondii infection in water buffaloes in veracruz, mexico meters above sea level c mean annual temperature d mean annual rainfall e buffaloes tested seropositivity to t. gondii region a municipality b climate no. no. % astatistically significant difference in seroprevalences among regions. bstatistically significant difference in seroprevalences among municipalities. cstatistically significant difference in seroprevalences among masl. dsignificantly higher seroprevalence at 27°c than at -25°c matp. estatistically significant difference in seroprevalences among mar. table  shows the correlation of t. gondii seropositivity rates and the general characteristics of the buffaloes. seroprevalence of t. gondii infection did not vary with age, sex, breed, weight, and type of buffaloes, and with sharing of water, or contact with cattle. the seroprevalence of t. gondii infection was similar in female buffaloes with abortion history than in female buffaloes without abortion history. all buffaloes had contact with cats and dogs.table correlation of general characteristics of the buffaloes and seroprevalence of t. gondii infection buffaloes tested seroprevalence of t. gondii infection characteristics no. no. % p value environmental and buffaloes characteristics with a p value equal to or less than in the bivariate analysis included region, municipality, altitude, a mean annual temperature of 27°c, mean annual rainfall, and water sharing. multivariate analysis of such characteristics showed that t. gondii seropositivity in buffaloes was associated only with a mean annual rainfall between 1266–1650 mm. the result of the hosmer-lemeshow test was which indicates an acceptable fit of our regression model. discussion our results indicate that water buffaloes in veracruz, mexico have a relatively high seroprevalence of t. gondii infection. the worldwide prevalence of t. gondii infection in water buffaloes until was reviewed previously, and seroprevalences varied from 0% to 100% by using mat. since then, a few additional papers were published on this subject. antibodies to t. gondii were found in of water buffaloes from northern brazil. they used an in-house elisa and the cut-off titer for ifat was 1:. in a report from southern brazil, antibodies were found in of water buffaloes by ifat; sera were run at 1: and 1: dilutions and the seropositivity results were based on a titer of 1:. in a study in argentina, researchers found t. gondii antibodies in of buffaloes by ifat using a 1: cut off titer. using the same mat that we used, t. gondii antibodies were found in of water buffaloes in iran; most of the buffaloes had low titers. in most parts of the world water buffaloes are domesticated and probably acquire t. gondii by ingesting food or water contaminated with oocysts shed by infected domestic cats. water buffaloes in the present report ranged freely and had contact with domestic and wild cats. further research is needed to understand the dynamics of feline-buffalo transmission under free-ranging conditions in veracruz, mexico. in the present study water buffaloes living in municipalities with a mean annual rainfall of 1266–1650 mm had a higher seroprevalence than those living in municipalities with higher mean annual rainfall. it is not clear why a lower mean annual rainfall is associated with higher seroprevalence of t. gondii infection. it is possible that a higher mean annual rainfall might be accompanied with higher erosion of contaminated soil. in addition, copious rainfalls may dilute oocysts in contaminated water that might in turn lower the risk for t. gondii infection. although we are unable to explain why other environmental factors were associated with t. gondii infection, it has been postulated that shifts in environmental conditions can increase the prevalence of toxoplasmosis in susceptible hosts. environmental factors influencing the degree of oocysts exposure may also cause the difference in seropositivity among ranches as noted in water buffaloes from trinidad. there are no data regarding seroprevalence of t. gondii infection in cats among municipalities in veracruz state. it would be of interest to test domestic and wild cats in the region for t. gondii infection. nothing is known of the validity of different serological tests used for the diagnosis of toxoplasmosis in buffaloes. we are not aware of any serious attempts at isolation of viable t. gondii from tissues of naturally exposed buffaloes. buffaloes, like cattle, are considered resistant to clinical toxoplasmosis and we are not aware of any report of clinical toxoplasmosis in buffaloes. based on studies with naturally and experimentally infected cattle, the mat gave the best results for determining antibodies to t. gondii in cattle, and titers < 1: were considered nonspecific. a comparison of serological and bioassay data on naturally infected buffaloes is required to determine if the same criteria apply for mat diagnosis of t. gondii infection in water buffaloes. the reported high excretion of viable t. gondii in milk of naturally infected buffaloes from iran by dehkordi et al. needs confirmation. further research should be conducted to determine the role of consumption of raw or undercooked meat from buffaloes in the transmission of t. gondii infection to humans.  results of the present study indicate that buffaloes in veracruz state have a high t. gondii exposure. further research is needed to determine the risk of ingestion of raw or undercook buffalo meat for t. gondii infection in humans. competing interests the authors declare that they have no competing interests. authors’ contributions cae performed the laboratory tests, data analysis, and wrote the manuscript. drs designed the study protocol, obtained the blood samples and general data of the buffaloes, analyzed the results, and helped in the writing of the manuscript. zgv analyzed the results. acr, apc, nip, and mad obtained the blood samples and general data of the buffaloes, and analyzed the results. aapl performed the data analysis and helped in the writing of the manuscript. jpd analyzed the results and wrote the manuscript. all authors read and approved the final version of the manuscript. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
37,0373c5f7-f972-4ccf-800f-b0cff07a3ca3_flant5_gen,"t. gondii infection in water buffaloes in veracruz state, mexico."," toxoplasma gondii is a widely distributed parasite infecting warm-blooded animals including the water buffalo. toxoplasmosis in humans may be a severe disease affecting the lymph nodes, eyes, and central nervous system and can be life-threatening mostly in immunocompromised patients. water buffaloes are important to the economy of many countries and in mexico they represent an emerging alternative for diversified livestock production. in asia, water buffaloes are the major source of milk and milk products, and their meat is consumed by humans in several countries. in general, buffaloes, like cattle, are considered resistant to clinical toxoplasmosis and there is no valid report of isolation of viable t. gondii from buffalo meat. recently, dehkordi et al. reported isolation of viable t. gondii from milk of of buffaloes in iran, but the validity of these results has been questioned. this report has raised concerns regarding transmission of t. gondii by consuming raw products from buffaloes. we are not aware of any report of t. gondii infection in water buffaloes from mexico. the objective of this study was to determine the seroprevalence and correlates of t. gondii infection in water buffaloes raised in several municipalities in veracruz, mexico. methods water buffaloes surveyed water buffaloes from geographical regions of veracruz, mexico were sampled from september to august these water buffaloes ranged freely and grazed on natural pastures. sampling was based on accessibility to ranches raising buffaloes in the mexican state of veracruz that shares its eastern border with the gulf of mexico. water buffaloes were located in ranches throughout these municipalities: isla, juan rodriguez clara, las choapas, and sayula de alemán. a questionnaire was used to obtain the general characteristics of the buffalo herds including age, sex, weight, breed, and obstetric history. additionally, environmental data were recorded including presence of common water source shared with other animals in the ranch, cohabitation with other animals, and climatic conditions. the age of the buffaloes ranged from to 11 years old, were males, and females. three water buffalo breeds were represented: murrah, carabao, and jafarabadi. ethics statement this project was approved by the bioethics and animal welfare commission of the facultad de medicina veterinaria y zootecnia of universidad veracruzana. consent was obtained from the owners of the buffaloes. serological examination for t. gondii antibodies serum samples were obtained and stored at −20°c until tested. testing for t. gondii antibodies in the buffaloes’ sera was performed using 2-fold serial dilutions from 1: to 1: with the modified agglutination test as described by dubey and desmonts. a titer of 1: was used as cut off for seropositivity in the mat. statistical analysis statistical analysis was performed with the aid of epi info version. software. the pearson’s chi-squared test was used for comparison of the frequencies among groups. the association between the buffaloes’ characteristics and t. gondii seropositivity was assessed by multivariable analysis. the dependent variable was seropositivity to t. gondii by mat for an individual animal. independent variables included in the multivariable analysis were those with a p value ≤ in the bivariate analysis: region, municipality, altitude, mean annual temperature, mean annual rainfall, and common water source. odds ratio and 95% confidence interval were calculated by multivariate analysis using backward stepwise logistic regression analysis. the hosmer-lemeshow goodness of fit test was used to assess the fitness of the regression model. statistical significance was set at a p value of < .  antibodies to t. gondii were found in of the buffaloes with mat titers of 1: in 1: in and 1: in 9; none of the samples had a higher titer. seroprevalence of t. gondii infection was significantly higher in buffaloes in the olmeca region than in the papaloapan region. all ranches had seropositive buffaloes, and seroprevalence in buffaloes varied significantly among ranches. a correlation of t. gondii seropositivity rates and environmental characteristics is shown in table  the seroprevalence varied among municipalities. the seroprevalence of t. gondii infection was significantly higher in buffaloes at 80– meters above sea level than those at 10– meters above sea level. the seroprevalence in warm climate was similar to the one in warm-humid climate. in contrast, the seroprevalence was significantly higher in municipalities with 27°c of mean annual temperature than in those with -25°c mean annual temperature. in addition, seroprevalence varied among mean annual rainfall, the seroprevalence was significantly higher in municipalities with 1266–1650 mm of mean annual rainfall than those with 2316–2900 mm of mean annual rainfall.table seroprevalence of t. gondii infection in water buffaloes in veracruz, mexico meters above sea level c mean annual temperature d mean annual rainfall e buffaloes tested seropositivity to t. gondii region a municipality b climate no. no. % astatistically significant difference in seroprevalences among regions. bstatistically significant difference in seroprevalences among municipalities. cstatistically significant difference in seroprevalences among masl. dsignificantly higher seroprevalence at 27°c than at -25°c matp. estatistically significant difference in seroprevalences among mar. table  shows the correlation of t. gondii seropositivity rates and the general characteristics of the buffaloes. seroprevalence of t. gondii infection did not vary with age, sex, breed, weight, and type of buffaloes, and with sharing of water, or contact with cattle. the seroprevalence of t. gondii infection was similar in female buffaloes with abortion history than in female buffaloes without abortion history. all buffaloes had contact with cats and dogs.table correlation of general characteristics of the buffaloes and seroprevalence of t. gondii infection buffaloes tested seroprevalence of t. gondii infection characteristics no. no. % p value environmental and buffaloes characteristics with a p value equal to or less than in the bivariate analysis included region, municipality, altitude, a mean annual temperature of 27°c, mean annual rainfall, and water sharing. multivariate analysis of such characteristics showed that t. gondii seropositivity in buffaloes was associated only with a mean annual rainfall between 1266–1650 mm. the result of the hosmer-lemeshow test was which indicates an acceptable fit of our regression model. discussion our results indicate that water buffaloes in veracruz, mexico have a relatively high seroprevalence of t. gondii infection. the worldwide prevalence of t. gondii infection in water buffaloes until was reviewed previously, and seroprevalences varied from 0% to 100% by using mat. since then, a few additional papers were published on this subject. antibodies to t. gondii were found in of water buffaloes from northern brazil. they used an in-house elisa and the cut-off titer for ifat was 1:. in a report from southern brazil, antibodies were found in of water buffaloes by ifat; sera were run at 1: and 1: dilutions and the seropositivity results were based on a titer of 1:. in a study in argentina, researchers found t. gondii antibodies in of buffaloes by ifat using a 1: cut off titer. using the same mat that we used, t. gondii antibodies were found in of water buffaloes in iran; most of the buffaloes had low titers. in most parts of the world water buffaloes are domesticated and probably acquire t. gondii by ingesting food or water contaminated with oocysts shed by infected domestic cats. water buffaloes in the present report ranged freely and had contact with domestic and wild cats. further research is needed to understand the dynamics of feline-buffalo transmission under free-ranging conditions in veracruz, mexico. in the present study water buffaloes living in municipalities with a mean annual rainfall of 1266–1650 mm had a higher seroprevalence than those living in municipalities with higher mean annual rainfall. it is not clear why a lower mean annual rainfall is associated with higher seroprevalence of t. gondii infection. it is possible that a higher mean annual rainfall might be accompanied with higher erosion of contaminated soil. in addition, copious rainfalls may dilute oocysts in contaminated water that might in turn lower the risk for t. gondii infection. although we are unable to explain why other environmental factors were associated with t. gondii infection, it has been postulated that shifts in environmental conditions can increase the prevalence of toxoplasmosis in susceptible hosts. environmental factors influencing the degree of oocysts exposure may also cause the difference in seropositivity among ranches as noted in water buffaloes from trinidad. there are no data regarding seroprevalence of t. gondii infection in cats among municipalities in veracruz state. it would be of interest to test domestic and wild cats in the region for t. gondii infection. nothing is known of the validity of different serological tests used for the diagnosis of toxoplasmosis in buffaloes. we are not aware of any serious attempts at isolation of viable t. gondii from tissues of naturally exposed buffaloes. buffaloes, like cattle, are considered resistant to clinical toxoplasmosis and we are not aware of any report of clinical toxoplasmosis in buffaloes. based on studies with naturally and experimentally infected cattle, the mat gave the best results for determining antibodies to t. gondii in cattle, and titers < 1: were considered nonspecific. a comparison of serological and bioassay data on naturally infected buffaloes is required to determine if the same criteria apply for mat diagnosis of t. gondii infection in water buffaloes. the reported high excretion of viable t. gondii in milk of naturally infected buffaloes from iran by dehkordi et al. needs confirmation. further research should be conducted to determine the role of consumption of raw or undercooked meat from buffaloes in the transmission of t. gondii infection to humans.  results of the present study indicate that buffaloes in veracruz state have a high t. gondii exposure. further research is needed to determine the risk of ingestion of raw or undercook buffalo meat for t. gondii infection in humans. competing interests the authors declare that they have no competing interests. authors’ contributions cae performed the laboratory tests, data analysis, and wrote the manuscript. drs designed the study protocol, obtained the blood samples and general data of the buffaloes, analyzed the results, and helped in the writing of the manuscript. zgv analyzed the results. acr, apc, nip, and mad obtained the blood samples and general data of the buffaloes, and analyzed the results. aapl performed the data analysis and helped in the writing of the manuscript. jpd analyzed the results and wrote the manuscript. all authors read and approved the final version of the manuscript. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
38,4f3febc4-c96c-44b1-ad6f-feeec5b2b20a_gpt3_gen,"The article describes a method for detecting copy number variants (CNVs) in targeted high-throughput sequencing data using a combination of depth of coverage and partially-mapped reads analysis. The method allows for the identification of DNA gain or loss even where breakpoints are outside the targeted regions and exact breakpoint characterization where breakpoints are within targeted regions. The method was tested on data from targeted sequencing of genomic regions that contribute to inherited breast and ovarian cancer susceptibility, and was able to detect CNVs of any size with a low false-positive rate. The authors highlight the advantages of their method over previous methods that rely on sequence-based data or relative coverage, and conclude that their method is simple yet robust and scalable."," massively parallel sequencing technology can be used to efficiently interrogate multiple targeted genomic regions for clinically relevant mutations. the use of short unique sequence indexes, or barcodes, increases sequencing throughput and allows analysis of multiple samples in a single sequencing run. application of this technology will allow cost-efficient screening of genes known or suspected to harbor clinically relevant pathogenic mutations. while small mutations are readily detectable with current analysis platforms, methods for the identification of copy-number variants are not well established for targeted data. the ability to detect the full spectrum of mutations is critical to the success of targeted sequencing projects. current methods for detecting structural variation from massively parallel data use either paired-end mapping or depth of coverage methods. paired-end mapping methods perform well for mate-pair sequence data and have the advantage of identifying both balanced and unbalanced structural variation. comprehensive cnv scanning using paired-end mapping requires mulitple insert sizes and the presence of paired tags that bridge the breakpoint of the event. this approach is widely used in the assembly of whole genomes but cannot be applied to targeted enrichment protocols, as hybridization-based capture methods for massively parallel sequencing typically require small insert fragments and breakpoints of structural variants may lie outside of targeted regions. depth of coverage methods do not require breakpoint capture or have specific size restrictions, yet such methods are hampered by low signal to noise ratio due to sparse sampling and sampling bias based on sequence gc-content, bait coverage, and other factors affecting capture efficiency. further, depth of coverage methods require cross-sample normalization and comparison in order to deal with variation in coverage across genomic regions and samples. we previously showed that a basic depth of coverage approach performs well to identify cnvs from high-coverage targeted sequence data. depth of coverage methods have achieved higher signal to noise by averaging data across a genomic region, however, doing so results in a loss of the ability to detect smaller mutations. in addition, depth of coverage methods are poor at localizing breakpoints. here we describe a method that combines cnv detection through high-resolution depth of coverage analysis with call confirmation through partially-mapped reads. this allows for the identification of dna gain or loss even where breakpoints are outside the targeted regions, and exact breakpoint characterization where breakpoints are within the targeted regions. by combining these orthologous approaches, cnvs of any size can be identified from targeted high-throughput sequence data with a low false-positive rate.  our method uses two independent approaches, depth of coverage and a scan for partially-mapped reads at cnv edges. we implemented a straightforward depth of coverage algorithm and internally validated cnv calls by looking for a signature of partially-mapped reads that confirm the cnv breakpoints where possible. partially-mapped reads are defined as high-quality full length reads where the best alignment to targeted regions is a perfect match less than bases in length. a minimum match length of bp was used for this analysis. where partially-mapped reads match to a cnv edge, it is assumed that the unaligned portion of the read maps to sequence flanking the other breakpoint and the partially-mapping reads can be aligned to each other to form a consensus sequence that flanks the breakpoint. for example, in the case of a deletion, the partially mapped reads will correspond to sequence flanking the deleted region, giving the exact breakpoints of the cnv. partially-mapped reads map to the reference sequence differently for gains and losses, as described for paired-end mapping methods of cnv detection. where cnv breakpoints lie within non-targeted sequence, partially-mapped reads are unavailable and depth of coverage is the only evidence used for cnv calling. our data were massively parallel sequence reads from a capture design that targets genomic sequence across genes which are known to predispose to high risks of breast and ovarian cancer. a total of kbp sequence was targeted in samples concurrently, running samples per lane on an illumina gaiix instrument. sequencing was performed with a standard multiplex × paired-end reads using truseq sbs chemistry and analyzed with illumina scs /rta and the demultiplexing script within casava http://www.illumina.com. single base coverage was calculated based on the number of tags for each sample overlapping each base across targeted regions. figure illustrates the regional variation in raw coverage and the increase in signal-to-noise ratio after cross-sample normalization for a representative diploid region of brca resulting in ratio values that closely cluster around one in a region with no cnvs in the samples analyzed. we obtained median raw coverage of 350× across the kbp of targeted sequence. low coverage regions were primarily gc-rich, consistent with other targeted sequence data, and account for the majority of bases excluded from screening for structural variation. % of targeted bases had median coverage of at least 10×, permitting high-confidence detection of single base and short indels for nearly all sequence assayed. in order to estimate the effect of random noise on the false-negative rate, we simulated data where one cnv of bp, bp, bp, bp, or bp was present within mb of sequence and tested for detection of the cnv across varying signal-to-noise ratios. this analysis indicated that our methods can detect a bp cnv with 87% sensitivity at a signal-to-noise ratio of a criteria met by > % of the bases targeted in this experiment, and a bp cnv with 80% sensitivity at signal-to-noise ratio of a criteria met by % of the bases. in the samples that passed quality control, we identified a total of cnvs in four genes through depth of coverage analysis that passed minimum coverage and z-score requirements and were confirmed by sanger sequencing or mlpa. for losses, one homozygous deletion and four hemizygous deletions were detected, with no reads from the homozygous deletion and median ratio across hemizygous deletion regions between and. for single copy gains, median duplication ratios were between and. a triplication was also observed with a ratio of, demonstrating that ratio accurately reflects copy number. all samples were previously tested for cnvs in brca and brca and we correctly identified all known mutations and generated no false positive calls in these genes. a size reflects minimum size, as breakpoints are located within flanking repetetive sequence b for homozygous deletion, no reads are present within region cnvs identified within high-risk breast and ovarian cancer genes targeted by this experiment. calls were made via depth of coverage and confirmed with partially-mapped read analysis where possible. after applying depth of coverage methods to detect cnv regions, we mapped sequence reads at the edges of the events to confirm the calls and identify exact breakpoints. this process requires that at least one breakpoint be within unique targeted sequence, as targeted capture generates sequences only over targeted regions and non-unique short sequence tags are difficult or impossible to map accurately. of the cnvs, four deletions were predicted to have at least one breakpoint in unique sequence. using a signature of partially-mapped reads, we confirmed these calls and identified exact breakpoints for all four events. while we identified no duplications with edges in unique sequence, duplications will produce a similar signature to deletions and can be confirmed using the same process. the first deletion, of bp, removes an exon of brca. we confirmed a bp homozygous deletion in brca that matches a known indel, indicating that our method is sensitive to small cnvs. the final two deletions mapped to the same pten coordinates and overlap with a known cnv previously identified by array comparative genomic hybridization. in comparison to acgh methods, we were able to resolve exact breakpoints for this bp polymorphic deletion. importantly, mapping sequence tags to the breakpoints allowed exclusion of a large number of false positive calls. all seven cnvs with breakpoints predicted to be within repetitive non-targeted sequence were validated by sanger sequencing or mlpa. in the kbp in samples there was one cnv called that could not be confirmed. this bp duplication could not be verified through sequence mapping or sanger sequencing and is a likely false positive. breakpoint resolution via partial read mapping reduced the number of false positives to a single duplication across samples and kbp. discussion targeted high-thoughput sequencing data is used to produce high-coverage sequence data on specific regions of the genome. targeted regions are often non-contiguous, as in the case of coding sequence capture or interruptions due to repeat sequences. we created a method that is specific to high-coverage, non-contiguous sequence data for robust cnv detection from targeted sequence data. our method does not require sequencing across cnv breakpoints, but leverages sequence level data for exact cnv characterization where breakpoints are within targeted regions. using a test dataset of regions that contribute to inherited breast and ovarian cancer susceptibility, we identified mutations, localizing mutations to exact genomic breakpoints. the minimum size for a cnv that we detected was bp, and there was only one suspected false positive among all samples that passed quality control. our method has several advantages over previous methods used to detect cnvs from high-throughput sequencing. while sequence-based cnv signal is preferable over relative coverage, sequence data is unavailable in targeted data whenever the cnv breakpoints are not in the targeted region. this introduces a major issue for methods that rely on sequence-based data for cnv detection. additionally, as described earlier, paired-end mapping strategies are not currently applicable when targeted enrichment is used. in comparison, relative depth of coverage is problematic due to local variation in coverage within samples and variation in coverage across samples. this leads to problems with false-positive signal when scanning for regions that depart from expected diploid coverage. this issue can be partially addressed by averaging read depth across a genomic region, however, doing so reduces the ability to detect small mutations. by combining ortholgous algorithms, we eliminated from consideration a large number of false-positive cnvs called by depth of coverage methods where no signal of partially-mapped reads was present. the ability to computationally resolve the majority of false-positive calls permitted us to use high-resolution analysis even where signal-to-noise ratio was intermediate. in addition, depth of coverage analysis has the benefit of producing a quantitative estimate of copy-count, as demonstrated by the clear distinction between duplication and triplication ratios. the major limitation of depth of coverage methods arises in duplicated genomic regions, such as segmental duplications or smaller regions of homology between genomic regions. within such regions, the expected ratio for deletions and duplications is relative to the copy count in the genome. for depth of coverage, a copy number change from two to one or two to three produces a strong signal, however, copy number changes in duplicated regions of the genome produce weaker signal that can be easily overwhelmed by noise. for example, variation between samples will overwhelm the signal of a change from six copies to five, where the expected ratio would be. as such, we limit analysis to unique regions of the genome. in addition, depth of coverage methods do not detect balanced structural variation. the methods we describe here were optimized for multiplexed high-coverage data, but we expect the fundamental approach will be applicable to experiments with a larger volume of targeted sequence, such as exome capture. while we used multiplexed data from a relatively small number of targeted bases, the method we describe is scalable and could be used on any dataset where signal-to-noise ratio allows reliable depth of coverage cnv calling. where local variation is too high or coverage too low, average coverage across a genomic window can be used instead of single base coverage, although this lowers resolution to the size of the window used. however, scanning across the window for partially-mapped reads as we do here would still permit exact cnv breakpoint characterization when breakpoints are in targeted sequence.  targeted massively parallel sequencing permits screening of genomic regions for multiple samples simultaneously, and thus is a powerful and cost-effective tool for characterizing mutations in contexts where multiple genes or pathways are involved. we demonstrate that a combination of depth of coverage and analysis of partially-mapped reads allows detection with high-confidence of cnvs within unique sequence, to a resolution of bp. furthermore, we demonstrate that ratio can be used to estimate absolute copy number and that depth of coverage alone is sufficient for cnvs where breakpoints are not represented within targeted regions. the method we describe here is robust, yet simple to implement; while we employ specific mapping and segmentation algorithms, the overall framework is amenable to improvement and variation in the algorithms as massively parallel sequencing technology progresses. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
39,4f3febc4-c96c-44b1-ad6f-feeec5b2b20a_flant5_gen,a method for detecting copy-number variants from targeted sequencing data," massively parallel sequencing technology can be used to efficiently interrogate multiple targeted genomic regions for clinically relevant mutations. the use of short unique sequence indexes, or barcodes, increases sequencing throughput and allows analysis of multiple samples in a single sequencing run. application of this technology will allow cost-efficient screening of genes known or suspected to harbor clinically relevant pathogenic mutations. while small mutations are readily detectable with current analysis platforms, methods for the identification of copy-number variants are not well established for targeted data. the ability to detect the full spectrum of mutations is critical to the success of targeted sequencing projects. current methods for detecting structural variation from massively parallel data use either paired-end mapping or depth of coverage methods. paired-end mapping methods perform well for mate-pair sequence data and have the advantage of identifying both balanced and unbalanced structural variation. comprehensive cnv scanning using paired-end mapping requires mulitple insert sizes and the presence of paired tags that bridge the breakpoint of the event. this approach is widely used in the assembly of whole genomes but cannot be applied to targeted enrichment protocols, as hybridization-based capture methods for massively parallel sequencing typically require small insert fragments and breakpoints of structural variants may lie outside of targeted regions. depth of coverage methods do not require breakpoint capture or have specific size restrictions, yet such methods are hampered by low signal to noise ratio due to sparse sampling and sampling bias based on sequence gc-content, bait coverage, and other factors affecting capture efficiency. further, depth of coverage methods require cross-sample normalization and comparison in order to deal with variation in coverage across genomic regions and samples. we previously showed that a basic depth of coverage approach performs well to identify cnvs from high-coverage targeted sequence data. depth of coverage methods have achieved higher signal to noise by averaging data across a genomic region, however, doing so results in a loss of the ability to detect smaller mutations. in addition, depth of coverage methods are poor at localizing breakpoints. here we describe a method that combines cnv detection through high-resolution depth of coverage analysis with call confirmation through partially-mapped reads. this allows for the identification of dna gain or loss even where breakpoints are outside the targeted regions, and exact breakpoint characterization where breakpoints are within the targeted regions. by combining these orthologous approaches, cnvs of any size can be identified from targeted high-throughput sequence data with a low false-positive rate.  our method uses two independent approaches, depth of coverage and a scan for partially-mapped reads at cnv edges. we implemented a straightforward depth of coverage algorithm and internally validated cnv calls by looking for a signature of partially-mapped reads that confirm the cnv breakpoints where possible. partially-mapped reads are defined as high-quality full length reads where the best alignment to targeted regions is a perfect match less than bases in length. a minimum match length of bp was used for this analysis. where partially-mapped reads match to a cnv edge, it is assumed that the unaligned portion of the read maps to sequence flanking the other breakpoint and the partially-mapping reads can be aligned to each other to form a consensus sequence that flanks the breakpoint. for example, in the case of a deletion, the partially mapped reads will correspond to sequence flanking the deleted region, giving the exact breakpoints of the cnv. partially-mapped reads map to the reference sequence differently for gains and losses, as described for paired-end mapping methods of cnv detection. where cnv breakpoints lie within non-targeted sequence, partially-mapped reads are unavailable and depth of coverage is the only evidence used for cnv calling. our data were massively parallel sequence reads from a capture design that targets genomic sequence across genes which are known to predispose to high risks of breast and ovarian cancer. a total of kbp sequence was targeted in samples concurrently, running samples per lane on an illumina gaiix instrument. sequencing was performed with a standard multiplex × paired-end reads using truseq sbs chemistry and analyzed with illumina scs /rta and the demultiplexing script within casava http://www.illumina.com. single base coverage was calculated based on the number of tags for each sample overlapping each base across targeted regions. figure illustrates the regional variation in raw coverage and the increase in signal-to-noise ratio after cross-sample normalization for a representative diploid region of brca resulting in ratio values that closely cluster around one in a region with no cnvs in the samples analyzed. we obtained median raw coverage of 350× across the kbp of targeted sequence. low coverage regions were primarily gc-rich, consistent with other targeted sequence data, and account for the majority of bases excluded from screening for structural variation. % of targeted bases had median coverage of at least 10×, permitting high-confidence detection of single base and short indels for nearly all sequence assayed. in order to estimate the effect of random noise on the false-negative rate, we simulated data where one cnv of bp, bp, bp, bp, or bp was present within mb of sequence and tested for detection of the cnv across varying signal-to-noise ratios. this analysis indicated that our methods can detect a bp cnv with 87% sensitivity at a signal-to-noise ratio of a criteria met by > % of the bases targeted in this experiment, and a bp cnv with 80% sensitivity at signal-to-noise ratio of a criteria met by % of the bases. in the samples that passed quality control, we identified a total of cnvs in four genes through depth of coverage analysis that passed minimum coverage and z-score requirements and were confirmed by sanger sequencing or mlpa. for losses, one homozygous deletion and four hemizygous deletions were detected, with no reads from the homozygous deletion and median ratio across hemizygous deletion regions between and. for single copy gains, median duplication ratios were between and. a triplication was also observed with a ratio of, demonstrating that ratio accurately reflects copy number. all samples were previously tested for cnvs in brca and brca and we correctly identified all known mutations and generated no false positive calls in these genes. a size reflects minimum size, as breakpoints are located within flanking repetetive sequence b for homozygous deletion, no reads are present within region cnvs identified within high-risk breast and ovarian cancer genes targeted by this experiment. calls were made via depth of coverage and confirmed with partially-mapped read analysis where possible. after applying depth of coverage methods to detect cnv regions, we mapped sequence reads at the edges of the events to confirm the calls and identify exact breakpoints. this process requires that at least one breakpoint be within unique targeted sequence, as targeted capture generates sequences only over targeted regions and non-unique short sequence tags are difficult or impossible to map accurately. of the cnvs, four deletions were predicted to have at least one breakpoint in unique sequence. using a signature of partially-mapped reads, we confirmed these calls and identified exact breakpoints for all four events. while we identified no duplications with edges in unique sequence, duplications will produce a similar signature to deletions and can be confirmed using the same process. the first deletion, of bp, removes an exon of brca. we confirmed a bp homozygous deletion in brca that matches a known indel, indicating that our method is sensitive to small cnvs. the final two deletions mapped to the same pten coordinates and overlap with a known cnv previously identified by array comparative genomic hybridization. in comparison to acgh methods, we were able to resolve exact breakpoints for this bp polymorphic deletion. importantly, mapping sequence tags to the breakpoints allowed exclusion of a large number of false positive calls. all seven cnvs with breakpoints predicted to be within repetitive non-targeted sequence were validated by sanger sequencing or mlpa. in the kbp in samples there was one cnv called that could not be confirmed. this bp duplication could not be verified through sequence mapping or sanger sequencing and is a likely false positive. breakpoint resolution via partial read mapping reduced the number of false positives to a single duplication across samples and kbp. discussion targeted high-thoughput sequencing data is used to produce high-coverage sequence data on specific regions of the genome. targeted regions are often non-contiguous, as in the case of coding sequence capture or interruptions due to repeat sequences. we created a method that is specific to high-coverage, non-contiguous sequence data for robust cnv detection from targeted sequence data. our method does not require sequencing across cnv breakpoints, but leverages sequence level data for exact cnv characterization where breakpoints are within targeted regions. using a test dataset of regions that contribute to inherited breast and ovarian cancer susceptibility, we identified mutations, localizing mutations to exact genomic breakpoints. the minimum size for a cnv that we detected was bp, and there was only one suspected false positive among all samples that passed quality control. our method has several advantages over previous methods used to detect cnvs from high-throughput sequencing. while sequence-based cnv signal is preferable over relative coverage, sequence data is unavailable in targeted data whenever the cnv breakpoints are not in the targeted region. this introduces a major issue for methods that rely on sequence-based data for cnv detection. additionally, as described earlier, paired-end mapping strategies are not currently applicable when targeted enrichment is used. in comparison, relative depth of coverage is problematic due to local variation in coverage within samples and variation in coverage across samples. this leads to problems with false-positive signal when scanning for regions that depart from expected diploid coverage. this issue can be partially addressed by averaging read depth across a genomic region, however, doing so reduces the ability to detect small mutations. by combining ortholgous algorithms, we eliminated from consideration a large number of false-positive cnvs called by depth of coverage methods where no signal of partially-mapped reads was present. the ability to computationally resolve the majority of false-positive calls permitted us to use high-resolution analysis even where signal-to-noise ratio was intermediate. in addition, depth of coverage analysis has the benefit of producing a quantitative estimate of copy-count, as demonstrated by the clear distinction between duplication and triplication ratios. the major limitation of depth of coverage methods arises in duplicated genomic regions, such as segmental duplications or smaller regions of homology between genomic regions. within such regions, the expected ratio for deletions and duplications is relative to the copy count in the genome. for depth of coverage, a copy number change from two to one or two to three produces a strong signal, however, copy number changes in duplicated regions of the genome produce weaker signal that can be easily overwhelmed by noise. for example, variation between samples will overwhelm the signal of a change from six copies to five, where the expected ratio would be. as such, we limit analysis to unique regions of the genome. in addition, depth of coverage methods do not detect balanced structural variation. the methods we describe here were optimized for multiplexed high-coverage data, but we expect the fundamental approach will be applicable to experiments with a larger volume of targeted sequence, such as exome capture. while we used multiplexed data from a relatively small number of targeted bases, the method we describe is scalable and could be used on any dataset where signal-to-noise ratio allows reliable depth of coverage cnv calling. where local variation is too high or coverage too low, average coverage across a genomic window can be used instead of single base coverage, although this lowers resolution to the size of the window used. however, scanning across the window for partially-mapped reads as we do here would still permit exact cnv breakpoint characterization when breakpoints are in targeted sequence.  targeted massively parallel sequencing permits screening of genomic regions for multiple samples simultaneously, and thus is a powerful and cost-effective tool for characterizing mutations in contexts where multiple genes or pathways are involved. we demonstrate that a combination of depth of coverage and analysis of partially-mapped reads allows detection with high-confidence of cnvs within unique sequence, to a resolution of bp. furthermore, we demonstrate that ratio can be used to estimate absolute copy number and that depth of coverage alone is sufficient for cnvs where breakpoints are not represented within targeted regions. the method we describe here is robust, yet simple to implement; while we employ specific mapping and segmentation algorithms, the overall framework is amenable to improvement and variation in the algorithms as massively parallel sequencing technology progresses. ",pubmed_generic,Flan T5,a method for detecting copy-number variants from targeted sequencing data,non_factual,factual,minor,,intrinsic,,,,,
40,c2188a48-6f65-4895-825d-e2d5f172dc90_flant5_gen,This study aimed to identify suitable endogenous control genes for use in rt-pcr experiments in bovine endometrium.," quantitative real-time reverse transcription pcr is an extremely sensitive technique that allows the precise measurement of gene expression across more than seven orders of magnitude. rt-pcr is often considered the gold standard for quantifying gene expression, and is commonly used to validate techniques with greater throughput but less overall sensitivity, such as microarray analysis. rt-pcr relies on the use of fluorescent dyes to quantify transcript amplification, with the amplification cycle number at which these dyes/transcripts are detected giving an indication as to the relative abundance of the target molecules. the sensitivity of rt-pcr makes it a powerful tool for gene expression measurement, especially when sample quantities are limited or a transcript is expressed at a low level. however, this sensitivity also means that a great deal of care must be taken with regards to experimental design and implementation of the procedure. when designing an experiment to evaluate gene expression in a group of samples, a number of critical factors must be kept constant. these include rna extraction, dnase treatments, and cdna synthesis. normalisation of rt-pcr results is required to control inter-sample differences that may arise as a result of these sample processing steps, and ensure the gene expression of target transcripts are robustly quantifiable. the most common method for normalising rt-pcr data involves the use of one or more endogenous control genes. an ideal endogenous control gene is one that is stably expressed within the samples to be compared, regardless of tissue differences, experimental conditions, or treatments. choosing an endogenous control gene to normalise gene expression data is one of the most crucial steps in the experimental design. genes used as endogenous controls in rt-pcr experiments are often chosen with little prior knowledge of their expression over the experimental conditions examined, and are often selected arbitrarily from a pool of commonly used endogenous control genes such as gapdh, and β-actin. the most widely used endogenous control gene in studies of endometrial gene expression is gapdh. however, the suitability of gapdh as an endogenous control gene has recently come into question, especially due to its potential regulation in a wide variety of physiological states, making it a questionable choice for rt-pcr normalisation. over the past three decades, genetic selection for milk production has resulted in a significant decline in dairy cattle fertility. the fertilisation rate in dairy cattle is around 90% and does not differ between low-moderate and high-producing animals. however, the calving rate in lower producing animals is approximately 55%, whereas in high-producing animals this rate is approximately 35%. pregnancy losses are thought to occur primarily during the pregnancy recognition/pre-implantation period, making studies of endometrial gene expression critical to further understanding of pregnancy establishment, recognition and maintenance within the bovine reproductive cycle. the primary aim of this study was to identify suitable endogenous control genes for analysis of endometrial tissues from pregnant and cycling bovines. this study also aimed to investigate the potential use of microarray data analysis for identification of novel endogenous control genes, and the effect of endogenous control gene selection on the calculated expression of a target gene. a total of candidate endogenous control genes were analysed in samples representing two different tissues from animals. these animals were either pregnant or cycling at day of the reproductive cycle, and represented holstein-friesian cows from two divergent genetic backgrounds, and new zealand ). two strategies were employed to identify the candidates. five genes were selected on the basis that they had been previously used as housekeeping genes, and an additional novel genes were derived from a microarray experiment based around the same samples used in the current analysis. genespring gx software was used to generate a list through filtering on expression stability across the samples. this list was subjected to genorm and normfinder analysis to identify the most suitable genes. the suitability of all genes was then tested through statistical analyses, including a comparison of expression stability as determined by genorm and normfinder algorithms. the effect of using these endogenous control genes was then evaluated using relative quantification of a gene known to be differentially expressed in the study.  microarray analysis of the endometrial samples revealed transcripts with a high degree of expression stability. genorm and normfinder were utilised to identify the most stably expressed transcripts for further analysis. for rt-pcr design, full length transcripts were identified by querying microarray probe sequences against the bovine genome using ncbi blast. gene expression levels of the candidate endogenous control genes are displayed in table and figure cq values for sample replicates had very low variability with a mean intra-assay coefficient of variation of %. all genes had low overall variability, with the cq range between and cycles, standard deviations ranging from to cycles, and cv values ranging from to % table significance calculations between gene expression data for pregnant and cycling animals were performed on cq and relative concentration values, as estimated through absolute quantification using the roche lc software. no significant differences in means or variances between pregnant and cycling endometrial tissues were apparent for any candidate genes for variance between pregnant and cycling animals). the means and variances between the two different strains of holstein-friesians also lacked significance. cqs and relative concentration variances between the two different tissue types showed no significant differences, however means were significantly different for all genes, except rps15a, p = ). the differences in means calculated between tissue subtypes likely reflect the distinct morphological and functional differences between caruncular and intercaruncular endometrium, which relate to their respective roles in reproduction. the'caruncules' of the endometrium are specialised projections that are the site of embryo attachment. caruncules become highly vascularised, and are the major site for small molecule and gaseous exchange. in comparison, intercaruncular tissue is highly glandular and responsible for early nourishment of the embryo through secretions of large molecules into the uterus. the intercaruncular tissue is often thought to be more important in early pregnancy and, therefore, the majority of expression studies in pre-implantation bovine endometrium focus solely on intercaruncular tissue gene expression. there is very little reported expression analysis of caruncular endometrium and no known studies comparing expression profiles of the two tissues. expression stability testing of candidate genes to further analyse the suitability of the candidate genes for use as endogenous controls for bovine endometrial tissues, expression stability was assessed using the genorm and normfinder algorithms. genorm rankings for the genes tested are presented in table and figure 2a. genorm identified suz and znf as the most stably expressed genes of the candidates. four of the five most stable genes were those derived from microarray data; the other was rps15a, which was selected from the literature. by contrast, four of the five least stable genes were chosen from the literature, including gapdh. the most stably expressed gene identified by normfinder was suz, which was also one of the two most stable genes identified in the genorm analysis. the best combination of genes identified by normfinder was suz and c2orf the five most stably expressed genes according to normfinder consisted entirely of microarray-derived genes, while the least stable five contained three out of five genes selected from the literature, again including gapdh. the comparative ranking of all genes for both genorm and normfinder algorithm analyses is displayed in table normfinder rankings of genes through analysis of inter- and intra group variability. genorm rankings of genes based on pairwise analysis of expression stability. genorm calculates an expression stability value for each candidate gene based on pairwise comparisons of variability. each gene is compared to every other gene to determine the two genes that contain the least variation. the stability value calculated for each gene is used to rank genes from least to most stable. the authors of the method give an m-value of as a cut-off for suitability as an endogenous control gene. the principal behind the pairwise stability measure ranking is that two ideal candidate normalisation genes should have an equal expression ratio in all samples. in the present study, all genes are well below the stipulated m-value. the program then calculates a normalisation factor in each sample for the most stable genes. genorm also calculates the optimal number of endogenous control genes to be used in the analysis of gene expression. this value is determined by locating the point where addition of the next most stable gene does not significantly affect the normalisation factor, using a cut-off value of. in this study, the value for genes was, suggesting that genes should be sufficient to normalise the experimental data. genorm calculates the minimum number of genes required for accurate normalisation. in this case, two genes were sufficient. the number of genes necessary for accurate normalisation is defined as the point at which the addition of a gene has a non-significant effect on the calculation of the normalisation factor, the threshold for a non-significant difference being. normfinder is another freely available tool for the identification of stable endogenous control genes. the main point of difference between the two methods is that normfinder takes into account both inter- and intra-group variability. the program not only identifies the most stable pair of endogenous control genes but also identifies the best overall endogenous control gene. the calculation of variability between groups is especially important in the present study considering the significant expression differences between the two tissue subtypes. the use of the two most stably expressed genes, in this case suz and c2orf, should provide sufficient normalisation for tissue comparisons as normfinder selects the best combination of genes whilst taking into account any grouping effects such as tissue type. the differences in rankings of gene stability using the two algorithms could be due to the fact that they use very different methods to assess gene stability. genorm selects genes based on the pairwise variation between genes. the two most stably expressed genes are therefore those genes that share an expression profile. in contrast, normfinder uses a model based algorithm that takes into account overall stability as well as any groups that may be present in the sample set. for example, if there are any grouping effects on gene expression a gene would be ranked lower than one that demonstrated variability not associated with any particular group. effect of endogenous control gene on target gene relative quantification temporal down-regulation of endometrial oxytocin receptor expression is a hallmark of early pregnancy, with embryonic interferon tau thought to elicit this response. given the expectation of differential oxtr expression between pregnant and cycling animals, the effect of control gene stability on gene expression values of oxtr in the endometrial samples was tested. oxtr expression was significantly greater in cycling than in pregnant cows regardless of the endogenous control gene used. notably, oxtr expression in pregnant animals was greater on average and more variable in na animals than for nz animals, and was also related to embryo size. the use of different endogenous control genes had no effect on oxtr expression differences in these group comparisons. however, there were differences in the normalised oxtr expression values that were inconsistent across the samples, depending on which endogenous control genes were employed. for example, in sample pregnant nz-5a the calculated relative oxtr expression value was when normalised to suz when normalised to gapdh, when normalised to uxt, and when normalised to both suz and znf another sample, the values were,,, and when normalised to suz gapdh, uxt and both suz and znf respectively. the average calculated fold change difference between pregnant and cycling animals was not affected by the choice of normalisation gene, possibly due to the large difference in expression level for this comparison. however, the choice of reference gene could be important when normalising genes that exhibit more subtle variation between experimental groups, given the considerable variation in expression shown between individual samples.  this study provides the first reported assessment of endogenous control genes for use in expression studies in bovine endometrium. normalisation is a critical factor in reporting rt-pcr expression data, providing a necessary control for error associated with sample preparation. normalisation using endogenous control genes provides a means of controlling this error, provided the gene used are stably expressed across all samples under investigation. the study described here tested candidate reference genes across bovine endometrial samples representing a range of physiological states and tissue subtypes. this study evaluated the suitability of both commonly used and novel experimentally derived reference genes for use in normalisation of rt-pcr data. candidates derived via microarray analysis were superior to existing, commonly used endogenous control genes, demonstrating the suitability of using microarray data for deriving novel endogenous control genes. this study also highlighted the importance of accurate normalisation with a stable endogenous control gene, by demonstrating relative expression of a differentially expressed gene when normalised using control genes of varying stability. suz was ranked first for stability across samples as determined by the statistical algorithms used in genorm and normfinder, and is therefore proposed as the best gene for normalisation of rt-pcr data in the current study. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
41,c2188a48-6f65-4895-825d-e2d5f172dc90_gpt3_gen,"The article discusses the importance of normalizing gene expression data in quantitative real-time reverse transcription polymerase chain reaction (rt-PCR) experiments and the selection of suitable endogenous control genes for this normalization. The study aimed to identify endogenous control genes for analyzing endometrial tissues from pregnant and cycling bovines and investigated the potential use of microarray data analysis for identifying novel endogenous control genes. The study found that the commonly used endogenous control gene, gapdh, appeared to be unsuitable, and identified suz as the most stable gene for normalizing rt-PCR data in the current study. The article highlights the importance of accurate normalization with a stable endogenous control gene for reliable gene expression analysis."," quantitative real-time reverse transcription pcr is an extremely sensitive technique that allows the precise measurement of gene expression across more than seven orders of magnitude. rt-pcr is often considered the gold standard for quantifying gene expression, and is commonly used to validate techniques with greater throughput but less overall sensitivity, such as microarray analysis. rt-pcr relies on the use of fluorescent dyes to quantify transcript amplification, with the amplification cycle number at which these dyes/transcripts are detected giving an indication as to the relative abundance of the target molecules. the sensitivity of rt-pcr makes it a powerful tool for gene expression measurement, especially when sample quantities are limited or a transcript is expressed at a low level. however, this sensitivity also means that a great deal of care must be taken with regards to experimental design and implementation of the procedure. when designing an experiment to evaluate gene expression in a group of samples, a number of critical factors must be kept constant. these include rna extraction, dnase treatments, and cdna synthesis. normalisation of rt-pcr results is required to control inter-sample differences that may arise as a result of these sample processing steps, and ensure the gene expression of target transcripts are robustly quantifiable. the most common method for normalising rt-pcr data involves the use of one or more endogenous control genes. an ideal endogenous control gene is one that is stably expressed within the samples to be compared, regardless of tissue differences, experimental conditions, or treatments. choosing an endogenous control gene to normalise gene expression data is one of the most crucial steps in the experimental design. genes used as endogenous controls in rt-pcr experiments are often chosen with little prior knowledge of their expression over the experimental conditions examined, and are often selected arbitrarily from a pool of commonly used endogenous control genes such as gapdh, and β-actin. the most widely used endogenous control gene in studies of endometrial gene expression is gapdh. however, the suitability of gapdh as an endogenous control gene has recently come into question, especially due to its potential regulation in a wide variety of physiological states, making it a questionable choice for rt-pcr normalisation. over the past three decades, genetic selection for milk production has resulted in a significant decline in dairy cattle fertility. the fertilisation rate in dairy cattle is around 90% and does not differ between low-moderate and high-producing animals. however, the calving rate in lower producing animals is approximately 55%, whereas in high-producing animals this rate is approximately 35%. pregnancy losses are thought to occur primarily during the pregnancy recognition/pre-implantation period, making studies of endometrial gene expression critical to further understanding of pregnancy establishment, recognition and maintenance within the bovine reproductive cycle. the primary aim of this study was to identify suitable endogenous control genes for analysis of endometrial tissues from pregnant and cycling bovines. this study also aimed to investigate the potential use of microarray data analysis for identification of novel endogenous control genes, and the effect of endogenous control gene selection on the calculated expression of a target gene. a total of candidate endogenous control genes were analysed in samples representing two different tissues from animals. these animals were either pregnant or cycling at day of the reproductive cycle, and represented holstein-friesian cows from two divergent genetic backgrounds, and new zealand ). two strategies were employed to identify the candidates. five genes were selected on the basis that they had been previously used as housekeeping genes, and an additional novel genes were derived from a microarray experiment based around the same samples used in the current analysis. genespring gx software was used to generate a list through filtering on expression stability across the samples. this list was subjected to genorm and normfinder analysis to identify the most suitable genes. the suitability of all genes was then tested through statistical analyses, including a comparison of expression stability as determined by genorm and normfinder algorithms. the effect of using these endogenous control genes was then evaluated using relative quantification of a gene known to be differentially expressed in the study.  microarray analysis of the endometrial samples revealed transcripts with a high degree of expression stability. genorm and normfinder were utilised to identify the most stably expressed transcripts for further analysis. for rt-pcr design, full length transcripts were identified by querying microarray probe sequences against the bovine genome using ncbi blast. gene expression levels of the candidate endogenous control genes are displayed in table and figure cq values for sample replicates had very low variability with a mean intra-assay coefficient of variation of %. all genes had low overall variability, with the cq range between and cycles, standard deviations ranging from to cycles, and cv values ranging from to % table significance calculations between gene expression data for pregnant and cycling animals were performed on cq and relative concentration values, as estimated through absolute quantification using the roche lc software. no significant differences in means or variances between pregnant and cycling endometrial tissues were apparent for any candidate genes for variance between pregnant and cycling animals). the means and variances between the two different strains of holstein-friesians also lacked significance. cqs and relative concentration variances between the two different tissue types showed no significant differences, however means were significantly different for all genes, except rps15a, p = ). the differences in means calculated between tissue subtypes likely reflect the distinct morphological and functional differences between caruncular and intercaruncular endometrium, which relate to their respective roles in reproduction. the'caruncules' of the endometrium are specialised projections that are the site of embryo attachment. caruncules become highly vascularised, and are the major site for small molecule and gaseous exchange. in comparison, intercaruncular tissue is highly glandular and responsible for early nourishment of the embryo through secretions of large molecules into the uterus. the intercaruncular tissue is often thought to be more important in early pregnancy and, therefore, the majority of expression studies in pre-implantation bovine endometrium focus solely on intercaruncular tissue gene expression. there is very little reported expression analysis of caruncular endometrium and no known studies comparing expression profiles of the two tissues. expression stability testing of candidate genes to further analyse the suitability of the candidate genes for use as endogenous controls for bovine endometrial tissues, expression stability was assessed using the genorm and normfinder algorithms. genorm rankings for the genes tested are presented in table and figure 2a. genorm identified suz and znf as the most stably expressed genes of the candidates. four of the five most stable genes were those derived from microarray data; the other was rps15a, which was selected from the literature. by contrast, four of the five least stable genes were chosen from the literature, including gapdh. the most stably expressed gene identified by normfinder was suz, which was also one of the two most stable genes identified in the genorm analysis. the best combination of genes identified by normfinder was suz and c2orf the five most stably expressed genes according to normfinder consisted entirely of microarray-derived genes, while the least stable five contained three out of five genes selected from the literature, again including gapdh. the comparative ranking of all genes for both genorm and normfinder algorithm analyses is displayed in table normfinder rankings of genes through analysis of inter- and intra group variability. genorm rankings of genes based on pairwise analysis of expression stability. genorm calculates an expression stability value for each candidate gene based on pairwise comparisons of variability. each gene is compared to every other gene to determine the two genes that contain the least variation. the stability value calculated for each gene is used to rank genes from least to most stable. the authors of the method give an m-value of as a cut-off for suitability as an endogenous control gene. the principal behind the pairwise stability measure ranking is that two ideal candidate normalisation genes should have an equal expression ratio in all samples. in the present study, all genes are well below the stipulated m-value. the program then calculates a normalisation factor in each sample for the most stable genes. genorm also calculates the optimal number of endogenous control genes to be used in the analysis of gene expression. this value is determined by locating the point where addition of the next most stable gene does not significantly affect the normalisation factor, using a cut-off value of. in this study, the value for genes was, suggesting that genes should be sufficient to normalise the experimental data. genorm calculates the minimum number of genes required for accurate normalisation. in this case, two genes were sufficient. the number of genes necessary for accurate normalisation is defined as the point at which the addition of a gene has a non-significant effect on the calculation of the normalisation factor, the threshold for a non-significant difference being. normfinder is another freely available tool for the identification of stable endogenous control genes. the main point of difference between the two methods is that normfinder takes into account both inter- and intra-group variability. the program not only identifies the most stable pair of endogenous control genes but also identifies the best overall endogenous control gene. the calculation of variability between groups is especially important in the present study considering the significant expression differences between the two tissue subtypes. the use of the two most stably expressed genes, in this case suz and c2orf, should provide sufficient normalisation for tissue comparisons as normfinder selects the best combination of genes whilst taking into account any grouping effects such as tissue type. the differences in rankings of gene stability using the two algorithms could be due to the fact that they use very different methods to assess gene stability. genorm selects genes based on the pairwise variation between genes. the two most stably expressed genes are therefore those genes that share an expression profile. in contrast, normfinder uses a model based algorithm that takes into account overall stability as well as any groups that may be present in the sample set. for example, if there are any grouping effects on gene expression a gene would be ranked lower than one that demonstrated variability not associated with any particular group. effect of endogenous control gene on target gene relative quantification temporal down-regulation of endometrial oxytocin receptor expression is a hallmark of early pregnancy, with embryonic interferon tau thought to elicit this response. given the expectation of differential oxtr expression between pregnant and cycling animals, the effect of control gene stability on gene expression values of oxtr in the endometrial samples was tested. oxtr expression was significantly greater in cycling than in pregnant cows regardless of the endogenous control gene used. notably, oxtr expression in pregnant animals was greater on average and more variable in na animals than for nz animals, and was also related to embryo size. the use of different endogenous control genes had no effect on oxtr expression differences in these group comparisons. however, there were differences in the normalised oxtr expression values that were inconsistent across the samples, depending on which endogenous control genes were employed. for example, in sample pregnant nz-5a the calculated relative oxtr expression value was when normalised to suz when normalised to gapdh, when normalised to uxt, and when normalised to both suz and znf another sample, the values were,,, and when normalised to suz gapdh, uxt and both suz and znf respectively. the average calculated fold change difference between pregnant and cycling animals was not affected by the choice of normalisation gene, possibly due to the large difference in expression level for this comparison. however, the choice of reference gene could be important when normalising genes that exhibit more subtle variation between experimental groups, given the considerable variation in expression shown between individual samples.  this study provides the first reported assessment of endogenous control genes for use in expression studies in bovine endometrium. normalisation is a critical factor in reporting rt-pcr expression data, providing a necessary control for error associated with sample preparation. normalisation using endogenous control genes provides a means of controlling this error, provided the gene used are stably expressed across all samples under investigation. the study described here tested candidate reference genes across bovine endometrial samples representing a range of physiological states and tissue subtypes. this study evaluated the suitability of both commonly used and novel experimentally derived reference genes for use in normalisation of rt-pcr data. candidates derived via microarray analysis were superior to existing, commonly used endogenous control genes, demonstrating the suitability of using microarray data for deriving novel endogenous control genes. this study also highlighted the importance of accurate normalisation with a stable endogenous control gene, by demonstrating relative expression of a differentially expressed gene when normalised using control genes of varying stability. suz was ranked first for stability across samples as determined by the statistical algorithms used in genorm and normfinder, and is therefore proposed as the best gene for normalisation of rt-pcr data in the current study. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
42,fa772325-68e1-47d4-bad3-68e0482a782b_gpt3_gen,"The article describes the complete mitochondrial DNA sequence of the fat innkeeper worm, Urechis caupo, a representative of the phylum Echiura. The mitochondrial genome of U. caupo contains the same genes commonly found in animal mitochondrial DNA and shares many features with annelid mitochondrial DNA, including a high A+T content, use of protein initiation codons, and the relative arrangement of genes. The genome also contains non-coding regions with potential for forming stem-loop structures and short hairpins that may play a role in regulating transcription and replication. The article highlights the potential of comparing mitochondrial DNA sequences across taxa to address general questions of genome evolution."," mitochondrial genomes are physically separate from the nuclear genome. for animals, they are typically circular with a compact arrangement of an identical set of genes. for some animals, all genes are on the same strand, whereas for others they are divided between the two. the arrangement of these genes can remain stable for long periods of time; for example, human and shark mtdnas have the same gene arrangement, and do those of fruit fly and shrimp. however, in other lineages, rearrangements have occurred much more rapidly. many of the same processes that occur in large and complex nuclear genomes also take place in these diminutive genomes, so comparisons among mtdnas can address general questions of genome evolution, but in a model system that is much more tractable for a large number of taxa. toward this end, this article describes the complete mtdna sequence of the fat innkeeper worm, urechis caupo, the first example from the phylum echiura. echiurans comprise about species and are commonly called spoon worms because of the shape of their extensible proboscis. unlike annelids, they have no overt segmentation, but they develop via trochophore larvae, very similar to those of annelids. u. caupo is a pink, sausage shaped worm that lives in u-shaped burrows in the mud or sand of the intertidal or subtidal zones. unlike other echiurans, it feeds on plankton by filtering using an elaborate mucus net.  gene content and organization the mtdna of urechis caupo is nts in length and contains the same genes found for nearly all animal mtdnas. all genes are transcribed from the same strand, as is the case for the two studied annelid mtdnas, the polychaete platynereis dumerilii and the oligochaete lumbricus terrestris and for several other animal mtdnas. the arrangement of the genes is substantially similar to those of the two annelids, and shares short regions of similarity with several other mtdnas, as can be seen in table base composition and codon usage the u. caupo mtdna is 62% a+t, about the same as for annelid mtdnas. as is typical, all homodinucleotides and homotrinucleotides are greatly over represented relative to a random distribution and cg is the least frequent dinucleotide, both in absolute number and in the ratio of observed to expected. the gene-coding strand has a strong skew against g vs. c but about equal amounts of a vs. t; g-skew is – and t-skew is –. these values show no striking variation across the length of the mtdna. codon usage reflects these values, with those ending in a or t being most frequent. in all cases except for two, where they are synonymous, nnc codons are in greater abundance than nng codons, as is consistent with the coding strand being rich in c relative to g. the two exceptions are cgg and ggg codons, which are each in greater abundance than their respective synonyms, cgc and ggc. this invites the speculation that there is something favored about the gg dinucleotide created when g appears in the second codon position. however, this is not consistently seen, since in the remaining case, agc codons outnumber agg codons two-to-one. this effect has been shown to be very strong for codon usage pattern of the mtdna of the brachiopod terebratalia transversa. gene initiation and termination mitochondrial genes commonly use several alternatives to atg as start codons. however, of the proteins coding genes of u. caupo mtdna use atg. the only exceptions are cox which uses gtg and nad which uses atc. in the case of cox there is an in frame stop only three codons upstream and neither of the intervening codons is atg. also, this inference of starting on gtg specifies a set of amino acids well matched to those at the beginning of other cox proteins. the situation for nad is nearly identical, with an in frame stop only four codons upstream and no intervening atg codons. however, downstream of the inferred start are several ata codons that can not be ruled out as alternatives. the commonality of using atg as a start codon has also been noted for mitochondrial genes of four annelids, platynereis dumerilii, lumbricus terrestris, helobdella robusta and galathealinum brachiosum and a sipunculid, phascolopsis gouldii. a complete stop codon without overlap of the downstream gene is found for all except cox nad nad cob, and nad. in each of these cases, it appears that an abbreviated stop codon is generated by cleavage of a downstream trna from the polycistronic transcript, which is then completed to a taa stop codon by polyadenylation. however, in two of these cases, a complete stop codon could be formed by including only the next two nucleotides, and two other cases, there is an in frame stop codon just one or two codons downstream, respectively. it is not clear how gene overlaps could be resolved from a polycistronic transcript, but the presence of these stop codons seems beyond coincidence. it could be that they serve as a ""back up"" in case translation should begin in the absence of transcript cleavage. transfer rnas twenty-two regions can be folded into the typical cloverleaf structures of the expected set of trnas. there are several mismatched nucleotide pairs within stems; nearly all of these are flanked by multiple g-c pairs, suggesting that they may provide compensatory stability for these arms. t precedes the anticodon and a purine follows it for all trnas. the two serine trnas lack potential for folding a dhu arm, as has been found for a number of other animal mtdnas. there is an alternative folding possible for trna with a six-member anticodon stem and only one nucleotide separating the acceptor and dhu stems; this unusual folding has been found for the homologous genes of some mammals. trna also does not have potential for a normally paired dhu arm, although there are three potential nucleotide pairs if two nucleotides were between the dhu and anticodon stems. however, this potential pairing could, alternatively, be a coincidence, with the dhu arm having no paired stem for this trna. those with paired dhu arms have stems of three to five nucleotide pairs and loops of three to eight nts. all trnas have potential for stems of three to six nucleotide pairs for their tΨc arms with loops of three to seven nts. one of the trnas for serine has the anticodon tct; although this is often found, the alternative of gct is otherwise common. ribosomal rnas as has been the case for all studied animal mtdnas to date, two rrna genes are identified, one for each of the small and large mitochondrial ribosomal subunits. determining the precise ends of the rrna transcript requires experimentation, but if it's assumed that they extend to the boundaries of the adjacent genes, then rrns is nucleotides and rrnl is nucleotides in length. these genes are arranged sequentially, but without an intervening trna gene as is otherwise commonly found. non-coding regions the largest non-coding region is only nts long. the region is 71% a+t and contains one palindrome of an nt sequence, but otherwise no large repeat elements. obviously, this has potential for forming a stem-loop structure, and it may be significant that a short sequence a few nucleotides upstream, tcaaaa, has the potential for competing with this to form a short hairpin with the ttttga at the end of the palindrome. there has been previous speculation that regions with potential for competing, mutually exclusive hairpins may play a role in regulating transcription and/or replication. there are four other potential hairpins in this region with stems of 5– bp and loops of 5– nt. all four nucleotides occur in homopolymers with much greater frequency than expected by chance, often in runs of four or five. the second largest non-coding region is nt between trns and cox this has no repeat elements and the base composition is unremarkable. what role, if any, these sequences have in the regulation of transcription and/or replication awaits further study. aside from these and nt regions, there are only total intergenic nucleotides scattered among regions. in seven cases these are 2– nts long. for the other seven cases, genes are separated by a single nucleotide, and in six of these, that nucleotide is a c. the prevalence of c is consistent with the measured g-skew between the strands, although it is possible that this otherwise indicates some function of these nucleotides.  this is the first description of a complete mitochondrial genome sequence of a representative of the phylum echiura. the genome contains the same genes most commonly found in animal mtdnas. many features are most similar to those found for annelid mtdnas, including a+t content, use of protein initiation codons, size and potential secondary structures of the largest non-coding region, and the relative arrangement of many genes. as in annelids examined to date, all genes are found on the same dna strand. as noted for brachiopod mtdna, there is a preference for g nucleotides to appear in tandem, without obvious explanation. further description and comparison of complete mtdna sequences will continue to produce a picture of genome evolution, particularly once sampling includes representatives of each animal phylum. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
43,fa772325-68e1-47d4-bad3-68e0482a782b_flant5_gen,"This article describes the complete mitochondrial genome sequence of the fat innkeeper worm, urechis caupo, the first example from the phylum echiura."," mitochondrial genomes are physically separate from the nuclear genome. for animals, they are typically circular with a compact arrangement of an identical set of genes. for some animals, all genes are on the same strand, whereas for others they are divided between the two. the arrangement of these genes can remain stable for long periods of time; for example, human and shark mtdnas have the same gene arrangement, and do those of fruit fly and shrimp. however, in other lineages, rearrangements have occurred much more rapidly. many of the same processes that occur in large and complex nuclear genomes also take place in these diminutive genomes, so comparisons among mtdnas can address general questions of genome evolution, but in a model system that is much more tractable for a large number of taxa. toward this end, this article describes the complete mtdna sequence of the fat innkeeper worm, urechis caupo, the first example from the phylum echiura. echiurans comprise about species and are commonly called spoon worms because of the shape of their extensible proboscis. unlike annelids, they have no overt segmentation, but they develop via trochophore larvae, very similar to those of annelids. u. caupo is a pink, sausage shaped worm that lives in u-shaped burrows in the mud or sand of the intertidal or subtidal zones. unlike other echiurans, it feeds on plankton by filtering using an elaborate mucus net.  gene content and organization the mtdna of urechis caupo is nts in length and contains the same genes found for nearly all animal mtdnas. all genes are transcribed from the same strand, as is the case for the two studied annelid mtdnas, the polychaete platynereis dumerilii and the oligochaete lumbricus terrestris and for several other animal mtdnas. the arrangement of the genes is substantially similar to those of the two annelids, and shares short regions of similarity with several other mtdnas, as can be seen in table base composition and codon usage the u. caupo mtdna is 62% a+t, about the same as for annelid mtdnas. as is typical, all homodinucleotides and homotrinucleotides are greatly over represented relative to a random distribution and cg is the least frequent dinucleotide, both in absolute number and in the ratio of observed to expected. the gene-coding strand has a strong skew against g vs. c but about equal amounts of a vs. t; g-skew is – and t-skew is –. these values show no striking variation across the length of the mtdna. codon usage reflects these values, with those ending in a or t being most frequent. in all cases except for two, where they are synonymous, nnc codons are in greater abundance than nng codons, as is consistent with the coding strand being rich in c relative to g. the two exceptions are cgg and ggg codons, which are each in greater abundance than their respective synonyms, cgc and ggc. this invites the speculation that there is something favored about the gg dinucleotide created when g appears in the second codon position. however, this is not consistently seen, since in the remaining case, agc codons outnumber agg codons two-to-one. this effect has been shown to be very strong for codon usage pattern of the mtdna of the brachiopod terebratalia transversa. gene initiation and termination mitochondrial genes commonly use several alternatives to atg as start codons. however, of the proteins coding genes of u. caupo mtdna use atg. the only exceptions are cox which uses gtg and nad which uses atc. in the case of cox there is an in frame stop only three codons upstream and neither of the intervening codons is atg. also, this inference of starting on gtg specifies a set of amino acids well matched to those at the beginning of other cox proteins. the situation for nad is nearly identical, with an in frame stop only four codons upstream and no intervening atg codons. however, downstream of the inferred start are several ata codons that can not be ruled out as alternatives. the commonality of using atg as a start codon has also been noted for mitochondrial genes of four annelids, platynereis dumerilii, lumbricus terrestris, helobdella robusta and galathealinum brachiosum and a sipunculid, phascolopsis gouldii. a complete stop codon without overlap of the downstream gene is found for all except cox nad nad cob, and nad. in each of these cases, it appears that an abbreviated stop codon is generated by cleavage of a downstream trna from the polycistronic transcript, which is then completed to a taa stop codon by polyadenylation. however, in two of these cases, a complete stop codon could be formed by including only the next two nucleotides, and two other cases, there is an in frame stop codon just one or two codons downstream, respectively. it is not clear how gene overlaps could be resolved from a polycistronic transcript, but the presence of these stop codons seems beyond coincidence. it could be that they serve as a ""back up"" in case translation should begin in the absence of transcript cleavage. transfer rnas twenty-two regions can be folded into the typical cloverleaf structures of the expected set of trnas. there are several mismatched nucleotide pairs within stems; nearly all of these are flanked by multiple g-c pairs, suggesting that they may provide compensatory stability for these arms. t precedes the anticodon and a purine follows it for all trnas. the two serine trnas lack potential for folding a dhu arm, as has been found for a number of other animal mtdnas. there is an alternative folding possible for trna with a six-member anticodon stem and only one nucleotide separating the acceptor and dhu stems; this unusual folding has been found for the homologous genes of some mammals. trna also does not have potential for a normally paired dhu arm, although there are three potential nucleotide pairs if two nucleotides were between the dhu and anticodon stems. however, this potential pairing could, alternatively, be a coincidence, with the dhu arm having no paired stem for this trna. those with paired dhu arms have stems of three to five nucleotide pairs and loops of three to eight nts. all trnas have potential for stems of three to six nucleotide pairs for their tΨc arms with loops of three to seven nts. one of the trnas for serine has the anticodon tct; although this is often found, the alternative of gct is otherwise common. ribosomal rnas as has been the case for all studied animal mtdnas to date, two rrna genes are identified, one for each of the small and large mitochondrial ribosomal subunits. determining the precise ends of the rrna transcript requires experimentation, but if it's assumed that they extend to the boundaries of the adjacent genes, then rrns is nucleotides and rrnl is nucleotides in length. these genes are arranged sequentially, but without an intervening trna gene as is otherwise commonly found. non-coding regions the largest non-coding region is only nts long. the region is 71% a+t and contains one palindrome of an nt sequence, but otherwise no large repeat elements. obviously, this has potential for forming a stem-loop structure, and it may be significant that a short sequence a few nucleotides upstream, tcaaaa, has the potential for competing with this to form a short hairpin with the ttttga at the end of the palindrome. there has been previous speculation that regions with potential for competing, mutually exclusive hairpins may play a role in regulating transcription and/or replication. there are four other potential hairpins in this region with stems of 5– bp and loops of 5– nt. all four nucleotides occur in homopolymers with much greater frequency than expected by chance, often in runs of four or five. the second largest non-coding region is nt between trns and cox this has no repeat elements and the base composition is unremarkable. what role, if any, these sequences have in the regulation of transcription and/or replication awaits further study. aside from these and nt regions, there are only total intergenic nucleotides scattered among regions. in seven cases these are 2– nts long. for the other seven cases, genes are separated by a single nucleotide, and in six of these, that nucleotide is a c. the prevalence of c is consistent with the measured g-skew between the strands, although it is possible that this otherwise indicates some function of these nucleotides.  this is the first description of a complete mitochondrial genome sequence of a representative of the phylum echiura. the genome contains the same genes most commonly found in animal mtdnas. many features are most similar to those found for annelid mtdnas, including a+t content, use of protein initiation codons, size and potential secondary structures of the largest non-coding region, and the relative arrangement of many genes. as in annelids examined to date, all genes are found on the same dna strand. as noted for brachiopod mtdna, there is a preference for g nucleotides to appear in tandem, without obvious explanation. further description and comparison of complete mtdna sequences will continue to produce a picture of genome evolution, particularly once sampling includes representatives of each animal phylum. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
44,05bbed11-24ff-4f82-b465-e701377361a9_flant5_gen,sigma is a web-based application for the integrative cross platform analysis of array cgh data.," array comparative genomic hybridization is a method used to detect segmental dna copy number alterations and is widely used to discover chromosomal aberrations in cancer and other genetic diseases. in this method, differentially labeled genomic dna samples are competitively hybridized to chromosomal targets, and the copy number balance between the two samples is reflected by their signal intensity ratio. numerous array cgh platforms exist; these vary in the type of elements present on the array and their corresponding coverage of the human genome. with the development of high resolution, genome wide arrays, tens of thousands of loci can be evaluated for copy number status, facilitating the high throughput search for genes potentially involved in pathogenesis. this has allowed the identification of discrete regions of alteration that may have been missed by traditional cytogenetic methods and has proven to be a useful platform for exploring the underlying genetic basis of cancer. with the increasing utilization of array cgh, it has not only become important to establish standards for data deposition, but to develop tools to facilitate public access and to ease mining of available data. currently, the national center for biotechnology information gene expression omnibus repository and european bioinformatics institute arrayexpress provide storage for array cgh data, but these databases have been largely designed for gene expression microarrays. although these sites support visualization of previously analyzed gene expression profiles, there are limited tools available for direct mining and analysis of array cgh data. hence, there is a need for forums specific to array cgh data. recently, attempts have been made in making a database primarily of lower resolution array cgh data. however, with the accumulation of high density array data generated with diverse technology, the viewing of array data has become a bioinformatics challenge, especially when the integration of multiple datasets from different platforms is required. therefore, a central database with analytical software tailored specifically for analyzing and visualizing different types of high resolution array cgh data would greatly facilitate data mining. in this study we have created a database consisting of high-resolution, whole-genome array cgh profiles for nearly commonly used cancer cell lines profiled on four different array platforms, which have been instrumental in biochemical and pharmacogenetic studies. moreover, we have developed a user friendly, web-based java application called the system for integrative genomic microarray analysis for comparative analysis of multiple genomes.  cell-line collection we have assembled a collection of array cgh profiles, representing distinct cell lines profiled on at least one of the four array cgh platforms. moreover, different cancer tissue origins and distinct cancer types are represented in this database, resulting in the assembly of a wide spectrum of genomes in this repository. significantly, of the cgh profiles are unpublished raw data which is now made public. main functionalities of sigma in order to increase the utility of this collection, a significant component of sigma is the web-based application which allows for the user-friendly mining of this dataset. four major types of functionalities are offered by sigma: interrogation of a single sample, visualization and analysis of a single group of samples, comparative analysis of two groups of samples, and integration of data from multiple platforms. visualization and interrogation of a single genome the first function we discuss is the ability to view a single high resolution array cgh profile at multiple magnification levels. the major utility of this function is to display the underlying genomic architecture of a cell line, so that genetic features can be considered in experimental interpretation. for example, a whole genome karyogram of lung adenocarcinoma cell line h profiled on the smrt array platform. from this image, we see many changes such as the loss of the 3p arm as well as segmental changes in chromosomes and specifically, we can select chromosome and view that separately, then zoom into the region of interest and visualize it in finer detail. users can then highlight or place boundary lines in this region and query for which genes are located within the region of interest. subsequently, using the interval search option, users can retrieve the genes which are located in a desired region and have the option to query commonly used biological databases such as ncbi mim, ncbi gene, ncbi pubmed and the ucsc genome browser. for example, if we look at band 8q, we can highlight the region and search the interval for which genes it contains. when we invoke the region search and retrieve only genes curated by refseq, we see there are genes in the amplicon. if the user selects a particular gene, options to link out to the above mentioned biological databases become available. the utility of this function is to facilitate a direct connection from experimental findings to known, relevant information. moreover, the ability to interrogate for specific genes and regions can be done for any types of the analysis outlined. multiple genome comparison and mining across tumor types a common research question is to look across a series of samples with common phenotype to identify recurrent genetic changes, for example comparison of lung adenocarcinomas. with the spectrum of samples warehoused in sigma, such a query can be performed across multiple cancer types. for example, the alignment of a set of samples representing different cancer types revealed common amplification of the myc oncogene locus, while the epidermal growth factor receptor locus is amplified only in a subset of samples. recurrent alterations detected in one group of samples can be compared against those in another group, for example, the comparison of lung squamous cell carcinoma with cervical sqcc. the strategy for comparison, for example the overlay of frequency plots derived from two groups of profiles, has been described elsewhere. simultaneous visualization of data from multiple platforms cross platform comparison is essential to the multi-dimensional descriptions of a genome. here, we have included a feature in sigma to allow users to view multiple platforms of data simultaneously. we use the breast cancer cell line, mcf to illustrate this functionality. data from four different array cgh platforms were available publicly: smrt array, stanford cdna microarray, affymetrix 10k snp array and the affymetrix 100k snp array. figure 4a illustrates the cross platform display of chromosome while figure 4b shows the variable density of coverage by these four commonly used platforms. integrative visualization of dna copy number and methylation one of the novel features we have provided is the integrative visualization of copy number alterations with dna methylation status. the major premise in studying copy number alterations at the dna level is that these are the primary changes involved in driving changes in gene expression. though gene dosage variation may be responsible for expression changes, alteration in dna methylation pattern also contributes significantly to regulating gene expression. recently, methods for global methylation analysis to measure aberrant dna methylation status across tumor genomes have been developed. wilson et al compared methylation patterns with copy number profiles in lung cancer cells. utilizing genomic and epigenetic data from this study for the h lung cancer cell line, we illustrate a parallel display in sigma. figure shows a large segmental copy number gain spanning 1q to 1q with corresponding hypomethylation, localized precisely to 1q. significantly, both copy number gain and decreased methylation can elevate gene expression. the s calcium binding protein a gene within this region has been previously shown to be over-expressed in lung cancer. it is readily apparent of the value of integrative studies examining aberrant dna methylation and genomic copy number. with increased prevalence of studies of whole genome methylation, this feature will be of greater importance.  we have developed an application for the integrative cross platform analysis of array cgh data. the sigma application facilitates consolidation and structuring of diverse sources of array cgh data into a repository that is accessible with a new easy-to-use built-in web-based analytical application. the launch version contains data for array cgh profiles, representing cancer cell lines of over different types of tissue. the ability of sigma to incorporate multiple array cgh platforms facilitates the archiving of array cgh data from future publications, regardless of current or future array platform used. though currently sigma's architecture facilitates the direct mining of genomic and epigenomic data, this can be easily adapted, and not limited to, high resolution genetic and gene expression surveys. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
45,05bbed11-24ff-4f82-b465-e701377361a9_gpt3_gen,"Array Comparative Genomic Hybridization (aCGH) is utilized to detect segmental DNA copy number alterations to discover chromosomal aberrations in cancer and other genetic diseases. High-resolution, whole-genome array CGH profiles have been gathered for nearly 100 commonly used cancer cell lines profiled on four different array platforms, resulting in the assembly of a wide spectrum of genomes in this repository. A user-friendly, web-based java application called the System for Integrative Genomic Microarray Analysis facilitates the mining of the gathered data, making it an easy-to-use built-in web-based analytical application. The application contains data for array CGH profiles, representing cancer cell lines of over different types of tissue, integrating multiple datasets from different platforms. It also aids integrative visualization of copy number alterations with DNA methylation status to examine aberrant DNA methylation and genomic copy number in driving changes in gene expression."," array comparative genomic hybridization is a method used to detect segmental dna copy number alterations and is widely used to discover chromosomal aberrations in cancer and other genetic diseases. in this method, differentially labeled genomic dna samples are competitively hybridized to chromosomal targets, and the copy number balance between the two samples is reflected by their signal intensity ratio. numerous array cgh platforms exist; these vary in the type of elements present on the array and their corresponding coverage of the human genome. with the development of high resolution, genome wide arrays, tens of thousands of loci can be evaluated for copy number status, facilitating the high throughput search for genes potentially involved in pathogenesis. this has allowed the identification of discrete regions of alteration that may have been missed by traditional cytogenetic methods and has proven to be a useful platform for exploring the underlying genetic basis of cancer. with the increasing utilization of array cgh, it has not only become important to establish standards for data deposition, but to develop tools to facilitate public access and to ease mining of available data. currently, the national center for biotechnology information gene expression omnibus repository and european bioinformatics institute arrayexpress provide storage for array cgh data, but these databases have been largely designed for gene expression microarrays. although these sites support visualization of previously analyzed gene expression profiles, there are limited tools available for direct mining and analysis of array cgh data. hence, there is a need for forums specific to array cgh data. recently, attempts have been made in making a database primarily of lower resolution array cgh data. however, with the accumulation of high density array data generated with diverse technology, the viewing of array data has become a bioinformatics challenge, especially when the integration of multiple datasets from different platforms is required. therefore, a central database with analytical software tailored specifically for analyzing and visualizing different types of high resolution array cgh data would greatly facilitate data mining. in this study we have created a database consisting of high-resolution, whole-genome array cgh profiles for nearly commonly used cancer cell lines profiled on four different array platforms, which have been instrumental in biochemical and pharmacogenetic studies. moreover, we have developed a user friendly, web-based java application called the system for integrative genomic microarray analysis for comparative analysis of multiple genomes.  cell-line collection we have assembled a collection of array cgh profiles, representing distinct cell lines profiled on at least one of the four array cgh platforms. moreover, different cancer tissue origins and distinct cancer types are represented in this database, resulting in the assembly of a wide spectrum of genomes in this repository. significantly, of the cgh profiles are unpublished raw data which is now made public. main functionalities of sigma in order to increase the utility of this collection, a significant component of sigma is the web-based application which allows for the user-friendly mining of this dataset. four major types of functionalities are offered by sigma: interrogation of a single sample, visualization and analysis of a single group of samples, comparative analysis of two groups of samples, and integration of data from multiple platforms. visualization and interrogation of a single genome the first function we discuss is the ability to view a single high resolution array cgh profile at multiple magnification levels. the major utility of this function is to display the underlying genomic architecture of a cell line, so that genetic features can be considered in experimental interpretation. for example, a whole genome karyogram of lung adenocarcinoma cell line h profiled on the smrt array platform. from this image, we see many changes such as the loss of the 3p arm as well as segmental changes in chromosomes and specifically, we can select chromosome and view that separately, then zoom into the region of interest and visualize it in finer detail. users can then highlight or place boundary lines in this region and query for which genes are located within the region of interest. subsequently, using the interval search option, users can retrieve the genes which are located in a desired region and have the option to query commonly used biological databases such as ncbi mim, ncbi gene, ncbi pubmed and the ucsc genome browser. for example, if we look at band 8q, we can highlight the region and search the interval for which genes it contains. when we invoke the region search and retrieve only genes curated by refseq, we see there are genes in the amplicon. if the user selects a particular gene, options to link out to the above mentioned biological databases become available. the utility of this function is to facilitate a direct connection from experimental findings to known, relevant information. moreover, the ability to interrogate for specific genes and regions can be done for any types of the analysis outlined. multiple genome comparison and mining across tumor types a common research question is to look across a series of samples with common phenotype to identify recurrent genetic changes, for example comparison of lung adenocarcinomas. with the spectrum of samples warehoused in sigma, such a query can be performed across multiple cancer types. for example, the alignment of a set of samples representing different cancer types revealed common amplification of the myc oncogene locus, while the epidermal growth factor receptor locus is amplified only in a subset of samples. recurrent alterations detected in one group of samples can be compared against those in another group, for example, the comparison of lung squamous cell carcinoma with cervical sqcc. the strategy for comparison, for example the overlay of frequency plots derived from two groups of profiles, has been described elsewhere. simultaneous visualization of data from multiple platforms cross platform comparison is essential to the multi-dimensional descriptions of a genome. here, we have included a feature in sigma to allow users to view multiple platforms of data simultaneously. we use the breast cancer cell line, mcf to illustrate this functionality. data from four different array cgh platforms were available publicly: smrt array, stanford cdna microarray, affymetrix 10k snp array and the affymetrix 100k snp array. figure 4a illustrates the cross platform display of chromosome while figure 4b shows the variable density of coverage by these four commonly used platforms. integrative visualization of dna copy number and methylation one of the novel features we have provided is the integrative visualization of copy number alterations with dna methylation status. the major premise in studying copy number alterations at the dna level is that these are the primary changes involved in driving changes in gene expression. though gene dosage variation may be responsible for expression changes, alteration in dna methylation pattern also contributes significantly to regulating gene expression. recently, methods for global methylation analysis to measure aberrant dna methylation status across tumor genomes have been developed. wilson et al compared methylation patterns with copy number profiles in lung cancer cells. utilizing genomic and epigenetic data from this study for the h lung cancer cell line, we illustrate a parallel display in sigma. figure shows a large segmental copy number gain spanning 1q to 1q with corresponding hypomethylation, localized precisely to 1q. significantly, both copy number gain and decreased methylation can elevate gene expression. the s calcium binding protein a gene within this region has been previously shown to be over-expressed in lung cancer. it is readily apparent of the value of integrative studies examining aberrant dna methylation and genomic copy number. with increased prevalence of studies of whole genome methylation, this feature will be of greater importance.  we have developed an application for the integrative cross platform analysis of array cgh data. the sigma application facilitates consolidation and structuring of diverse sources of array cgh data into a repository that is accessible with a new easy-to-use built-in web-based analytical application. the launch version contains data for array cgh profiles, representing cancer cell lines of over different types of tissue. the ability of sigma to incorporate multiple array cgh platforms facilitates the archiving of array cgh data from future publications, regardless of current or future array platform used. though currently sigma's architecture facilitates the direct mining of genomic and epigenomic data, this can be easily adapted, and not limited to, high resolution genetic and gene expression surveys. ",pubmed_generic,GPT 3.5,"A user-friendly, web-based java application called the System for Integrative Genomic Microarray Analysis facilitates the mining of the gathered data, making it an easy-to-use built-in web-based analytical application.",non_factual,factual,minor,,intrinsic,,,,,
46,05bbed11-24ff-4f82-b465-e701377361a9_gpt3_gen,"Array Comparative Genomic Hybridization (aCGH) is utilized to detect segmental DNA copy number alterations to discover chromosomal aberrations in cancer and other genetic diseases. High-resolution, whole-genome array CGH profiles have been gathered for nearly 100 commonly used cancer cell lines profiled on four different array platforms, resulting in the assembly of a wide spectrum of genomes in this repository. A user-friendly, web-based java application called the System for Integrative Genomic Microarray Analysis facilitates the mining of the gathered data, making it an easy-to-use built-in web-based analytical application. The application contains data for array CGH profiles, representing cancer cell lines of over different types of tissue, integrating multiple datasets from different platforms. It also aids integrative visualization of copy number alterations with DNA methylation status to examine aberrant DNA methylation and genomic copy number in driving changes in gene expression."," array comparative genomic hybridization is a method used to detect segmental dna copy number alterations and is widely used to discover chromosomal aberrations in cancer and other genetic diseases. in this method, differentially labeled genomic dna samples are competitively hybridized to chromosomal targets, and the copy number balance between the two samples is reflected by their signal intensity ratio. numerous array cgh platforms exist; these vary in the type of elements present on the array and their corresponding coverage of the human genome. with the development of high resolution, genome wide arrays, tens of thousands of loci can be evaluated for copy number status, facilitating the high throughput search for genes potentially involved in pathogenesis. this has allowed the identification of discrete regions of alteration that may have been missed by traditional cytogenetic methods and has proven to be a useful platform for exploring the underlying genetic basis of cancer. with the increasing utilization of array cgh, it has not only become important to establish standards for data deposition, but to develop tools to facilitate public access and to ease mining of available data. currently, the national center for biotechnology information gene expression omnibus repository and european bioinformatics institute arrayexpress provide storage for array cgh data, but these databases have been largely designed for gene expression microarrays. although these sites support visualization of previously analyzed gene expression profiles, there are limited tools available for direct mining and analysis of array cgh data. hence, there is a need for forums specific to array cgh data. recently, attempts have been made in making a database primarily of lower resolution array cgh data. however, with the accumulation of high density array data generated with diverse technology, the viewing of array data has become a bioinformatics challenge, especially when the integration of multiple datasets from different platforms is required. therefore, a central database with analytical software tailored specifically for analyzing and visualizing different types of high resolution array cgh data would greatly facilitate data mining. in this study we have created a database consisting of high-resolution, whole-genome array cgh profiles for nearly commonly used cancer cell lines profiled on four different array platforms, which have been instrumental in biochemical and pharmacogenetic studies. moreover, we have developed a user friendly, web-based java application called the system for integrative genomic microarray analysis for comparative analysis of multiple genomes.  cell-line collection we have assembled a collection of array cgh profiles, representing distinct cell lines profiled on at least one of the four array cgh platforms. moreover, different cancer tissue origins and distinct cancer types are represented in this database, resulting in the assembly of a wide spectrum of genomes in this repository. significantly, of the cgh profiles are unpublished raw data which is now made public. main functionalities of sigma in order to increase the utility of this collection, a significant component of sigma is the web-based application which allows for the user-friendly mining of this dataset. four major types of functionalities are offered by sigma: interrogation of a single sample, visualization and analysis of a single group of samples, comparative analysis of two groups of samples, and integration of data from multiple platforms. visualization and interrogation of a single genome the first function we discuss is the ability to view a single high resolution array cgh profile at multiple magnification levels. the major utility of this function is to display the underlying genomic architecture of a cell line, so that genetic features can be considered in experimental interpretation. for example, a whole genome karyogram of lung adenocarcinoma cell line h profiled on the smrt array platform. from this image, we see many changes such as the loss of the 3p arm as well as segmental changes in chromosomes and specifically, we can select chromosome and view that separately, then zoom into the region of interest and visualize it in finer detail. users can then highlight or place boundary lines in this region and query for which genes are located within the region of interest. subsequently, using the interval search option, users can retrieve the genes which are located in a desired region and have the option to query commonly used biological databases such as ncbi mim, ncbi gene, ncbi pubmed and the ucsc genome browser. for example, if we look at band 8q, we can highlight the region and search the interval for which genes it contains. when we invoke the region search and retrieve only genes curated by refseq, we see there are genes in the amplicon. if the user selects a particular gene, options to link out to the above mentioned biological databases become available. the utility of this function is to facilitate a direct connection from experimental findings to known, relevant information. moreover, the ability to interrogate for specific genes and regions can be done for any types of the analysis outlined. multiple genome comparison and mining across tumor types a common research question is to look across a series of samples with common phenotype to identify recurrent genetic changes, for example comparison of lung adenocarcinomas. with the spectrum of samples warehoused in sigma, such a query can be performed across multiple cancer types. for example, the alignment of a set of samples representing different cancer types revealed common amplification of the myc oncogene locus, while the epidermal growth factor receptor locus is amplified only in a subset of samples. recurrent alterations detected in one group of samples can be compared against those in another group, for example, the comparison of lung squamous cell carcinoma with cervical sqcc. the strategy for comparison, for example the overlay of frequency plots derived from two groups of profiles, has been described elsewhere. simultaneous visualization of data from multiple platforms cross platform comparison is essential to the multi-dimensional descriptions of a genome. here, we have included a feature in sigma to allow users to view multiple platforms of data simultaneously. we use the breast cancer cell line, mcf to illustrate this functionality. data from four different array cgh platforms were available publicly: smrt array, stanford cdna microarray, affymetrix 10k snp array and the affymetrix 100k snp array. figure 4a illustrates the cross platform display of chromosome while figure 4b shows the variable density of coverage by these four commonly used platforms. integrative visualization of dna copy number and methylation one of the novel features we have provided is the integrative visualization of copy number alterations with dna methylation status. the major premise in studying copy number alterations at the dna level is that these are the primary changes involved in driving changes in gene expression. though gene dosage variation may be responsible for expression changes, alteration in dna methylation pattern also contributes significantly to regulating gene expression. recently, methods for global methylation analysis to measure aberrant dna methylation status across tumor genomes have been developed. wilson et al compared methylation patterns with copy number profiles in lung cancer cells. utilizing genomic and epigenetic data from this study for the h lung cancer cell line, we illustrate a parallel display in sigma. figure shows a large segmental copy number gain spanning 1q to 1q with corresponding hypomethylation, localized precisely to 1q. significantly, both copy number gain and decreased methylation can elevate gene expression. the s calcium binding protein a gene within this region has been previously shown to be over-expressed in lung cancer. it is readily apparent of the value of integrative studies examining aberrant dna methylation and genomic copy number. with increased prevalence of studies of whole genome methylation, this feature will be of greater importance.  we have developed an application for the integrative cross platform analysis of array cgh data. the sigma application facilitates consolidation and structuring of diverse sources of array cgh data into a repository that is accessible with a new easy-to-use built-in web-based analytical application. the launch version contains data for array cgh profiles, representing cancer cell lines of over different types of tissue. the ability of sigma to incorporate multiple array cgh platforms facilitates the archiving of array cgh data from future publications, regardless of current or future array platform used. though currently sigma's architecture facilitates the direct mining of genomic and epigenomic data, this can be easily adapted, and not limited to, high resolution genetic and gene expression surveys. ",pubmed_generic,GPT 3.5,"High-resolution, whole-genome array CGH profiles have been gathered for nearly 100 commonly used cancer cell lines profiled on four different array platforms, resulting in the assembly of a wide spectrum of genomes in this repository. ",non_factual,factual,minor,,intrinsic,,,,,
47,9d60200c-d58e-4763-9b64-498b9ac66798_flant5_gen,"We introduce the marvis tool, which implements the concept of one-dimensional self-organizing maps for the visualization of metabolomic intensity profiles."," metabolomic profiling in general aims to identify or confirm biomarkers that are represented by specific metabolite intensity profiles in the context of different physiological and/or experimental conditions. these conditions may represent different phenotypes of a species, disease or environmental and genetic perturbations, or a time course comparing different developmental or physiological stages of an organism. high-throughput analytical measurements, as obtained from mass spectrometry experiments, provide a large number of intensity profiles for accumulation of different metabolites. these data sets show an even higher complexity when repeated measurements for each condition have been performed. for an interpretation based on the experimental conditions these replicas need to be aggregated using e.g. the corresponding mean or median value. for comparative analysis of relative metabolite concentrations it is usually necessary to normalize the resulting intensity vectors, e.g according to a unit euclidean or ""city block"" norm. in the following, the aggregated and normalized multivariate intensity profiles are referred to as marker candidates. clustering is a well-established technique in the context of gene expression analysis and coexpression studies. intensity-based clustering by analogy aims to group similar intensity profiles in order to identify interesting groups of marker candidates and visualize them in a convenient way. a major problem with the application of clustering algorithms is that an adequate number of clusters can often not be inferred automatically. a purely data-driven approach always bears the risk of over- or under-clustering because the correct number of clusters usually depends on task-specific constraints. one-dimensional self-organizing maps realize a linear array of prototypes that correspond to local averages of the data, ordered according to their similarity. in metabolomic analysis the visualization of ordered prototypes provides a quick overview on relevant intensity patterns in the data and allows to easily merge neighboring groups of marker candidates into meaningful clusters. for example, in we detected a significant number of clusters representing different physiological stages during a plant wounding time course as described in. the 1d-som realizes a robust and reproducible ordering in particular with regard to changing data quality. unlike the classical two-dimensional self-organizing maps, which are utilized in a number of software tools for gene expression analysis and metabolomics, 1d-soms allow a simultaneous visualization of the clustering and the underlying intensity profiles by means of the topologically ordered prototype array. this visualization corresponds to a two-dimensional color-coded matrix, where the first dimension represents the prototype order and the second dimension represents the experimental conditions. while 2d-soms can be used to visualize the two-dimensional variation in a single condition, 1d-soms provide a complete view on the one-dimensional variation in all conditions simultaneously. therefore, 1d-soms provide a convenient overview of highly complex metabolomic data sets. beside a number of general software packages, like the well-known som toolbox or the ""clustering for business analytics"" and som packages for the r-project, several more specific tools provide functions to order and visualize multivariate intensity profiles along a one-dimensional array. though, none of them provides a specialized interface for convenient 1d-som visualization and analysis of metabolomics data. in the following, we introduce the marvis tool, which implements the concept of 1d-som clustering and visualization. based on an example workflow, the functionality and utility of marvis is demonstrated. implementation marvis was written in the matlab® programming language and has been compiled for microsoft® windows xp/vista and linux x execution of the software requires installation of the matlab® compiler runtime, which is provided with marvis. the installation packages and the documentation can be downloaded from the project home page. for data import and export marvis uses the csv file format, which can easily be processed by statistical analysis software and spreadsheet applications. besides data set meta information and customizable headers, a csv file for use with marvis consists of marker candidate-specific lines. each line contains data fields with intensity measurements for all conditions and replicas. by default, marvis performs an aggregation of repeated measurements for each condition using the corresponding mean or median value. the resulting intensity vectors are normalized before clustering using the euclidean or ""city block"" norm or a z-score transformation. if alternatively normalized intensity profiles should be used for clustering, these user-normalized profiles can be stored as additional data in the csv file. it is also possible to store additional marker candidate properties, which are displayed by marvis as text. for high-contrast visualization of prototype and marker candidate profiles marvis uses customizable colormaps, which map original and normalized intensity values to a broad color spectrum. the colormapping for original and normalized intensities is calculated independently according to the respective minimum and maximum intensity values.  in the following, the functionality of marvis is demonstrated on the basis of a metabolomic case study of a plant wounding experiment analyzed by ultra performance liquid chromatography coupled with an orthogonal time-of-flight mass spectrometer as described before in. the data set contains marker candidates for the wound response of the thale cress arabidopsis thaliana under conditions. the first four conditions reflect the metabolic situation within a wounding time course of wild type plants starting with the control plants followed by the plants harvested, and hours post wounding. the conditions to represent the same time course for the jasmonate deficient mutant plant dde 2-. each condition contains replica samples. the corresponding data set is supplied with the marvis tool as a csv file. file import the data set is imported using the open for clustering entry in the file menu. after choosing the input file, marvis displays the import dialog, where the delimiter character, the start row and column of the header, the number of conditions, and the number of samples for each condition are specified. in this example, we use the mean intensity value for aggregation of replicas and the euclidean norm for normalization of intensity profiles. clustering after confirmation of the import options, the clustering dialog is opened. here, a title and the number of prototypes have to be specified. marvis starts the iterative clustering process and displays the intermediate prototype intensity profiles for each clustering state and the number of currently associated marker candidates in a separate window. the clustering process for the example data set only takes a few seconds on a standard pc. after the clustering process has been finished, the clustering state can be selected according to the desired degree of prototype smoothing by adjusting a scrollbar. here, we choose the final clustering state corresponding to a minimal amount of smoothing, which is suitable for analysis in most cases. visualization and analysis after selection of an appropriate clustering state for analysis, marvis returns to the main window and displays the prototype profiles and the number of associated marker candidates in the upper right region. after mouse click on a column corresponding to a particular prototype, further information regarding this prototype is displayed in the other regions of the main window. the prototype plot shows the array of prototypes according to the current colormap and additional information on the associated marker candidates. the vertical axis of region 1a represents the number of data set conditions, while the horizontal axis corresponds to the prototype numbers. a cursor marks the current prototype under investigation. by default, the displayed prototype profiles are equally spaced and region 1b shows the associated cluster sizes as a bar diagram. clicking on the toggle view button changes between different graphical representation modes. besides the default view, the prototype profiles can be spaced according to the size of their associated clusters, which helps to identify dominating intensity profiles. in this case, region 1b contains the original or normalized intensity profiles of the marker candidates associated with each prototype. the title above region 1a indicates, which graphical representation mode is currently activated. by clicking on one of the columns corresponding to a prototype the associated cluster can be activated. for the data set of the wounding case study the prototype plot reveals • a block of marker candidates that show high intensities in the conditions representing wt plants only • an intermediate block of different profiles representing high intensities across wt and dde 2- mutant plants • a block of prototypes that show high intensities in the jasmonate deficient mutant plants only • and a block of candidates that particularly represent high concentrations in the third and eighth condition. the first block corresponds to clusters in that contain wound induced markers exclusively associated with wild type plants as described in. in addition, clusters related to the third block contained markers that seem to be dependent on the jasmonate deficiency. the corresponding bar diagram shows that a number of clusters contain just a few or no marker candidates at all. these ""sparse"" clusters result from the restriction of the prototypes on a 1d-topology and usually indicate the use of too many prototypes. the cluster plot shows the intensity profiles of marker candidates in the activated cluster. each column represents the intensity profile of a single marker candidate displayed according to the current colormap. a cursor indicates the currently activated candidate. by clicking the toggle view button, marvis switches between normalized and original intensities. by default normalized intensities are shown. the example data set shows large differences regarding the original intensity values. this results in a colormapping, where low original intensities cannot be visually distinguished. when the logarithmic intensities checkbox in the view menu is activated, the colormapping for original intensity profiles is calculated logarithmically. this improves the visibility of small intensity differences significantly. the logarithmic transformation is only used for the visualization of original intensity profiles and does not affect the clustering results. the marker information box shows a table of available information on all marker candidates in the currently activated cluster. each candidate is represented by one row. apart from marker candidate id, retention time and mass-to-charge-ratio, also the values for additional data attributes are displayed. in this example, the column kwpvalue represents p-values obtained from a kruskal-wallis test. these values have been used as a quality measure for selection of marker candidates in. by pressing the up and down cursor keys or selecting a particular row via mouse click, the specific candidate can be highlighted. within the marker information box, the candidates are sorted by retention time. marvis keeps this order of the input file when displaying the candidates of single clusters. the marker scatter plot displays the rt vs. m/z values of each marker candidate in the currently activated cluster using big red dots. the currently activated candidate is represented by a big blue dot. in the background all marker candidates of the data set are plotted as small gray dots. by clicking into the plot a particular candidate can be activated. using the scatter plot, putative isotopomers or adducts of compounds can easily be identified by vertical stacks of candidates that do not differ in retention time. the active-prototype/marker plot by default displays the magnified prototype of the activated cluster according to the current colormap. additional functionality marvis stores a list of selected marker candidates in memory. single candidates or entire clusters can easily be added to or removed from this list. the selected marker candidates can be exported as a csv file for further analysis, e.g. for identification of related metabolic pathways based on mass values of candidates. the candidates may also be re-clustered using a lower number of prototypes in order to avoid sparse clusters. in addition to the export of selected marker candidates, marvis can save the entire clustering result as a csv file. this includes the marker data with additional values for normalized marker candidates, cluster number, and intensity profiles of the associated prototypes. the current settings, which include the data set and all user-specific parameters, can be saved and restored. for details on the above-mentioned functions see the marvis documentation.  marvis provides a graphical user interface for exploratory data analysis, well-suited for the visualization of metabolomic intensity profiles. the realization of 1d-soms gives a convenient overview of multivariate data sets. in particular, the specialized visualization effectively supports researchers to cope with the problem of an unknown number of biologically meaningful groups of intensity profiles. in that way, interesting groups can easily be identified based on their intensity patterns and their position in the prototype array. additional data attributes that support the analysis and interpretation of marker candidates can be integrated in marvis using customized data fields in the csv input file. by using the csv export functions, the clustering results can be imported and processed by other statistical analysis software. the customizable csv file format also allows to import, cluster and analyze experimental data from other than metabolomic studies, e.g. from gene expression experiments. an example application on gene expression data is shown in the marvis documentation. availability and requirements • project name: marvis • project home page: • operating system: microsoft® windows xp/vista and linux x86 • programming language: matlab® • other requirements: matlab® compiler runtime • license: free for academic use authors' contributions ak implemented the marvis graphical user interface and drafted parts of the manuscript. tl contributed conceptually and drafted parts of the manuscript. kf, cg and if provided the metabolomic case study data set, tested the software, contributed conceptually and drafted parts of the manuscript. pm implemented the clustering algorithm and drafted parts of the manuscript. all authors read and approved the final manuscript. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
48,9d60200c-d58e-4763-9b64-498b9ac66798_gpt3_gen,"The article discusses Marvis, a tool for metabolomic data analysis through clustering and visualization using one-dimensional self-organizing maps. Marvis aggregates and normalizes multivariate intensity profiles and clusters them using an adequate number of prototypes, allowing for the identification of interesting groups of marker candidates and visualization in a convenient way. The tool uses customizable colormaps to map original and normalized intensity values to visual colors for easier analysis. Marvis also includes additional functionality such as exporting selected marker candidates, re-clustering using a lower number of prototypes, and saving clustering results for further analysis. The authors illustrate the utility of the tool using a case study of plant wounding experiment analyzed by ultra performance liquid chromatography coupled with an orthogonal time-of-flight mass spectrometer. The authors conclude that Marvis provides an efficient platform for exploratory data analysis, which is readily customizable for metabolomic and other experimental data."," metabolomic profiling in general aims to identify or confirm biomarkers that are represented by specific metabolite intensity profiles in the context of different physiological and/or experimental conditions. these conditions may represent different phenotypes of a species, disease or environmental and genetic perturbations, or a time course comparing different developmental or physiological stages of an organism. high-throughput analytical measurements, as obtained from mass spectrometry experiments, provide a large number of intensity profiles for accumulation of different metabolites. these data sets show an even higher complexity when repeated measurements for each condition have been performed. for an interpretation based on the experimental conditions these replicas need to be aggregated using e.g. the corresponding mean or median value. for comparative analysis of relative metabolite concentrations it is usually necessary to normalize the resulting intensity vectors, e.g according to a unit euclidean or ""city block"" norm. in the following, the aggregated and normalized multivariate intensity profiles are referred to as marker candidates. clustering is a well-established technique in the context of gene expression analysis and coexpression studies. intensity-based clustering by analogy aims to group similar intensity profiles in order to identify interesting groups of marker candidates and visualize them in a convenient way. a major problem with the application of clustering algorithms is that an adequate number of clusters can often not be inferred automatically. a purely data-driven approach always bears the risk of over- or under-clustering because the correct number of clusters usually depends on task-specific constraints. one-dimensional self-organizing maps realize a linear array of prototypes that correspond to local averages of the data, ordered according to their similarity. in metabolomic analysis the visualization of ordered prototypes provides a quick overview on relevant intensity patterns in the data and allows to easily merge neighboring groups of marker candidates into meaningful clusters. for example, in we detected a significant number of clusters representing different physiological stages during a plant wounding time course as described in. the 1d-som realizes a robust and reproducible ordering in particular with regard to changing data quality. unlike the classical two-dimensional self-organizing maps, which are utilized in a number of software tools for gene expression analysis and metabolomics, 1d-soms allow a simultaneous visualization of the clustering and the underlying intensity profiles by means of the topologically ordered prototype array. this visualization corresponds to a two-dimensional color-coded matrix, where the first dimension represents the prototype order and the second dimension represents the experimental conditions. while 2d-soms can be used to visualize the two-dimensional variation in a single condition, 1d-soms provide a complete view on the one-dimensional variation in all conditions simultaneously. therefore, 1d-soms provide a convenient overview of highly complex metabolomic data sets. beside a number of general software packages, like the well-known som toolbox or the ""clustering for business analytics"" and som packages for the r-project, several more specific tools provide functions to order and visualize multivariate intensity profiles along a one-dimensional array. though, none of them provides a specialized interface for convenient 1d-som visualization and analysis of metabolomics data. in the following, we introduce the marvis tool, which implements the concept of 1d-som clustering and visualization. based on an example workflow, the functionality and utility of marvis is demonstrated. implementation marvis was written in the matlab® programming language and has been compiled for microsoft® windows xp/vista and linux x execution of the software requires installation of the matlab® compiler runtime, which is provided with marvis. the installation packages and the documentation can be downloaded from the project home page. for data import and export marvis uses the csv file format, which can easily be processed by statistical analysis software and spreadsheet applications. besides data set meta information and customizable headers, a csv file for use with marvis consists of marker candidate-specific lines. each line contains data fields with intensity measurements for all conditions and replicas. by default, marvis performs an aggregation of repeated measurements for each condition using the corresponding mean or median value. the resulting intensity vectors are normalized before clustering using the euclidean or ""city block"" norm or a z-score transformation. if alternatively normalized intensity profiles should be used for clustering, these user-normalized profiles can be stored as additional data in the csv file. it is also possible to store additional marker candidate properties, which are displayed by marvis as text. for high-contrast visualization of prototype and marker candidate profiles marvis uses customizable colormaps, which map original and normalized intensity values to a broad color spectrum. the colormapping for original and normalized intensities is calculated independently according to the respective minimum and maximum intensity values.  in the following, the functionality of marvis is demonstrated on the basis of a metabolomic case study of a plant wounding experiment analyzed by ultra performance liquid chromatography coupled with an orthogonal time-of-flight mass spectrometer as described before in. the data set contains marker candidates for the wound response of the thale cress arabidopsis thaliana under conditions. the first four conditions reflect the metabolic situation within a wounding time course of wild type plants starting with the control plants followed by the plants harvested, and hours post wounding. the conditions to represent the same time course for the jasmonate deficient mutant plant dde 2-. each condition contains replica samples. the corresponding data set is supplied with the marvis tool as a csv file. file import the data set is imported using the open for clustering entry in the file menu. after choosing the input file, marvis displays the import dialog, where the delimiter character, the start row and column of the header, the number of conditions, and the number of samples for each condition are specified. in this example, we use the mean intensity value for aggregation of replicas and the euclidean norm for normalization of intensity profiles. clustering after confirmation of the import options, the clustering dialog is opened. here, a title and the number of prototypes have to be specified. marvis starts the iterative clustering process and displays the intermediate prototype intensity profiles for each clustering state and the number of currently associated marker candidates in a separate window. the clustering process for the example data set only takes a few seconds on a standard pc. after the clustering process has been finished, the clustering state can be selected according to the desired degree of prototype smoothing by adjusting a scrollbar. here, we choose the final clustering state corresponding to a minimal amount of smoothing, which is suitable for analysis in most cases. visualization and analysis after selection of an appropriate clustering state for analysis, marvis returns to the main window and displays the prototype profiles and the number of associated marker candidates in the upper right region. after mouse click on a column corresponding to a particular prototype, further information regarding this prototype is displayed in the other regions of the main window. the prototype plot shows the array of prototypes according to the current colormap and additional information on the associated marker candidates. the vertical axis of region 1a represents the number of data set conditions, while the horizontal axis corresponds to the prototype numbers. a cursor marks the current prototype under investigation. by default, the displayed prototype profiles are equally spaced and region 1b shows the associated cluster sizes as a bar diagram. clicking on the toggle view button changes between different graphical representation modes. besides the default view, the prototype profiles can be spaced according to the size of their associated clusters, which helps to identify dominating intensity profiles. in this case, region 1b contains the original or normalized intensity profiles of the marker candidates associated with each prototype. the title above region 1a indicates, which graphical representation mode is currently activated. by clicking on one of the columns corresponding to a prototype the associated cluster can be activated. for the data set of the wounding case study the prototype plot reveals • a block of marker candidates that show high intensities in the conditions representing wt plants only • an intermediate block of different profiles representing high intensities across wt and dde 2- mutant plants • a block of prototypes that show high intensities in the jasmonate deficient mutant plants only • and a block of candidates that particularly represent high concentrations in the third and eighth condition. the first block corresponds to clusters in that contain wound induced markers exclusively associated with wild type plants as described in. in addition, clusters related to the third block contained markers that seem to be dependent on the jasmonate deficiency. the corresponding bar diagram shows that a number of clusters contain just a few or no marker candidates at all. these ""sparse"" clusters result from the restriction of the prototypes on a 1d-topology and usually indicate the use of too many prototypes. the cluster plot shows the intensity profiles of marker candidates in the activated cluster. each column represents the intensity profile of a single marker candidate displayed according to the current colormap. a cursor indicates the currently activated candidate. by clicking the toggle view button, marvis switches between normalized and original intensities. by default normalized intensities are shown. the example data set shows large differences regarding the original intensity values. this results in a colormapping, where low original intensities cannot be visually distinguished. when the logarithmic intensities checkbox in the view menu is activated, the colormapping for original intensity profiles is calculated logarithmically. this improves the visibility of small intensity differences significantly. the logarithmic transformation is only used for the visualization of original intensity profiles and does not affect the clustering results. the marker information box shows a table of available information on all marker candidates in the currently activated cluster. each candidate is represented by one row. apart from marker candidate id, retention time and mass-to-charge-ratio, also the values for additional data attributes are displayed. in this example, the column kwpvalue represents p-values obtained from a kruskal-wallis test. these values have been used as a quality measure for selection of marker candidates in. by pressing the up and down cursor keys or selecting a particular row via mouse click, the specific candidate can be highlighted. within the marker information box, the candidates are sorted by retention time. marvis keeps this order of the input file when displaying the candidates of single clusters. the marker scatter plot displays the rt vs. m/z values of each marker candidate in the currently activated cluster using big red dots. the currently activated candidate is represented by a big blue dot. in the background all marker candidates of the data set are plotted as small gray dots. by clicking into the plot a particular candidate can be activated. using the scatter plot, putative isotopomers or adducts of compounds can easily be identified by vertical stacks of candidates that do not differ in retention time. the active-prototype/marker plot by default displays the magnified prototype of the activated cluster according to the current colormap. additional functionality marvis stores a list of selected marker candidates in memory. single candidates or entire clusters can easily be added to or removed from this list. the selected marker candidates can be exported as a csv file for further analysis, e.g. for identification of related metabolic pathways based on mass values of candidates. the candidates may also be re-clustered using a lower number of prototypes in order to avoid sparse clusters. in addition to the export of selected marker candidates, marvis can save the entire clustering result as a csv file. this includes the marker data with additional values for normalized marker candidates, cluster number, and intensity profiles of the associated prototypes. the current settings, which include the data set and all user-specific parameters, can be saved and restored. for details on the above-mentioned functions see the marvis documentation.  marvis provides a graphical user interface for exploratory data analysis, well-suited for the visualization of metabolomic intensity profiles. the realization of 1d-soms gives a convenient overview of multivariate data sets. in particular, the specialized visualization effectively supports researchers to cope with the problem of an unknown number of biologically meaningful groups of intensity profiles. in that way, interesting groups can easily be identified based on their intensity patterns and their position in the prototype array. additional data attributes that support the analysis and interpretation of marker candidates can be integrated in marvis using customized data fields in the csv input file. by using the csv export functions, the clustering results can be imported and processed by other statistical analysis software. the customizable csv file format also allows to import, cluster and analyze experimental data from other than metabolomic studies, e.g. from gene expression experiments. an example application on gene expression data is shown in the marvis documentation. availability and requirements • project name: marvis • project home page: • operating system: microsoft® windows xp/vista and linux x86 • programming language: matlab® • other requirements: matlab® compiler runtime • license: free for academic use authors' contributions ak implemented the marvis graphical user interface and drafted parts of the manuscript. tl contributed conceptually and drafted parts of the manuscript. kf, cg and if provided the metabolomic case study data set, tested the software, contributed conceptually and drafted parts of the manuscript. pm implemented the clustering algorithm and drafted parts of the manuscript. all authors read and approved the final manuscript. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
49,13001452-a348-4f08-8fa9-0296a66c692e_flant5_gen,We have developed a protocol based on the dual-luciferase system in zebrafish embryos to determine the activity of constitutive and inducible promoters in the context of the whole organism.," the zebrafish has been established as an excellent model for studying any biological process. this organism possesses many advantages including ease of experimentation, optical clarity, drug administration, amenability to in vivo manipulation and feasibility of reverse and forward genetic approaches. the fish reach sexual maturity in only to months, and adult females are capable of producing to eggs weekly. many thousands of animals can be kept in a fish facility requiring much less space than mice or other mammals, and hence the zebrafish is regarded as a cost-effective experimental vertebrate model for large-scale genetic screening. furthermore, the high degree of homology between the zebrafish genome and that of humans makes such discoveries especially pertinent to human disease and development. morpholino antisense oligonucleotides have been widely used to inhibit gene function in zebrafish embryos and are usually used as sequence-specific translation-blocking or splicing-blocking agents. recently, a quantitative assessment of the knockdown efficiency of morpholinos has been performed in zebrafish embryos and its effectiveness proved. furthermore, microinjection of dna constructs into single-cell fertilized zebrafish embryos has also proven successful in the generation of transgenic zebrafish. the widespread use of fluorescent proteins in mammalian systems has been successfully adapted for use in zebrafish, which are well-suited to the use of fluorescence because of their optical clarity and external development. by linking a fluorescent protein such as enhanced green fluorescent protein or discosoma sp. red fluorescent protein to a gene or promoter of interest, expression can be easily visualized in living animals. the dual luciferase assay has been widely used in cell lines to determine rapidly and accurately the activity of a given promoter. although this strategy has been very useful, it does not allow analysis of the promoter and gene function in the context of the whole organism. to overcome these limitations, we have developed a protocol based on the dual luciferase system in zebrafish embryos. we illustrate the usefulness of this system for studying the promoter of telomerase, a key enzyme in the fields of cancer, stem cells and aging, and a nf-κb-dependent promoter, a master regulator of the immune response. the luciferase reporter dna plasmids were injected into zebrafish embryos at the one-cell developmental stage, together with mo or the expression constructs of interest, and the luciferase activity was determined in the time frame of mo activity. in addition, the flexibility of this assay is also illustrated by activation of the nf-κb-dependent promoters by simultaneous microinjection of different pathogen-associated molecular patterns. the protocol presented here provides details of how to apply the dual-luciferase assay to determining the activity of constitutive and inducible promoters in zebrafish embryos. this approach involves three steps: cloning the promoter of interest in the firefly luciferase reporter construct, microinjecting the embryos with this construct together with the appropriate renilla luciferase reporter and measuring the promoter activity with the dual luciferase system in whole embryo extracts.  the protocol presented here should result in very sensitive and accurate measurement of promoter activity and analysis of gene function in the context of the whole organism, which represents an important advantage over traditional measurement in cell lines. we first illustrated the usefulness of our protocol to analyze the promoter activity of zebrafish telomerase-reverse transcriptase. at h post-injection, the kb fragment upstream of the zftert coding sequence was able to drive the expression of the firefly luciferase reporter while the kb fragment failed to significantly increased the basal expression. therefore, the relative promoter activity of each fragment could be quantitatively determined. the critical step in the protocol presented here is the correct choice of the promoter used for normalization. the cytomegalovirus immediate-early promoter is a strong promoter used for both the in vitro and in vivo expression of proteins in signal transduction and gene therapy studies. however, cmv activity is induced by external stimuli such as endotoxin from gram-negative bacteria, cytokines and phorbol esters. therefore, for the study of nf-κb activation, we first have studied the effects of bacterial lps and dna in the expression of several renilla luciferase reporter constructs. among the four candidates tested, the cmv promoter was strongly induced by both pamps, i.e. escherichia coli lps and vibrio anguillarum dna, whereas the translation elongation factor ef1α promoter was inhibited by eclps and, to some extent, by vadna. in contrast, the herpes simplex virus thymidine kinase promoter and the early sv enhancer/promoter region showed a more constant expression and were therefore selected for further studies. figure 2c illustrates the profound effects of the plasmid used for normalization in the measurement of the induction of nf-κb. when using eclps, a vs. fold induction of nf-κb activity was obtained with the tk and the cmv promoters, respectively, indicating that induction of cmv by eclps resulted in the underestimation of the nf-κb activation by this pamp. similarly, vs. fold induction of nf-κb was observed with vadna when using the sv and the tk promoters, respectively, indicating that the inhibition of the tk promoter by vadna resulted in the overestimation of the nf-κb induced by this pamp. we finally validated the usefulness of this technique for studying a gene of interest by using mo-gene mediated knockdown. figure illustrates an example of the inhibition of the nf-κb activation triggered by vadna using a translation-blocking mo against myd, an adaptor protein involved in the downstream signalling following the engagement of bacterial dna by its cognate receptor. the results showed that injection of the mo against myd resulted in a significant inhibition of the nf-κb activation induced by bacterial dna, while injection of a mo directed against tlr which is involved in the recognition of double-stranded rna, failed to affect the nf-κb activation induced by bacterial dna. discussion the protocol presented here provides details of how to apply the dual-luciferase assay to determining the activity of both constitutive and inducible promoters in zebrafish embryos. beyond genetics and experimental tools, the strength of the zebrafish resides in the analysis of phenotype. perhaps no other organism is better suited to high-throughput phenotyping. the scale that can be achieved in zebrafish experiments is impressive by vertebrate standards. early zebrafish embryos are less than mm in diameter, allowing several embryos to fit easily in a single well of a 384-well plate. whole organisms offer several advantages over cell lines for forward chemical genetic screens, providing information on tissue specificity, toxicity and accounting for bioavailability. furthermore, cells are not transformed and are in their normal physiological milieu of cell-cell and cell-extracellular matrix interactions. use of the whole organism can also allow the screening of processes that are not easily replicated in vitro such as organ development. the advantages of zebrafish screening over invertebrate model organisms are their closer evolutionary relationship to humans. therefore, the assay described here represents a promising route to the identification and validation of novel drug targets. analysis of the promoter of newly identified genes that underlie zebrafish disease phenotypes might lead directly to the identification of novel drug targets or genes that can correct the phenotype. because zebrafish development occurs ex uterus and they have a large number of offspring, hundreds or thousands of embryos can be injected per day and the results of this assay can be obtained within 24– h, although shorter time points can also be analyzed if either the mrna coding for the gene under study or the recombinant protein are used. although some variation was found between replicates, these can be easily avoided by the high number of technical replicates achievable. the high-fold induction of luciferase activity, together with barely detectable levels of basal expression, makes it an ideal system for the in vivo analysis of inducible promoters. in addition, the assay can be combined with powerful mo-gene mediated knockdown or gene over-expression to rapidly determine the functions of a particular gene. therefore, this technique appears to be suitable for studying the activity and responses of different promoters and gene functions as well as for the validation of genetic constructs. however, this technique does not provide spatial information on gene expression and, therefore, it might be useful as a complementary technique to in situ hybridization and fluorescent microscopy. to avoid this limitation, all our promoters drive the expression of a fusion of egfp and firefly luciferase, which might allow the simultaneous determination of the expression levels and the spatial localization of the promoter under analysis. a shortcoming of the present assay, however, is the transient expression of the constructs and, therefore, only short-term responses of promoters can be studied. for example, the adaptive immune response can not be studied with the assay since it develops after several weeks. on the other hand, we have found that normalization is absolutely required for the elimination of experimental variations. as we have found that the renilla luciferase plasmid used for normalization can be induced by external stimuli, the choice of the normalization plasmid is critical. thus, the cmv immediate-early promoter, which is commonly used for normalization in both in vitro and in vivo studies, is significantly induced by external stimuli such as endotoxin and genomic dna from bacteria, as previously reported in cell lines with lps, cytokines and phorbol esters. however, this limitation could be easily overcome using other commercial renilla luciferase reporter vectors, such as those driven by the herpes simplex virus tk promoter or the early sv enhancer/promoter region.  we have developed a rapid and sensitive assay based on the classical dual-luciferase reporter technique which can be used as a new tool to characterize the minimum promoter region of a gene and the in vivo response of inducible promoters to different stimuli as well as in high throughput screening experiments. the flexibility of this assay is demonstrated by induction of the nf-κb-dependent promoters using simultaneous microinjection of different pamps as well as with the use of mo-gene mediated knockdown. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
50,13001452-a348-4f08-8fa9-0296a66c692e_gpt3_gen,"The zebrafish is a versatile model organism for studying biological processes due to its ease of experimentation, optical clarity, ability to administer drugs, and feasibility of genetic approaches. It reaches sexual maturity quickly, and its genome is highly homologous to that of humans, making it especially useful for studying human diseases. The dual luciferase assay has been adapted for use in zebrafish embryos, providing a sensitive and accurate measurement of promoter activity and analysis of gene function in the context of the whole organism. This technique is particularly useful for high-throughput screening experiments and identifying novel drug targets. However, it does have its limitations, including the transient expression of constructs and the need for careful normalization to eliminate experimental variations."," the zebrafish has been established as an excellent model for studying any biological process. this organism possesses many advantages including ease of experimentation, optical clarity, drug administration, amenability to in vivo manipulation and feasibility of reverse and forward genetic approaches. the fish reach sexual maturity in only to months, and adult females are capable of producing to eggs weekly. many thousands of animals can be kept in a fish facility requiring much less space than mice or other mammals, and hence the zebrafish is regarded as a cost-effective experimental vertebrate model for large-scale genetic screening. furthermore, the high degree of homology between the zebrafish genome and that of humans makes such discoveries especially pertinent to human disease and development. morpholino antisense oligonucleotides have been widely used to inhibit gene function in zebrafish embryos and are usually used as sequence-specific translation-blocking or splicing-blocking agents. recently, a quantitative assessment of the knockdown efficiency of morpholinos has been performed in zebrafish embryos and its effectiveness proved. furthermore, microinjection of dna constructs into single-cell fertilized zebrafish embryos has also proven successful in the generation of transgenic zebrafish. the widespread use of fluorescent proteins in mammalian systems has been successfully adapted for use in zebrafish, which are well-suited to the use of fluorescence because of their optical clarity and external development. by linking a fluorescent protein such as enhanced green fluorescent protein or discosoma sp. red fluorescent protein to a gene or promoter of interest, expression can be easily visualized in living animals. the dual luciferase assay has been widely used in cell lines to determine rapidly and accurately the activity of a given promoter. although this strategy has been very useful, it does not allow analysis of the promoter and gene function in the context of the whole organism. to overcome these limitations, we have developed a protocol based on the dual luciferase system in zebrafish embryos. we illustrate the usefulness of this system for studying the promoter of telomerase, a key enzyme in the fields of cancer, stem cells and aging, and a nf-κb-dependent promoter, a master regulator of the immune response. the luciferase reporter dna plasmids were injected into zebrafish embryos at the one-cell developmental stage, together with mo or the expression constructs of interest, and the luciferase activity was determined in the time frame of mo activity. in addition, the flexibility of this assay is also illustrated by activation of the nf-κb-dependent promoters by simultaneous microinjection of different pathogen-associated molecular patterns. the protocol presented here provides details of how to apply the dual-luciferase assay to determining the activity of constitutive and inducible promoters in zebrafish embryos. this approach involves three steps: cloning the promoter of interest in the firefly luciferase reporter construct, microinjecting the embryos with this construct together with the appropriate renilla luciferase reporter and measuring the promoter activity with the dual luciferase system in whole embryo extracts.  the protocol presented here should result in very sensitive and accurate measurement of promoter activity and analysis of gene function in the context of the whole organism, which represents an important advantage over traditional measurement in cell lines. we first illustrated the usefulness of our protocol to analyze the promoter activity of zebrafish telomerase-reverse transcriptase. at h post-injection, the kb fragment upstream of the zftert coding sequence was able to drive the expression of the firefly luciferase reporter while the kb fragment failed to significantly increased the basal expression. therefore, the relative promoter activity of each fragment could be quantitatively determined. the critical step in the protocol presented here is the correct choice of the promoter used for normalization. the cytomegalovirus immediate-early promoter is a strong promoter used for both the in vitro and in vivo expression of proteins in signal transduction and gene therapy studies. however, cmv activity is induced by external stimuli such as endotoxin from gram-negative bacteria, cytokines and phorbol esters. therefore, for the study of nf-κb activation, we first have studied the effects of bacterial lps and dna in the expression of several renilla luciferase reporter constructs. among the four candidates tested, the cmv promoter was strongly induced by both pamps, i.e. escherichia coli lps and vibrio anguillarum dna, whereas the translation elongation factor ef1α promoter was inhibited by eclps and, to some extent, by vadna. in contrast, the herpes simplex virus thymidine kinase promoter and the early sv enhancer/promoter region showed a more constant expression and were therefore selected for further studies. figure 2c illustrates the profound effects of the plasmid used for normalization in the measurement of the induction of nf-κb. when using eclps, a vs. fold induction of nf-κb activity was obtained with the tk and the cmv promoters, respectively, indicating that induction of cmv by eclps resulted in the underestimation of the nf-κb activation by this pamp. similarly, vs. fold induction of nf-κb was observed with vadna when using the sv and the tk promoters, respectively, indicating that the inhibition of the tk promoter by vadna resulted in the overestimation of the nf-κb induced by this pamp. we finally validated the usefulness of this technique for studying a gene of interest by using mo-gene mediated knockdown. figure illustrates an example of the inhibition of the nf-κb activation triggered by vadna using a translation-blocking mo against myd, an adaptor protein involved in the downstream signalling following the engagement of bacterial dna by its cognate receptor. the results showed that injection of the mo against myd resulted in a significant inhibition of the nf-κb activation induced by bacterial dna, while injection of a mo directed against tlr which is involved in the recognition of double-stranded rna, failed to affect the nf-κb activation induced by bacterial dna. discussion the protocol presented here provides details of how to apply the dual-luciferase assay to determining the activity of both constitutive and inducible promoters in zebrafish embryos. beyond genetics and experimental tools, the strength of the zebrafish resides in the analysis of phenotype. perhaps no other organism is better suited to high-throughput phenotyping. the scale that can be achieved in zebrafish experiments is impressive by vertebrate standards. early zebrafish embryos are less than mm in diameter, allowing several embryos to fit easily in a single well of a 384-well plate. whole organisms offer several advantages over cell lines for forward chemical genetic screens, providing information on tissue specificity, toxicity and accounting for bioavailability. furthermore, cells are not transformed and are in their normal physiological milieu of cell-cell and cell-extracellular matrix interactions. use of the whole organism can also allow the screening of processes that are not easily replicated in vitro such as organ development. the advantages of zebrafish screening over invertebrate model organisms are their closer evolutionary relationship to humans. therefore, the assay described here represents a promising route to the identification and validation of novel drug targets. analysis of the promoter of newly identified genes that underlie zebrafish disease phenotypes might lead directly to the identification of novel drug targets or genes that can correct the phenotype. because zebrafish development occurs ex uterus and they have a large number of offspring, hundreds or thousands of embryos can be injected per day and the results of this assay can be obtained within 24– h, although shorter time points can also be analyzed if either the mrna coding for the gene under study or the recombinant protein are used. although some variation was found between replicates, these can be easily avoided by the high number of technical replicates achievable. the high-fold induction of luciferase activity, together with barely detectable levels of basal expression, makes it an ideal system for the in vivo analysis of inducible promoters. in addition, the assay can be combined with powerful mo-gene mediated knockdown or gene over-expression to rapidly determine the functions of a particular gene. therefore, this technique appears to be suitable for studying the activity and responses of different promoters and gene functions as well as for the validation of genetic constructs. however, this technique does not provide spatial information on gene expression and, therefore, it might be useful as a complementary technique to in situ hybridization and fluorescent microscopy. to avoid this limitation, all our promoters drive the expression of a fusion of egfp and firefly luciferase, which might allow the simultaneous determination of the expression levels and the spatial localization of the promoter under analysis. a shortcoming of the present assay, however, is the transient expression of the constructs and, therefore, only short-term responses of promoters can be studied. for example, the adaptive immune response can not be studied with the assay since it develops after several weeks. on the other hand, we have found that normalization is absolutely required for the elimination of experimental variations. as we have found that the renilla luciferase plasmid used for normalization can be induced by external stimuli, the choice of the normalization plasmid is critical. thus, the cmv immediate-early promoter, which is commonly used for normalization in both in vitro and in vivo studies, is significantly induced by external stimuli such as endotoxin and genomic dna from bacteria, as previously reported in cell lines with lps, cytokines and phorbol esters. however, this limitation could be easily overcome using other commercial renilla luciferase reporter vectors, such as those driven by the herpes simplex virus tk promoter or the early sv enhancer/promoter region.  we have developed a rapid and sensitive assay based on the classical dual-luciferase reporter technique which can be used as a new tool to characterize the minimum promoter region of a gene and the in vivo response of inducible promoters to different stimuli as well as in high throughput screening experiments. the flexibility of this assay is demonstrated by induction of the nf-κb-dependent promoters using simultaneous microinjection of different pamps as well as with the use of mo-gene mediated knockdown. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
51,e3625fc5-41d6-46d2-b763-53f29725e3c2_flant5_gen,a high resolution rh map of chicken chromosome gga was constructed using the chickrh panel.," chicken is the first major agricultural species for which the complete genome sequencing was undertaken. this is partly due to its position as a model species in various fields of biology including embryo development, oncology, immunology and evolution. moreover, as it is the only bird species for which the genome study is so advanced, very much is expected from its use in comparative genome analyses for annotation, including that of the human genome, by detection of conserved sequences. its intermediate phylogenetic position between mammals and fishes will also certainly provide valuable information on the evolution of vertebrate karyotypes. radiation hybrid maps have a resolution power intermediate to that of the genetic and bac contig maps and are also a powerful tool for the mapping of ests and genes by simple pcr. they are thus useful at two levels: first, they can be used constructively as scaffolds for a correct genome assembly or for detecting and correcting misassembled portions of the genome; second, before obtaining whole annotated genome sequences, they are very efficient tools for inter-species comparative genome analyses through the easy mapping of genes and ests. the successful production of a rh panel in chicken is quite recent, and therefore rh maps are only available for a limited number of chromosomes. having identified qtl for fatness on chicken chromosome, our objective was to build a high-resolution and gene-rich rh map for this chromosome, as a basis for high precision comparative mapping with human and for the development of new polymorphic markers. the available human/chicken comparative mapping data indicated conservation of synteny between gga and portions of hsa hsa and hsa in addition, two genes from hsa had also been shown to be located on gga. this information was used to develop markers from chicken est sequence data orthologous to genes in these human regions, in addition to the existing markers from the chicken chromosome genetic map. while in the process of finishing our map, the first draft sequence assembly of the chicken genome was released. the quality of both the gga rh map and of the sequence assembly was therefore checked by alignment of all the markers by blast searches.  development of est markers in addition to the microsatellite markers from the genetic map, and primer pairs chosen either from available primer data in the literature or designed using the gene sequence deposited in genbank/embl, primer pairs were chosen from chicken est markers selected on the basis of the known conservations of synteny between human and chicken using the iccare software. constraints on the design of primers were to avoid presence of long introns, whose position and length was predicted on the basis of the orthologous human gene structure, and to design primers in the most divergent regions of the human/chicken alignment, to limit cross-amplification with the hamster dna present in the hybrids. one hundred and thirty nine primer pairs out of enabled a successful amplification and the subsequent mapping of the corresponding genes, confirming the high success rate obtained when using the iccare software for designing chicken pcr primers based on est data. construction of the gga rh map altogether, genotyping data was obtained for a total of markers, comprising gene fragments and microsatellites from the gga genetic map. two-point analysis using a lod threshold of enabled to constitute a group of markers, including all the microsatellite markers from the genetic map. the remaining markers correspond to the external boundaries of the regions of conserved synteny with human, from which ests were chosen for marker development and map either to other chromosomes for which rh maps were developed or to unknown regions. after multipoint analysis, a 1000: framework map cr long, comprising a total of markers including microsatellites and ests was obtained. the remaining markers are located relative to the framework map within confidence intervals, to build a comprehensive map. to compare the rh and the genetic maps, the best possible position of the non-framework common markers had to be estimated. that of the markers on the rh map was computed by the carthagene program and is indicated in addition to the confidence interval. for the genetic map, the central position of the marker's confidence interval was used as their most probable position. as a result, the order of the markers on the rh map matches exactly that of the same markers on genetic map, with only one notable discrepancy concerning the position of brf. however, when the position of this gene was checked on the sequence assembly, the agreement was with the rh map, suggesting the position of this gene on the genetic map is erroneous. an average retention frequency of % was observed for the gga markers studied here, although with a high variation, with values ranging from % to %. this finding is within the range observed in other studies reported on this panel: % overall retention using markers chosen genome-wise, % for gga, for gga and 18% for gga. as already noticed for several species including human or cow, but also for chicken chromosomes and, a centromeric effect is detected when observing retention frequencies of markers along the map, with a higher retention of markers in the region between to cr, in which the retention culminates at a value of %, whereas it is around 15% for the rest of the chromosome. alignment of the rh map to the genomic sequence a preliminary data set based on the first draft chicken genome assembly has been deposited into public databases by a team led by r. wilson and w. warren, from the washington university school of medicine in st. louis. we compared our data with the gga sequence, by using blastn searches and sequence alignments. the agreement between the rh framework map and the sequence orders is almost perfect, although with a few discrepancies, most of them suggesting possible improvements to be made in the sequence assembly. first, a group of markers, that we developed on the basis of the conservation of synteny between gga and hsa is assigned to gga in the sequence assembly. three of these markers are on the framework map and for all four, the rh genotypings obtained are very similar to those obtained with the flanking rh framework markers slc17a and arntl, both located on the gga sequence assembly. furthermore, when two-point analysis of the four markers was computed with the flanking markers loc and slc22a suggested in the gga sequence assembly, lod scores were equal to zero. this part of the genome assigned to a wrong chromosome on the sequence assembly covers a region at least cr long, corresponding to a distance of to mb, as estimated from the cr to mb ratio. indeed, the length of the sequence between the two extreme markers cstf and gpr on the gga assembly is mb. the retention frequency of these four markers is amongst the highest of all, suggesting that their location is close to the centromere and that the possible sequence assembly problems are related to this proximity, perhaps due to repetitive sequences. second, we observed an inversion of the gene order for a segment in the upper part of the chromosome adjacent to the group we described as wrongly assigned to gga in the sequence assembly. as the difference of likelihood between our 1000: framework map and the map order in this area suggested from the assembly is higher than we considered that order of the rh map is the correct one. this could also be due to assembly difficulties close to the centromere region. third, several markers absent in the sequence assembly could be localised on the rh map. most of these markers belong to regions for which sequence information is available, but that couldn't be incorporated in the sequence assembly at all or that could be assigned to gga but without a clear location. in addition, one gene also appeared to belong to a region with no sequence available. this gene had previously been located on the cytogenetic map to the short arm of gga, so we consider our data as a confirmation. fourth, we observed a discrepancy in the local order of the two framework map markers mcw and gtf2a however, the difference of likelihood between our framework map and the same map with an inversion of these two markers is only. it is therefore difficult to conclude as to which between the sequence and the rh map presents the correct order. from these data we conclude that radiation hybrid maps can be useful to help detect errors in the draft sequence assembly and for mapping genes either absent or of unknown location in the assembly. comparison cr6000/cm/kb the average cr/cm ratio is when calculated over the whole map length. this relatively high value, as compared to the cr/cm obtained for gga, must be inflected by the disparity observed along the chromosome. this heterogeneity actually reflects disparities in the recombination rate along the chromosome, with recombination events more frequent at the end of the long arm. the agreement between the gene order found on rh map and the sequence assembly is very high. considering only the q arm of the chromosome, the cr/mb ratio is, or kb per cr. this ratio, similar to that obtained for gga, is quite lower than the kb/cr and kb/cr values obtained for gga and gga respectively, suggesting a higher resolution for the larger chromosomes. this result can have two origins: first, the kb/cr ratio is not constant from one chromosome to another, regardless of their physical length; second, the previous calculations were based on physical length values estimated from cytogenetic studies: mb for gga and mb for gga. if we consider the actual chromosome length based on sequence assembly, these chromosomes are shorter than previously estimated, with values of and mb, the ratio is thus now closer to the value we obtain here for gga comparative mapping  we have built a high resolution rh map of chicken chromosome using the chickrh panel. in doing this, we fulfilled our objective of obtaining a detailed comparative map of gga providing jointly a source of potential polymorphic markers and of candidate genes for qtl mapping on this chromosome. at the end of our work, the first draft chicken genome assembly was released and we aligned it to our gga rh map. although we detected a few errors to correct, this allowed us to demonstrate the high quality of the sequence assembly, which may have benefited from a low frequency of repeated elements. in the near future, the chickrh panel will be used to assist in improving the chicken genome assembly. this is clearly needed in the regions for which the genetic map is still not complete, such as some microchromosomes, but also for parts of macrochromosomes, as shown in this study. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
52,e3625fc5-41d6-46d2-b763-53f29725e3c2_gpt3_gen,"The complete genome sequencing for chickens was the first of its kind, and it serves as a valuable model for various fields of biology. Among other things, chickens are useful for comparative genome analyses and the detection of conserved sequences with possible implications for the annotation of the human genome. Additionally, chicken's intermediate phylogenetic position between mammals and fishes can provide valuable insights into the evolution of vertebrate karyotypes. A high-resolution and gene-rich radiation hybrid (RH) map of the chicken chromosome was developed, and its quality was checked by tools such as genome alignment with available gene sequences. The RH map is useful for comparative mapping with the human genome and the detection of errors in the chromosome sequence assembly. The frequency of the markers' retention on the chromosome was higher in the region closer to the centromere, observed in other species, including humans. Overall, the RH map provided a detailed comparative map of the gga and served as a source of potential polymorphic markers and candidate genes for quantitative trait loci (QTL) mapping on this chromosome. The gga RH panel will be used to improve the chicken's genome assembly further, especially in the case of microchromosomes and parts of the macrochromosomes that are still not complete."," chicken is the first major agricultural species for which the complete genome sequencing was undertaken. this is partly due to its position as a model species in various fields of biology including embryo development, oncology, immunology and evolution. moreover, as it is the only bird species for which the genome study is so advanced, very much is expected from its use in comparative genome analyses for annotation, including that of the human genome, by detection of conserved sequences. its intermediate phylogenetic position between mammals and fishes will also certainly provide valuable information on the evolution of vertebrate karyotypes. radiation hybrid maps have a resolution power intermediate to that of the genetic and bac contig maps and are also a powerful tool for the mapping of ests and genes by simple pcr. they are thus useful at two levels: first, they can be used constructively as scaffolds for a correct genome assembly or for detecting and correcting misassembled portions of the genome; second, before obtaining whole annotated genome sequences, they are very efficient tools for inter-species comparative genome analyses through the easy mapping of genes and ests. the successful production of a rh panel in chicken is quite recent, and therefore rh maps are only available for a limited number of chromosomes. having identified qtl for fatness on chicken chromosome, our objective was to build a high-resolution and gene-rich rh map for this chromosome, as a basis for high precision comparative mapping with human and for the development of new polymorphic markers. the available human/chicken comparative mapping data indicated conservation of synteny between gga and portions of hsa hsa and hsa in addition, two genes from hsa had also been shown to be located on gga. this information was used to develop markers from chicken est sequence data orthologous to genes in these human regions, in addition to the existing markers from the chicken chromosome genetic map. while in the process of finishing our map, the first draft sequence assembly of the chicken genome was released. the quality of both the gga rh map and of the sequence assembly was therefore checked by alignment of all the markers by blast searches.  development of est markers in addition to the microsatellite markers from the genetic map, and primer pairs chosen either from available primer data in the literature or designed using the gene sequence deposited in genbank/embl, primer pairs were chosen from chicken est markers selected on the basis of the known conservations of synteny between human and chicken using the iccare software. constraints on the design of primers were to avoid presence of long introns, whose position and length was predicted on the basis of the orthologous human gene structure, and to design primers in the most divergent regions of the human/chicken alignment, to limit cross-amplification with the hamster dna present in the hybrids. one hundred and thirty nine primer pairs out of enabled a successful amplification and the subsequent mapping of the corresponding genes, confirming the high success rate obtained when using the iccare software for designing chicken pcr primers based on est data. construction of the gga rh map altogether, genotyping data was obtained for a total of markers, comprising gene fragments and microsatellites from the gga genetic map. two-point analysis using a lod threshold of enabled to constitute a group of markers, including all the microsatellite markers from the genetic map. the remaining markers correspond to the external boundaries of the regions of conserved synteny with human, from which ests were chosen for marker development and map either to other chromosomes for which rh maps were developed or to unknown regions. after multipoint analysis, a 1000: framework map cr long, comprising a total of markers including microsatellites and ests was obtained. the remaining markers are located relative to the framework map within confidence intervals, to build a comprehensive map. to compare the rh and the genetic maps, the best possible position of the non-framework common markers had to be estimated. that of the markers on the rh map was computed by the carthagene program and is indicated in addition to the confidence interval. for the genetic map, the central position of the marker's confidence interval was used as their most probable position. as a result, the order of the markers on the rh map matches exactly that of the same markers on genetic map, with only one notable discrepancy concerning the position of brf. however, when the position of this gene was checked on the sequence assembly, the agreement was with the rh map, suggesting the position of this gene on the genetic map is erroneous. an average retention frequency of % was observed for the gga markers studied here, although with a high variation, with values ranging from % to %. this finding is within the range observed in other studies reported on this panel: % overall retention using markers chosen genome-wise, % for gga, for gga and 18% for gga. as already noticed for several species including human or cow, but also for chicken chromosomes and, a centromeric effect is detected when observing retention frequencies of markers along the map, with a higher retention of markers in the region between to cr, in which the retention culminates at a value of %, whereas it is around 15% for the rest of the chromosome. alignment of the rh map to the genomic sequence a preliminary data set based on the first draft chicken genome assembly has been deposited into public databases by a team led by r. wilson and w. warren, from the washington university school of medicine in st. louis. we compared our data with the gga sequence, by using blastn searches and sequence alignments. the agreement between the rh framework map and the sequence orders is almost perfect, although with a few discrepancies, most of them suggesting possible improvements to be made in the sequence assembly. first, a group of markers, that we developed on the basis of the conservation of synteny between gga and hsa is assigned to gga in the sequence assembly. three of these markers are on the framework map and for all four, the rh genotypings obtained are very similar to those obtained with the flanking rh framework markers slc17a and arntl, both located on the gga sequence assembly. furthermore, when two-point analysis of the four markers was computed with the flanking markers loc and slc22a suggested in the gga sequence assembly, lod scores were equal to zero. this part of the genome assigned to a wrong chromosome on the sequence assembly covers a region at least cr long, corresponding to a distance of to mb, as estimated from the cr to mb ratio. indeed, the length of the sequence between the two extreme markers cstf and gpr on the gga assembly is mb. the retention frequency of these four markers is amongst the highest of all, suggesting that their location is close to the centromere and that the possible sequence assembly problems are related to this proximity, perhaps due to repetitive sequences. second, we observed an inversion of the gene order for a segment in the upper part of the chromosome adjacent to the group we described as wrongly assigned to gga in the sequence assembly. as the difference of likelihood between our 1000: framework map and the map order in this area suggested from the assembly is higher than we considered that order of the rh map is the correct one. this could also be due to assembly difficulties close to the centromere region. third, several markers absent in the sequence assembly could be localised on the rh map. most of these markers belong to regions for which sequence information is available, but that couldn't be incorporated in the sequence assembly at all or that could be assigned to gga but without a clear location. in addition, one gene also appeared to belong to a region with no sequence available. this gene had previously been located on the cytogenetic map to the short arm of gga, so we consider our data as a confirmation. fourth, we observed a discrepancy in the local order of the two framework map markers mcw and gtf2a however, the difference of likelihood between our framework map and the same map with an inversion of these two markers is only. it is therefore difficult to conclude as to which between the sequence and the rh map presents the correct order. from these data we conclude that radiation hybrid maps can be useful to help detect errors in the draft sequence assembly and for mapping genes either absent or of unknown location in the assembly. comparison cr6000/cm/kb the average cr/cm ratio is when calculated over the whole map length. this relatively high value, as compared to the cr/cm obtained for gga, must be inflected by the disparity observed along the chromosome. this heterogeneity actually reflects disparities in the recombination rate along the chromosome, with recombination events more frequent at the end of the long arm. the agreement between the gene order found on rh map and the sequence assembly is very high. considering only the q arm of the chromosome, the cr/mb ratio is, or kb per cr. this ratio, similar to that obtained for gga, is quite lower than the kb/cr and kb/cr values obtained for gga and gga respectively, suggesting a higher resolution for the larger chromosomes. this result can have two origins: first, the kb/cr ratio is not constant from one chromosome to another, regardless of their physical length; second, the previous calculations were based on physical length values estimated from cytogenetic studies: mb for gga and mb for gga. if we consider the actual chromosome length based on sequence assembly, these chromosomes are shorter than previously estimated, with values of and mb, the ratio is thus now closer to the value we obtain here for gga comparative mapping  we have built a high resolution rh map of chicken chromosome using the chickrh panel. in doing this, we fulfilled our objective of obtaining a detailed comparative map of gga providing jointly a source of potential polymorphic markers and of candidate genes for qtl mapping on this chromosome. at the end of our work, the first draft chicken genome assembly was released and we aligned it to our gga rh map. although we detected a few errors to correct, this allowed us to demonstrate the high quality of the sequence assembly, which may have benefited from a low frequency of repeated elements. in the near future, the chickrh panel will be used to assist in improving the chicken genome assembly. this is clearly needed in the regions for which the genetic map is still not complete, such as some microchromosomes, but also for parts of macrochromosomes, as shown in this study. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
53,0edfcce1-3383-41e2-bde9-2979904376f2_gpt3_gen,"The article discusses the Ca2+-dependent activator protein for secretion (CAPS) family and its two members, CAPS1/CADPS and CAPS2/CADPS. CAPS plays a role in the release of neurotrophins BDNF and NT- and is involved in vesicle exocytosis. The article identifies six CAPS isoforms and discusses their functional differences, including their association with the membrane and their ability to release BDNF. The study also examines the developmental expression patterns of CAPS isoforms and their tissue distribution. Finally, the article notes that the splicing of exon 3, which is associated with autism, was not observed in mouse tissues."," the ca2+-dependent activator protein for secretion family consists of two members, caps1/cadps and caps2/cadps. caps was shown to play a role in the atp-dependent priming step of ca2+-triggered dense-core vesicle exocytosis by binding to both phosphatidyl inositol -bisphosphate and dcvs in response to ca2+ increase; it also interacts with the dopamine receptor. a study of caps1-deficient mice suggested that caps is involved in catecholamine loading of dcvs in embryonic chromaffin cells. on the other hand, caps is associated with secretory vesicles containing the neurotrophins bdnf and nt- in the parallel fiber terminals of cerebellar granule cells, and is involved in the release of bdnf and nt-. caps is widely localized across various brain regions, and shows overlapping distribution patterns with bdnf in many areas. our recent studies of caps2-deficient mice indicated that caps plays pivotal roles in bdnf release, cellular phenotypes, and behavioral phenotypes. the expression of an aberrant splicing variant of caps in some patients with autism has also been reported. the autistic isoform, caps2Δexon is missing exon which encodes the dynactin 1-interacting domain. exogenously expressed caps2Δexon failed to localize to axons but accumulated in somato-dendritic areas in cultured cerebellar and cortical neurons, suggesting a possible disturbance of local caps2-mediated neurotrophin release. in this study, we further explore splicing variations in caps and identified five additional splice isoforms. we characterized the expression patterns and neurotrophin release properties of these isoforms.  using cdna probes comprising the sequence of both exons and of caps we screened a p mouse cerebellar cdna library for splicing variants of caps in addition to the original clone designated caps2a, which was identical to the one that we previously reported, we isolated five additional variants, probably derived from full-length transcripts, designated caps2b, 2c, 2d, 2e, and 2f. sequence analyses against genome databases showed that these sequences could be produced by the different usage of the exons of the caps gene. all splicing acceptor and donor sequences of these clones were consistent with the ag/gt rule. the full-length caps protein consists of the following functional domains, as shown in figure 2: a dynactin 1-interacting domain, a c domain, a pleckstrin homology domain and a munc13-1-homologous domain. caps2b lacks only exon which encodes a part of the mhd. caps2a lacks two exons, and which encode part of the mhd sequence. caps2c lacks two exons, exon encoding a c-terminal part of the ph domain, and exon in contrast to these three long isoforms, caps2d, 2e and 2f have large c-terminal large truncations from exon and respectively; thus, these isoforms have neither the mhd nor the c-tail domain, which mediates the association of caps with dcvs. these three short isoforms have an additional unique exon at their 3' end. the shortest isoform, caps2f, has only the first four authentic exons and none of the functional domains identified so far. all isoforms have exon which contains the domain interacting with p150glued. the mouse caps exon coding sequence is identical to the human caps exon coding sequence, which is absent in some autistic patients. as shown in figure 3a, no exon skipping was observed during the development of the cerebellum, from e to p provided there were sufficient pcr cycles. moreover, no exon skipping was observed in whole brain, thymus, lung, heart, liver, spleen, kidney, or testis from p or p mice. these results suggest that exon skipping does not normally occur in mouse caps we examined the patterns of caps splicing during cerebellar development, by rt-pcr using specific primer sets for each isoform. caps2b is the only isoform that contains exon therefore, rt-pcr with a primer pair spanning exon 21-exon resulted in a longer band for caps2b in addition to a shorter band for caps2a and 2c. interestingly, there was a peak in the expression of caps2a and/or 2c at p whereas caps2b was up-regulated throughout development. the expression of caps2d reached a peak at p and decreased thereafter, whereas that of both caps2e and 2f reached a peak between p and p among the eight mouse tissues tested, the brain, lung, kidney, and testis showed expression of all isoforms except for caps2b. interestingly, expression of caps2b was detectable only in the brain. among these isoforms, the expression level of caps2f was the lowest as shown by its requiring the highest cycle number of pcr cycles to detect it. we next examined the cellular distribution of caps isoform mrnas in p and p mouse brains by in situ hybridization analyses. exon which contains a part of the ph-domain coding sequence, is skipped in caps2c, but is included in caps2a, 2b, 2d, and 2e. the probe for exon showed expression in the hippocampal formation, neocortex, midbrain, and cerebellar granule cells. exon which contains a part of the mhd coding sequence, is skipped in caps2a and 2c, but is included in caps2b. the probe for exon showed an expression pattern with the most prominent level in cerebellar granule cells. expression of caps2d, 2e and 2f was also observed mainly in cerebellar granule cells. moreover, there was no apparent difference in the expression patterns of these isoforms in the p cerebellar cortex, as shown in figure 4k. caps family proteins are essentially soluble proteins, but a fraction of them is capable of being associated with membrane. therefore, we next examined the subcellular fractionation patterns of these splicing variant proteins, exogenously expressed in pc cells. all isoforms were stably expressed in transfected pc cells. caps isoforms containing an intact ph domain were recovered from the membrane fraction, although a major portion of each isoform was included in the soluble fraction. on the other hand, caps isoforms lacking a part of the ph domain or the entire ph domain were not detectable in the membrane fraction, suggesting that the ph domain has a role in the membrane association of caps protein, as previously shown. we next examined the expression of the endogenous proteins produced from these splice isoform mrnas in the mouse brain. immunoreactive bands corresponding to short isoforms were observed at low to undetectable protein levels in the mouse cerebellum. in addition, the previous report showed that in non-neural tissue such as pituitary, lung, pancreas and kidney, only a kda band immunoreactive for caps was detected. at the mrna level, more reaction cycles and time were needed for the amplification of transcripts encoding the short isoforms by rt-pcr and for the colorimetric detection of transcripts by in situ hybridization, respectively, indicating that the expression levels of the genes encoding the short isoforms are very low. these results indicate that the function of caps in vivo is apparently due to the long isoforms rather than the short isoforms. however, the functional role of the short isoforms remain to be studied. to analyze functional differences between splicing variants, we carried out a bdnf secretion assay. to investigate the effect of these isoforms on bdnf releasing activity, we exogenously expressed the three long isoforms together with bdnf in pc cells. short isoforms were not analyzed because of their large c-terminal truncation and very low expression levels in mouse brain. as shown in figure the levels of bdnf released into the culture medium in response to high-kcl stimulation were increased approximately two-fold by the expression of caps2a or 2b compared with cells without exogenous caps expression. caps2c-expressing cells showed lower bdnf-releasing activity than caps2a- or 2b-expressing cells; however, caps2c-expressing cells also showed an increase in bdnf release in response to high-kcl stimulation. moreover, there was no significant difference in basal bdnf release between caps2c-expressing cells and cells expressing either of the other two isoforms. there was a partial deletion of the ph domain in caps2c. the partial ph domain of plc-gamma is known to interact with a complementary partial ph-like domain of another protein and elicit its function. therefore, it is possible that caps2c has some bdnf-releasing activity, although its activity is lower than that of intact ph domain-containing isoforms. interestingly, expression of the exon 22-containing isoform was up-regulated in the developing mouse cerebellum, whereas exon 22-skipped isoforms were expressed transiently, peaking at p moreover, the exon 22-containing isoform showed higher bdnf-releasing activity than other long isoforms. on the other hand, as described in our previous report, caps immunoreactivities are detected in both the soma and axon of cerebellar granule cells at p but almost exclusively in the axon at p. these results suggest that the exon splicing patterns are related to high releasing activity and axonal localization in cerebellar granule cells. caps2-mediated regulation of neurotrophin actions in terms of their releasing dose and subcellular localization may be important for normal cerebellar development. the splicing of exon is interesting for reasons other than the developmental differences in expression; that is, the exon 22-containing isoform was detectable only in the brain, whereas exon 22-skipped isoforms were widely expressed in various tissues. exon encodes part of the mhd, specifically a proline-rich domain. proline-rich motifs occurred often in many protein-protein interaction sites, including one recognized by the src homology domain. our preliminary screening of protein candidates that interact with the exon 22-encoded region, by yeast two-hybrid, isolated five candidates; however, none of these had an sh domain. future analyses of caps proline-rich domain-interacting proteins will clarify the significance of the alternative splicing of exon  we explored the alternative splicing diversity of caps and identified six caps isoforms. the alternative splicing of exon was associated with a difference in tissue distribution and a developmental expression pattern. our study showed that an intact ph domain is required for the association of caps with the membrane and efficient bdnf release activity. on the other hand, exon 3-skipping, found in autistic patients, was not observed in the mouse tissues tested. ",pubmed_generic,GPT 3.5,"The article identifies six CAPS isoforms and discusses their functional differences, including their association with the membrane and their ability to release BDNF.",non_factual,factual,minor,,intrinsic,,,,,
54,0edfcce1-3383-41e2-bde9-2979904376f2_flant5_gen,splicing variations in caps2 and their effect on neurotrophin release.," the ca2+-dependent activator protein for secretion family consists of two members, caps1/cadps and caps2/cadps. caps was shown to play a role in the atp-dependent priming step of ca2+-triggered dense-core vesicle exocytosis by binding to both phosphatidyl inositol -bisphosphate and dcvs in response to ca2+ increase; it also interacts with the dopamine receptor. a study of caps1-deficient mice suggested that caps is involved in catecholamine loading of dcvs in embryonic chromaffin cells. on the other hand, caps is associated with secretory vesicles containing the neurotrophins bdnf and nt- in the parallel fiber terminals of cerebellar granule cells, and is involved in the release of bdnf and nt-. caps is widely localized across various brain regions, and shows overlapping distribution patterns with bdnf in many areas. our recent studies of caps2-deficient mice indicated that caps plays pivotal roles in bdnf release, cellular phenotypes, and behavioral phenotypes. the expression of an aberrant splicing variant of caps in some patients with autism has also been reported. the autistic isoform, caps2Δexon is missing exon which encodes the dynactin 1-interacting domain. exogenously expressed caps2Δexon failed to localize to axons but accumulated in somato-dendritic areas in cultured cerebellar and cortical neurons, suggesting a possible disturbance of local caps2-mediated neurotrophin release. in this study, we further explore splicing variations in caps and identified five additional splice isoforms. we characterized the expression patterns and neurotrophin release properties of these isoforms.  using cdna probes comprising the sequence of both exons and of caps we screened a p mouse cerebellar cdna library for splicing variants of caps in addition to the original clone designated caps2a, which was identical to the one that we previously reported, we isolated five additional variants, probably derived from full-length transcripts, designated caps2b, 2c, 2d, 2e, and 2f. sequence analyses against genome databases showed that these sequences could be produced by the different usage of the exons of the caps gene. all splicing acceptor and donor sequences of these clones were consistent with the ag/gt rule. the full-length caps protein consists of the following functional domains, as shown in figure 2: a dynactin 1-interacting domain, a c domain, a pleckstrin homology domain and a munc13-1-homologous domain. caps2b lacks only exon which encodes a part of the mhd. caps2a lacks two exons, and which encode part of the mhd sequence. caps2c lacks two exons, exon encoding a c-terminal part of the ph domain, and exon in contrast to these three long isoforms, caps2d, 2e and 2f have large c-terminal large truncations from exon and respectively; thus, these isoforms have neither the mhd nor the c-tail domain, which mediates the association of caps with dcvs. these three short isoforms have an additional unique exon at their 3' end. the shortest isoform, caps2f, has only the first four authentic exons and none of the functional domains identified so far. all isoforms have exon which contains the domain interacting with p150glued. the mouse caps exon coding sequence is identical to the human caps exon coding sequence, which is absent in some autistic patients. as shown in figure 3a, no exon skipping was observed during the development of the cerebellum, from e to p provided there were sufficient pcr cycles. moreover, no exon skipping was observed in whole brain, thymus, lung, heart, liver, spleen, kidney, or testis from p or p mice. these results suggest that exon skipping does not normally occur in mouse caps we examined the patterns of caps splicing during cerebellar development, by rt-pcr using specific primer sets for each isoform. caps2b is the only isoform that contains exon therefore, rt-pcr with a primer pair spanning exon 21-exon resulted in a longer band for caps2b in addition to a shorter band for caps2a and 2c. interestingly, there was a peak in the expression of caps2a and/or 2c at p whereas caps2b was up-regulated throughout development. the expression of caps2d reached a peak at p and decreased thereafter, whereas that of both caps2e and 2f reached a peak between p and p among the eight mouse tissues tested, the brain, lung, kidney, and testis showed expression of all isoforms except for caps2b. interestingly, expression of caps2b was detectable only in the brain. among these isoforms, the expression level of caps2f was the lowest as shown by its requiring the highest cycle number of pcr cycles to detect it. we next examined the cellular distribution of caps isoform mrnas in p and p mouse brains by in situ hybridization analyses. exon which contains a part of the ph-domain coding sequence, is skipped in caps2c, but is included in caps2a, 2b, 2d, and 2e. the probe for exon showed expression in the hippocampal formation, neocortex, midbrain, and cerebellar granule cells. exon which contains a part of the mhd coding sequence, is skipped in caps2a and 2c, but is included in caps2b. the probe for exon showed an expression pattern with the most prominent level in cerebellar granule cells. expression of caps2d, 2e and 2f was also observed mainly in cerebellar granule cells. moreover, there was no apparent difference in the expression patterns of these isoforms in the p cerebellar cortex, as shown in figure 4k. caps family proteins are essentially soluble proteins, but a fraction of them is capable of being associated with membrane. therefore, we next examined the subcellular fractionation patterns of these splicing variant proteins, exogenously expressed in pc cells. all isoforms were stably expressed in transfected pc cells. caps isoforms containing an intact ph domain were recovered from the membrane fraction, although a major portion of each isoform was included in the soluble fraction. on the other hand, caps isoforms lacking a part of the ph domain or the entire ph domain were not detectable in the membrane fraction, suggesting that the ph domain has a role in the membrane association of caps protein, as previously shown. we next examined the expression of the endogenous proteins produced from these splice isoform mrnas in the mouse brain. immunoreactive bands corresponding to short isoforms were observed at low to undetectable protein levels in the mouse cerebellum. in addition, the previous report showed that in non-neural tissue such as pituitary, lung, pancreas and kidney, only a kda band immunoreactive for caps was detected. at the mrna level, more reaction cycles and time were needed for the amplification of transcripts encoding the short isoforms by rt-pcr and for the colorimetric detection of transcripts by in situ hybridization, respectively, indicating that the expression levels of the genes encoding the short isoforms are very low. these results indicate that the function of caps in vivo is apparently due to the long isoforms rather than the short isoforms. however, the functional role of the short isoforms remain to be studied. to analyze functional differences between splicing variants, we carried out a bdnf secretion assay. to investigate the effect of these isoforms on bdnf releasing activity, we exogenously expressed the three long isoforms together with bdnf in pc cells. short isoforms were not analyzed because of their large c-terminal truncation and very low expression levels in mouse brain. as shown in figure the levels of bdnf released into the culture medium in response to high-kcl stimulation were increased approximately two-fold by the expression of caps2a or 2b compared with cells without exogenous caps expression. caps2c-expressing cells showed lower bdnf-releasing activity than caps2a- or 2b-expressing cells; however, caps2c-expressing cells also showed an increase in bdnf release in response to high-kcl stimulation. moreover, there was no significant difference in basal bdnf release between caps2c-expressing cells and cells expressing either of the other two isoforms. there was a partial deletion of the ph domain in caps2c. the partial ph domain of plc-gamma is known to interact with a complementary partial ph-like domain of another protein and elicit its function. therefore, it is possible that caps2c has some bdnf-releasing activity, although its activity is lower than that of intact ph domain-containing isoforms. interestingly, expression of the exon 22-containing isoform was up-regulated in the developing mouse cerebellum, whereas exon 22-skipped isoforms were expressed transiently, peaking at p moreover, the exon 22-containing isoform showed higher bdnf-releasing activity than other long isoforms. on the other hand, as described in our previous report, caps immunoreactivities are detected in both the soma and axon of cerebellar granule cells at p but almost exclusively in the axon at p. these results suggest that the exon splicing patterns are related to high releasing activity and axonal localization in cerebellar granule cells. caps2-mediated regulation of neurotrophin actions in terms of their releasing dose and subcellular localization may be important for normal cerebellar development. the splicing of exon is interesting for reasons other than the developmental differences in expression; that is, the exon 22-containing isoform was detectable only in the brain, whereas exon 22-skipped isoforms were widely expressed in various tissues. exon encodes part of the mhd, specifically a proline-rich domain. proline-rich motifs occurred often in many protein-protein interaction sites, including one recognized by the src homology domain. our preliminary screening of protein candidates that interact with the exon 22-encoded region, by yeast two-hybrid, isolated five candidates; however, none of these had an sh domain. future analyses of caps proline-rich domain-interacting proteins will clarify the significance of the alternative splicing of exon  we explored the alternative splicing diversity of caps and identified six caps isoforms. the alternative splicing of exon was associated with a difference in tissue distribution and a developmental expression pattern. our study showed that an intact ph domain is required for the association of caps with the membrane and efficient bdnf release activity. on the other hand, exon 3-skipping, found in autistic patients, was not observed in the mouse tissues tested. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
55,1020a637-1816-438d-8ae9-8e18a12b967c_flant5_gen,a novel protein function prediction method that uses protein domain composition and ppi networks.," genome sequencing projects are generating massive amounts of sequence data, and the functional annotation of these sequences became one of the most challenging tasks, especially for the many proteins whose functions remain unknown. traditional computational methods have utilized sequence features and machine learning algorithms to predict functions. in recent years, high-throughput technologies, such as yeast-two hybrid, have provided large scale protein-protein interaction data, making it possible to develop new function prediction methods based on protein-protein interaction networks. existing protein function prediction methods based on ppi can be categorized into two classes: direct methods based only on the protein interactions and module-assisted methods. direct methods directly infer protein functions from interactions in the ppi networks while module-assisted methods first try to find functional modules in the ppi networks and then assign protein functions based on the module functions. direct methods are based on the assumption that interacting proteins probably have identical or similar functions. this assumption is supported by previous studies which show that 70%-80% of proteins share at least one identical function with their interacting partners. schwikowski et al used a neighbor counting method to predict protein functions. they took up to three most frequent functions of interacting partners as indicators of the function of each protein, which turned out to cover over 70% of the known functions. hisigaki et al tried to predict protein functions by computing the chi-square statistics as an indicator of functions that were statistically significantly frequent among neighboring proteins. chua et al investigated the relationships between functional similarity and network distance. they utilized functional information from proteins within or neighborhoods of a protein by giving different weights to different network distances. vazquez et al assigned functions to proteins via an iterative algorithm by maximizing the number of edges that connect proteins with the same function. other graph-based methods include those of karaoz et al and nabieva et al. instead of predicting individual protein functions, module-assisted methods first identify functional modules in ppi networks and then assign functions to the proteins according to functions of the module members. these methods are based on previous observations that a group of cellular components and their interactions usually can be attributed to a specific function. the approaches of different module-assisted methods vary mainly on the methods for identifying functional modules, which divide the methods into those based on network topology only and those which integrate multiple data sources. network topology based methods include mcode, a module-assisted method based on clustering coefficients, the clustering method of rives et al and the hierarchical clustering method of spirin et al. ge et al showed that proteins having similar functions tend to have similar expression patterns, which can be used to predict protein functions. ideker et al developed a framework to identify active sub-networks by detecting significant changes in expression over a particular set of conditions. hanisch et al applied a co-clustering methodology that combined similarities in gene expression patterns and network topologies. hierarchical clustering was then used to define functional modules. although several existing methods have combined multiple information resources, such as gene expression information, gene regulatory networks and ppi networks, none of them have yet integrated protein domain information and ppi networks to predict protein functions. this paper presents a novel protein function prediction method that uses protein domain composition and ppi networks. this paper first demonstrates that proteins having similar functions are often in similar domain contexts in ppi networks and then develops the protein function prediction method based on this observation. the method gives satisfactory results compared to several existing methods. methods yeast ppi network data was obtained from dip database. proteins and protein-protein interactions were included in the network. the yeast ppi network was chosen because it is comparatively more complete with fewer missing interactions. nearly 70% of the orfs of yeast are covered by the yeast ppi network, which is the highest coverage ratio among ppi networks of all organisms. besides, the yeast ppi network is the most frequently used in previous protein function prediction studies, which allows accuracy comparison to other methods. the domain annotation information was retrieved from the pfam database. the hmmer software package was used to annotate domains in the yeast orfs. domains of domain types were obtained from proteins. the protein function annotation information was provided by the gene ontology database. domains are basic functional units in proteins. cellular functions are accomplished by the cooperation of many domains in proteins. therefore, the ppi network was decomposed into the domain level to investigate protein functions in terms of domain. figure shows a simplified model. protein a has neighbors in the ppi network, which all-together contain different domains, while protein b has neighbors with the same domains. domain shuffling or recombination during evolution may have changed the domain distribution among proteins. one possible situation is that domain is in the same protein with domain in one organism, while in another organism, it is combined with domain. despite the different domain distribution, similar domain compositions of neighbors of protein a and b in the ppi network may indicate both functional similarity and evolutionary relationship. thus proteins with similar domain contexts in the ppi network may share similar functions. the domain context similarity is defined as: where m is the number of domain types in the ppi network. given proteins a and b, sa and sb are the sets of domains included in a's neighbors and in b's neighbors. the number of domain types in sa is a, while the number of domain types in sb is b. the intersection of sa and sb is s, containing s types of domains. c denotes combinatorial numbers. the larger f indicates a greater probability that a and b share similar functions. for each go term, there is a positive data set composed of present proteins, and a negative data set including absent ones. for example, go: is used to describe yeast proteins, so these proteins were treated as positive samples. since some go terms contains only a few proteins and other go terms are too general, only go terms containing 10- proteins were considered. given a protein p with unknown function, in order to examine its function with regard to each particular go term, the domain context similarities, f, between p and each protein in both the positive and negative data sets were calculated. the function annotation of the protein with the highest f value was then assigned to p. the 7-fold cross validation, which has been widely implemented in previous researches, was used to evaluate the performance of our prediction. for every go term, both the positive and negative data sets were divided into seven equal parts randomly. every time six positive parts and six negative parts were used as the training data set while the remaining parts was used as the test data set. this procedure was repeated times to ensure that every part was used once as the test data set for one go term. then the whole procedure was repeated for every go term. the final accuracy was the average of the evaluations. four frequently used measurement indices, accuracy, precision, recall and mathew correlation coefficient, were used to evaluate the prediction performance. the mathew correlation coefficient was calculated to assess the prediction performance when the numbers of proteins in the positive and negative data sets differed significantly. mcc ranges from - to a larger mcc indicating better prediction performance. for data with positive predictions, the real positives are defined as true positives, while others are defined as false positives. for data with negative predictions, the real positives are defined as false negatives, while the others are defined as true negatives. then, the measurement indices are defined as:  the relationships between protein function similarity and domain context similarity in the ppi network were investigated based on the measurement indices. first, pairs of proteins were randomly extracted from one go term with the domain context similarity, f, then calculated for each pair. secondly, another random protein pairs were generated using pair of proteins from different go terms. their f values are also calculated. the two sets of similarities were then compared to demonstrate the positive significant relationship between functional similarity and domain context similarity. the results showed that set a has a mean similarity, f, of compared to for set b. kolmogorov-smirnov test showed that set a is significantly higher than set b with a p-value less than 10- the distributions of the similarity for sets a and b are shown in figures and there are many values between and in set a, while most values in set b are near hence, the domain context similarity can be a useful index to predict protein function similarity. the method was then used to predict protein functions in yeast. go terms were divided into groups according to the number of proteins in each go term. go terms containing less than proteins were excluded due to the lack of a satisfactory number of proteins for accurate predictions. go terms including more than proteins were also eliminated because the function annotations in these go terms are usually too general. the results are shown in table the prediction accuracies are between 63%-67%. the results show that the method has satisfactory robustness for various numbers of proteins within one go term. as number of proteins increases from 10- to 100- the accuracy only decreases slightly, by about 4%. the phenomenon that accuracies decrease as number of proteins in the go term increases can be attributed to the fact that functional annotations in larger go terms are not as specific as in smaller go terms. fuzzy, general annotation information may affect the prediction performance. further investigation is required to explain this observation. besides, the recall is higher than the precision, demonstrating that false positive predictions are more common than false negative predictions. this method was then compared with existing methods based on the roc curves. the three previously developed methods included in comparison are mrf, neighbor counting and chi-square method. the random prediction performance was also presented. the roc curves shown in figure indicate that the current method outperforms the other methods. discussion a new prediction method for protein function based on protein-protein interaction and domain context was presented in this research. domain context similarity in the protein-protein interaction network was defined and used as in index for prediction. the underling principle of this method was that proteins tend to interact with each other via domain-domain interaction. so the high quality domain-domain interaction information may improve the prediction accuracy. riley at al developed domain pair exclusion analysis to infer high-confidence domain interaction from protein interactions. besides, dima try to identify known and predicted domain interactions which may be helpful if this information was utilized in our method. this research also suggests several future directions of research. first, domain context similarity measurements or prediction systems can be improved to reduce false positive predictions and boost accuracy. for example, the cutoff value for domain context similarity can be introduced to improve the accuracy and to deal with multiple function problems. since the underlying rationale of this method is the domain-domain interaction, high-quality domain interactions can definitely contribute to the accuracy. as mentioned above, the newly developed domain interaction inferring method can be used in our future algorithm improvement. second, as shown by chua et al, functional similarities exist between neighbor proteins with distances equal to or larger than which may be useful information to be included in function prediction. third, other data resources, such as gene expression profiles and gene regulatory networks, could be combined with domain context information to prediction functions. different weight can be assigned to different types of information. machine learning methods, such as svm, can also be utilized to take the information listed above as input features. finally, since protein domains are conserved and can be easily detected in various organisms, this method should be promising in comparing protein functions across species.  the availability of large scale protein-protein interaction data sets makes it possible to predict protein functions based on protein-protein interaction networks. several existing methods combine multiple information resources to predict protein functions. we present a novel protein function prediction method that combines protein domain composition information and ppi networks. performance evaluations show that this method outperforms existing methods. the results are used to analyze the relationships between domain context similarity and protein function similarity, while this research may have potential future research directions. competing interests the authors declare that they have no competing interests. authors' contributions zs, hc designed the study, collected study data, performed the analysis, prediction and cross validation and produced the first draft of the manuscript. kl provided assistance in the process of collecting data and revising the manuscript. zs was involved in designing the study and revising the manuscript. all authors read and approved the final manuscript. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
56,1020a637-1816-438d-8ae9-8e18a12b967c_gpt3_gen,"This article discusses the challenges in annotating the functions of proteins and describes a novel approach to predicting protein functions based on protein domain composition and protein-protein interaction networks. The method uses domain context similarity as an index for predicting protein function similarity and outperforms existing methods. The article suggests several future directions for research, including improving domain context similarity measurements and incorporating additional data resources such as gene expression profiles and gene regulatory networks. The method has potential for comparing protein functions across species and could be useful in predicting functions for the many proteins whose functions remain unknown."," genome sequencing projects are generating massive amounts of sequence data, and the functional annotation of these sequences became one of the most challenging tasks, especially for the many proteins whose functions remain unknown. traditional computational methods have utilized sequence features and machine learning algorithms to predict functions. in recent years, high-throughput technologies, such as yeast-two hybrid, have provided large scale protein-protein interaction data, making it possible to develop new function prediction methods based on protein-protein interaction networks. existing protein function prediction methods based on ppi can be categorized into two classes: direct methods based only on the protein interactions and module-assisted methods. direct methods directly infer protein functions from interactions in the ppi networks while module-assisted methods first try to find functional modules in the ppi networks and then assign protein functions based on the module functions. direct methods are based on the assumption that interacting proteins probably have identical or similar functions. this assumption is supported by previous studies which show that 70%-80% of proteins share at least one identical function with their interacting partners. schwikowski et al used a neighbor counting method to predict protein functions. they took up to three most frequent functions of interacting partners as indicators of the function of each protein, which turned out to cover over 70% of the known functions. hisigaki et al tried to predict protein functions by computing the chi-square statistics as an indicator of functions that were statistically significantly frequent among neighboring proteins. chua et al investigated the relationships between functional similarity and network distance. they utilized functional information from proteins within or neighborhoods of a protein by giving different weights to different network distances. vazquez et al assigned functions to proteins via an iterative algorithm by maximizing the number of edges that connect proteins with the same function. other graph-based methods include those of karaoz et al and nabieva et al. instead of predicting individual protein functions, module-assisted methods first identify functional modules in ppi networks and then assign functions to the proteins according to functions of the module members. these methods are based on previous observations that a group of cellular components and their interactions usually can be attributed to a specific function. the approaches of different module-assisted methods vary mainly on the methods for identifying functional modules, which divide the methods into those based on network topology only and those which integrate multiple data sources. network topology based methods include mcode, a module-assisted method based on clustering coefficients, the clustering method of rives et al and the hierarchical clustering method of spirin et al. ge et al showed that proteins having similar functions tend to have similar expression patterns, which can be used to predict protein functions. ideker et al developed a framework to identify active sub-networks by detecting significant changes in expression over a particular set of conditions. hanisch et al applied a co-clustering methodology that combined similarities in gene expression patterns and network topologies. hierarchical clustering was then used to define functional modules. although several existing methods have combined multiple information resources, such as gene expression information, gene regulatory networks and ppi networks, none of them have yet integrated protein domain information and ppi networks to predict protein functions. this paper presents a novel protein function prediction method that uses protein domain composition and ppi networks. this paper first demonstrates that proteins having similar functions are often in similar domain contexts in ppi networks and then develops the protein function prediction method based on this observation. the method gives satisfactory results compared to several existing methods. methods yeast ppi network data was obtained from dip database. proteins and protein-protein interactions were included in the network. the yeast ppi network was chosen because it is comparatively more complete with fewer missing interactions. nearly 70% of the orfs of yeast are covered by the yeast ppi network, which is the highest coverage ratio among ppi networks of all organisms. besides, the yeast ppi network is the most frequently used in previous protein function prediction studies, which allows accuracy comparison to other methods. the domain annotation information was retrieved from the pfam database. the hmmer software package was used to annotate domains in the yeast orfs. domains of domain types were obtained from proteins. the protein function annotation information was provided by the gene ontology database. domains are basic functional units in proteins. cellular functions are accomplished by the cooperation of many domains in proteins. therefore, the ppi network was decomposed into the domain level to investigate protein functions in terms of domain. figure shows a simplified model. protein a has neighbors in the ppi network, which all-together contain different domains, while protein b has neighbors with the same domains. domain shuffling or recombination during evolution may have changed the domain distribution among proteins. one possible situation is that domain is in the same protein with domain in one organism, while in another organism, it is combined with domain. despite the different domain distribution, similar domain compositions of neighbors of protein a and b in the ppi network may indicate both functional similarity and evolutionary relationship. thus proteins with similar domain contexts in the ppi network may share similar functions. the domain context similarity is defined as: where m is the number of domain types in the ppi network. given proteins a and b, sa and sb are the sets of domains included in a's neighbors and in b's neighbors. the number of domain types in sa is a, while the number of domain types in sb is b. the intersection of sa and sb is s, containing s types of domains. c denotes combinatorial numbers. the larger f indicates a greater probability that a and b share similar functions. for each go term, there is a positive data set composed of present proteins, and a negative data set including absent ones. for example, go: is used to describe yeast proteins, so these proteins were treated as positive samples. since some go terms contains only a few proteins and other go terms are too general, only go terms containing 10- proteins were considered. given a protein p with unknown function, in order to examine its function with regard to each particular go term, the domain context similarities, f, between p and each protein in both the positive and negative data sets were calculated. the function annotation of the protein with the highest f value was then assigned to p. the 7-fold cross validation, which has been widely implemented in previous researches, was used to evaluate the performance of our prediction. for every go term, both the positive and negative data sets were divided into seven equal parts randomly. every time six positive parts and six negative parts were used as the training data set while the remaining parts was used as the test data set. this procedure was repeated times to ensure that every part was used once as the test data set for one go term. then the whole procedure was repeated for every go term. the final accuracy was the average of the evaluations. four frequently used measurement indices, accuracy, precision, recall and mathew correlation coefficient, were used to evaluate the prediction performance. the mathew correlation coefficient was calculated to assess the prediction performance when the numbers of proteins in the positive and negative data sets differed significantly. mcc ranges from - to a larger mcc indicating better prediction performance. for data with positive predictions, the real positives are defined as true positives, while others are defined as false positives. for data with negative predictions, the real positives are defined as false negatives, while the others are defined as true negatives. then, the measurement indices are defined as:  the relationships between protein function similarity and domain context similarity in the ppi network were investigated based on the measurement indices. first, pairs of proteins were randomly extracted from one go term with the domain context similarity, f, then calculated for each pair. secondly, another random protein pairs were generated using pair of proteins from different go terms. their f values are also calculated. the two sets of similarities were then compared to demonstrate the positive significant relationship between functional similarity and domain context similarity. the results showed that set a has a mean similarity, f, of compared to for set b. kolmogorov-smirnov test showed that set a is significantly higher than set b with a p-value less than 10- the distributions of the similarity for sets a and b are shown in figures and there are many values between and in set a, while most values in set b are near hence, the domain context similarity can be a useful index to predict protein function similarity. the method was then used to predict protein functions in yeast. go terms were divided into groups according to the number of proteins in each go term. go terms containing less than proteins were excluded due to the lack of a satisfactory number of proteins for accurate predictions. go terms including more than proteins were also eliminated because the function annotations in these go terms are usually too general. the results are shown in table the prediction accuracies are between 63%-67%. the results show that the method has satisfactory robustness for various numbers of proteins within one go term. as number of proteins increases from 10- to 100- the accuracy only decreases slightly, by about 4%. the phenomenon that accuracies decrease as number of proteins in the go term increases can be attributed to the fact that functional annotations in larger go terms are not as specific as in smaller go terms. fuzzy, general annotation information may affect the prediction performance. further investigation is required to explain this observation. besides, the recall is higher than the precision, demonstrating that false positive predictions are more common than false negative predictions. this method was then compared with existing methods based on the roc curves. the three previously developed methods included in comparison are mrf, neighbor counting and chi-square method. the random prediction performance was also presented. the roc curves shown in figure indicate that the current method outperforms the other methods. discussion a new prediction method for protein function based on protein-protein interaction and domain context was presented in this research. domain context similarity in the protein-protein interaction network was defined and used as in index for prediction. the underling principle of this method was that proteins tend to interact with each other via domain-domain interaction. so the high quality domain-domain interaction information may improve the prediction accuracy. riley at al developed domain pair exclusion analysis to infer high-confidence domain interaction from protein interactions. besides, dima try to identify known and predicted domain interactions which may be helpful if this information was utilized in our method. this research also suggests several future directions of research. first, domain context similarity measurements or prediction systems can be improved to reduce false positive predictions and boost accuracy. for example, the cutoff value for domain context similarity can be introduced to improve the accuracy and to deal with multiple function problems. since the underlying rationale of this method is the domain-domain interaction, high-quality domain interactions can definitely contribute to the accuracy. as mentioned above, the newly developed domain interaction inferring method can be used in our future algorithm improvement. second, as shown by chua et al, functional similarities exist between neighbor proteins with distances equal to or larger than which may be useful information to be included in function prediction. third, other data resources, such as gene expression profiles and gene regulatory networks, could be combined with domain context information to prediction functions. different weight can be assigned to different types of information. machine learning methods, such as svm, can also be utilized to take the information listed above as input features. finally, since protein domains are conserved and can be easily detected in various organisms, this method should be promising in comparing protein functions across species.  the availability of large scale protein-protein interaction data sets makes it possible to predict protein functions based on protein-protein interaction networks. several existing methods combine multiple information resources to predict protein functions. we present a novel protein function prediction method that combines protein domain composition information and ppi networks. performance evaluations show that this method outperforms existing methods. the results are used to analyze the relationships between domain context similarity and protein function similarity, while this research may have potential future research directions. competing interests the authors declare that they have no competing interests. authors' contributions zs, hc designed the study, collected study data, performed the analysis, prediction and cross validation and produced the first draft of the manuscript. kl provided assistance in the process of collecting data and revising the manuscript. zs was involved in designing the study and revising the manuscript. all authors read and approved the final manuscript. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
57,d193f064-45d7-45d9-acbe-ea9aa07a1713_flant5_gen,genorm analysis identifies candidate reference genes for accurate normalization of gene expression levels in c. elegans.," real-time quantitative pcr has become a very powerful tool for gene expression studies. one of the main difficulties associated with this highly sensitive technique is the necessity of accurate normalization, to account for varying amounts of cdna input. this variation is inherent to the multistep process required to extract and process the rna. the use of internal controls or reference genes has become the method of choice to account for this source of variation. the choice of an appropriate internal standard is therefore critical for relative gene expression analysis in order to obtain consistent and reliable results, especially when measuring small expression differences. a suitable reference gene to which expression can be normalized should have constant expression in all samples under investigation and should be insensitive to varying experimental treatments. although the nematode c. elegans is a commonly used model organism that has proven its importance in the unraveling of many important signaling pathways, to date no comprehensive analysis has been performed to validate candidate reference genes for gene expression analysis. therefore, commonly used reference genes such as act- and ama- are often used without validating their usefulness. however, several reports indicate that the expression of commonly used reference genes can vary under different experimental conditions, possibly leading to dramatic misinterpretation of the expression level of a target gene. although there is no universally accepted approach for data normalization, the method of using multiple stably expressed reference genes is currently the golden standard. the straightforward method developed by vandesompele and colleagues to identify the most stably expressed reference genes from a set of candidate control genes can be used to normalize gene expression levels. their method also allows the determination of the optimal number of genes required for reliable normalization of qpcr generated gene expression data. they advocate use of the geometric mean of multiple stably expressed reference genes for normalization of relative quantities. this approach has been widely implemented by many researchers and has been statistically validated by szabo et al. and by the bootstrap procedure of gabrielsson et al., but surprisingly seems to be neglected in the c. elegans research field. the ins/igf- signaling pathway is a well-known life span regulator in c. elegans, drosophila and mice. a reduced activity of the pathway in c. elegans leads to nuclear localization of the transcription factor daf- causing dauer formation and extended adult life span. long-lived iis mutants are highly resistant to a wide diversity of stressors, including enhanced survival upon exposure to the superoxide generator paraquat. given the potential role of reactive oxygen species in the ageing process, it is assumed that enzymes involved in the breakdown of ros play an important role in the longevity phenotype of dauers and long-lived iis mutants. five different genes encoding superoxide dismutase have been predicted in c. elegans. sod- and sod- encode cytosolic cuznsods. sod- expresses two splice variants, one membrane bound and one secreted. sod- and sod- encode mitochondrial mnsods. it is well-established that increased life span is often associated with increased stress resistance and high antioxidant activity. for example, the long life span of dauers and iis mutants is associated with increased stress resistance and high sod activity. northern blot and microarray analysis have shown that sod- and possibly also sod- are upregulated in dauers and daf- mutants. we demonstrate the usefulness of genorm to determine the expression levels of the sod genes in c. elegans. genorm analysis evaluates the stability of candidate reference genes based on the mean pairwise variation of a gene with all other tested genes. we compared the expression level of the candidate reference genes in different c. elegans samples to validate internal controls for the analysis of sod gene expression. the presented approach can be applied to accurately normalize the expression of any c. elegans gene of interest.  we carefully selected potential reference genes from different functional classes to minimize the chance of coregulation using two different approaches. first we selected commonly used reference genes such as ama-, act-, eif- c, gpd- and tba-. in a second approach we screened publicly available c. elegans microarray expression data. in this procedure we ranked all genes according to their standard deviation in experiments and chose potential reference genes within the top ranked ones based on the following three criteria: functional description available, expression data available for at least experiments and cdna confirmed. this strategy resulted in cdc- pmp- rgs- unc- and y45f10d. as candidate reference genes. after initial screening, we found that two genes from the available expression data in kim et al. were expressed at very low levels and therefore excluded for further analysis. in an attempt to validate the remaining candidate reference genes as internal control for analysis of sod gene expression in c. elegans, we set up an experiment containing young adult wild-type, three strains carrying mutations in the ins/igf pathway, wild type dauer worms and wild-type l stage larvae. data were collected using rna from replicate c. elegans cultures. since the reverse transcription step is the source of most of the variability in quantitative pcr, cdna synthesis was performed in duplicate from each of the three different biological replicates and pooled to use as template in the pcr experiments. for every primer pair concentrations were optimized in a range between nm and nm, based on a standard curve made with dilution series of a mixture of all cdna templates. these standard curves produced efficiencies between and with standard deviations ranging from to and correlation coefficients greater than, as determined by qbase. three identical real-time qpcr experiments were performed. in each experiment, the expression levels of the candidate reference genes and sod genes were measured in duplicate in different worm samples. the candidate control genes display a wide expression range with mean cycle threshold values between and. to identify the most stable reference genes we applied the genorm program. the ranking of the candidate reference genes according to their stability measure value in every biological replicate is displayed in table this gene expression stability measure m is the mean pairwise variation between a candidate reference gene and all other tested candidates. a higher value of m means greater variation in expression. the stepwise elimination of genes with the highest m values allows the ranking of the tested genes according to their expression stability. interestingly, in the three biological repeat experiments cdc- and pmp- turned out to be among the three best performing reference genes. moreover, in each of the three biological repeats the ranking of the least stable genes included mdh- act- and gpd- the consistent ranking of the best and worst reference genes illustrates the excellent correspondence and reproducibility between the independently grown nematode cultures. pairwise variations vn/n+ between each combination of sequential normalization factors were calculated by genorm to determine the optimal number of reference genes required for accurate normalization. based on the recommendations by vandesompele et al. we used a cut-off value of, below which the inclusion of an additional reference gene does not result in a significant improvement of normalization. following this criterion the inclusion of a third reference gene is required for assay set but not for analyzing replicate sets and. for consistency reasons we prefer to use the most stably expressed genes for all replicate assays. to demonstrate the need for accurate relative quantification using suitable reference genes, the expression of the sod genes was studied. in each of the three assays a normalization factor based on the geometric mean of cdc- pmp- and y45f10d. expression level was used to determine the relative expression level of all sod genes. the average normalised sod mrna values and the 95% confidence intervals are shown in figure the 95% confidence intervals clearly illustrate that sod- and sod- are significantly upregulated in daf- relative to n in agreement with microarray studies of mcelwee et al. and murphy et al.. in dauers, sod- is significantly downregulated relative to l sod- is significantly upregulated relative to l and sod- and sod- are significantly upregulated relative to both l and n we illustrate that normalization to a single reference gene without appropriate validation can lead to erroneous results by normalizing sod- to act- gpd- and mdh- respectively. when normalized only to act- the expression level of sod- in daf- differs by more than % and is not found to be significantly upregulated. moreover the expression level of sod- in the dauer is upregulated instead of downregulated relative to l this shows that act- is unsuitable as a reference gene. when using mdh- only a modest, but not significant, increase by 2-fold in daf- could be seen, and the expression level of sod- appears to be strongly upregulated in dauers. moreover, if gpd- or ama- had been used, no significant differential expression would have been detected in daf- mutants or dauers. discussion an ideal reference gene is expressed at the same level in all cell types and under all experimental conditions. numerous publications demonstrate that no single gene is able to fulfill these criteria. to reliably measure small expression differences, normalization using stably expressed reference genes is of crucial importance. this forced us to undertake a comprehensive analysis of different potential reference genes in different c. elegans samples, including distinct developmental stages of the wild-type and adults of ins/igf pathway mutants. we here provide validated assays for a newly developed set of multiple candidate reference genes. the genorm analysis revealed that cdc- and pmp- are among the best performing reference genes identified in each of biological replicates. they were picked up from a microarray screen of differentially regulated genes underscoring the reliability of this strategy to identify new candidate reference genes. they are far more stably expressed than conventional reference genes, at least in this study. since in all biological repeats addition of a fourth reference gene did not substantially improve the newly calculated normalization factor, there was no need to include more reference genes. therefore we recommend to use three reference genes since we generally found that this number allows reliable and accurate quantification with a minimal effort. our analysis showed that mdh- is the least stable reference gene, which is in concordance with a previously published paper of mcelwee et al. who demonstrated by microarray analysis that mdh- was downregulated in dauers. similarly, mendenhall et al. have recently shown that gpd- was upregulated in daf- worms. both studies suggest that gpd- and mdh- are downstream genes of daf- as expected, genorm ranked these genes as the two least stable reference genes in two of the three biological repeats. interestingly, the most commonly used reference gene act- is one of the least stable reference genes as indicated by the genorm analysis. we used the reference genes to reveal the expression levels of sod-genes in long-lived ins/igf mutants and dauers. our results largely confirm and extend previous studies using norhern blots, sage and microarray analysis. the increased expression of sod- in dauers and daf- mutants has been well documented,. elevated expression of sod- in dauers was reported by jones et al.. we also detected an increased expression of sod- in daf- mutants which is in accordance with the increased activity of cytosolic sod in long-lived ins/igf- pathway mutants given that sod- appears to be the most active cuznsod.  this study demonstrates the importance of appropriate validation of internal reference genes chosen for gene expression analysis using real-time qpcr. we show that candidate reference genes for accurate normalization of gene expression levels in c. elegans can be identified from publicly available microarray databases. the methodology used in the present study enables accurate analysis of differential gene expression of any set of candidate genes. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
58,d193f064-45d7-45d9-acbe-ea9aa07a1713_gpt3_gen,"Real-time quantitative PCR is a powerful tool for gene expression studies, but accurate normalization is necessary to account for varying amounts of cDNA input. Using internal controls or reference genes as a standard is essential. However, the commonly used reference genes such as act- and ama- can vary under different experimental conditions, leading to misinterpretation of the gene expression level. In c. elegans, no comprehensive analysis has been performed to validate candidate reference genes for gene expression analysis. The study aimed to identify the most stably expressed reference genes and demonstrate their usefulness in determining the expression levels of the sod genes in c. elegans. The genorm program evaluated the stability of candidate reference genes based on the mean pairwise variation of a gene with all other tested genes. Two genes, cdc- and pmp-, were identified as the best performing reference genes, and they were recommended to be used with three reference genes for reliable and accurate quantification. The analysis also revealed that the commonly used reference gene act- is one of the least stable reference genes. The study demonstrated the importance of appropriate validation of internal reference genes and recommended the use of multiple stably expressed reference genes for accurate normalization of gene expression levels."," real-time quantitative pcr has become a very powerful tool for gene expression studies. one of the main difficulties associated with this highly sensitive technique is the necessity of accurate normalization, to account for varying amounts of cdna input. this variation is inherent to the multistep process required to extract and process the rna. the use of internal controls or reference genes has become the method of choice to account for this source of variation. the choice of an appropriate internal standard is therefore critical for relative gene expression analysis in order to obtain consistent and reliable results, especially when measuring small expression differences. a suitable reference gene to which expression can be normalized should have constant expression in all samples under investigation and should be insensitive to varying experimental treatments. although the nematode c. elegans is a commonly used model organism that has proven its importance in the unraveling of many important signaling pathways, to date no comprehensive analysis has been performed to validate candidate reference genes for gene expression analysis. therefore, commonly used reference genes such as act- and ama- are often used without validating their usefulness. however, several reports indicate that the expression of commonly used reference genes can vary under different experimental conditions, possibly leading to dramatic misinterpretation of the expression level of a target gene. although there is no universally accepted approach for data normalization, the method of using multiple stably expressed reference genes is currently the golden standard. the straightforward method developed by vandesompele and colleagues to identify the most stably expressed reference genes from a set of candidate control genes can be used to normalize gene expression levels. their method also allows the determination of the optimal number of genes required for reliable normalization of qpcr generated gene expression data. they advocate use of the geometric mean of multiple stably expressed reference genes for normalization of relative quantities. this approach has been widely implemented by many researchers and has been statistically validated by szabo et al. and by the bootstrap procedure of gabrielsson et al., but surprisingly seems to be neglected in the c. elegans research field. the ins/igf- signaling pathway is a well-known life span regulator in c. elegans, drosophila and mice. a reduced activity of the pathway in c. elegans leads to nuclear localization of the transcription factor daf- causing dauer formation and extended adult life span. long-lived iis mutants are highly resistant to a wide diversity of stressors, including enhanced survival upon exposure to the superoxide generator paraquat. given the potential role of reactive oxygen species in the ageing process, it is assumed that enzymes involved in the breakdown of ros play an important role in the longevity phenotype of dauers and long-lived iis mutants. five different genes encoding superoxide dismutase have been predicted in c. elegans. sod- and sod- encode cytosolic cuznsods. sod- expresses two splice variants, one membrane bound and one secreted. sod- and sod- encode mitochondrial mnsods. it is well-established that increased life span is often associated with increased stress resistance and high antioxidant activity. for example, the long life span of dauers and iis mutants is associated with increased stress resistance and high sod activity. northern blot and microarray analysis have shown that sod- and possibly also sod- are upregulated in dauers and daf- mutants. we demonstrate the usefulness of genorm to determine the expression levels of the sod genes in c. elegans. genorm analysis evaluates the stability of candidate reference genes based on the mean pairwise variation of a gene with all other tested genes. we compared the expression level of the candidate reference genes in different c. elegans samples to validate internal controls for the analysis of sod gene expression. the presented approach can be applied to accurately normalize the expression of any c. elegans gene of interest.  we carefully selected potential reference genes from different functional classes to minimize the chance of coregulation using two different approaches. first we selected commonly used reference genes such as ama-, act-, eif- c, gpd- and tba-. in a second approach we screened publicly available c. elegans microarray expression data. in this procedure we ranked all genes according to their standard deviation in experiments and chose potential reference genes within the top ranked ones based on the following three criteria: functional description available, expression data available for at least experiments and cdna confirmed. this strategy resulted in cdc- pmp- rgs- unc- and y45f10d. as candidate reference genes. after initial screening, we found that two genes from the available expression data in kim et al. were expressed at very low levels and therefore excluded for further analysis. in an attempt to validate the remaining candidate reference genes as internal control for analysis of sod gene expression in c. elegans, we set up an experiment containing young adult wild-type, three strains carrying mutations in the ins/igf pathway, wild type dauer worms and wild-type l stage larvae. data were collected using rna from replicate c. elegans cultures. since the reverse transcription step is the source of most of the variability in quantitative pcr, cdna synthesis was performed in duplicate from each of the three different biological replicates and pooled to use as template in the pcr experiments. for every primer pair concentrations were optimized in a range between nm and nm, based on a standard curve made with dilution series of a mixture of all cdna templates. these standard curves produced efficiencies between and with standard deviations ranging from to and correlation coefficients greater than, as determined by qbase. three identical real-time qpcr experiments were performed. in each experiment, the expression levels of the candidate reference genes and sod genes were measured in duplicate in different worm samples. the candidate control genes display a wide expression range with mean cycle threshold values between and. to identify the most stable reference genes we applied the genorm program. the ranking of the candidate reference genes according to their stability measure value in every biological replicate is displayed in table this gene expression stability measure m is the mean pairwise variation between a candidate reference gene and all other tested candidates. a higher value of m means greater variation in expression. the stepwise elimination of genes with the highest m values allows the ranking of the tested genes according to their expression stability. interestingly, in the three biological repeat experiments cdc- and pmp- turned out to be among the three best performing reference genes. moreover, in each of the three biological repeats the ranking of the least stable genes included mdh- act- and gpd- the consistent ranking of the best and worst reference genes illustrates the excellent correspondence and reproducibility between the independently grown nematode cultures. pairwise variations vn/n+ between each combination of sequential normalization factors were calculated by genorm to determine the optimal number of reference genes required for accurate normalization. based on the recommendations by vandesompele et al. we used a cut-off value of, below which the inclusion of an additional reference gene does not result in a significant improvement of normalization. following this criterion the inclusion of a third reference gene is required for assay set but not for analyzing replicate sets and. for consistency reasons we prefer to use the most stably expressed genes for all replicate assays. to demonstrate the need for accurate relative quantification using suitable reference genes, the expression of the sod genes was studied. in each of the three assays a normalization factor based on the geometric mean of cdc- pmp- and y45f10d. expression level was used to determine the relative expression level of all sod genes. the average normalised sod mrna values and the 95% confidence intervals are shown in figure the 95% confidence intervals clearly illustrate that sod- and sod- are significantly upregulated in daf- relative to n in agreement with microarray studies of mcelwee et al. and murphy et al.. in dauers, sod- is significantly downregulated relative to l sod- is significantly upregulated relative to l and sod- and sod- are significantly upregulated relative to both l and n we illustrate that normalization to a single reference gene without appropriate validation can lead to erroneous results by normalizing sod- to act- gpd- and mdh- respectively. when normalized only to act- the expression level of sod- in daf- differs by more than % and is not found to be significantly upregulated. moreover the expression level of sod- in the dauer is upregulated instead of downregulated relative to l this shows that act- is unsuitable as a reference gene. when using mdh- only a modest, but not significant, increase by 2-fold in daf- could be seen, and the expression level of sod- appears to be strongly upregulated in dauers. moreover, if gpd- or ama- had been used, no significant differential expression would have been detected in daf- mutants or dauers. discussion an ideal reference gene is expressed at the same level in all cell types and under all experimental conditions. numerous publications demonstrate that no single gene is able to fulfill these criteria. to reliably measure small expression differences, normalization using stably expressed reference genes is of crucial importance. this forced us to undertake a comprehensive analysis of different potential reference genes in different c. elegans samples, including distinct developmental stages of the wild-type and adults of ins/igf pathway mutants. we here provide validated assays for a newly developed set of multiple candidate reference genes. the genorm analysis revealed that cdc- and pmp- are among the best performing reference genes identified in each of biological replicates. they were picked up from a microarray screen of differentially regulated genes underscoring the reliability of this strategy to identify new candidate reference genes. they are far more stably expressed than conventional reference genes, at least in this study. since in all biological repeats addition of a fourth reference gene did not substantially improve the newly calculated normalization factor, there was no need to include more reference genes. therefore we recommend to use three reference genes since we generally found that this number allows reliable and accurate quantification with a minimal effort. our analysis showed that mdh- is the least stable reference gene, which is in concordance with a previously published paper of mcelwee et al. who demonstrated by microarray analysis that mdh- was downregulated in dauers. similarly, mendenhall et al. have recently shown that gpd- was upregulated in daf- worms. both studies suggest that gpd- and mdh- are downstream genes of daf- as expected, genorm ranked these genes as the two least stable reference genes in two of the three biological repeats. interestingly, the most commonly used reference gene act- is one of the least stable reference genes as indicated by the genorm analysis. we used the reference genes to reveal the expression levels of sod-genes in long-lived ins/igf mutants and dauers. our results largely confirm and extend previous studies using norhern blots, sage and microarray analysis. the increased expression of sod- in dauers and daf- mutants has been well documented,. elevated expression of sod- in dauers was reported by jones et al.. we also detected an increased expression of sod- in daf- mutants which is in accordance with the increased activity of cytosolic sod in long-lived ins/igf- pathway mutants given that sod- appears to be the most active cuznsod.  this study demonstrates the importance of appropriate validation of internal reference genes chosen for gene expression analysis using real-time qpcr. we show that candidate reference genes for accurate normalization of gene expression levels in c. elegans can be identified from publicly available microarray databases. the methodology used in the present study enables accurate analysis of differential gene expression of any set of candidate genes. ",pubmed_generic,GPT 3.5,The analysis also revealed that the commonly used reference gene act- is one of the least stable reference genes.,factual,non_factual,,minor,,other,,,,It is mentioned that in this analysis  mdh- is the least stable reference gene. So for this analysis mdh- is the least stable reference gene.however previous studies also reported that act- is one of the least stable reference gene
59,22e2e9ef-c515-4f2c-89a2-8e5d8792a530_flant5_gen,a novel cloning and expression system for amps in e. coli," antimicrobial peptides are widely distributed in nature and play a critical role in the innate immunity of host defense systems. they act with broad spectrum and, hence, are promising candidates for therapeutic and industrial application. for research studies and clinical trials, large quantities of these peptides are needed. the number of described amps has increased over recent decades; however, the recent generation of huge amounts of genomic, proteomic and est data enables novel strategies for the discovery of new candidate amps. in silico methods based on bioinformatic analyses, combined with experimental screening techniques have been developed to screen and identify new amp genes from huge ""-omics"" data sets. belarmino et al. screened ests of sugarcane using a computational approach and successfully identified new defensin isoforms. following in silico prediction, however, there is a requirement for a high throughput genome-scale dna cloning and expression system to enable the antimicrobial activities of putative amps to be characterized. expression of fusion proteins that form inclusion bodies has several advantages that can overcome major barriers of amp expression in e. coli: high rates of expression, easy collection by centrifugation, protection from proteolysis and the avoidance of intrinsic amp antimicrobial activity against host cells. however, recombinant amps expressed in e. coli often include 1- non-native amino acid residuals at the n terminus of the target protein due to a specific linker sequence recognized by endoproteases or chemical agents, typically located between the native protein sequence and the tag. these non-authentic n termini of amps often alter their characteristics. it is, therefore, very important to develop a new strategy for authentic recombinant amp expression. the n-terminal autoprotease, npro, of classical swine fever virus cleaves itself between the c-terminal cys and position, which represent the authentic n-terminal amino acid of the target protein. it is also a relatively hydrophobic protein that tends to form insoluble aggregates on refolding, preventing autoproteolysis. in this approach, the target protein is fused to the c-terminus of npro and is expressed in inclusion bodies. after inclusion bodies are isolated, an in vitro refolding step is necessary to induce autoproteolysis, and render the amps biologically active. importantly, cleavage does not need to be initiated by the use of reducing agents or by temperature and ph shifts. eddie, a mutant of npro, shows improved solubility and faster refolding and cleavage than wild-type npro. in our previous work, the fusion protein eddie-cad was successfully expressed in e. coli after codon optimization and the purified recombinant mature cecropin ad was fully bioactive. the in vitro cloning of dna molecules traditionally uses pcr or site-specific restriction endonucleases to generate linear dna inserts with defined termini and requires dna ligase to covalently join these inserts to vectors with the corresponding ends. however, restriction endonuclease sites often introduce a few amino acids to the n-terminus of mature peptides, and it is very difficult to analyze recombinant clones when the insert dna fragment is very short. for high throughput subcloning of short peptide genes, we constructed the vector, pet30a/his-eddie-gfp, and used a seamless enzyme-free cloning method for high level expression of amps in e. coli, this method allows one-step assembly of dna fragments in vivo via homologous recombination in e. coli. for high level expression, codon usages of synthesized amp genes were optimized according to the host strains. for efficient analysis of short insert dna fragments, the recombinants were easily screened by gfp green/white colony selection. in this article, our approach was validated using target amps of variable length.  construction of his-eddie-gfp fusion expression plasmid the construction of the pet30a/his-eddie-gfp vector was based on pet30a/his- eddie-cad. after pcr amplification, the gfp fragment was successfully subcloned into pet30a/his-eddie-cad. colonies showing green fluorescence were picked and pcr amplification of the gfp gene followed by gel electrophoresis showed that the gfp fragment had been successfully inserted into the expression vector. dna sequencing validated that the gfp gene was inserted downstream of the eddie gene. construction of the his-eddie-amp fusion expression plasmid to clone amp genes in a high-throughput manner, we performed a green/white colony screen using the gfp in pet30a/his-eddie-gfp. after a target gene is cloned into the vector by a one-step pcr technique, the gfp gene is destroyed; therefore, green fluorescence indicates non-linearized parental vector. four amp genes, temporin g, hexapeptide, combi- and histatin were amplified and cloned downstream of eddie using a one-step pcr process, and then transformed into e. coli cells. blp- and histatin genes were assembled using four primers in one pcr reaction, respectively. pet30a/his-eddie-gfp was replicated at the same time. the two pcr products were then transformed into e. coli cells together. the transformants were screened under ultraviolet light, and the white colonies were further screened by pcr verification and sequencing. the recombinant pet30a/his-eddie-amp plasmid is smaller than the parental pet30a/his-eddie-gfp plasmid, which makes it very easy to distinguish the two plasmids by agarose gel electrophoresis. expression and purification of fusion proteins e. coli bl cells harboring pet30a/his-eddie-amp were induced by iptg, and the expression of his-eddie-amp proteins was analyzed by sds-page. fusion proteins of kda represented the majority of the insoluble components in cell lysates. the recombinant his-eddie-amps were estimated to constitute about 40% of the total protein present in cells. the yield of inclusion bodies was quite high due to the properties of the fusion partner. refolding and activity analysis purified his-eddie-amp inclusion bodies were diluted in optimized refolding buffer and incubated to enable self-cleavage to occur. to examine the antimicrobial activity of six recombinant amps, the purified supernatants were assayed using a radial diffusion assay. as shown in figure there were large halos around the six amps, indicating that all six amps had specific bactericidal activities against e. coli atcc m. luteus or s. cerevisiae. no inhibition zones were seen around the negative control spots. the recombinant amps were clearly bioactive and very effective in killing these sensitive strains. discussion we have described a new method for cloning and expressing amp genes. the desired amps are amplified using orf-specific primers with flanking sequences identical to the two ends of a linearized vector. the pcr product and the linearized vector are then cotransformed into e. coli cells, where the orf is incorporated into the vector in vivo. short amps can even directly incorporate into the linearized vector through self-ligation. unlike conventional methods that use restriction enzymes or site-specific recombinases, pcr products could be seamlessly assembled without the need for specific sequences for ligation or site-specific recombination. this system is more efficient than cloning methods requiring ligase and will be useful for standard dna cloning and for constructing genome-scale clone resources that facilitate functional analysis. most amp genes are very small and it is difficult to identify recombinant plasmids containing these genes. we, therefore, incorporated the gfp reporter gene into the expression vector to enable convenient recombinant colony picking. amps expressed as npro fusions are deposited as insoluble proteins in inclusion bodies. this greatly increases yield due to resistance to proteolytic degradation. during refolding in vitro, eddie self-cleaved at the specific site and the six target peptides were released. our construct also encodes the affinity tag, preceding the coding regions of eddie, to enable fast and straightforward purification using ni2+-chelating affinity chromatography after refolding. the target peptides could be easily purified to homogeneity. these results validated this high throughput amp subcloning method. using this method, we successfully cloned peptides into the expression vector and identified about new amps from brassica napus cdna libraries that showed antimicrobial activities. this approach, combined with bioinformatic analyses of genome and est sequence data, will be useful in screening for new amps.  in conclusion, this is a simple, reliable, automated, robust, flexible and low-cost expression cloning approach in which pcr fragments are fused into an expression vector without unwanted amino acids. this strategy advances the methodologies available for amp prokaryote expression. the main barriers to amp expression, such as, codon preference, the intrinsic antimicrobial activity of amps to host cells, and inefficient production of amps owing to proteolytic degradation, are overcome by this expression system. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
60,22e2e9ef-c515-4f2c-89a2-8e5d8792a530_gpt3_gen,"Antimicrobial peptides (AMPs) play a critical role in innate immunity and are promising candidates for therapeutic and industrial use. However, large quantities are needed for research and clinical trials, and new AMP genes must be identified. In silico methods combined with experimental screening techniques have been developed to discover new AMP genes. A new strategy for authentic recombinant AMP expression has been developed using the hydrophobic protein Npro to form inclusion bodies, with the use of a mutant, Eddie, to improve solubility and faster refolding and cleavage. A high-throughput, seamless, and enzyme-free cloning method was used for high-level expression of AMPs in E. coli. The construct also encodes the affinity tag for fast and easy purification. This system overcomes the main barriers to AMP expression and allows for the efficient cloning and expression of AMP genes for functional analysis."," antimicrobial peptides are widely distributed in nature and play a critical role in the innate immunity of host defense systems. they act with broad spectrum and, hence, are promising candidates for therapeutic and industrial application. for research studies and clinical trials, large quantities of these peptides are needed. the number of described amps has increased over recent decades; however, the recent generation of huge amounts of genomic, proteomic and est data enables novel strategies for the discovery of new candidate amps. in silico methods based on bioinformatic analyses, combined with experimental screening techniques have been developed to screen and identify new amp genes from huge ""-omics"" data sets. belarmino et al. screened ests of sugarcane using a computational approach and successfully identified new defensin isoforms. following in silico prediction, however, there is a requirement for a high throughput genome-scale dna cloning and expression system to enable the antimicrobial activities of putative amps to be characterized. expression of fusion proteins that form inclusion bodies has several advantages that can overcome major barriers of amp expression in e. coli: high rates of expression, easy collection by centrifugation, protection from proteolysis and the avoidance of intrinsic amp antimicrobial activity against host cells. however, recombinant amps expressed in e. coli often include 1- non-native amino acid residuals at the n terminus of the target protein due to a specific linker sequence recognized by endoproteases or chemical agents, typically located between the native protein sequence and the tag. these non-authentic n termini of amps often alter their characteristics. it is, therefore, very important to develop a new strategy for authentic recombinant amp expression. the n-terminal autoprotease, npro, of classical swine fever virus cleaves itself between the c-terminal cys and position, which represent the authentic n-terminal amino acid of the target protein. it is also a relatively hydrophobic protein that tends to form insoluble aggregates on refolding, preventing autoproteolysis. in this approach, the target protein is fused to the c-terminus of npro and is expressed in inclusion bodies. after inclusion bodies are isolated, an in vitro refolding step is necessary to induce autoproteolysis, and render the amps biologically active. importantly, cleavage does not need to be initiated by the use of reducing agents or by temperature and ph shifts. eddie, a mutant of npro, shows improved solubility and faster refolding and cleavage than wild-type npro. in our previous work, the fusion protein eddie-cad was successfully expressed in e. coli after codon optimization and the purified recombinant mature cecropin ad was fully bioactive. the in vitro cloning of dna molecules traditionally uses pcr or site-specific restriction endonucleases to generate linear dna inserts with defined termini and requires dna ligase to covalently join these inserts to vectors with the corresponding ends. however, restriction endonuclease sites often introduce a few amino acids to the n-terminus of mature peptides, and it is very difficult to analyze recombinant clones when the insert dna fragment is very short. for high throughput subcloning of short peptide genes, we constructed the vector, pet30a/his-eddie-gfp, and used a seamless enzyme-free cloning method for high level expression of amps in e. coli, this method allows one-step assembly of dna fragments in vivo via homologous recombination in e. coli. for high level expression, codon usages of synthesized amp genes were optimized according to the host strains. for efficient analysis of short insert dna fragments, the recombinants were easily screened by gfp green/white colony selection. in this article, our approach was validated using target amps of variable length.  construction of his-eddie-gfp fusion expression plasmid the construction of the pet30a/his-eddie-gfp vector was based on pet30a/his- eddie-cad. after pcr amplification, the gfp fragment was successfully subcloned into pet30a/his-eddie-cad. colonies showing green fluorescence were picked and pcr amplification of the gfp gene followed by gel electrophoresis showed that the gfp fragment had been successfully inserted into the expression vector. dna sequencing validated that the gfp gene was inserted downstream of the eddie gene. construction of the his-eddie-amp fusion expression plasmid to clone amp genes in a high-throughput manner, we performed a green/white colony screen using the gfp in pet30a/his-eddie-gfp. after a target gene is cloned into the vector by a one-step pcr technique, the gfp gene is destroyed; therefore, green fluorescence indicates non-linearized parental vector. four amp genes, temporin g, hexapeptide, combi- and histatin were amplified and cloned downstream of eddie using a one-step pcr process, and then transformed into e. coli cells. blp- and histatin genes were assembled using four primers in one pcr reaction, respectively. pet30a/his-eddie-gfp was replicated at the same time. the two pcr products were then transformed into e. coli cells together. the transformants were screened under ultraviolet light, and the white colonies were further screened by pcr verification and sequencing. the recombinant pet30a/his-eddie-amp plasmid is smaller than the parental pet30a/his-eddie-gfp plasmid, which makes it very easy to distinguish the two plasmids by agarose gel electrophoresis. expression and purification of fusion proteins e. coli bl cells harboring pet30a/his-eddie-amp were induced by iptg, and the expression of his-eddie-amp proteins was analyzed by sds-page. fusion proteins of kda represented the majority of the insoluble components in cell lysates. the recombinant his-eddie-amps were estimated to constitute about 40% of the total protein present in cells. the yield of inclusion bodies was quite high due to the properties of the fusion partner. refolding and activity analysis purified his-eddie-amp inclusion bodies were diluted in optimized refolding buffer and incubated to enable self-cleavage to occur. to examine the antimicrobial activity of six recombinant amps, the purified supernatants were assayed using a radial diffusion assay. as shown in figure there were large halos around the six amps, indicating that all six amps had specific bactericidal activities against e. coli atcc m. luteus or s. cerevisiae. no inhibition zones were seen around the negative control spots. the recombinant amps were clearly bioactive and very effective in killing these sensitive strains. discussion we have described a new method for cloning and expressing amp genes. the desired amps are amplified using orf-specific primers with flanking sequences identical to the two ends of a linearized vector. the pcr product and the linearized vector are then cotransformed into e. coli cells, where the orf is incorporated into the vector in vivo. short amps can even directly incorporate into the linearized vector through self-ligation. unlike conventional methods that use restriction enzymes or site-specific recombinases, pcr products could be seamlessly assembled without the need for specific sequences for ligation or site-specific recombination. this system is more efficient than cloning methods requiring ligase and will be useful for standard dna cloning and for constructing genome-scale clone resources that facilitate functional analysis. most amp genes are very small and it is difficult to identify recombinant plasmids containing these genes. we, therefore, incorporated the gfp reporter gene into the expression vector to enable convenient recombinant colony picking. amps expressed as npro fusions are deposited as insoluble proteins in inclusion bodies. this greatly increases yield due to resistance to proteolytic degradation. during refolding in vitro, eddie self-cleaved at the specific site and the six target peptides were released. our construct also encodes the affinity tag, preceding the coding regions of eddie, to enable fast and straightforward purification using ni2+-chelating affinity chromatography after refolding. the target peptides could be easily purified to homogeneity. these results validated this high throughput amp subcloning method. using this method, we successfully cloned peptides into the expression vector and identified about new amps from brassica napus cdna libraries that showed antimicrobial activities. this approach, combined with bioinformatic analyses of genome and est sequence data, will be useful in screening for new amps.  in conclusion, this is a simple, reliable, automated, robust, flexible and low-cost expression cloning approach in which pcr fragments are fused into an expression vector without unwanted amino acids. this strategy advances the methodologies available for amp prokaryote expression. the main barriers to amp expression, such as, codon preference, the intrinsic antimicrobial activity of amps to host cells, and inefficient production of amps owing to proteolytic degradation, are overcome by this expression system. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
61,11be0cac-94b6-4501-bdcc-1aad88a53f5b_flant5_gen,phylogenetic foot printing of the 5' upstream region of stk11/lkb identifies regulatory elements and identifies a series of pjs cases in which exonic and splice site mutations have been excluded.," peutz-jeghers syndrome is a rare autosomal dominant disorder typified by hamartomatous polyposis of the gastrointestinal tract and melanin pigmentation of the oro-facial region. although germline mutations in the coding sequence of the serine-threonine kinase gene stk11/lkb have been found to cause pjs, such mutations only account for up to 80% of cases. in addition to locus heterogeneity mutations in regulatory sequences of stk11/lkb may cause pjs. identifying regulatory genomic sequences through functional assays is time consuming and problematic. as natural selection is more likely to tolerate sequence changes in redundant, non-functional sequence than in functionally important sequences, regulatory elements in non-coding sequence will be highly conserved through evolution. comparison of sequence between both closely related and highly divergent species therefore allows for the identification of non-coding sequence that has a high probability of being important to the regulation of gene transcription. this alternative approach to the identification of promoter elements is termed ""phylogenetic foot printing"". here we describe the phylogenetic foot printing of the 5' upstream region of stk11/lkb and the sequence analysis of this region in a series of pjs cases in whom exonic and splice site mutations in the gene had been excluded.  additional analysis using the tfbs prediction programs transplorer and proscan v identified binding sites between nucleotides - and - and binding sites between nucleotides - and - respectively, confirming the presence of regulatory elements within the consensus region. ecr browser/ rvista and consite have previously been shown to correctly identify 88% and 66% of tfbs in functionally verified promoter elements respectively and it is highly likely, therefore, that the consensus region encompassing nucleotides - to - contains stk11/lkb promoter elements. dna from a series of pjs patients that did not harbour germline stk11/lkb mutations was studied for mutations in the region between nucleotides - to - encompassing all tfbss predicted by rvista and consite. seven of the cases had a documented family history of pjs. the diagnosis of pjs in all cases was based on established criteria. three sequence changes were identified. the change g → c at position - was found in four cases and represented a previously documented single nucleotide polymorphism. an additional single nucleotide change at position - was identified in eight cases. a single sample of control dna used as a sequence reference was also found to be homozygous for the change. finally, a two base pair deletion coupled with a single base pair insertion at position - was identified in one case. a series of healthy population controls was screened by high performance liquid chromatography and one individual was found to harbour the sequence change. none of these three sequence changes identified were therefore deemed to be potentially pathogenic. there is a high degree of redundancy in promoter elements of genes, however point mutations in promoter regions of pten and mlh have been reported to be disease causing. to investigate the possibility of large-scale deletions or insertions undetectable by straightforward pcr primers p1fwd and p3rev were used to amplify an bp fragment with products visualised on a 2% agarose gel. no large-scale deletions or insertions were detected in any of the patients.  as understanding of the contribution of coding sequence changes to disease becomes clearer, attention will focus on regulatory elements of genes. phylogenetic foot printing using programs such as ecr browser and consite present potentially powerful tools in identifying regulatory elements, enabling the analysis of these sequences without time consuming functional studies. although the efficiency of in-silico delineation of promoter elements has not been rigorously evaluated, ecr browser/ rvista and consite have been shown to correctly identify 88% and 66% of tfbs respectively. on the basis of our findings, however, it appears unlikely that mutations in the promoter region of stk11/lkb are responsible for pjs cases not attributable to exonic sequence changes. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
62,11be0cac-94b6-4501-bdcc-1aad88a53f5b_gpt3_gen,"Phylogenetic foot printing was used to identify regulatory elements in the non-coding sequence of the stk11/lkb gene in patients with Peutz-Jeghers syndrome (PJS) that did not have known exonic mutations. Binding sites within a consensus region were confirmed, but no potentially pathogenic sequence changes were identified in this region. Large-scale deletions or insertions were also not detected. The study suggests that mutations in the promoter region of stk11/lkb are unlikely to be responsible for PJS cases not related to exonic sequence changes. Phylogenetic foot printing presents a potentially powerful tool in identifying regulatory elements without time-consuming functional studies."," peutz-jeghers syndrome is a rare autosomal dominant disorder typified by hamartomatous polyposis of the gastrointestinal tract and melanin pigmentation of the oro-facial region. although germline mutations in the coding sequence of the serine-threonine kinase gene stk11/lkb have been found to cause pjs, such mutations only account for up to 80% of cases. in addition to locus heterogeneity mutations in regulatory sequences of stk11/lkb may cause pjs. identifying regulatory genomic sequences through functional assays is time consuming and problematic. as natural selection is more likely to tolerate sequence changes in redundant, non-functional sequence than in functionally important sequences, regulatory elements in non-coding sequence will be highly conserved through evolution. comparison of sequence between both closely related and highly divergent species therefore allows for the identification of non-coding sequence that has a high probability of being important to the regulation of gene transcription. this alternative approach to the identification of promoter elements is termed ""phylogenetic foot printing"". here we describe the phylogenetic foot printing of the 5' upstream region of stk11/lkb and the sequence analysis of this region in a series of pjs cases in whom exonic and splice site mutations in the gene had been excluded.  additional analysis using the tfbs prediction programs transplorer and proscan v identified binding sites between nucleotides - and - and binding sites between nucleotides - and - respectively, confirming the presence of regulatory elements within the consensus region. ecr browser/ rvista and consite have previously been shown to correctly identify 88% and 66% of tfbs in functionally verified promoter elements respectively and it is highly likely, therefore, that the consensus region encompassing nucleotides - to - contains stk11/lkb promoter elements. dna from a series of pjs patients that did not harbour germline stk11/lkb mutations was studied for mutations in the region between nucleotides - to - encompassing all tfbss predicted by rvista and consite. seven of the cases had a documented family history of pjs. the diagnosis of pjs in all cases was based on established criteria. three sequence changes were identified. the change g → c at position - was found in four cases and represented a previously documented single nucleotide polymorphism. an additional single nucleotide change at position - was identified in eight cases. a single sample of control dna used as a sequence reference was also found to be homozygous for the change. finally, a two base pair deletion coupled with a single base pair insertion at position - was identified in one case. a series of healthy population controls was screened by high performance liquid chromatography and one individual was found to harbour the sequence change. none of these three sequence changes identified were therefore deemed to be potentially pathogenic. there is a high degree of redundancy in promoter elements of genes, however point mutations in promoter regions of pten and mlh have been reported to be disease causing. to investigate the possibility of large-scale deletions or insertions undetectable by straightforward pcr primers p1fwd and p3rev were used to amplify an bp fragment with products visualised on a 2% agarose gel. no large-scale deletions or insertions were detected in any of the patients.  as understanding of the contribution of coding sequence changes to disease becomes clearer, attention will focus on regulatory elements of genes. phylogenetic foot printing using programs such as ecr browser and consite present potentially powerful tools in identifying regulatory elements, enabling the analysis of these sequences without time consuming functional studies. although the efficiency of in-silico delineation of promoter elements has not been rigorously evaluated, ecr browser/ rvista and consite have been shown to correctly identify 88% and 66% of tfbs respectively. on the basis of our findings, however, it appears unlikely that mutations in the promoter region of stk11/lkb are responsible for pjs cases not attributable to exonic sequence changes. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
63,ab30d3f8-09fe-4d9a-aaad-b7227cfeab74_flant5_gen,a java based linkage disequilibrium plotter," a great deal of effort and expense are being expended internationally in attempts to detect genetic polymorphisms contributing to susceptibility to complex human disease. concomitantly, the technology for detecting and scoring single nucleotide polymorphisms has undergone rapid development, yielding extensive catalogues of snps across the genome. population-based maps of the correlations amongst snps are now being developed with the aim to accelerate the progress of complex human gene discovery. a growing problem in complex disease genetics is the sheer volume of snp data being generated in gene discovery projects. with such large volumes of data available, it is essential to have the ability to examine results in a graphical form rather than text. linkage disequilibrium is a statistical measure of the non-independence of alleles at adjacent loci. two markers having alleles that are correlated with each other in a population are said to be in ld. such loci are generally in close physical proximity, but the relationship can vary dramatically. when a new variant is first introduced into a population it will be perfectly correlated with nearby variants. over successive generations the process of meiotic recombination will break down the correlations among nearby variants, and thus ld decays. markers that are in'perfect' ld with each other are entirely redundant in the sense that an individual's genotype at one locus will completely predict that at the other locus. conversely, markers that show no ld are statistically independent and convey no information about each other, even if they are in extremely close physical proximity. the indirect association mapping model that is the current paradigm for gene discovery in complex human disease relies on ld in the sense that the functional variant need not be studied at all, so long as one measures a variant that is in ld with it. we have developed a visualisation tool, referred to as java linkage disequilibrium plotter, to aid researchers in performing ld analysis. implementation jlin is written in java to enable cross-platform support, and is downloadable with a java installer. jlin has been tested on datasets ranging in size from several markers to in excess of markers. jlin is only limited by machine speed and memory size and has been tested on several hundred markers. while jlin has been tested on datasets containing nearly one thousand markers, we note that it is highly unlikely that a researcher will be looking for pairwise ld across thousands of markers as this implies a larger region than ld would normally extend across in an outbred population. coping with missing genotype data is an important and common problem when dealing with genetic datasets. jlin handles missing data by examining which snp genotypes for each individual contain missing data. rather than ignoring individuals with missing data, jlin only ignores a particular individual's data for pairwise ld comparisons where one or both of the snps contain missing data. this way, for all pairwise snp comparisons with no missing data, the data for each particular individual is fully utilised.  jlin is a customisable, intuitive ld visualisation tool. as no single ld measure appears to be the best for all circumstances, jlin allows the user to visually compare and contrast the results of a range of ld statistical measures. the ld statistics calculated are d, d', r or, pexcess, d and q, as described by devlin and risch, along with hardy weinberg equilibrium calculations for each snp marker. in addition, jlin has the ability to calculate empirical p-values for the pairwise association of two snps, as described by slatkin and excoffier, another unique feature amongst ld visualisation tools. we have developed a simple, intuitive interface that enables the user to customise the results presented. jlin allows the user to visualise one or two ld statistics in a single display along with the ability to export the display into three common publishing formats, namely portable document format, encapsulated postscript and portable network graphics. jlin accepts genotype data in a simple comma-separated value input file and imputes haplotypes using an expectation-maximisation algorithm. a visual representation of physical distance between markers is also available. in addition jlin has the ability to calculate empirical p-values, a unique feature among freely available and commercial ld analysis tools. the user has the flexibility to select different colour schemes, along with the ability to change the minimum, maximum and increment values independently for each of the statistics shown. future extensions to jlin will include calculating multi-locus haplotypes, imputation of missing genotype data and handling multi-allelic markers. a number of freely available and commercially released ld visualisation tools are available. gold has a rather distinct display format that is perhaps its strength and major weakness, in addition to being primarily windows based. lda and haploview are written in java, to enable cross-platform support, and implement a number of ld measures, but lda allows little flexibility or user control over the interface and presentation of results. gold and haploview do provide several features which are beyond the scope of jlin currently, such as the ability to utilise family data for haplotypes estimation and the estimation of haplotype tagging snps. helixtree is similarly designed in java, and while it has numerous features, is both commercial software and only freely available as a trial version. jlin introduces a number of unique features in terms of statistical calculation and presentation, and adds flexibility and customisation for the user that does not appear in existing ld visualisation tools.  jlin is a novel and intuitive visualisation tools designed to give the user capability and flexibility for ld analysis. jlin implements a wide range of statistical measures and analysis methods, coupled with export options and a range of features that forms a unique integrated analysis package. availability and requirements project name: jlin: a java based linkage disequilibrium plotter project home page: operating system: platform independent programming language: java other requirements: java. or higher license: free for non-commercial use any restrictions to use by non-academics: please contact authors authors' contributions kwc designed and developed the java implementation of the underlying algorithms and gui. pam designed the statistical analysis framework and aided with design of the gui. ljp conceived of the software and participated in the design and coordination of its development.",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
64,ab30d3f8-09fe-4d9a-aaad-b7227cfeab74_gpt3_gen,"The article discusses the growing use of genetic polymorphisms in detecting susceptibility to complex human diseases and the development of technology to detect single nucleotide polymorphisms (SNPs). However, the sheer volume of SNP data generated in gene discovery projects has become a problem, and visual representation is necessary. Linkage disequilibrium (LD) is a statistical measure of non-independence of alleles at adjacent loci, and JLIN is a Java-based LD visualisation tool developed to aid researchers in performing LD analysis. It handles missing data and provides customisable, intuitive visualisation of LD statistics, with the ability to export the display into three publishing formats. JLIN is a novel, flexible, and integrated analysis package that adds unique features to existing LD visualisation tools."," a great deal of effort and expense are being expended internationally in attempts to detect genetic polymorphisms contributing to susceptibility to complex human disease. concomitantly, the technology for detecting and scoring single nucleotide polymorphisms has undergone rapid development, yielding extensive catalogues of snps across the genome. population-based maps of the correlations amongst snps are now being developed with the aim to accelerate the progress of complex human gene discovery. a growing problem in complex disease genetics is the sheer volume of snp data being generated in gene discovery projects. with such large volumes of data available, it is essential to have the ability to examine results in a graphical form rather than text. linkage disequilibrium is a statistical measure of the non-independence of alleles at adjacent loci. two markers having alleles that are correlated with each other in a population are said to be in ld. such loci are generally in close physical proximity, but the relationship can vary dramatically. when a new variant is first introduced into a population it will be perfectly correlated with nearby variants. over successive generations the process of meiotic recombination will break down the correlations among nearby variants, and thus ld decays. markers that are in'perfect' ld with each other are entirely redundant in the sense that an individual's genotype at one locus will completely predict that at the other locus. conversely, markers that show no ld are statistically independent and convey no information about each other, even if they are in extremely close physical proximity. the indirect association mapping model that is the current paradigm for gene discovery in complex human disease relies on ld in the sense that the functional variant need not be studied at all, so long as one measures a variant that is in ld with it. we have developed a visualisation tool, referred to as java linkage disequilibrium plotter, to aid researchers in performing ld analysis. implementation jlin is written in java to enable cross-platform support, and is downloadable with a java installer. jlin has been tested on datasets ranging in size from several markers to in excess of markers. jlin is only limited by machine speed and memory size and has been tested on several hundred markers. while jlin has been tested on datasets containing nearly one thousand markers, we note that it is highly unlikely that a researcher will be looking for pairwise ld across thousands of markers as this implies a larger region than ld would normally extend across in an outbred population. coping with missing genotype data is an important and common problem when dealing with genetic datasets. jlin handles missing data by examining which snp genotypes for each individual contain missing data. rather than ignoring individuals with missing data, jlin only ignores a particular individual's data for pairwise ld comparisons where one or both of the snps contain missing data. this way, for all pairwise snp comparisons with no missing data, the data for each particular individual is fully utilised.  jlin is a customisable, intuitive ld visualisation tool. as no single ld measure appears to be the best for all circumstances, jlin allows the user to visually compare and contrast the results of a range of ld statistical measures. the ld statistics calculated are d, d', r or, pexcess, d and q, as described by devlin and risch, along with hardy weinberg equilibrium calculations for each snp marker. in addition, jlin has the ability to calculate empirical p-values for the pairwise association of two snps, as described by slatkin and excoffier, another unique feature amongst ld visualisation tools. we have developed a simple, intuitive interface that enables the user to customise the results presented. jlin allows the user to visualise one or two ld statistics in a single display along with the ability to export the display into three common publishing formats, namely portable document format, encapsulated postscript and portable network graphics. jlin accepts genotype data in a simple comma-separated value input file and imputes haplotypes using an expectation-maximisation algorithm. a visual representation of physical distance between markers is also available. in addition jlin has the ability to calculate empirical p-values, a unique feature among freely available and commercial ld analysis tools. the user has the flexibility to select different colour schemes, along with the ability to change the minimum, maximum and increment values independently for each of the statistics shown. future extensions to jlin will include calculating multi-locus haplotypes, imputation of missing genotype data and handling multi-allelic markers. a number of freely available and commercially released ld visualisation tools are available. gold has a rather distinct display format that is perhaps its strength and major weakness, in addition to being primarily windows based. lda and haploview are written in java, to enable cross-platform support, and implement a number of ld measures, but lda allows little flexibility or user control over the interface and presentation of results. gold and haploview do provide several features which are beyond the scope of jlin currently, such as the ability to utilise family data for haplotypes estimation and the estimation of haplotype tagging snps. helixtree is similarly designed in java, and while it has numerous features, is both commercial software and only freely available as a trial version. jlin introduces a number of unique features in terms of statistical calculation and presentation, and adds flexibility and customisation for the user that does not appear in existing ld visualisation tools.  jlin is a novel and intuitive visualisation tools designed to give the user capability and flexibility for ld analysis. jlin implements a wide range of statistical measures and analysis methods, coupled with export options and a range of features that forms a unique integrated analysis package. availability and requirements project name: jlin: a java based linkage disequilibrium plotter project home page: operating system: platform independent programming language: java other requirements: java. or higher license: free for non-commercial use any restrictions to use by non-academics: please contact authors authors' contributions kwc designed and developed the java implementation of the underlying algorithms and gui. pam designed the statistical analysis framework and aided with design of the gui. ljp conceived of the software and participated in the design and coordination of its development.",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
65,fa00508d-4402-4590-b1e2-f52eefd623a6_gpt3_gen,"The article discusses the need for programs to create and improve multiple sequence alignments that are the basis of many analyses in fields such as phylogenetics and protein domain analysis. While several programs are available, there is a lack of editors that can align both sequence and structural information simultaneously. 4SALE is a new alignment editor that allows synchronous editing of sequences and their corresponding secondary structures, using standard protein alignment algorithms to align nucleotides and secondary structures for building and improving RNA sequence alignments. The editor also integrates several useful features, such as selecting multiple sections of an alignment, pattern matching, and alignment column conservation visualization. The program is freely available and requires a Java virtual machine and an internet connection for webservice-based alignments."," since multiple sequence alignments are the basis of many analyses, for example in phylogenetics or in analysing functional protein domains, there is a need for programs to create and improve those alignments. currently, several programs are available to fulfil these necessities, e.g., clustal w, muscle, dialign, t-coffee or dca all of which are able to align multiple sequences globally. the underlying methods have their strengths and weaknesses, and resulting alignments can diverge from the biologically correct ones. editors like jalview, seaview, cinema or align are needed to enhance the results by hand. the just mentioned tools are based on sequence information only, but in rna sequence analyses there is often also structural information available. databases like the its database provide a growing number of sequences and their known secondary structures, as a prerequisite for constructing rna alignments for inferring phylogenies, which of course is a precondition to understand the evolution of such rna secondary structures. all available methods that include structural information to build rna sequence alignments have a very high complexity. rfam provides a method to compare a single nucleotide query sequence to handcurated alignments of non-coding rna families with annotated consensus secondary structures. marna and rnaforester can be used to build global multiple alignments based on sequence and simultaneously on secondary structure information. however, the amount of sequences and/or sequence lengths is limited due to the complexity of their underlying algorithms, which is at least o. in current alignment editors like ralee, dcse or jphydit secondary structure information support is very limited. while ralee relys on the consensus structure only, jphydit just shows the pairing information of the selected sequence. another rna alignment editor called sarse has become available recently and focuses on detection and editing of structural groups in rna families. so there is no editor available to align both, sequence and secondary structure information of every single rna sequence simultaneously. implementation 4sale is entirely written in java, which enables to execute the software on any platform with a java virtual machine available. the application consists of two parts, the alignment algorithm, which is based on standard protein alignment algorithms, and the graphical editor frontend. for sequence and secondary structure alignments running on the local machine 4sale takes use of clustal w, so the binary is required to be installed. integration of different multiple alignment tools is realised by using soap based webservices. here, we take use of rnaforester, clustal w, dca or dialign. the dialign and dca webservices currently support sequence alignments without secondary structure information only. the webservice technology enables the user to run the tasks on remote machines. therefore, it is possible to use 4sale without restriction of any kind during the calculation of the alignment. all webservices require an internet connection.  supported data for rna sequence and secondary structure alignment and editing, 4sale reads vienna style dotbracket formatted files. the its database represents a good source for these kind of data. in addition we provide direct access to the its database from within 4sale through the its soap interface. while rna sequence information only is supported via the standard fasta format, alignment data can be loaded using the clustal importer. furthermore 4sale handles xml based rna formats namely rnastructml and rnastructalignmentml. standard features in addition to the secondary structure based functionality, 4sale integrates many useful features, that are known from other alignment editors/programs. this includes selecting multiple sections of an alignment to highlight interesting regions and temporarily hide sequences to focus on a subset of the alignment. sequence-motifs, including those, which are based on sequence and secondary structure information, can easily be highlighted by pattern matching. alignment column conservation based on sequence information is visualized by either sequence logos or simply by bars on top of each column. further importing, exporting and deleting sequences is possible by using the sequence names' context menu. additionally sequences can be reordered with the help of the ""rearrange sequences"" window. algorithm beside the integration of rnaforester we developed an algorithm that uses the secondary structure information of every single sequence to align multiple rna sequences. this algorihm inherits the complexity of those based on sequence information only. we achieve this by mapping the sequence and secondary structure information of every single rna sequence to artificial protein sequences. the algorithm can be described as string alignment on a letter alphabet comprised of the nucleotides in three structural states. horizontal dependencies given by the sequence bindings are not modeled by this approach. to align the string we use common alignment programs, like clustal w with a suitable scoring matrix. there are several substitution models for this kind of scoring matrices discussed, we used a model as described by. the model is based on subsitutions that were extracted from its sequence and secondary structure alignments. those sequences and their associated secondary structures were obtained from the its database. synchronous editing one of the main features of 4sale is synchronizing the sequence and secondary structure alignment, that is, every operation on the sequence alignment is also performed on the secondary structure alignment and vice versa. alignment editing in general works like in most alignment editors by using the space key to insert and the backspace key to remove gaps. block editing as an effect of not using horizontal dependencies in our greedy sequence and secondary structure alignment algorithm, there are often misaligned ""blocks"" in the result of clustal w. as shown in fig. 2e the alignment could be improved very fast, by using the block editing feature in 4sale. cursors to make editing as convenient as possible, we provide different edit cursors. beside the standard cursor, that behaves as you expect from text editors for example, we have an exclusive cursor, which performs the edit operation on every sequence but the selected ones. the leftside cursor allows edit operations only at the beginning of the sequence. as mentioned above all cursors perform synchronously on sequences and their secondary structures. working with secondary structures as current predictions of secondary structure information is not highly reliable, performing changes to correct the secondary structures is often needed. adding secondary structure information 4sale supports two methods to add secondary structure information to rna sequences. first, by using the remote folding feature to call the rnafold webservice provided by the university of bielefeld, or manually adding secondary structures by using the secondary structure editing feature. secondary structure editing the secondary structure editing mode available in 4sale allows easy modification of the secondary structure information. it is context sensitive, which means it uses sequence and secondary structure information to validate whether a binding in this context is possible or not. furthermore, it supports column based editing by holding the control key. this enables insertion and deletion of equivalent bindings in all sequences. in this case bindings are only added to sequences allowing this binding. secondary structure inspector a secondary structure inspector allows to view and select specific helical regions in secondary structures of loaded sequences. the inspector consists of two parts; the upper part shows a consensus of all secondary structures, the lower part shows all secondary structures separately. the secondary structure consensus is calculated not only on column conservation, but also with respect of horizontal dependencies, so the result is a valid secondary structure. the conservation threshold can be modified using the slider above. selecting an element in the inspector highlights the corresponding part in the alignment view. as shown in fig. the inspector simplifies visualizing misaligned sequences. ""masking"" the sequence alignment based on the current consensus structure is also possible. the result is shown in a new window, which contains the alignment based on sequence information only. the alignment can be processed like any other sequence alignment loaded in 4sale. this is particularly useful for calculating phylogenetic trees based on the collective helical regions in the sequence alignment. analyzing compensatory base changes compensatory base changes occur when both nucleotides of a paired site mutate while the pairing itself stays stable. cbc analysis is important in detecting species that are discriminated by their sexual incompatibility. we provide an easy-to-use cbc analysis mechanism with the ability to calculate cbc matrices on the current sequence and secondary structure based alignment. the numbers in the cbc matrix are the counts of compensatory base changes in a pairwise sequence structure alignment, which are naturally given in the considered multiple sequence structure alignment. a cbc-window in 4sale allows to select cbc counts between two sequences and highlights directly all cbcs within the alignment, giving an overview of all cbcs in the aligned sequences. output & connection to other tools for further analyses we provide several output formats. calculated cbc matrices can be saved as comma/tab seperated values to be used in cbcanalyzer. cbctree can be used to calculate phylogenetic trees based on a cbc count matrix. at present, no program is available to handle alignment outputs that include sequences and their individual secondary structures. however, for viewing purposes and publication we support a marna-like output. sequence alignments optimized by structural information could, of course, be saved separately. for phylogenetic analyses here we support the phylip formats. other tools that rely on multiple alignments are supported by fasta. discussion 4sale is the first alignment editor which allows synchronous editing of sequences and their corresponding secondary structures. since it is targeted on rna sequence alignment and editing it contains many features using the secondary structure information, e.g., the secondary structure inspector. all current standard alignment editors can handle secondary structures as character sequence only. by using standard greedy protein alignment algorithms we inherit their time efficiency. in contrast to, e.g., marna or rnaforester, the time complexity of calculation grows not rapidly with large files. we present a completely new approach using nucleotides and every single secondary structure for building and improving rna sequence alignments in comparison to others, which just take the consensus structure information. the structure output converted to vienna style dotbracket can be created from any desired rna folding program, e.g., rnafold, mfold or rnastructure. it is then aligned by using a suitable substitution matrix, which in our case is based on information of the its database. due to the natural limitation that two structures can be hidden in one sequence, in general only one will be considered by our approach. a future version of 4sale will integrate in addition to rnaforester more real structural alignment methods as webservices via the soap interface. also secondary structure prediction algorithms as an alternative to rnafold will be included. furthermore, more visualizations like secondary structure drawings can be implemented.  4sale is easy to use and has a fast ) and good heuristic to globally align multiple rna sequences and their associated secondary structures simultaneously. availability and requirements 4sale is freely available at. a java virtual machine is needed to run the application. furthermore, for automatic sequence and structure based alignments a local installation of clustal w and/or internet connection for webservice based alignments is required. list of abbreviations used cbc: compensatory base change its2: internal transcribed spacer 2 authors' contributions mw conceived the study. tm and mw provided the alignment algorithm. tm estimated the sequence and secondary structure substitution model and its associated score matrix. architecture, implementation and graphical design by ps. mw, ps and tm drafted the manuscript. mw, tm, js and td participated in study design and coordination. all authors read and approved the final version of the manuscript. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
66,fa00508d-4402-4590-b1e2-f52eefd623a6_flant5_gen,4sale is a graphical editor for rna sequence alignment and secondary structure alignment. it is based on a standard protein alignment algorithm and uses the secondary structure information of every single sequence to align multiple rna sequences simultaneously.," since multiple sequence alignments are the basis of many analyses, for example in phylogenetics or in analysing functional protein domains, there is a need for programs to create and improve those alignments. currently, several programs are available to fulfil these necessities, e.g., clustal w, muscle, dialign, t-coffee or dca all of which are able to align multiple sequences globally. the underlying methods have their strengths and weaknesses, and resulting alignments can diverge from the biologically correct ones. editors like jalview, seaview, cinema or align are needed to enhance the results by hand. the just mentioned tools are based on sequence information only, but in rna sequence analyses there is often also structural information available. databases like the its database provide a growing number of sequences and their known secondary structures, as a prerequisite for constructing rna alignments for inferring phylogenies, which of course is a precondition to understand the evolution of such rna secondary structures. all available methods that include structural information to build rna sequence alignments have a very high complexity. rfam provides a method to compare a single nucleotide query sequence to handcurated alignments of non-coding rna families with annotated consensus secondary structures. marna and rnaforester can be used to build global multiple alignments based on sequence and simultaneously on secondary structure information. however, the amount of sequences and/or sequence lengths is limited due to the complexity of their underlying algorithms, which is at least o. in current alignment editors like ralee, dcse or jphydit secondary structure information support is very limited. while ralee relys on the consensus structure only, jphydit just shows the pairing information of the selected sequence. another rna alignment editor called sarse has become available recently and focuses on detection and editing of structural groups in rna families. so there is no editor available to align both, sequence and secondary structure information of every single rna sequence simultaneously. implementation 4sale is entirely written in java, which enables to execute the software on any platform with a java virtual machine available. the application consists of two parts, the alignment algorithm, which is based on standard protein alignment algorithms, and the graphical editor frontend. for sequence and secondary structure alignments running on the local machine 4sale takes use of clustal w, so the binary is required to be installed. integration of different multiple alignment tools is realised by using soap based webservices. here, we take use of rnaforester, clustal w, dca or dialign. the dialign and dca webservices currently support sequence alignments without secondary structure information only. the webservice technology enables the user to run the tasks on remote machines. therefore, it is possible to use 4sale without restriction of any kind during the calculation of the alignment. all webservices require an internet connection.  supported data for rna sequence and secondary structure alignment and editing, 4sale reads vienna style dotbracket formatted files. the its database represents a good source for these kind of data. in addition we provide direct access to the its database from within 4sale through the its soap interface. while rna sequence information only is supported via the standard fasta format, alignment data can be loaded using the clustal importer. furthermore 4sale handles xml based rna formats namely rnastructml and rnastructalignmentml. standard features in addition to the secondary structure based functionality, 4sale integrates many useful features, that are known from other alignment editors/programs. this includes selecting multiple sections of an alignment to highlight interesting regions and temporarily hide sequences to focus on a subset of the alignment. sequence-motifs, including those, which are based on sequence and secondary structure information, can easily be highlighted by pattern matching. alignment column conservation based on sequence information is visualized by either sequence logos or simply by bars on top of each column. further importing, exporting and deleting sequences is possible by using the sequence names' context menu. additionally sequences can be reordered with the help of the ""rearrange sequences"" window. algorithm beside the integration of rnaforester we developed an algorithm that uses the secondary structure information of every single sequence to align multiple rna sequences. this algorihm inherits the complexity of those based on sequence information only. we achieve this by mapping the sequence and secondary structure information of every single rna sequence to artificial protein sequences. the algorithm can be described as string alignment on a letter alphabet comprised of the nucleotides in three structural states. horizontal dependencies given by the sequence bindings are not modeled by this approach. to align the string we use common alignment programs, like clustal w with a suitable scoring matrix. there are several substitution models for this kind of scoring matrices discussed, we used a model as described by. the model is based on subsitutions that were extracted from its sequence and secondary structure alignments. those sequences and their associated secondary structures were obtained from the its database. synchronous editing one of the main features of 4sale is synchronizing the sequence and secondary structure alignment, that is, every operation on the sequence alignment is also performed on the secondary structure alignment and vice versa. alignment editing in general works like in most alignment editors by using the space key to insert and the backspace key to remove gaps. block editing as an effect of not using horizontal dependencies in our greedy sequence and secondary structure alignment algorithm, there are often misaligned ""blocks"" in the result of clustal w. as shown in fig. 2e the alignment could be improved very fast, by using the block editing feature in 4sale. cursors to make editing as convenient as possible, we provide different edit cursors. beside the standard cursor, that behaves as you expect from text editors for example, we have an exclusive cursor, which performs the edit operation on every sequence but the selected ones. the leftside cursor allows edit operations only at the beginning of the sequence. as mentioned above all cursors perform synchronously on sequences and their secondary structures. working with secondary structures as current predictions of secondary structure information is not highly reliable, performing changes to correct the secondary structures is often needed. adding secondary structure information 4sale supports two methods to add secondary structure information to rna sequences. first, by using the remote folding feature to call the rnafold webservice provided by the university of bielefeld, or manually adding secondary structures by using the secondary structure editing feature. secondary structure editing the secondary structure editing mode available in 4sale allows easy modification of the secondary structure information. it is context sensitive, which means it uses sequence and secondary structure information to validate whether a binding in this context is possible or not. furthermore, it supports column based editing by holding the control key. this enables insertion and deletion of equivalent bindings in all sequences. in this case bindings are only added to sequences allowing this binding. secondary structure inspector a secondary structure inspector allows to view and select specific helical regions in secondary structures of loaded sequences. the inspector consists of two parts; the upper part shows a consensus of all secondary structures, the lower part shows all secondary structures separately. the secondary structure consensus is calculated not only on column conservation, but also with respect of horizontal dependencies, so the result is a valid secondary structure. the conservation threshold can be modified using the slider above. selecting an element in the inspector highlights the corresponding part in the alignment view. as shown in fig. the inspector simplifies visualizing misaligned sequences. ""masking"" the sequence alignment based on the current consensus structure is also possible. the result is shown in a new window, which contains the alignment based on sequence information only. the alignment can be processed like any other sequence alignment loaded in 4sale. this is particularly useful for calculating phylogenetic trees based on the collective helical regions in the sequence alignment. analyzing compensatory base changes compensatory base changes occur when both nucleotides of a paired site mutate while the pairing itself stays stable. cbc analysis is important in detecting species that are discriminated by their sexual incompatibility. we provide an easy-to-use cbc analysis mechanism with the ability to calculate cbc matrices on the current sequence and secondary structure based alignment. the numbers in the cbc matrix are the counts of compensatory base changes in a pairwise sequence structure alignment, which are naturally given in the considered multiple sequence structure alignment. a cbc-window in 4sale allows to select cbc counts between two sequences and highlights directly all cbcs within the alignment, giving an overview of all cbcs in the aligned sequences. output & connection to other tools for further analyses we provide several output formats. calculated cbc matrices can be saved as comma/tab seperated values to be used in cbcanalyzer. cbctree can be used to calculate phylogenetic trees based on a cbc count matrix. at present, no program is available to handle alignment outputs that include sequences and their individual secondary structures. however, for viewing purposes and publication we support a marna-like output. sequence alignments optimized by structural information could, of course, be saved separately. for phylogenetic analyses here we support the phylip formats. other tools that rely on multiple alignments are supported by fasta. discussion 4sale is the first alignment editor which allows synchronous editing of sequences and their corresponding secondary structures. since it is targeted on rna sequence alignment and editing it contains many features using the secondary structure information, e.g., the secondary structure inspector. all current standard alignment editors can handle secondary structures as character sequence only. by using standard greedy protein alignment algorithms we inherit their time efficiency. in contrast to, e.g., marna or rnaforester, the time complexity of calculation grows not rapidly with large files. we present a completely new approach using nucleotides and every single secondary structure for building and improving rna sequence alignments in comparison to others, which just take the consensus structure information. the structure output converted to vienna style dotbracket can be created from any desired rna folding program, e.g., rnafold, mfold or rnastructure. it is then aligned by using a suitable substitution matrix, which in our case is based on information of the its database. due to the natural limitation that two structures can be hidden in one sequence, in general only one will be considered by our approach. a future version of 4sale will integrate in addition to rnaforester more real structural alignment methods as webservices via the soap interface. also secondary structure prediction algorithms as an alternative to rnafold will be included. furthermore, more visualizations like secondary structure drawings can be implemented.  4sale is easy to use and has a fast ) and good heuristic to globally align multiple rna sequences and their associated secondary structures simultaneously. availability and requirements 4sale is freely available at. a java virtual machine is needed to run the application. furthermore, for automatic sequence and structure based alignments a local installation of clustal w and/or internet connection for webservice based alignments is required. list of abbreviations used cbc: compensatory base change its2: internal transcribed spacer 2 authors' contributions mw conceived the study. tm and mw provided the alignment algorithm. tm estimated the sequence and secondary structure substitution model and its associated score matrix. architecture, implementation and graphical design by ps. mw, ps and tm drafted the manuscript. mw, tm, js and td participated in study design and coordination. all authors read and approved the final version of the manuscript. ",pubmed_generic,Flan T5,4sale is a graphical editor for rna sequence alignment and secondary structure alignment.,non_factual,factual,minor,,intrinsic,,,,,
67,40f2bdec-a942-4ff3-86aa-8326816c1232_gpt3_gen,"Enterobacter sakazakii is a pathogen mainly found in neonatal intensive care units, and outbreaks have been linked to contaminated powdered infant milk formula. It was previously defined as a new species using DNA-DNA hybridization and biogroups were described based on biochemical profiles. Recent studies using 16s rDNA sequence analysis have shown that strains identified as E. sakazakii using commercial identification kits form at least four distinct clusters. This study further compares and differentiates the biogroups and genomic clusters using biochemical tests and DNA sequence analysis. It identifies a new biogroup and subgroups within the original biogroups, and shows that strains in biogroup 1 are the most commonly isolated from clinical sources. It is possible to differentiate the four genomic clusters using indole, dulcitol, and inositol tests."," enterobacter sakazakii is an emergent pathogen that is associated with neonatal infection. most reported outbreaks have occurred in neonatal intensive care units and some have been linked to the ingestion of contaminated powdered infant milk formula. e. sakazakii was defined as a new species by farmer et al. using dna-dna hybridization the previously'yellow pigmented enterobacter cloacae' was shown to be 41–54% related to enterobacter and citrobacter species. farmer et al. described biogroups of e. sakazakii based on biochemical profiles with the wild type biogroup being the most common. since prokaryotic systematics has changed with the increasing use of 16s rdna sequence analysis. harada and ishikawa used dna sequence analysis of the groel operon to determine the phylogenetic relationship among enterobacter, pantoea, klebsiella, serratia and erwinia species. hoffmann and roggenkamp used hsp dna sequence variation to investigate e. cloacae polyphyletic groups. previously, it has been shown by both partial 16s rdna and hsp gene sequencing that isolates identified as e. sakazakii using commercial identification kits form at least four distinct clusters. recently, an artificial neural network has been published which identified key biochemical and 16s rdna sequences that distinguish e. sakazakii from closely related organisms. in this study, we compare the biogroups of strains with the four 16s rdna cluster groups. we also identified key biochemical characteristics for the differentiation of these four genotypes. this significantly extends the previous work of farmer et al., which used five strains to genetically define the species and a total of strains to define biogroups.  biogroups the biochemical profiles obtained for each strain were compared to the biogroups originally described by farmer et al. clinical strains were distributed among fourteen of the biogroups. the defining tests were motility, voges-proskauer, methyl red, indole, ornithine decarboxylase, reduction of nitrate to nitrite, production of gas from d-glucose, malonate utilization and production of acid from myo-inositol and dulcitol. where strains could not be assigned to an original biogroup, a new biogroup or subgroup was designated. the majority of isolates were in biogroup with the e. sakazakii atcc 29544t type strain. these strains were motile, produced gas from glucose, produced acid from inositol, reduced nitrate and were positive for voges-proskauer and ornithine decarboxylase, but negative for methyl red, indole, malonate utilization and acid production from dulcitol. biogroup contained isolates negative for acid production from inositol; four of these were also non-motile. biogroup contained six strains and biogroup contained nine strains three of which were non-motile. biogroup was positive for malonate utilization and six of these were non-motile. biogroup was positive for indole and biogroup was negative for gas production from glucose. biogroup was defined by the inability to reduce nitrate. two of these strains were positive in the malonate test, three were negative for the inositol test and two were inositol negative but malonate positive. biogroup contained strains that were inositol negative and malonate positive. biogroup contained one strain that was inositol negative and indole positive, while biogroup contained one strain that was inositol negative and dulcitol positive. biogroup was also represented by only one strain, which was indole and malonate positive. the seven isolates in biogroup were negative for the voges-proskauer reaction, three were non-motile, one was negative for methyl red and one was negative for ornithine. biogroup was negative for ornithine decarboxylase and inositol, with four of these strains being positive for malonate. biogroup was positive for all the tests performed except methyl red. a new group had to be defined to accommodate strains which were inositol and dulcitol positive, but indole negative. they were malonate positive, with the exception of one strain. two strains were non-motile and one of these was also ornithine decarboxylase negative. acid production from α-methyl-d-glucoside was included in the original study and all biogroups were reported positive for this trait with the exception of biogroup as biogroup could be distinguished from the other biogroups without the α-methyl-d-glucoside test, this was not repeated for all strains in this study. phylogenetic analysis partial 16s rdna sequences containing less than 1% undetermined positions were obtained for all strains in this study. the sequences were analysed using the maximum parsimony method, which is an evolutionary model that searches for the simplest tree that can be constructed using the fewest inferred changes between characters. the topology was optimised using simulated annealing, a heuristic that occasionally accepts a worse tree during the course of the search allowing it to escape local optima. this method is more economical than the more usual heuristic searches, which can require many randon re-starts, especially with large data matrices. in agreement with previous reports, the isolates used in this study were divided into four genomic groups by 16s rdna sequence analysis. the majority of the presumptive e. sakazakii isolates in this study clustered with the type strain. cluster was composed of the majority of biogroups, biogroups 1– 7– and the isolates forming the new proposed biogroup corresponded with e. sakazakii cluster, with between – % 16s rdna sequence difference from the e. sakazakii type strain. no strains representative of this biochemical profile were included in the original study by farmer et al.. the six isolates in biogroup corresponded to e. sakazakii cluster. the four strains described as e. sakazakii cluster represent biogroups and for this dataset, the four partial 16s rdna cluster groups can be distinguished biochemically using the indole, dulcitol, and inositol tests. cluster strains are variable for inositol, negative for indole, and dulcitol; with the exception of biogroup which is dulcitol positive and inositol negative. cluster – biogroup strains are positive for inositol and dulcitol but negative for indole. cluster – biogroup is positive for inositol, dulcitol and indole. cluster strains were also positive for indole but can be distinguished from cluster as they are negative for dulcitol. one of the strains in cluster was inositol negative and one was malonate positive. there were insufficient isolates in cluster biogroups to determine whether these biogroups could be further genomically divided. discussion farmer et al. described biogroups of strains of e. sakazakii. five strains were used to genetically define the species by dna-dna hybridization and the remaining strain definitions were phenotypic. this study defines isolates in terms of both phenotype and genotype and extends the initial study with the analysis of strains. according to partial 16s rdna sequence analysis the majority of e. sakazakii strains clustered with the type strain, and within this cluster there was no clear further genomic division corresponding to biogroup. a second cluster of closely related strains was identified which were biochemically distinct from cluster and formed a biogroup that had not been previously described by farmer et al. these strains were not assigned a species match using the microseq or supplemental bacterial databases, but the nearest match was e. sakazakii. biogroup corresponds to e. sakazakii cluster while biogroups and correspond to e. sakazakii cluster. analysis of the full 16s sequence of strains corresponding to cluster groups and show these are less than 3% divergent from cluster group although dna-dna hybridization is the acknowledged standard for species delineation this technique was beyond the scope of this study, which focuses on evaluation of the biogroups reported when e. sakazakii was originally described. as well as defining a new biogroup, this study found subgroups within the original biogroups. the malonate and motility tests account for the majority of the subdivisions of the original biogroups. in this study, the majority of food isolates belonged to biogroups and all biogroups except and contained at least one strain from a clinical source. the greatest number of clinical strains was found to belong to biogroup. however, this included isolates out of the ten from the same hospital. therefore this may not be an indication of increased pathogenicity of this biogroup, but is likely due to an over representation of one clonal type from a single source. most of the food isolates belonged to biogroups and  biogroup was the major group with approximately one third of the e. sakazakii strains. cluster was the major dna cluster, and was composed of biogroups 1– 7– and cluster is equivalent to biogroup and a new biogroup was designated for the strains in cluster for this dataset it is possible to differentiate the four genomic clusters using indole, dulcitol and inositol tests. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
68,40f2bdec-a942-4ff3-86aa-8326816c1232_flant5_gen,"e. sakazakii is a novel species of enterobacteriaceae that has been associated with neonatal infections. the e. sakazakii biogroups were originally described by farmer et al. based on biochemical profiles. this study extends the original study by farmer et al. with the analysis of strains. according to partial 16s rdna sequence analysis the majority of e. sakazakii strains clustered with the type strain, and within this cluster there was no clear further genomic division corresponding to biogroup. a second cluster of closely related strains was identified which were biochemically distinct from cluster and formed a biogroup that had not been previously described by farmer et al. this study defines isolates in terms of both phenotype and genotype and extends the initial study with the analysis of strains. the malonate and motility tests account for the majority of the subdivisions of the original biogroups."," enterobacter sakazakii is an emergent pathogen that is associated with neonatal infection. most reported outbreaks have occurred in neonatal intensive care units and some have been linked to the ingestion of contaminated powdered infant milk formula. e. sakazakii was defined as a new species by farmer et al. using dna-dna hybridization the previously'yellow pigmented enterobacter cloacae' was shown to be 41–54% related to enterobacter and citrobacter species. farmer et al. described biogroups of e. sakazakii based on biochemical profiles with the wild type biogroup being the most common. since prokaryotic systematics has changed with the increasing use of 16s rdna sequence analysis. harada and ishikawa used dna sequence analysis of the groel operon to determine the phylogenetic relationship among enterobacter, pantoea, klebsiella, serratia and erwinia species. hoffmann and roggenkamp used hsp dna sequence variation to investigate e. cloacae polyphyletic groups. previously, it has been shown by both partial 16s rdna and hsp gene sequencing that isolates identified as e. sakazakii using commercial identification kits form at least four distinct clusters. recently, an artificial neural network has been published which identified key biochemical and 16s rdna sequences that distinguish e. sakazakii from closely related organisms. in this study, we compare the biogroups of strains with the four 16s rdna cluster groups. we also identified key biochemical characteristics for the differentiation of these four genotypes. this significantly extends the previous work of farmer et al., which used five strains to genetically define the species and a total of strains to define biogroups.  biogroups the biochemical profiles obtained for each strain were compared to the biogroups originally described by farmer et al. clinical strains were distributed among fourteen of the biogroups. the defining tests were motility, voges-proskauer, methyl red, indole, ornithine decarboxylase, reduction of nitrate to nitrite, production of gas from d-glucose, malonate utilization and production of acid from myo-inositol and dulcitol. where strains could not be assigned to an original biogroup, a new biogroup or subgroup was designated. the majority of isolates were in biogroup with the e. sakazakii atcc 29544t type strain. these strains were motile, produced gas from glucose, produced acid from inositol, reduced nitrate and were positive for voges-proskauer and ornithine decarboxylase, but negative for methyl red, indole, malonate utilization and acid production from dulcitol. biogroup contained isolates negative for acid production from inositol; four of these were also non-motile. biogroup contained six strains and biogroup contained nine strains three of which were non-motile. biogroup was positive for malonate utilization and six of these were non-motile. biogroup was positive for indole and biogroup was negative for gas production from glucose. biogroup was defined by the inability to reduce nitrate. two of these strains were positive in the malonate test, three were negative for the inositol test and two were inositol negative but malonate positive. biogroup contained strains that were inositol negative and malonate positive. biogroup contained one strain that was inositol negative and indole positive, while biogroup contained one strain that was inositol negative and dulcitol positive. biogroup was also represented by only one strain, which was indole and malonate positive. the seven isolates in biogroup were negative for the voges-proskauer reaction, three were non-motile, one was negative for methyl red and one was negative for ornithine. biogroup was negative for ornithine decarboxylase and inositol, with four of these strains being positive for malonate. biogroup was positive for all the tests performed except methyl red. a new group had to be defined to accommodate strains which were inositol and dulcitol positive, but indole negative. they were malonate positive, with the exception of one strain. two strains were non-motile and one of these was also ornithine decarboxylase negative. acid production from α-methyl-d-glucoside was included in the original study and all biogroups were reported positive for this trait with the exception of biogroup as biogroup could be distinguished from the other biogroups without the α-methyl-d-glucoside test, this was not repeated for all strains in this study. phylogenetic analysis partial 16s rdna sequences containing less than 1% undetermined positions were obtained for all strains in this study. the sequences were analysed using the maximum parsimony method, which is an evolutionary model that searches for the simplest tree that can be constructed using the fewest inferred changes between characters. the topology was optimised using simulated annealing, a heuristic that occasionally accepts a worse tree during the course of the search allowing it to escape local optima. this method is more economical than the more usual heuristic searches, which can require many randon re-starts, especially with large data matrices. in agreement with previous reports, the isolates used in this study were divided into four genomic groups by 16s rdna sequence analysis. the majority of the presumptive e. sakazakii isolates in this study clustered with the type strain. cluster was composed of the majority of biogroups, biogroups 1– 7– and the isolates forming the new proposed biogroup corresponded with e. sakazakii cluster, with between – % 16s rdna sequence difference from the e. sakazakii type strain. no strains representative of this biochemical profile were included in the original study by farmer et al.. the six isolates in biogroup corresponded to e. sakazakii cluster. the four strains described as e. sakazakii cluster represent biogroups and for this dataset, the four partial 16s rdna cluster groups can be distinguished biochemically using the indole, dulcitol, and inositol tests. cluster strains are variable for inositol, negative for indole, and dulcitol; with the exception of biogroup which is dulcitol positive and inositol negative. cluster – biogroup strains are positive for inositol and dulcitol but negative for indole. cluster – biogroup is positive for inositol, dulcitol and indole. cluster strains were also positive for indole but can be distinguished from cluster as they are negative for dulcitol. one of the strains in cluster was inositol negative and one was malonate positive. there were insufficient isolates in cluster biogroups to determine whether these biogroups could be further genomically divided. discussion farmer et al. described biogroups of strains of e. sakazakii. five strains were used to genetically define the species by dna-dna hybridization and the remaining strain definitions were phenotypic. this study defines isolates in terms of both phenotype and genotype and extends the initial study with the analysis of strains. according to partial 16s rdna sequence analysis the majority of e. sakazakii strains clustered with the type strain, and within this cluster there was no clear further genomic division corresponding to biogroup. a second cluster of closely related strains was identified which were biochemically distinct from cluster and formed a biogroup that had not been previously described by farmer et al. these strains were not assigned a species match using the microseq or supplemental bacterial databases, but the nearest match was e. sakazakii. biogroup corresponds to e. sakazakii cluster while biogroups and correspond to e. sakazakii cluster. analysis of the full 16s sequence of strains corresponding to cluster groups and show these are less than 3% divergent from cluster group although dna-dna hybridization is the acknowledged standard for species delineation this technique was beyond the scope of this study, which focuses on evaluation of the biogroups reported when e. sakazakii was originally described. as well as defining a new biogroup, this study found subgroups within the original biogroups. the malonate and motility tests account for the majority of the subdivisions of the original biogroups. in this study, the majority of food isolates belonged to biogroups and all biogroups except and contained at least one strain from a clinical source. the greatest number of clinical strains was found to belong to biogroup. however, this included isolates out of the ten from the same hospital. therefore this may not be an indication of increased pathogenicity of this biogroup, but is likely due to an over representation of one clonal type from a single source. most of the food isolates belonged to biogroups and  biogroup was the major group with approximately one third of the e. sakazakii strains. cluster was the major dna cluster, and was composed of biogroups 1– 7– and cluster is equivalent to biogroup and a new biogroup was designated for the strains in cluster for this dataset it is possible to differentiate the four genomic clusters using indole, dulcitol and inositol tests. ",pubmed_generic,Flan T5,with the analysis of strains.,non_factual,factual,minor,,intrinsic,,,,"This sentence is just no cutted? The complete sentence should be ""this study defines isolates in terms of both phenotype and genotype and extends the initial study with the analysis of strain"". However it would rely on marked option",
69,3bb2cc9c-30c0-44d1-856b-1104984928f6_flant5_gen,"Allelic imbalance (ai) is a genetic effect that can alter gene expression in an individual. ai events can be detected in rna sequencing data, but the detection of ai events is not trivial, comprising several steps, including library preparation, sequencing, mapping, and analysis of somatic mutations and rna-editing, which can bias the allele count. the allelicimbalance package was developed to address these issues, allowing the user to test ai at a single gene or snp quickly. Nevertheless, the package is suitable for performing any custom global ai analysis, because there is always a counting step and the need to store counts in a smart container, which facilitates access to custom requests from the user. for genes that have more than one heterozygous snp and at least one sample, there is a function to visualize ai consistency easily over the gene as an internal validation to select snps that are suitable for further ai qtl study. the package is easy to use, comprising an infrastructure that is linked to the bioconductor environment, and allows the user to pose genetic questions quickly."," regulatory variants that alter gene expression can be examined, based on allelic imbalance, i.e., alleles can be differently expressed in an individual if the regulatory region around a gene differs. in rna sequencing data, it is possible to determine the allele from which a specific read originates when there is at least one heterozygous snp in the sequence read. an ai event indicates that there is a variant that changes gene expression within or near that gene. it only takes one individual, assuming that there is a heterozygous site in the gene of interest. the detection of an ai event is not trivial, comprising several steps, including library preparation, sequencing, mapping, and analysis of somatic mutations and rna-editing, which can bias the allele count. to counter such biases when determining the true ai for an exon or gene, a smaller region must be visualized to discover inconsistent patterns. the allelicimbalance package was developed to address these issues, allowing the user to test ai at a single gene or snp quickly. nevertheless, the package is suitable for performing any custom global ai analysis, because there is always a counting step and the need to store counts in a smart container, which facilitates access to custom requests from the user. for genes that have more than one heterozygous snp and at least one sample, there is a function to visualize ai consistency easily over the gene as an internal validation to select snps that are suitable for further ai qtl study. the package is easy to use, comprising an infrastructure that is linked to the bioconductor environment, and allows the user to pose genetic questions quickly.fig. short title: ai consistency using glocationplot. detailed legend: on top are the fractions of alleles over apob for snps with a maf > . each bar represents one of eight samples, and the grey lines in the middle show the snp locations in apob beneath in yellow. all snps shown are close around the black line, denoting 1: expression of the alleles. see additional file for the total allele count for each snp allelicimbalance was developed to provide usability for inexperienced as experienced r-users. for inexperienced users, there is a standard protocol to create an aseset from bam files, and functions, such as barplot, can be used directly on that aseset class object; experienced users can customize nearly any part of the workflow. the design is based on rna-sequencing, but allelicimbalance can be used with any allele that is focused on a count-based technique, such as digital qpcr. implementation management aseset is a new object class that summarizes sequencing data. it contains allele counts, phenotypes, and snp positions and inherits the summarizedexperiments class and all functions that can be applied to that class, such as subset and range operation. the class has support for strand- and nonstrand-specific data. the first step in ai analysis is to create an aseset from mapped data in bam file format and a set of snps of interest. the support functions will summarize the allele counts for each snp rapidly and save them in an aseset object.fig. short title: flowchart of a typical workflow in the allelicimbalance package fig. short title: a few simple commands are needed to construct an aseset-class object. detailed legend: if the bam files are unprocessed before being imported into r, we recommend elaborating the filtering on the mapping with regard to quality and perfect mate-pairs before counting the alleles detection equal amounts of reads are expected from two alleles, but one allele might be read more than the other by chance. a greater number of reads improves the estimate of the total distribution. statistical tests, such as the chi-square and binomial tests, generate the probability that an observed difference is due to this sampling bias. these relatively simple and general tests can be applied directly to aseset objects and return a matrix with p-values for each snp and sample. the user can easily apply other custom tests by taking advantage of the aseset accessor methods to retrieve allele fractions or counts, for example. visualization and annotation allelicimbalance has good visualization capabilities and provides a rich description of allele-specific expression in a region. the barplot function has options to display the data as a fraction or count plot and can be used with the bioconductor annotationdbi and genomicfeatures packages to show the annotation of a gene, an exon, and transcript information.fig. short title: the dual-strand barplot. detailed legend: the barplot from the allelicimbalance package shows the number of reads aligning to each allele and strand for one snp. upward bars indicate the strand, and downward bars indicate the strand. the numbers under the bars are the p-values from testing whether a difference in allele expression is due to chance. because the data are strand-specific, nearly all reads over this snp are mapped to one strand, consistent with the location of the investigated genes. all samples in this figure are from liver. a of the heterozygote individuals 5– and show no ai, whereas individual shows significant ai. but, the plot also shows expression off of the opposite strand, which might comprise antisense transcripts. b individuals and show ai. c individuals and show strong ai. d individuals and show ai, whereas subjects and show no ai. see additional file and for barplots using different aligners the bioconductor package gviz uses tracks and trellis graphics to imitate genome browsers’ visualization of a genomic region. to integrate allelicimbalance data as a track, it takes merely a function call over an aseset object to create an object that is directly applicable for use with gviz. the most common applications of these tracks have been wrapped in a function, called glocationplot. the glocationplot function displays several barplots in the same graph and marks their location in a region.fig. short title: ai consistency for different alignment methods for fn detailed legend: a comparison of fractions over snps between a star, b star with n-replaced snp reference genome, and c tophat in the normal star and tophat run, the fraction lies around 1: for most snps, except snp, which shows strong ai. in c, however, the fractions are approximately 1: for all snps. d this graph summarizes the total counts for each snp over all samples for the alignment methods. see additional file for the total allele count for each snp mapping bias an rna sequencing read that contains snps can lead to a mapping bias—eg, reads that are more similar to the reference will map more often. this bias must be measured in the alignment step, such as through the generation of artificial reads that are equally distributed for both alleles over each snp of interest. in the alignment of reads, it is also possible to allow for more mismatches to decrease the bias toward the reference allele, but this step could affect the accuracy of the mapping. alignment to personal phased genomes is another method to handle mapping bias, requiring dna sequencing of the same individuals or ultimately personal transcriptomes, necessitating longer rna sequencing reads. to this end, allelicimbalance has a function that defines the expected allele ratios other than 1: to adjust for this mapping bias when searching for ai. the package also has a function that creates a reference genome in which known snps are masked by the generic nucleotide n, which can then be used in a realignment. in this article, we reduced the mapping bias effect using this method and masked all known variants in dbsnp build prior to alignment.  allelicimbalance can detect ai from rna sequencing data that originate from transcriptional material. with sufficient read depth over a gene, it is even possible to detect and quantify the alleles in introns of the precursor mrna. for example, we analyzed unpublished, strand-specific rna sequencing data from the livers of individuals and the aortas of subjects. to exemplify how ai can be used in a simple qtl analysis, four genes with high coverage—fgb, c kng, and itih4—were plotted as dual barplots. the plots show the binomial test p-values and provide visual confirmation of the presence of ai events. in this example, allelicimbalance demonstrates that there are cis effects for several individuals in all of these genes. using established methods, such as eqtl, it would not have been possible to detect this effect in a limited sample size. in all of the exemplified genes, most reads came from one strand, suggesting that the interference of lncrnas, for example, is low. but, at least 40 % of human genes are transcribed in both directions, potentially affecting the measurements of ai for a gene if there is ai on its antisense transcript. to compare loci or individuals in which the read depth differs, it can be convenient to plot alleles as a fraction and inspect a wider region of all heterozygous snps, for example, of the same gene. without interference from allele-specific splicing, we expect all snps over a gene to show the same pattern of fractions. figure  shows an example for which there is consistency between heterozygous snps in a gene; there is no ai, but the overall 1: expression supports that the ai measurements are consistent in the rna-seq data. to illustrate the reduction in mapping bias, we replaced the snps in the reference genome with the generic nucleotide indicator n. all snps in dbsnp build were masked in this manner, and we then reperformed the alignment with star. figure  shows an example of how such steps can improve the detection of true ai compared with a default run using star or tophat.  the allelicimbalance package will be valuable in examining the genetics of rna sequencing experiments. this software is a novel tool in the bioconductor environment, in which no infrastructure that can perform ai analyses exists. the import functions are essential when retrieving allele counts for specific nucleotide positions from all rna-seq reads. similarly, the statistical analysis and plotting functions are necessary to identify any allele-specific expression patterns in one’s data. with merely a limited amount of samples, strong genetic effects on gene expression can be discovered. availability and requirements gpl3-licensed and available in the bioconductor framework.project name: allelicimbalance software project home page: http://www.bioconductor.org/packages/release/bioc/html/allelicimbalance.html operating system: linux, mac osx, windows programming language: r other requirements: none license: gpl3 any restrictions to use by nonacademics: gpl3 additional files additional file 1: figure a1-a the corresponding barplots to figure for a star alignment. barplots for a tophat alignment. comparison between star, star dbsnp-masked reference and tophat for ai fraction consistency in the apob gene. a glocationplot for the fn gene with transcript annotation. additional file 2: includes counts, fractions and binomial test p-values for all individuals, rsids and alignment methods. additional file 3: includes total counts over all samples for each snp for the alignment methods for apob. additional file 4: includes total counts over all samples for each snp for the alignment methods for fn competing interests the authors declare that they have no competing interests. authors’ contributions jg and lf wrote the code, and all authors contributed to the design, draft of the manuscript, and critical revision of important intellectual content. acknowledgments this work was supported by the swedish research council and the swedish heart-lung foundation.",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
70,3bb2cc9c-30c0-44d1-856b-1104984928f6_gpt3_gen,"The article discusses the development of a package called allelicimbalance, which allows the detection of allelic imbalance events in RNA sequencing data. This involves examining regulatory variants that can alter gene expression and determine if alleles are differently expressed in an individual. The package addresses issues such as bias in allele counting and mapping, and allows for customization of the workflow for both inexperienced and experienced users. The package also has visualization capabilities and can be used for QTL analysis. The authors demonstrate the effectiveness of the package in detecting cis effects in genes with high coverage and reducing mapping bias. Overall, allelicimbalance is a valuable tool for examining the genetics of RNA sequencing experiments."," regulatory variants that alter gene expression can be examined, based on allelic imbalance, i.e., alleles can be differently expressed in an individual if the regulatory region around a gene differs. in rna sequencing data, it is possible to determine the allele from which a specific read originates when there is at least one heterozygous snp in the sequence read. an ai event indicates that there is a variant that changes gene expression within or near that gene. it only takes one individual, assuming that there is a heterozygous site in the gene of interest. the detection of an ai event is not trivial, comprising several steps, including library preparation, sequencing, mapping, and analysis of somatic mutations and rna-editing, which can bias the allele count. to counter such biases when determining the true ai for an exon or gene, a smaller region must be visualized to discover inconsistent patterns. the allelicimbalance package was developed to address these issues, allowing the user to test ai at a single gene or snp quickly. nevertheless, the package is suitable for performing any custom global ai analysis, because there is always a counting step and the need to store counts in a smart container, which facilitates access to custom requests from the user. for genes that have more than one heterozygous snp and at least one sample, there is a function to visualize ai consistency easily over the gene as an internal validation to select snps that are suitable for further ai qtl study. the package is easy to use, comprising an infrastructure that is linked to the bioconductor environment, and allows the user to pose genetic questions quickly.fig. short title: ai consistency using glocationplot. detailed legend: on top are the fractions of alleles over apob for snps with a maf > . each bar represents one of eight samples, and the grey lines in the middle show the snp locations in apob beneath in yellow. all snps shown are close around the black line, denoting 1: expression of the alleles. see additional file for the total allele count for each snp allelicimbalance was developed to provide usability for inexperienced as experienced r-users. for inexperienced users, there is a standard protocol to create an aseset from bam files, and functions, such as barplot, can be used directly on that aseset class object; experienced users can customize nearly any part of the workflow. the design is based on rna-sequencing, but allelicimbalance can be used with any allele that is focused on a count-based technique, such as digital qpcr. implementation management aseset is a new object class that summarizes sequencing data. it contains allele counts, phenotypes, and snp positions and inherits the summarizedexperiments class and all functions that can be applied to that class, such as subset and range operation. the class has support for strand- and nonstrand-specific data. the first step in ai analysis is to create an aseset from mapped data in bam file format and a set of snps of interest. the support functions will summarize the allele counts for each snp rapidly and save them in an aseset object.fig. short title: flowchart of a typical workflow in the allelicimbalance package fig. short title: a few simple commands are needed to construct an aseset-class object. detailed legend: if the bam files are unprocessed before being imported into r, we recommend elaborating the filtering on the mapping with regard to quality and perfect mate-pairs before counting the alleles detection equal amounts of reads are expected from two alleles, but one allele might be read more than the other by chance. a greater number of reads improves the estimate of the total distribution. statistical tests, such as the chi-square and binomial tests, generate the probability that an observed difference is due to this sampling bias. these relatively simple and general tests can be applied directly to aseset objects and return a matrix with p-values for each snp and sample. the user can easily apply other custom tests by taking advantage of the aseset accessor methods to retrieve allele fractions or counts, for example. visualization and annotation allelicimbalance has good visualization capabilities and provides a rich description of allele-specific expression in a region. the barplot function has options to display the data as a fraction or count plot and can be used with the bioconductor annotationdbi and genomicfeatures packages to show the annotation of a gene, an exon, and transcript information.fig. short title: the dual-strand barplot. detailed legend: the barplot from the allelicimbalance package shows the number of reads aligning to each allele and strand for one snp. upward bars indicate the strand, and downward bars indicate the strand. the numbers under the bars are the p-values from testing whether a difference in allele expression is due to chance. because the data are strand-specific, nearly all reads over this snp are mapped to one strand, consistent with the location of the investigated genes. all samples in this figure are from liver. a of the heterozygote individuals 5– and show no ai, whereas individual shows significant ai. but, the plot also shows expression off of the opposite strand, which might comprise antisense transcripts. b individuals and show ai. c individuals and show strong ai. d individuals and show ai, whereas subjects and show no ai. see additional file and for barplots using different aligners the bioconductor package gviz uses tracks and trellis graphics to imitate genome browsers’ visualization of a genomic region. to integrate allelicimbalance data as a track, it takes merely a function call over an aseset object to create an object that is directly applicable for use with gviz. the most common applications of these tracks have been wrapped in a function, called glocationplot. the glocationplot function displays several barplots in the same graph and marks their location in a region.fig. short title: ai consistency for different alignment methods for fn detailed legend: a comparison of fractions over snps between a star, b star with n-replaced snp reference genome, and c tophat in the normal star and tophat run, the fraction lies around 1: for most snps, except snp, which shows strong ai. in c, however, the fractions are approximately 1: for all snps. d this graph summarizes the total counts for each snp over all samples for the alignment methods. see additional file for the total allele count for each snp mapping bias an rna sequencing read that contains snps can lead to a mapping bias—eg, reads that are more similar to the reference will map more often. this bias must be measured in the alignment step, such as through the generation of artificial reads that are equally distributed for both alleles over each snp of interest. in the alignment of reads, it is also possible to allow for more mismatches to decrease the bias toward the reference allele, but this step could affect the accuracy of the mapping. alignment to personal phased genomes is another method to handle mapping bias, requiring dna sequencing of the same individuals or ultimately personal transcriptomes, necessitating longer rna sequencing reads. to this end, allelicimbalance has a function that defines the expected allele ratios other than 1: to adjust for this mapping bias when searching for ai. the package also has a function that creates a reference genome in which known snps are masked by the generic nucleotide n, which can then be used in a realignment. in this article, we reduced the mapping bias effect using this method and masked all known variants in dbsnp build prior to alignment.  allelicimbalance can detect ai from rna sequencing data that originate from transcriptional material. with sufficient read depth over a gene, it is even possible to detect and quantify the alleles in introns of the precursor mrna. for example, we analyzed unpublished, strand-specific rna sequencing data from the livers of individuals and the aortas of subjects. to exemplify how ai can be used in a simple qtl analysis, four genes with high coverage—fgb, c kng, and itih4—were plotted as dual barplots. the plots show the binomial test p-values and provide visual confirmation of the presence of ai events. in this example, allelicimbalance demonstrates that there are cis effects for several individuals in all of these genes. using established methods, such as eqtl, it would not have been possible to detect this effect in a limited sample size. in all of the exemplified genes, most reads came from one strand, suggesting that the interference of lncrnas, for example, is low. but, at least 40 % of human genes are transcribed in both directions, potentially affecting the measurements of ai for a gene if there is ai on its antisense transcript. to compare loci or individuals in which the read depth differs, it can be convenient to plot alleles as a fraction and inspect a wider region of all heterozygous snps, for example, of the same gene. without interference from allele-specific splicing, we expect all snps over a gene to show the same pattern of fractions. figure  shows an example for which there is consistency between heterozygous snps in a gene; there is no ai, but the overall 1: expression supports that the ai measurements are consistent in the rna-seq data. to illustrate the reduction in mapping bias, we replaced the snps in the reference genome with the generic nucleotide indicator n. all snps in dbsnp build were masked in this manner, and we then reperformed the alignment with star. figure  shows an example of how such steps can improve the detection of true ai compared with a default run using star or tophat.  the allelicimbalance package will be valuable in examining the genetics of rna sequencing experiments. this software is a novel tool in the bioconductor environment, in which no infrastructure that can perform ai analyses exists. the import functions are essential when retrieving allele counts for specific nucleotide positions from all rna-seq reads. similarly, the statistical analysis and plotting functions are necessary to identify any allele-specific expression patterns in one’s data. with merely a limited amount of samples, strong genetic effects on gene expression can be discovered. availability and requirements gpl3-licensed and available in the bioconductor framework.project name: allelicimbalance software project home page: http://www.bioconductor.org/packages/release/bioc/html/allelicimbalance.html operating system: linux, mac osx, windows programming language: r other requirements: none license: gpl3 any restrictions to use by nonacademics: gpl3 additional files additional file 1: figure a1-a the corresponding barplots to figure for a star alignment. barplots for a tophat alignment. comparison between star, star dbsnp-masked reference and tophat for ai fraction consistency in the apob gene. a glocationplot for the fn gene with transcript annotation. additional file 2: includes counts, fractions and binomial test p-values for all individuals, rsids and alignment methods. additional file 3: includes total counts over all samples for each snp for the alignment methods for apob. additional file 4: includes total counts over all samples for each snp for the alignment methods for fn competing interests the authors declare that they have no competing interests. authors’ contributions jg and lf wrote the code, and all authors contributed to the design, draft of the manuscript, and critical revision of important intellectual content. acknowledgments this work was supported by the swedish research council and the swedish heart-lung foundation.",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
71,72087755-1723-40bc-b87e-dbf62c0457db_flant5_gen,Phylogenetic comparative analysis of the age of vertebrate species reveals that viviparous species are more resilient to cold climates than oviparous ones.," if we wish to predict the resilience of a species to current challenges, such as those caused by climate change, one important source of information may be the past history of that taxon. a species that has persisted through very long periods – and thus, survived across a wide range of environmental conditions – may be more resilient than a recently evolved taxon whose vulnerability has not yet been tested to the same degree. the age of a species can then be considered as a consequence of resilience, which, in turn, will be determined by specific phenotypic traits. all else being equal then, we might thus expect “older” species to be more resilient. an important question is then what are the factors that affect a species’ age? previous research shows that a species’ geographic location is linked to how long it has persisted since being formed. on average, terrestrial vertebrate species are older in the southern than in the northern hemisphere. the severity of the last glacial maximum was different in these two hemispheres: extensive ice sheets were almost entirely absent from the southern hemisphere, whereas large portions of north america and eurasia were covered by glaciers. these differences placed fewer constraints on organismal viability, enabling populations to persist over extensive areas in the southern hemisphere. as a result, the lack of glaciation reduced the loss of genetic diversity. for similar reasons, the latitudinal distribution of organisms might also impact the age of species. for example, weir and schluter found that within new world birds and mammals, the age of species, as well as the divergence between sister species is older towards the tropics. intrinsic factors might also influence the resilience of species. in particular, it has been proposed that the reproductive strategies and neonatal behaviour, phenotypic characteristics, as well as the presence of intraspecific phenotypic variations, can have an effect on species ages. in this respect, recent studies have shown that intraspecific colour polymorphism allows species to exploit different habitat types or have broader distributions because of potential differences in behaviour, thermoregulation capacities, or prey–predator interactions. in addition, a study strictly focusing on snakes highlighted that the age of colour polymorphic species was older than those of monomorphic taxa. in combination, these results suggest that being colour polymorphic enhances the resilience of species. concerning the reproduction strategies and precociality of neonates, studies on the evolution of viviparity in reptiles suggest that it is a key innovation compared to oviparity, buffering species against the negative impact of past climate fluctuations or enabling them to better exploit cold areas. however, it may also be a dead-end in some circumstances as the transition to viviparity is often irreversible, meaning that cold adapted viviparous species might be at high risk in a context of global warming. lastly, species with independent neonates would be expected to be more resilient. under changing conditions, independent neonates can move by themselves to find a better environment. in contrast, dependent neonates need to be carried during moves, which burdens the parents and lessens their survival rate. any investigation of intrinsic factors associated with species age must also consider the indirect effect of body size. it is well known that body size is correlated with generation time and life history traits, as well as with population density. for example, small-bodied species have been shown to be more resilient than large ones. nonetheless, this factor has been neglected in previous studies looking at the age of species. in the present study, we aim to understand how extrinsic and intrinsic factors influence the resilience of vertebrate taxa and hence their age. based on a dataset of species worldwide and using phylogenetic comparative methods, we tested for an effect of the geographic location, body size, reproduction mode, newborn dependence behaviour, and presence of intraspecific colour polymorphism on the timing of the oldest diversification event within species. our study differs from previous studies by including taxa that are distributed in all areas of the world and we consider in our model all the factors that have been hypothesized to affect the age of species. it is also the first to consider all classes of vertebrates simultaneously and consider for the first time the phylogenetic effects due to shared ancestry between species. it therefore provides a much more complete and clear picture of the factors shaping the resilience of species.  the phylogenetic tree for the vertebrate species was congruent with existing knowledge on the relationships of the taxonomic groups included. most of the nodes were well supported and the trees sampled from the posterior distribution of trees that were used to account for phylogenetic uncertainty showed small differences. the divergence times obtained by maximum likelihood are within the 95 % interval of the posterior samples obtained with beast. the two analyses resulted in very similar divergence times and we therefore use the dates obtained by maximum likelihood for the remaining of the analyses. the dates obtained for the main lineages of vertebrates are also congruent with recent large scale phylogenetic reconstructions. we used phylogenetic gls to test the factors affecting the age of species, which was used as the response variable in our analyses. the backward model selection retained three single factors and one interaction in the final phylogenetic gls model. colour polymorphism and latitude were highly significant, while mode of reproduction was maintained due to its significant interaction with latitude. polymorphic species had a much higher resilience than monomorphic ones and, on average, the age of the polymorphic species was myr older than the age of monomorphic ones. latitude was also significant, but its effect was influenced by the mode of reproduction. oviparous species showed a strong latitudinal trend, with species living far from the equator being younger than species living in tropical climates. in contrast, viviparous species did not show any latitudinal trend in species age.fig. best tree obtained from mrbayes and used for the comparative analyses fig. a distribution of p-values for the different explanatory factors retained in our final model with the age of species as response variable, for trees sampled from the posterior distribution of trees obtained from mrbayes; relationships between the age of species and the presence or absence of intraspecific colour polymorphism and the interaction between the mean latitudinal distribution of species and their reproduction mode discussion our study, based on a dataset of vertebrate species, allowed us to identify several extrinsic and intrinsic factors that influence significantly the age of vertebrate species. it also clarified results from previous studies that were not based on comparative methods, focused on particular taxa or considered fewer factors. overall, absolute mean latitude of the species distribution was negatively correlated with species age and colour-polymorphic species were older than monomorphic species. moreover, the age of oviparous species decreased with latitude, whereas no such pattern was apparent for viviparous ones. the latitudinal gradient found in this study is consistent with the results of weir and schluter, who found that within new world birds and mammals, the age of species, as well as the divergence between sister species, is younger towards the poles. using interspecific divergences, they estimated that the highest recent speciation and extinction rates occurred at high latitudes and declined toward the tropics. this pattern is likely explained by the presence of more stable climatic conditions in the tropics than in temperate areas during pleistocene climatic fluctuations. according to weir and schluter, this climatic stability leads to a lower species turnover in the tropics compared to temperate areas, resulting in a lower diversity in the latter. based on the similarity between our results and those of weir and schluter in term of intraspecific latitudinal gradient, this pattern might be generally valid for vertebrate species from both hemispheres. however, the situation is likely more complex. indeed, the age of viviparous vertebrate species was not influenced by their mean latitudinal distribution, whereas the age of oviparous species decreased towards the poles. this result suggests a higher resilience of viviparous species to cold climate, and can be attributed to their buffering capacity against inadequate environmental conditions during the embryogenesis. this is particularly true for heliothermic vertebrates, for which a cold year might result in an absence of reproduction if favourable nesting sites are absent. in contrast, viviparous species might be able to better deal with poor environmental conditions by modifying their sun-basking activities. for instance, pincheira-donoso et al.,, found that, in a widespread south american lizard genus, the evolution of viviparity was associated with a radiation into cold climates. this argument is not relevant to birds or placental and marsupial mammals because their breeding type is constant and they are more widely distributed. however, the argument can be extended to other ectothermic vertebrates. body colour plays a major role in the evolution of organisms as it is involved, for instance, in thermoregulation, prey–predator interaction, behaviour, protection against uv-light or abrasive agents. therefore, the presence of intraspecific colour polymorphism may promote the ecological success of species as previously shown for squamates, amphibians and owls, through their capacity to exploit a larger range of habitat types. in turn, polymorphic species might be more resilient to past and future climatic fluctuations. our results are also in agreement with the study of pizzatto & dubey, which found that colour-polymorphic snake species were older than monomorphic species. recent studies focusing on temperate vertebrate taxa highlighted that species from the southern hemisphere are older than those from the northern, and that differences in past climate are likely responsible for this pattern. interestingly, the hemisphere of origin is not impacting the age of species in our study, which is likely due to the inclusion of additional intrinsic and extrinsic factors and to the use of phylogenetic comparative methods. indeed, when the hemisphere of origin is included in our analyses without accounting for the phylogenetic relationships between taxa, southern species remained significantly older than northern ones. the same is true when strictly temperate species of our dataset are included. these differences illustrate the importance of considering an array of factors in such analyses. in addition, the phylogenetic relationships of studied taxa might deeply influence such studies, keeping in mind that northern and southern hemisphere temperate fauna are distantly related genetically, numerous families and genera being solely distributed in one of the two hemispheres.  in conclusion, our findings suggest that intrinsic and extrinsic variables might contribute to the resilience of species to past environmental changes and hence are relevant in a context of climate change. overall and independently of current threats, organisms which exhibit ancient intraspecific diversification events are more likely to deal with future modifications of their environment, those species being colour polymorphic, viviparous, or living at low latitudes. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
72,72087755-1723-40bc-b87e-dbf62c0457db_gpt3_gen,"The age of a species can be considered a consequence of its resilience to environmental challenges, including those caused by climate change. Geographic location, reproductive strategies, neonatal behavior, intraspecific phenotypic variations, and body size are all factors that can impact species age. A study of vertebrate species found that absolute mean latitude of a species distribution was negatively correlated with species age, and that colour-polymorphic species were older than monomorphic species. The age of oviparous species decreased with latitude, whereas no such pattern was apparent for viviparous ones. Intrinsic and extrinsic variables can contribute to the resilience of a species to past environmental changes, which is relevant in the context of climate change. Overall, ancient intraspecific diversification events can increase a species' likelihood of dealing with future modifications of their environment."," if we wish to predict the resilience of a species to current challenges, such as those caused by climate change, one important source of information may be the past history of that taxon. a species that has persisted through very long periods – and thus, survived across a wide range of environmental conditions – may be more resilient than a recently evolved taxon whose vulnerability has not yet been tested to the same degree. the age of a species can then be considered as a consequence of resilience, which, in turn, will be determined by specific phenotypic traits. all else being equal then, we might thus expect “older” species to be more resilient. an important question is then what are the factors that affect a species’ age? previous research shows that a species’ geographic location is linked to how long it has persisted since being formed. on average, terrestrial vertebrate species are older in the southern than in the northern hemisphere. the severity of the last glacial maximum was different in these two hemispheres: extensive ice sheets were almost entirely absent from the southern hemisphere, whereas large portions of north america and eurasia were covered by glaciers. these differences placed fewer constraints on organismal viability, enabling populations to persist over extensive areas in the southern hemisphere. as a result, the lack of glaciation reduced the loss of genetic diversity. for similar reasons, the latitudinal distribution of organisms might also impact the age of species. for example, weir and schluter found that within new world birds and mammals, the age of species, as well as the divergence between sister species is older towards the tropics. intrinsic factors might also influence the resilience of species. in particular, it has been proposed that the reproductive strategies and neonatal behaviour, phenotypic characteristics, as well as the presence of intraspecific phenotypic variations, can have an effect on species ages. in this respect, recent studies have shown that intraspecific colour polymorphism allows species to exploit different habitat types or have broader distributions because of potential differences in behaviour, thermoregulation capacities, or prey–predator interactions. in addition, a study strictly focusing on snakes highlighted that the age of colour polymorphic species was older than those of monomorphic taxa. in combination, these results suggest that being colour polymorphic enhances the resilience of species. concerning the reproduction strategies and precociality of neonates, studies on the evolution of viviparity in reptiles suggest that it is a key innovation compared to oviparity, buffering species against the negative impact of past climate fluctuations or enabling them to better exploit cold areas. however, it may also be a dead-end in some circumstances as the transition to viviparity is often irreversible, meaning that cold adapted viviparous species might be at high risk in a context of global warming. lastly, species with independent neonates would be expected to be more resilient. under changing conditions, independent neonates can move by themselves to find a better environment. in contrast, dependent neonates need to be carried during moves, which burdens the parents and lessens their survival rate. any investigation of intrinsic factors associated with species age must also consider the indirect effect of body size. it is well known that body size is correlated with generation time and life history traits, as well as with population density. for example, small-bodied species have been shown to be more resilient than large ones. nonetheless, this factor has been neglected in previous studies looking at the age of species. in the present study, we aim to understand how extrinsic and intrinsic factors influence the resilience of vertebrate taxa and hence their age. based on a dataset of species worldwide and using phylogenetic comparative methods, we tested for an effect of the geographic location, body size, reproduction mode, newborn dependence behaviour, and presence of intraspecific colour polymorphism on the timing of the oldest diversification event within species. our study differs from previous studies by including taxa that are distributed in all areas of the world and we consider in our model all the factors that have been hypothesized to affect the age of species. it is also the first to consider all classes of vertebrates simultaneously and consider for the first time the phylogenetic effects due to shared ancestry between species. it therefore provides a much more complete and clear picture of the factors shaping the resilience of species.  the phylogenetic tree for the vertebrate species was congruent with existing knowledge on the relationships of the taxonomic groups included. most of the nodes were well supported and the trees sampled from the posterior distribution of trees that were used to account for phylogenetic uncertainty showed small differences. the divergence times obtained by maximum likelihood are within the 95 % interval of the posterior samples obtained with beast. the two analyses resulted in very similar divergence times and we therefore use the dates obtained by maximum likelihood for the remaining of the analyses. the dates obtained for the main lineages of vertebrates are also congruent with recent large scale phylogenetic reconstructions. we used phylogenetic gls to test the factors affecting the age of species, which was used as the response variable in our analyses. the backward model selection retained three single factors and one interaction in the final phylogenetic gls model. colour polymorphism and latitude were highly significant, while mode of reproduction was maintained due to its significant interaction with latitude. polymorphic species had a much higher resilience than monomorphic ones and, on average, the age of the polymorphic species was myr older than the age of monomorphic ones. latitude was also significant, but its effect was influenced by the mode of reproduction. oviparous species showed a strong latitudinal trend, with species living far from the equator being younger than species living in tropical climates. in contrast, viviparous species did not show any latitudinal trend in species age.fig. best tree obtained from mrbayes and used for the comparative analyses fig. a distribution of p-values for the different explanatory factors retained in our final model with the age of species as response variable, for trees sampled from the posterior distribution of trees obtained from mrbayes; relationships between the age of species and the presence or absence of intraspecific colour polymorphism and the interaction between the mean latitudinal distribution of species and their reproduction mode discussion our study, based on a dataset of vertebrate species, allowed us to identify several extrinsic and intrinsic factors that influence significantly the age of vertebrate species. it also clarified results from previous studies that were not based on comparative methods, focused on particular taxa or considered fewer factors. overall, absolute mean latitude of the species distribution was negatively correlated with species age and colour-polymorphic species were older than monomorphic species. moreover, the age of oviparous species decreased with latitude, whereas no such pattern was apparent for viviparous ones. the latitudinal gradient found in this study is consistent with the results of weir and schluter, who found that within new world birds and mammals, the age of species, as well as the divergence between sister species, is younger towards the poles. using interspecific divergences, they estimated that the highest recent speciation and extinction rates occurred at high latitudes and declined toward the tropics. this pattern is likely explained by the presence of more stable climatic conditions in the tropics than in temperate areas during pleistocene climatic fluctuations. according to weir and schluter, this climatic stability leads to a lower species turnover in the tropics compared to temperate areas, resulting in a lower diversity in the latter. based on the similarity between our results and those of weir and schluter in term of intraspecific latitudinal gradient, this pattern might be generally valid for vertebrate species from both hemispheres. however, the situation is likely more complex. indeed, the age of viviparous vertebrate species was not influenced by their mean latitudinal distribution, whereas the age of oviparous species decreased towards the poles. this result suggests a higher resilience of viviparous species to cold climate, and can be attributed to their buffering capacity against inadequate environmental conditions during the embryogenesis. this is particularly true for heliothermic vertebrates, for which a cold year might result in an absence of reproduction if favourable nesting sites are absent. in contrast, viviparous species might be able to better deal with poor environmental conditions by modifying their sun-basking activities. for instance, pincheira-donoso et al.,, found that, in a widespread south american lizard genus, the evolution of viviparity was associated with a radiation into cold climates. this argument is not relevant to birds or placental and marsupial mammals because their breeding type is constant and they are more widely distributed. however, the argument can be extended to other ectothermic vertebrates. body colour plays a major role in the evolution of organisms as it is involved, for instance, in thermoregulation, prey–predator interaction, behaviour, protection against uv-light or abrasive agents. therefore, the presence of intraspecific colour polymorphism may promote the ecological success of species as previously shown for squamates, amphibians and owls, through their capacity to exploit a larger range of habitat types. in turn, polymorphic species might be more resilient to past and future climatic fluctuations. our results are also in agreement with the study of pizzatto & dubey, which found that colour-polymorphic snake species were older than monomorphic species. recent studies focusing on temperate vertebrate taxa highlighted that species from the southern hemisphere are older than those from the northern, and that differences in past climate are likely responsible for this pattern. interestingly, the hemisphere of origin is not impacting the age of species in our study, which is likely due to the inclusion of additional intrinsic and extrinsic factors and to the use of phylogenetic comparative methods. indeed, when the hemisphere of origin is included in our analyses without accounting for the phylogenetic relationships between taxa, southern species remained significantly older than northern ones. the same is true when strictly temperate species of our dataset are included. these differences illustrate the importance of considering an array of factors in such analyses. in addition, the phylogenetic relationships of studied taxa might deeply influence such studies, keeping in mind that northern and southern hemisphere temperate fauna are distantly related genetically, numerous families and genera being solely distributed in one of the two hemispheres.  in conclusion, our findings suggest that intrinsic and extrinsic variables might contribute to the resilience of species to past environmental changes and hence are relevant in a context of climate change. overall and independently of current threats, organisms which exhibit ancient intraspecific diversification events are more likely to deal with future modifications of their environment, those species being colour polymorphic, viviparous, or living at low latitudes. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
73,f81fd7dc-7be0-4528-95e6-61fd210824ac_gpt3_gen,"The goal of microarray studies with two classes is to identify genes that contribute to class differences and have further investigation potential. The traditional approach is to consider gene expression individually, but this ignores gene interactions. A better approach is to develop classification rules with gene combinations to identify genes for further investigation. However, these rules usually involve many genes, making it hard to determine which genes are not included by chance. Therefore, the goal is to identify classification rules that perform well with few genes. K-fold cross-validation and multiple random validation are common measures of performance. The traditional approaches for gene selection involve a threshold for the number of genes to include in a classification rule or a filter that selects genes with the best individual performances. A wrapper approach selects genes with poor individual performance but better performance together. The threshold is either specified in advance or determined by a performance criterion and typically yields a moderate to large number of genes. The interest is in identifying classification rules that perform well with the fewest genes, making it easier to identify genes with relatively high frequencies in multiple random validation. These few genes are most likely to represent a true ""signal,"" helping to identify genes for further research and to simplify dissemination of results. The study analyzed data from four published microarray studies involving colon cancer, leukemia, medulloblastoma, and breast cancer. The goal is to confidently identify genes that have further investigation potential by using multiple random validation to find classification rules that perform well with few genes and select genes with relatively high frequencies of occurrence in these classification rules."," an important goal of microarray studies with two classes is to identify genes, for further investigation, that ""explain"" much of the class differences. one common approach is to look separately at genes that exhibit high differential expression. the disadvantage of this approach is that it ignores the role of gene combinations in leading to good classification. another approach is to investigate classification rules for combinations of genes. while this approach accounts for gene interactions, too often these rules involve so many genes that it is difficult to determine those genes that are not included simply by chance. our strategy is to look for classification rules that perform well with few genes, so as to have a stronger ""signal"" to detect genes that contribute most to good classification. there are various approaches to developing classification rules for microarrays and identifying genes for further investigation. almost all approaches involve a split of the data into training and test samples. in the training sample a classification rule is developed, and in the test sample its performance is determined. two common measures of performance are cross-validation and multiple random validation. in k-fold cross-validation, the data are divided into k subsets. on each iteration of the cross-validation a different collection of the k- subsets serve as the training sample and the remaining subset serves as the test sample. the performance of the classification rule is the average performance in the k test samples. in multiple random validation, the data are randomly split into training and test samples many times. unlike cross-validation, the goal is not to average performance over test samples but to investigate the variability of performance over test samples and the frequencies of genes selected on random splits. there are also various approaches for formulating a classification rule in the training sample. one common approach, called a filter, selects genes with the best individual performances prior to formulation of the classification rule. another common approach, called a wrapper, splits the training sample into a training-training sample and a training-test sample and uses cross-validation within the training sample to both select genes and formulate a classification rule. unlike a filter, a wrapper can identify genes that perform poorly individually but well together, but the price is likely increased variability in the measure of performance due to a small training-test sample. importantly, both approaches for gene selection involve a threshold for the number of genes to include in a classification rule. without a threshold it is possible to obtain excellent classification in the training sample that would likely do poorly in the test sample because the classification rule has been overly tailored to the training sample. the threshold is either specified in advance or determined by a performance criterion and typically yields a moderate to large number of genes the identification of a moderate number of genes is theoretically desirable because the genes likely form a network. however we are concerned that, despite the use of refined approaches, it is more likely that with classification rules involving a moderate number of genes rather than a few genes, that some genes will be detected by chance therefore our goal was to identify classification rules that perform well with the fewest genes, and so may be more ""robust"" than rules with more genes. importantly with fewer genes in the classification rule, it is easier to identify genes with relatively high frequencies in multiple random validation. such genes are most likely to represent a true ""signal."" the identification of a few genes that contribute to good classification and are not likely detected by chance allows investigators to better focus further research efforts, perhaps leading to easier clinical application, simpler dissemination of results, and possibly improved scientific insights. although our general strategy could be applied to any of a variety of microarray classification techniques, we chose a simple approach. for classification we used a filter and the nearest centroid rule, which is easy to implement and has been previously shown to perform well. to measure performance in a comprehensive manner that captures errors in assignments to both classes, we used receiver operating characteristic curves and the estimated area under the roc curve, which ranges from 1/ for chance classification to for perfect classification. to characterize chance variability we used the previously mentioned multiple random validation procedure that involves repeated random splits of training and test samples. we analyzed data from four published microarray studies involving colon cancer, leukemia, medulloblastoma, and breast cancer. see table although multiple random validation strategy had been used with the colon cancer, medulloblastoma, and breast cancer data sets, these analyses did not involve a comparison of performances for few versus many genes.  the classification performance generally improved as the number of genes in the classification rule increased from to to to with small decreases in improvement likely due to chance. see figure and table because the classification for the medulloblastoma data was poor with an estimated auc not significantly better than chance, we only report in detail the results for the three other data sets. for these data sets, the performance of the classification rule was more similar between rules with and genes than between rules with and genes, particularly when considering the lower bound of the estimated auc. results when the training sample split was one half the data are given below. for the colon cancer data set the estimated auc was.,.,., and. with and genes respectively; for leukemia data set it was.,.,., and. for and genes, respectively; and for the breast cancer data set it was.,.,., and. for and genes, respectively. similar results were obtained with a four-fifths split into the training sample. for the three data sets in which the classification rule for genes performed well, we investigated the classification rule for genes to determine if any genes had relatively high frequencies of selection. gene histograms are shown in figure for the breast cancer data set, no gene had a relatively high frequency. for the colon cancer data set, the human desmin gene had a relatively high frequency. human desmin is essential for maintaining the structural integrity of skeletal muscle. desmin has also been used in a study of colon cancer as a marker for fat storing cells, and, in a study of colon polyps from cases, all were negative for desmin. for the leukemia data the zyxin gene had a high relative frequency, 44%, 34%, and 31% when the training sample contained four-fifths the data.) zyxin plays a pivotal role in mitosis. after completing our analysis, we found that other investigators of the same data set identified zyxin has the most significant feature for classification, discussed some possible biological links, and recommended further investigation of the role of zyxin in leukemia. secretory granule proteoglycan was the other gene with high relative frequency in the leukemia data set when the training sample contained four-fifths of the data. the peptide core of a secretory granule proteoglycan, serglycin, has been implicated in gene methylation of leukemia cells. methylation is an important process in the regulation of expression in many genes. serglycin is also involved in the formation of granules in neutrophil granulocytes. granules are important for distinguishing the two classes of leukemias. interestingly secretory granule proteoglycan was not listed among identified genes in other classifications of these data. discussion other classification rules for the same data sets performed similarly to ours; however precise comparison of misclassification rates is not meaningful due to differences in the validation procedures, particularly when there was no random splitting of training and test samples. in terms of methodology for gene selection and classification, there are several related approaches: a filter with multiple random validation of the entire sample, a wrapper with multiple random validation of the entire sample, and a wrapper with multiple random cross-validation within the training sample and no independent test sample. see table our approach can be viewed either as a wrapper with multiple random validation and a training-test sample instead of a test sample or a filter with multiple random validation of the entire sample. these related approaches computed either gene frequencies or a relevancy measure that can be viewed as a frequency when the weights equal our general strategy of finding classification rules with few genes that perform well and then identifying genes with relatively high frequencies under multiple random validation applies to both classification rules with filters and wrappers. future research using a wrapper would be of great interest because of the potential of the wrapper to identify genes that have good classification when considered together but poor classification when considered separately. the inclusion of additional genes in the classification rule can affect performance in one of two ways depending on whether or not the additional genes are predictive of outcome or not. if the additional genes are not predictive, the performance of the rule in the test sample will likely worsen due to additional ""noise"". if the additional genes are predictive, then performance in the test sample will improve with more ""signals."" improvement in performance is greatest if the additional predictive genes are independent and smaller if the additional predictive genes are correlated. in our microarray studies, which showed small gains in performance with additional genes, the genes were likely predictive and correlated. our goal is to identify genes with high relative frequencies of selection in the classification rule with few genes. it is important to consider only classification rules with few genes because with moderate numbers of genes in the classification rules, many genes invariably appear in nearly all the classification rule and hence there is a concern that many genes are included by chance. with few genes in the classification rule, one can sometimes find, as in two of our data sets, one or two genes with relatively high frequencies, which seems like a strong ""signal"" that these genes make a real contribution to classification and are hence worthy of further study. it is, however, possible that many highly associated genes could have similarly high frequencies of occurrence in classification rules with few genes and one should be aware of this potential scenario. throughout this study we have been ""conservative"" in our identification of genes for further study by trying to rule out, as much as possible, the role of chance in explaining good classification. hence we used multiple random validation and focused on as few genes as possible. we also wanted our measure of performance to be as informative as possible by using roc curves. the 95% confidence intervals we report are only approximate because they are based on repeated sampling from a finite population, namely to specimens. however for our purposes, approximate confidence intervals are acceptable, because the main focus is not precisely estimating the variability of classification performance but rather the identification of genes that make a strong contribution to good classification performance.  a relevant quote attributed to the noted mathematician henri poincare is, ""science is built up of facts, as a house is with stones. but a collection of facts is no more a science than a heap of stones is a house."" often investigators report large numbers of genes that are either differentially expressed or constitute a classification rule, but which, due to the influence of chance, may be more of a ""heap of stones"" than part of a ""house."" to confidently identify the basic ""building blocks"" for classification of cancer outcomes, investigators should use multiple random validation to find classification rules that perform well with few genes and select genes with relatively high frequencies of occurrence in these classification rules. ",pubmed_generic,GPT 3.5,The goal is to confidently identify genes that have further investigation potential by using multiple random validation to find classification rules that perform well with few genes and select genes with relatively high frequencies of occurrence in these classification rules.,non_factual,factual,minor,,intrinsic,,,,,
74,f81fd7dc-7be0-4528-95e6-61fd210824ac_flant5_gen,a comparison of the performance of classification rules with few genes and genes with relatively high frequencies of selection in multiple random validation.," an important goal of microarray studies with two classes is to identify genes, for further investigation, that ""explain"" much of the class differences. one common approach is to look separately at genes that exhibit high differential expression. the disadvantage of this approach is that it ignores the role of gene combinations in leading to good classification. another approach is to investigate classification rules for combinations of genes. while this approach accounts for gene interactions, too often these rules involve so many genes that it is difficult to determine those genes that are not included simply by chance. our strategy is to look for classification rules that perform well with few genes, so as to have a stronger ""signal"" to detect genes that contribute most to good classification. there are various approaches to developing classification rules for microarrays and identifying genes for further investigation. almost all approaches involve a split of the data into training and test samples. in the training sample a classification rule is developed, and in the test sample its performance is determined. two common measures of performance are cross-validation and multiple random validation. in k-fold cross-validation, the data are divided into k subsets. on each iteration of the cross-validation a different collection of the k- subsets serve as the training sample and the remaining subset serves as the test sample. the performance of the classification rule is the average performance in the k test samples. in multiple random validation, the data are randomly split into training and test samples many times. unlike cross-validation, the goal is not to average performance over test samples but to investigate the variability of performance over test samples and the frequencies of genes selected on random splits. there are also various approaches for formulating a classification rule in the training sample. one common approach, called a filter, selects genes with the best individual performances prior to formulation of the classification rule. another common approach, called a wrapper, splits the training sample into a training-training sample and a training-test sample and uses cross-validation within the training sample to both select genes and formulate a classification rule. unlike a filter, a wrapper can identify genes that perform poorly individually but well together, but the price is likely increased variability in the measure of performance due to a small training-test sample. importantly, both approaches for gene selection involve a threshold for the number of genes to include in a classification rule. without a threshold it is possible to obtain excellent classification in the training sample that would likely do poorly in the test sample because the classification rule has been overly tailored to the training sample. the threshold is either specified in advance or determined by a performance criterion and typically yields a moderate to large number of genes the identification of a moderate number of genes is theoretically desirable because the genes likely form a network. however we are concerned that, despite the use of refined approaches, it is more likely that with classification rules involving a moderate number of genes rather than a few genes, that some genes will be detected by chance therefore our goal was to identify classification rules that perform well with the fewest genes, and so may be more ""robust"" than rules with more genes. importantly with fewer genes in the classification rule, it is easier to identify genes with relatively high frequencies in multiple random validation. such genes are most likely to represent a true ""signal."" the identification of a few genes that contribute to good classification and are not likely detected by chance allows investigators to better focus further research efforts, perhaps leading to easier clinical application, simpler dissemination of results, and possibly improved scientific insights. although our general strategy could be applied to any of a variety of microarray classification techniques, we chose a simple approach. for classification we used a filter and the nearest centroid rule, which is easy to implement and has been previously shown to perform well. to measure performance in a comprehensive manner that captures errors in assignments to both classes, we used receiver operating characteristic curves and the estimated area under the roc curve, which ranges from 1/ for chance classification to for perfect classification. to characterize chance variability we used the previously mentioned multiple random validation procedure that involves repeated random splits of training and test samples. we analyzed data from four published microarray studies involving colon cancer, leukemia, medulloblastoma, and breast cancer. see table although multiple random validation strategy had been used with the colon cancer, medulloblastoma, and breast cancer data sets, these analyses did not involve a comparison of performances for few versus many genes.  the classification performance generally improved as the number of genes in the classification rule increased from to to to with small decreases in improvement likely due to chance. see figure and table because the classification for the medulloblastoma data was poor with an estimated auc not significantly better than chance, we only report in detail the results for the three other data sets. for these data sets, the performance of the classification rule was more similar between rules with and genes than between rules with and genes, particularly when considering the lower bound of the estimated auc. results when the training sample split was one half the data are given below. for the colon cancer data set the estimated auc was.,.,., and. with and genes respectively; for leukemia data set it was.,.,., and. for and genes, respectively; and for the breast cancer data set it was.,.,., and. for and genes, respectively. similar results were obtained with a four-fifths split into the training sample. for the three data sets in which the classification rule for genes performed well, we investigated the classification rule for genes to determine if any genes had relatively high frequencies of selection. gene histograms are shown in figure for the breast cancer data set, no gene had a relatively high frequency. for the colon cancer data set, the human desmin gene had a relatively high frequency. human desmin is essential for maintaining the structural integrity of skeletal muscle. desmin has also been used in a study of colon cancer as a marker for fat storing cells, and, in a study of colon polyps from cases, all were negative for desmin. for the leukemia data the zyxin gene had a high relative frequency, 44%, 34%, and 31% when the training sample contained four-fifths the data.) zyxin plays a pivotal role in mitosis. after completing our analysis, we found that other investigators of the same data set identified zyxin has the most significant feature for classification, discussed some possible biological links, and recommended further investigation of the role of zyxin in leukemia. secretory granule proteoglycan was the other gene with high relative frequency in the leukemia data set when the training sample contained four-fifths of the data. the peptide core of a secretory granule proteoglycan, serglycin, has been implicated in gene methylation of leukemia cells. methylation is an important process in the regulation of expression in many genes. serglycin is also involved in the formation of granules in neutrophil granulocytes. granules are important for distinguishing the two classes of leukemias. interestingly secretory granule proteoglycan was not listed among identified genes in other classifications of these data. discussion other classification rules for the same data sets performed similarly to ours; however precise comparison of misclassification rates is not meaningful due to differences in the validation procedures, particularly when there was no random splitting of training and test samples. in terms of methodology for gene selection and classification, there are several related approaches: a filter with multiple random validation of the entire sample, a wrapper with multiple random validation of the entire sample, and a wrapper with multiple random cross-validation within the training sample and no independent test sample. see table our approach can be viewed either as a wrapper with multiple random validation and a training-test sample instead of a test sample or a filter with multiple random validation of the entire sample. these related approaches computed either gene frequencies or a relevancy measure that can be viewed as a frequency when the weights equal our general strategy of finding classification rules with few genes that perform well and then identifying genes with relatively high frequencies under multiple random validation applies to both classification rules with filters and wrappers. future research using a wrapper would be of great interest because of the potential of the wrapper to identify genes that have good classification when considered together but poor classification when considered separately. the inclusion of additional genes in the classification rule can affect performance in one of two ways depending on whether or not the additional genes are predictive of outcome or not. if the additional genes are not predictive, the performance of the rule in the test sample will likely worsen due to additional ""noise"". if the additional genes are predictive, then performance in the test sample will improve with more ""signals."" improvement in performance is greatest if the additional predictive genes are independent and smaller if the additional predictive genes are correlated. in our microarray studies, which showed small gains in performance with additional genes, the genes were likely predictive and correlated. our goal is to identify genes with high relative frequencies of selection in the classification rule with few genes. it is important to consider only classification rules with few genes because with moderate numbers of genes in the classification rules, many genes invariably appear in nearly all the classification rule and hence there is a concern that many genes are included by chance. with few genes in the classification rule, one can sometimes find, as in two of our data sets, one or two genes with relatively high frequencies, which seems like a strong ""signal"" that these genes make a real contribution to classification and are hence worthy of further study. it is, however, possible that many highly associated genes could have similarly high frequencies of occurrence in classification rules with few genes and one should be aware of this potential scenario. throughout this study we have been ""conservative"" in our identification of genes for further study by trying to rule out, as much as possible, the role of chance in explaining good classification. hence we used multiple random validation and focused on as few genes as possible. we also wanted our measure of performance to be as informative as possible by using roc curves. the 95% confidence intervals we report are only approximate because they are based on repeated sampling from a finite population, namely to specimens. however for our purposes, approximate confidence intervals are acceptable, because the main focus is not precisely estimating the variability of classification performance but rather the identification of genes that make a strong contribution to good classification performance.  a relevant quote attributed to the noted mathematician henri poincare is, ""science is built up of facts, as a house is with stones. but a collection of facts is no more a science than a heap of stones is a house."" often investigators report large numbers of genes that are either differentially expressed or constitute a classification rule, but which, due to the influence of chance, may be more of a ""heap of stones"" than part of a ""house."" to confidently identify the basic ""building blocks"" for classification of cancer outcomes, investigators should use multiple random validation to find classification rules that perform well with few genes and select genes with relatively high frequencies of occurrence in these classification rules. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
75,0d94840d-4243-42de-ac8e-6aca319599d9_gpt3_gen,"The article describes a simplified and easy method for screening recombinant adenoviral vectors within the adeasy system, which is a widely used system for generating recombinant adenoviral vectors. The duplex-PCR method is independent of the transgene or insert and can be used for the complete adeasy system, producing results within a few hours. The article presents the protocol step by step and confirms the functionality of the gene expression using cytosin deaminase as an example. The presented protocol allows fast detection of recombinant clones within the adeasy system with an easy, cost-effective technique, providing a potential alternative for screening recombinants within the adeasy system."," recombinant adenoviral vectors are highly efficient for in vitro and in vivo gene delivery. they can easily be produced in large numbers, transduce a wide variety of cell types and generate high levels of transgene expression. the adeasy system is a widely used, simplified system for generating recombinant adenoviral vectors, which are created with a minimum of enzymatic manipulations and by employing homologous recombination in e. coli. the system consists of two adenoviral backbone vectors and four different shuttle vectors, into which the desired transgenes are inserted. the polylinkers are surrounded by adenoviral sequences that allow homologous recombination with adenoviral backbone plasmids in e. coli. the shuttle vectors differ by partly carrying a cytomegalievirus promoter and gfp as a tracer all of which contain a kanamycin resistance gene. therefore, the various components can easily be combined depending on the desired purpose. in this paper we describe a simplified and easy method for screening recombinant dna within the adeasy system. this duplex-pcr-method is independent of the transgene or insert and can be used for the complete adeasy-system. it is characterized by a simple standard protocol and the results can be obtained within a few hours. the pcr is run with two different primer sets. the primers kanafor and kanarev hybridizise with the kanamycin resistence gene and adfor and adrev detect the adenoviral backbone. in case of recombinant clones, two diagnostic fragments with a size of bp and bp are generated. methods the presented duplex-pcr is performed as follows: after co-transformation of the pme i-digested shuttle vector with the adenoviral backbone plasmid to e. coli and plating on agar, half of the overnight grown colonies are picked and used directly as template for the colony-pcr. the other half of the colony is used for inoculation with lb-kanamycin and then incubation at 37°c. only the positive, recombinant clones which have been detected by pcr are grown overnight, a minipreparation of dna is then performed the next morning. the pcr is run using two different primer sets. the primers kanafor and kanarev hybridize to the kanamycin resistence gene and adfor and adrev detect the adenoviral backbone. the optimised concentrations of the components for the duplex-pcr were as follows: mm mgcl mm dntps and units taq polymerase. the bacteria are denatured at 95°c for minutes. the pcr-products are amplified by cycles of annealing at 58°c, extension at 72°c and denaturation at 94°c. in our experience, this procedure produced the best results without generating false positive clones. pcr products are analyzed by agarose gel electrophoresis, half of the reaction volume is size fractionated with v for h in 1% agarose in the presence of ethidium bromide and the resulting bands visualized with ultraviolet illumination. the dna obtained by small scale alkali lysis from the recombinants is then extracted twice with a phenol-chloroform protocol, precipitated and carefully resuspended in μl rnase-free water. the construct is linearized with paci and directly transfected into cells, which are monitored for cytopathic effects, i.e. production of recombinant adenoviruses. the cytopathic effect is usually seen within to days. the expression of the transgene is confirmed by western blot analysis. the practicability of our procedure was verified with three different transgenes: cytosin deaminase, p and granulocyte macrophage colony stimulating factor.  the conventional way of screening for recombinants after co-transformation of the linearized shuttle vector with the adenoviral backbone vector in e. coli is by plating on lb/kanamycin, growing the bacteria overnight, then picking the colonies and growing them again for 10– hours. minipreps are then performed and the size is evaluated on agarose gels. a restriction digest with three different restriction enzymes is then done and finally again another agarose gel is run. this is a relatively time-consuming and laborious procedure, which takes about days. in contrast, the presented alternative protocol allows fast detection of recombinants with a simplified technique by minimizing the amount of necessary steps for generating a recombinant adenovirus. the method is time sparing and cost-effective. in our experience, the above described protocol showed no problems with false negative clones. after optimisation of the pcr protocol, we were able to run the conventional screening method for recombinant clones at the same time as the presented simplified pcr. we found no differences in regard to the final results for the two methods, but it has to be kept in mind that only a limited number of recombinant adenoviruses were actually generated with the new technique. furthermore, we exclusively then continued our work with the adcd-virus. therefore it cannot be ruled out that under other conditions the presented technique may produce other results than the conventional technique. the positive clones were processed and finally transfected into cells. after harvesting recombinant adenovirus, we infected cells with adcd and checked the expression of the cytosin deaminase protein by western blot. the functionality of the gene was proven by facs analysis. we confirmed expression of the protein as well as its functionality.  the presented protocol allows fast detection of recombinant clones within the adeasy system with an easy, cost-effective technique. therefore, this procedure is a potential alternative for screening recombinants within the adeasy system. authors' contributions da designed the study and was responsible for manuscript preparation, mk, ib optimised the pcr protocol, pk was responsible for manuscript preparation, mb contributed to manuscript preparation and jw was responsible for study design and manuscript preparation. all authors read and approved the final manuscript. figures and tables",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
76,0d94840d-4243-42de-ac8e-6aca319599d9_flant5_gen,We describe a simplified and easy method for screening recombinant dna within the adeasy system.," recombinant adenoviral vectors are highly efficient for in vitro and in vivo gene delivery. they can easily be produced in large numbers, transduce a wide variety of cell types and generate high levels of transgene expression. the adeasy system is a widely used, simplified system for generating recombinant adenoviral vectors, which are created with a minimum of enzymatic manipulations and by employing homologous recombination in e. coli. the system consists of two adenoviral backbone vectors and four different shuttle vectors, into which the desired transgenes are inserted. the polylinkers are surrounded by adenoviral sequences that allow homologous recombination with adenoviral backbone plasmids in e. coli. the shuttle vectors differ by partly carrying a cytomegalievirus promoter and gfp as a tracer all of which contain a kanamycin resistance gene. therefore, the various components can easily be combined depending on the desired purpose. in this paper we describe a simplified and easy method for screening recombinant dna within the adeasy system. this duplex-pcr-method is independent of the transgene or insert and can be used for the complete adeasy-system. it is characterized by a simple standard protocol and the results can be obtained within a few hours. the pcr is run with two different primer sets. the primers kanafor and kanarev hybridizise with the kanamycin resistence gene and adfor and adrev detect the adenoviral backbone. in case of recombinant clones, two diagnostic fragments with a size of bp and bp are generated. methods the presented duplex-pcr is performed as follows: after co-transformation of the pme i-digested shuttle vector with the adenoviral backbone plasmid to e. coli and plating on agar, half of the overnight grown colonies are picked and used directly as template for the colony-pcr. the other half of the colony is used for inoculation with lb-kanamycin and then incubation at 37°c. only the positive, recombinant clones which have been detected by pcr are grown overnight, a minipreparation of dna is then performed the next morning. the pcr is run using two different primer sets. the primers kanafor and kanarev hybridize to the kanamycin resistence gene and adfor and adrev detect the adenoviral backbone. the optimised concentrations of the components for the duplex-pcr were as follows: mm mgcl mm dntps and units taq polymerase. the bacteria are denatured at 95°c for minutes. the pcr-products are amplified by cycles of annealing at 58°c, extension at 72°c and denaturation at 94°c. in our experience, this procedure produced the best results without generating false positive clones. pcr products are analyzed by agarose gel electrophoresis, half of the reaction volume is size fractionated with v for h in 1% agarose in the presence of ethidium bromide and the resulting bands visualized with ultraviolet illumination. the dna obtained by small scale alkali lysis from the recombinants is then extracted twice with a phenol-chloroform protocol, precipitated and carefully resuspended in μl rnase-free water. the construct is linearized with paci and directly transfected into cells, which are monitored for cytopathic effects, i.e. production of recombinant adenoviruses. the cytopathic effect is usually seen within to days. the expression of the transgene is confirmed by western blot analysis. the practicability of our procedure was verified with three different transgenes: cytosin deaminase, p and granulocyte macrophage colony stimulating factor.  the conventional way of screening for recombinants after co-transformation of the linearized shuttle vector with the adenoviral backbone vector in e. coli is by plating on lb/kanamycin, growing the bacteria overnight, then picking the colonies and growing them again for 10– hours. minipreps are then performed and the size is evaluated on agarose gels. a restriction digest with three different restriction enzymes is then done and finally again another agarose gel is run. this is a relatively time-consuming and laborious procedure, which takes about days. in contrast, the presented alternative protocol allows fast detection of recombinants with a simplified technique by minimizing the amount of necessary steps for generating a recombinant adenovirus. the method is time sparing and cost-effective. in our experience, the above described protocol showed no problems with false negative clones. after optimisation of the pcr protocol, we were able to run the conventional screening method for recombinant clones at the same time as the presented simplified pcr. we found no differences in regard to the final results for the two methods, but it has to be kept in mind that only a limited number of recombinant adenoviruses were actually generated with the new technique. furthermore, we exclusively then continued our work with the adcd-virus. therefore it cannot be ruled out that under other conditions the presented technique may produce other results than the conventional technique. the positive clones were processed and finally transfected into cells. after harvesting recombinant adenovirus, we infected cells with adcd and checked the expression of the cytosin deaminase protein by western blot. the functionality of the gene was proven by facs analysis. we confirmed expression of the protein as well as its functionality.  the presented protocol allows fast detection of recombinant clones within the adeasy system with an easy, cost-effective technique. therefore, this procedure is a potential alternative for screening recombinants within the adeasy system. authors' contributions da designed the study and was responsible for manuscript preparation, mk, ib optimised the pcr protocol, pk was responsible for manuscript preparation, mb contributed to manuscript preparation and jw was responsible for study design and manuscript preparation. all authors read and approved the final manuscript. figures and tables",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
77,34fc0373-e4ca-40ce-874b-89c72009cd99_flant5_gen,Chronic agomelatine treatment reduces depolarization-evoked glutamate release from hippocampal synaptosomes.," compelling evidence suggest that long-term changes in different brain areas and circuits mediating cognitive and emotional behaviors represent the biological underpinnings of mood and anxiety disorders. since the vast majority of neurons and synapses in these areas use glutamate as neurotransmitter, the glutamatergic system plays a central role in the pathogenesis of different psychiatric disorders and, potentially, appears to be a final common pathway for the therapeutic action of antidepressant agents. a number of studies have shown that traditional antidepressants regulate ionotropic and metabotropic glutamate receptors and modulate glutamate release and transmission in relevant limbic and cortical areas. in this context, several lines of preclinical/clinical research, which have investigated the action of molecules that directly target the glutamate synapse, are opening the way for glutamatergic, rapid acting, novel antidepressants. we have previously found that chronic treatment with different antidepressants significantly reduced depolarization-evoked glutamate release from hippocampal synaptic terminals. the above effect was accounted for by changes in protein phosphorylation, in turn affecting protein/protein interactions that regulate the assembly of the presynaptic soluble n-ethylmaleimide-sensitive fusion protein attachment protein receptor complex, mediating fusion of synaptic vesicles with presynaptic membrane. we have also shown that acute footshock-stress induces a marked increase of depolarization-evoked overflow of glutamate from prefrontal and frontal cortex synaptosomes, via glucocorticoid receptor activation and snare complex accumulation in synaptic membranes. chronic fluoxetine, desipramine, venlafaxine or agomelatine completely prevented the increase of glutamate release induced by stress. agomelatine is a new antidepressant, synergically acting as an agonist of mt1/mt receptors and as an antagonist of 5-ht2c receptors. although the effects of agomelatine on glutamate release in prefrontal and frontal cortex have been investigated, no data are available on the effects of this drug in hippocampus. thus, aims of the present work were: to assess whether chronic treatment with agomelatine modulates glutamate release from superfused hippocampal synaptosomes. to study whether agomelatine reduces the accumulation of the presynaptic snare complex in hippocampus.  chronic treatment with agomelatine or venlafaxine reduces depolarization-evoked release of glutamate from hippocampal synaptosomes synaptosomes were purified from the hippocampus of chronically drug- or vehicle-treated rats, and exposed in superfusion to kcl or ionomycin to assess glutamate and γ-amminobutyric acid release. as shown in figure 1a, chronic treatment for weeks with either agomelatine or venlafaxine modified the depolarization-evoked overflow of glutamate. indeed, both agomelatine and venlafaxine significantly reduced the mm kcl-induced glutamate overflow. interestingly, the release of glutamate induced by the calcium ionophore ionomycin, which mobilizes vesicles from both the recycling and reserve pools, was unaffected by drug treatments, suggesting that the action of the drugs is mainly confined to vesicles docked to the presynaptic membrane and primed for release. moreover, as previously observed both in hippocampus and prefrontal/frontal cortex, the mm kcl-induced overflow of gaba was not modified by venlafaxine or agomelatine. chronic antidepressant treatments reduce snare complex in hippocampal presynaptic membranes the core of the presynaptic snare complex is formed by the coiled-coil domain interaction of two membrane proteins and one vesicle protein. a large body of evidence demonstrated that the snare complex mediates the fusion of synaptic vesicles and neurotransmitter release. because in hippocampus glutamate synaptic terminals represent the vast majority of total synapses, molecular changes in the presynaptic release apparatus can be likely correlated with changes in glutamate release. thus, we evaluated if the decrease of glutamate release induced by agomelatine and venlafaxine was associated with altered assembling of presynaptic snare complexes. the analysis of snare complexes in purified presynaptic membranes revealed two major syntaxin-1-containing complexes, migrating at ~ kda and ~ kda, as previously reported. no significant changes were found in total syntaxin- levels. in line with the reduction of depolarization-dependent glutamate release, chronic treatment with both venlafaxine and agomelatine significantly reduced the accumulation of kda snare complex in synaptic membranes. no significant changes were found in kda snare complex accumulation. overall, the present findings show that chronic administration of agomelatine or the reference antidepressant venlafaxine significantly reduced the endogenous release of glutamate from hippocampal synaptosomes, as previously found with other traditional antidepressants. at the same time, both drugs decreased the accumulation of snare complexes in presynaptic membranes. discussion and  this work demonstrates that chronic treatment with the new antidepressant agomelatine, a mt and mt receptor agonist and 5-ht2c receptor antagonist, as well as with venlafaxine, a selective serotonin and noradrenaline reuptake inhibitor, markedly reduces depolarization-evoked endogenous release of glutamate from hippocampal synaptosomes. interestingly, the depolarization-evoked release of gaba was not modified, suggesting that both drugs selectively inhibit glutamatergic release without affecting gaba transmission. these results are in line with previous studies, both in vivo and ex vivo, showing similar effects on glutamatergic transmission of a number of traditional antidepressants and of agomelatine. the reduction of glutamate release with no changes in gaba release suggests an alteration in the balance between excitatory and inhibitory neurotransmission that could improve the signal to noise ratio in glutamate transmission, when it becomes compromised by excessive release. in this regard, we have demonstrated that chronic treatment with different classes of antidepressants, includ-ing agomelatine, was able to completely prevent the marked increase of depolarization-evoked glutamate release from prefrontal and frontal cortex synaptosomes induced by acute stress. another intriguing result of this study is that, despite chronic agomelatine inhibited glutamate release evoked by mm kcl depolarization, it had no effect on release induced by mm ionomycin. indeed, if it is generally agreed that electrical/chemical depolarization mainly induces the fusion of vesicles of the readily releasable pool, ionomycin also promotes calcium-dependent fusion of vesicles, but mainly from the reserve pool. therefore, our results suggest that agomelatine may selectively affect the rrp of vesicles, thereby altering a physiologically relevant pool for neurotransmitter release. in line with this hypothesis, we found that the reduction of glutamate release induced by chronic agomelatine and venlafaxine was accompanied by reduced accumulation of snare complexes in synaptic membranes. these data are in line with our previous results showing that traditional antidepressant-induced reduction of glutamate release is accounted for by changes in protein-protein interactions regulating the assembly of the snare complex, and by reduction of complex accumulation in presynaptic membranes. however, contrary to previous results with traditional antidepressants, here we did not find major changes in the expression of syntaxin- after weeks of treatment with agomelatine or venlafaxine. because the same result was obtained with both drugs, we suggest that the difference from other antidepressants is probably due to the different timing of drug-treatment. however, the main finding is that, after treatment for weeks, agomelatine and venlafaxine still reduced both the accumulation of snare complexes at the level of the rrp and the physiological release of glutamate. indeed, the snare complex and associated proteins play a critical role in vesicle docking, priming, fusion and synchronization of neurotransmitter release at presynaptic membranes and it was established that the snare complex corresponds to the minimal machinery for membrane fusion in eukaryotic cells, forming a stable complex that make the vesicles competent for fusion. therefore, a reduction of snare complex accumulation in synaptic membranes is consistent with reduced neurotransmitter release. in conclusion, the present study demonstrated that chronic agomelatine dampens hippocampal glutamate neurotransmission, a likely component of the therapeutic action of antidepressants. the intriguing finding of reduced accumulation of snare complexes in presynaptic membranes suggests selected mechanisms in the exocytotic machinery as possible molecular targets of these drugs. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
78,34fc0373-e4ca-40ce-874b-89c72009cd99_gpt3_gen,"The glutamatergic system plays a central role in the pathogenesis of mood and anxiety disorders, and traditional antidepressants regulate ionotropic and metabotropic glutamate receptors. Preclinical and clinical research has investigated molecules that directly target the glutamate synapse for new glutamatergic, rapid-acting antidepressants. Chronic treatment with agomelatine and venlafaxine reduces depolarization-evoked release of glutamate from hippocampal synaptosomes and decreases the accumulation of snare complexes in presynaptic membranes, suggesting possible molecular targets for these drugs. However, the drugs have no effect on the release of GABA, suggesting that they selectively inhibit glutamatergic release without affecting GABA transmission."," compelling evidence suggest that long-term changes in different brain areas and circuits mediating cognitive and emotional behaviors represent the biological underpinnings of mood and anxiety disorders. since the vast majority of neurons and synapses in these areas use glutamate as neurotransmitter, the glutamatergic system plays a central role in the pathogenesis of different psychiatric disorders and, potentially, appears to be a final common pathway for the therapeutic action of antidepressant agents. a number of studies have shown that traditional antidepressants regulate ionotropic and metabotropic glutamate receptors and modulate glutamate release and transmission in relevant limbic and cortical areas. in this context, several lines of preclinical/clinical research, which have investigated the action of molecules that directly target the glutamate synapse, are opening the way for glutamatergic, rapid acting, novel antidepressants. we have previously found that chronic treatment with different antidepressants significantly reduced depolarization-evoked glutamate release from hippocampal synaptic terminals. the above effect was accounted for by changes in protein phosphorylation, in turn affecting protein/protein interactions that regulate the assembly of the presynaptic soluble n-ethylmaleimide-sensitive fusion protein attachment protein receptor complex, mediating fusion of synaptic vesicles with presynaptic membrane. we have also shown that acute footshock-stress induces a marked increase of depolarization-evoked overflow of glutamate from prefrontal and frontal cortex synaptosomes, via glucocorticoid receptor activation and snare complex accumulation in synaptic membranes. chronic fluoxetine, desipramine, venlafaxine or agomelatine completely prevented the increase of glutamate release induced by stress. agomelatine is a new antidepressant, synergically acting as an agonist of mt1/mt receptors and as an antagonist of 5-ht2c receptors. although the effects of agomelatine on glutamate release in prefrontal and frontal cortex have been investigated, no data are available on the effects of this drug in hippocampus. thus, aims of the present work were: to assess whether chronic treatment with agomelatine modulates glutamate release from superfused hippocampal synaptosomes. to study whether agomelatine reduces the accumulation of the presynaptic snare complex in hippocampus.  chronic treatment with agomelatine or venlafaxine reduces depolarization-evoked release of glutamate from hippocampal synaptosomes synaptosomes were purified from the hippocampus of chronically drug- or vehicle-treated rats, and exposed in superfusion to kcl or ionomycin to assess glutamate and γ-amminobutyric acid release. as shown in figure 1a, chronic treatment for weeks with either agomelatine or venlafaxine modified the depolarization-evoked overflow of glutamate. indeed, both agomelatine and venlafaxine significantly reduced the mm kcl-induced glutamate overflow. interestingly, the release of glutamate induced by the calcium ionophore ionomycin, which mobilizes vesicles from both the recycling and reserve pools, was unaffected by drug treatments, suggesting that the action of the drugs is mainly confined to vesicles docked to the presynaptic membrane and primed for release. moreover, as previously observed both in hippocampus and prefrontal/frontal cortex, the mm kcl-induced overflow of gaba was not modified by venlafaxine or agomelatine. chronic antidepressant treatments reduce snare complex in hippocampal presynaptic membranes the core of the presynaptic snare complex is formed by the coiled-coil domain interaction of two membrane proteins and one vesicle protein. a large body of evidence demonstrated that the snare complex mediates the fusion of synaptic vesicles and neurotransmitter release. because in hippocampus glutamate synaptic terminals represent the vast majority of total synapses, molecular changes in the presynaptic release apparatus can be likely correlated with changes in glutamate release. thus, we evaluated if the decrease of glutamate release induced by agomelatine and venlafaxine was associated with altered assembling of presynaptic snare complexes. the analysis of snare complexes in purified presynaptic membranes revealed two major syntaxin-1-containing complexes, migrating at ~ kda and ~ kda, as previously reported. no significant changes were found in total syntaxin- levels. in line with the reduction of depolarization-dependent glutamate release, chronic treatment with both venlafaxine and agomelatine significantly reduced the accumulation of kda snare complex in synaptic membranes. no significant changes were found in kda snare complex accumulation. overall, the present findings show that chronic administration of agomelatine or the reference antidepressant venlafaxine significantly reduced the endogenous release of glutamate from hippocampal synaptosomes, as previously found with other traditional antidepressants. at the same time, both drugs decreased the accumulation of snare complexes in presynaptic membranes. discussion and  this work demonstrates that chronic treatment with the new antidepressant agomelatine, a mt and mt receptor agonist and 5-ht2c receptor antagonist, as well as with venlafaxine, a selective serotonin and noradrenaline reuptake inhibitor, markedly reduces depolarization-evoked endogenous release of glutamate from hippocampal synaptosomes. interestingly, the depolarization-evoked release of gaba was not modified, suggesting that both drugs selectively inhibit glutamatergic release without affecting gaba transmission. these results are in line with previous studies, both in vivo and ex vivo, showing similar effects on glutamatergic transmission of a number of traditional antidepressants and of agomelatine. the reduction of glutamate release with no changes in gaba release suggests an alteration in the balance between excitatory and inhibitory neurotransmission that could improve the signal to noise ratio in glutamate transmission, when it becomes compromised by excessive release. in this regard, we have demonstrated that chronic treatment with different classes of antidepressants, includ-ing agomelatine, was able to completely prevent the marked increase of depolarization-evoked glutamate release from prefrontal and frontal cortex synaptosomes induced by acute stress. another intriguing result of this study is that, despite chronic agomelatine inhibited glutamate release evoked by mm kcl depolarization, it had no effect on release induced by mm ionomycin. indeed, if it is generally agreed that electrical/chemical depolarization mainly induces the fusion of vesicles of the readily releasable pool, ionomycin also promotes calcium-dependent fusion of vesicles, but mainly from the reserve pool. therefore, our results suggest that agomelatine may selectively affect the rrp of vesicles, thereby altering a physiologically relevant pool for neurotransmitter release. in line with this hypothesis, we found that the reduction of glutamate release induced by chronic agomelatine and venlafaxine was accompanied by reduced accumulation of snare complexes in synaptic membranes. these data are in line with our previous results showing that traditional antidepressant-induced reduction of glutamate release is accounted for by changes in protein-protein interactions regulating the assembly of the snare complex, and by reduction of complex accumulation in presynaptic membranes. however, contrary to previous results with traditional antidepressants, here we did not find major changes in the expression of syntaxin- after weeks of treatment with agomelatine or venlafaxine. because the same result was obtained with both drugs, we suggest that the difference from other antidepressants is probably due to the different timing of drug-treatment. however, the main finding is that, after treatment for weeks, agomelatine and venlafaxine still reduced both the accumulation of snare complexes at the level of the rrp and the physiological release of glutamate. indeed, the snare complex and associated proteins play a critical role in vesicle docking, priming, fusion and synchronization of neurotransmitter release at presynaptic membranes and it was established that the snare complex corresponds to the minimal machinery for membrane fusion in eukaryotic cells, forming a stable complex that make the vesicles competent for fusion. therefore, a reduction of snare complex accumulation in synaptic membranes is consistent with reduced neurotransmitter release. in conclusion, the present study demonstrated that chronic agomelatine dampens hippocampal glutamate neurotransmission, a likely component of the therapeutic action of antidepressants. the intriguing finding of reduced accumulation of snare complexes in presynaptic membranes suggests selected mechanisms in the exocytotic machinery as possible molecular targets of these drugs. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
79,38689e3f-0932-4a5e-9820-dfc4e8a39bfb_flant5_gen,"sr-aom community was enriched in a high-pressure bioreactor, originating from a mud volcano from the gulf of cadiz. the sr-aom activity was mmol sulfide production per day. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s."," anaerobic oxidation of methane coupled to sulphate reduction is a major process determining deep-sea geochemistry and cold-seep ecosystems. first of all, it controls the atmospheric methane efflux from the ocean floor, consuming more than 90% of the methane produced in marine sediments. moreover, it fuels the deep sea ecosystem by channelling thermal generated and biogenetic methane into organic matter and carbonate. finally, sr-aom shapes the sea floor landscape by contributing to bicarbonate and alkalinity production, resulting in massive carbonate precipitation. the overall sr-aom reaction is: two groups of microorganisms are the key players in sr-aom process: anaerobic methanotrophic archaea with three groups and sulphate reducing bacteria. all anme groups discovered so far are related clades of methanogens, while their srb partner was always found in the same environment with or without forming spatial closely related consortia. however, neither anme nor srb from sr-aom active spots has been obtained in pure culture yet. the main difficulty lies on the extremely long doubling time and low growth yield of anme and srb from in vitro incubations. to stimulate the in vitro sr-aom activity and to enrich the sr-aom community, different types of bioreactors, which can be operated at ambient/high pressure in continuous/batch mode, have been developed by different research groups. due to the extremely low affinity for methane and the low methane solubility at ambient pressure, high-pressure bioreactors have the advantage of permitting a higher sr-aom activity. nevertheless, it is still unknown if the high-pressure bioreactor also confers advantage on biomass enrichment, and if it has an effect on selective enrichment of certain groups of anme. moreover, the information is lacking on the community architecture inside the high-pressure bioreactor, meaning if the microbes live as single cells or form consortia. through high-pressure incubation, we have obtained an enrichment originating from a mud volcano from the gulf of cadiz, performing anaerobic oxidation of methane. the sr-aom activities at different incubation conditions have been described previously. in this study, the community structure and architecture of this enrichment were investigated. the potential growth of anme and srb under high pressure has been evaluated.  community architectural distribution to access the community architectural distribution, a dapi staining was applied on the samples s and s. based on dapi staining cell counts, both single cells and aggregates were commonly observed in s and s the aggregates had different sizes ranging from to μm in diameter. in both s and s single cells were 1- orders more abundant than the aggregates. among all the aggregates, the ones with diameter from to μm were the most abundant ones. few spherical aggregates bigger than μm were observed in s or s. for some aggregates we observed that it was dividing into two smaller spherical aggregates in both s and s. this was also reported in another enrichment from a semi-continuous bioreactor operated under mpa methane pressure. it is an indication that these large aggregates may have reached a ""critical size"" during growth, which then may disintegrate into smaller aggregates for further growth. cell aggregates accounted for the major part of the biovolume. the middle size aggregates contributed for about half of the total biovolume. although the big size aggregates had very low concentrations, they also contributed for large part of the biovolume. enrichment of total biomass the total biovolume concentration increased from * μm3/ml slurry in s to * μm3/ml slurry in s. since the reactor volume was fixed and the biomass washing out during reactor operation was negligible, the total biomass inside the reactor increased times within days. this reactor system was the first system that was able to accumulate total biomass while maintaining high sr-aom activity-- mmol sulfide production per day while the reactor was operated at batch mode under mpa methane pressure. in the systems previously reported by other authors, either only specific groups but not the total biomass was quantified or there was major loss of biomass due to sampling and decay. the biovolume data was converted into cell dry weight for a comparison with vss data. taken the same assumption as described by nauhaus et al., there was about g cell dry weight/ml biovolume in the sediment sample with sr-aom activity. therefore the biomass concentration in the high-pressure bioreactor increased from in s to in s however, this value was one order lower compared to the g/l of vss as reported by zhang et al.. one possibility is that the assumption g cell dry weight/ml biovolume was based on analysis of two strains of small marine microorganism, which could be not representative of the cells enriched in the reactor. another possibility would be the extracellular polymeric substances contributed large part of vss. for example, for granular microbial aggregates enriched in an oland reactor, as much as 50-80% of the space occupied by bacteria was constituted of eps. for the deep-sea sediment, the presence of eps has been reported both from in situ sediment and in vitro enrichments at different locations. however whether the production of eps was stimulated during high-pressure incubations and what was the mechanism behind still needs to be further investigated. community structure to identify the cells and aggregates observed under microscope, catalyzed reporter deposition fluorescence in situ hybridization with probes on anme- and srb was applied on s and s based on card-fish counts, anme- and srb were the most abundant ones compared to other types of anme, especially in the form of aggregates. among the free-living cells, only less than 10% belonged to anme- or srb. the number of anme- aggregates accounted for ± % of the total aggregates in s and ± % in s while srb accounted for ± % of the total aggregates in s and ± % in s however, it has to be taken into account that the card-fish in this study was performed with single probe hybridization. aggregates with anme- are most probably also containing srb as well, because they tend to live closely and form consortia. no anme- was detected in s and s about 2% of anme- was detected in the aggregates. the average value and standard error were calculated based on fields of view on each hybridization. no anme- cell or aggregate was observed based on our method. detection limit of × cells/ml slurry. detection limit of × cells/ml slurry the card-fish result showed that a large part of biomass in s and s especially single cells, did not belong to anme or srb. there was growth of other unknown microbes within a mixed community of anme/srb. therefore a clone library analysis was performed on s to approach to the complete archaeal and bacterial communities. archaeal community had extremely low diversity, where anme-2a and mbg-d were the only two groups of archaea detected. anme-2a was the dominant, which accounted for 88% of the archaeal community. no 16s rrna gene from anme- was detected. the absence of anme- in the archaeal clone library was contradictory to card-fish result. the size of the clone library was not large enough to detect the rare anme- or the hybridization experiment may have led to mis-hybridization, thus giving false positive signal. dissimilar from archaeal community, the bacterial community was highly diverse. gammaproteobacteria were the most dominant followed by the deltaproteobacteria, which includes the srb. among total bacteria population in s 8% was belonging to seep-srb1a subgroup of deltaproteobacteria, which were found to be specifically associated with anme-2a in other enrichments mediating sr-aom process. most of the gammaproteobacteria found in the community were closely related to methylophaga sp. and methylobacter sp., which are known to use reduced one-carbon compounds, such as methane, methanol or dimethylsulphide. the presence of such bacteria in our anaerobic reactor is intriguing since methane and sulphate were the only electron donor and acceptor supplied. the presence and even production of sulphide was an indication of anaerobic condition inside the reactor. however we cannot exclude the possibility of a limited amount of dissolved oxygen in the reactor influent, which could explain the presence of aerobic. further tests need to show if these gammaproteobacteria are playing an important active role in the reactor. enrichment of anme- and srb card-fish results showed that percentages of anme- and srb biovolume increased from ± % and ± % in s to ± % and ± % in s. by combining with the total biovolume data from dapi staining, the biovolume of anme- in s was: * % = * μm3/ml slurry the biovolume of anme- in s was: * % = * μm3/ml slurry therefore after days incubation, the anme- population increased for times. following the same method of calculation, the srb population increased for times after days incubation in this high-pressure bioreactor. the populations of anme- and srb both increased faster than the total biomass, which indicated that anme- and srb were selectively enriched in the system. this selective enrichment of anme- and srb was another proof that the incubation condition inside this high-pressure bioreactor was favourable for sr-aom community. to our knowledge, this is the first report on the enrichment of sr-aom community under high methane pressure, although potential growth of anme- anme- and srb has been reported in other engineered systems at ambient or low methane pressures. the different inocula showed different doubling times. when anme- and anme-2c were incubated in continuous flow bioreactors under ambient methane partial pressure, anme- had doubling time of months while anme-2c had doubling time of months. high methane partial pressure appeared to have advantage on stimulating the growth of anme. in the experiment of krüger et al., the methane-dependent uptake of 15n-nh by aom community dominated by anme- was higher at mpa methane pressure than at ambient methane pressure. if we assume the anme-2a cells in our system were following a logarithmic growth curve, a doubling time of months can be estimated based on anme- biovolume in s and s which is shorter than the result obtained by meulepas et al.. the increase of energy gained from sr-aom process by increasing methane pressure may favour the biomass growth. continuous flow also stimulated growth: anme-2a/2c had longer doubling time in a fed-batch bioreactor than in continuous flow bioreactors.  after days incubation in a simulated cold seep environment under high methane pressure, anme- and srb in the sediment from captain arutyunov mud volcano were enriched. based on biovolume calculation, the populations of anme- and srb increased for times and times. within total biomass volume, % was accounted from aggregates. therefore the incubation condition apparently favoured the cells to form aggregates, especially in small size, rather than to live as single cells. no aggregate bigger than μm in diameter was observed; they apparently divided after reaching a critical size. based on the 16s rrna gene clone library, the archaeal diversity was low, and contained only anme- and mbg-d. in contrast, the bacterial community was highly diverse. ",pubmed_generic,Flan T5,the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s. the total biomass concentration increased from m3/ml slurry in s to m3/ml slurry in s to m3/ml slurry in s.,non_factual,non_factual,minor,minor,intrinsic,other,,,Several repetition of a sentences in the summary,Repitition
80,38689e3f-0932-4a5e-9820-dfc4e8a39bfb_gpt3_gen,"The article discusses the anaerobic oxidation of methane coupled to sulfate reduction (SR-AOM) process, which is essential in determining deep-sea geochemistry and cold-seep ecosystems. The process consumes more than 90% of the methane produced in marine sediments and fuels the deep-sea ecosystem by channelling thermal-generated and biogenetic methane into organic matter and carbonate. The article also talks about the challenges of studying the process, such as the difficulty of obtaining pure cultures of the microorganisms involved, and the development of different types of bioreactors to enrich the SR-AOM community. The article reports on an enrichment originated from a mud volcano from the Gulf of Cadiz, where the community structure and architecture were investigated, and the potential growth of anme and srb under high pressure was evaluated. The study found that the incubation condition inside the high-pressure bioreactor was favourable for the selective enrichment of anme- and srb, and the populations of anme- and srb both increased faster than the total biomass, indicating that the process was stimulated."," anaerobic oxidation of methane coupled to sulphate reduction is a major process determining deep-sea geochemistry and cold-seep ecosystems. first of all, it controls the atmospheric methane efflux from the ocean floor, consuming more than 90% of the methane produced in marine sediments. moreover, it fuels the deep sea ecosystem by channelling thermal generated and biogenetic methane into organic matter and carbonate. finally, sr-aom shapes the sea floor landscape by contributing to bicarbonate and alkalinity production, resulting in massive carbonate precipitation. the overall sr-aom reaction is: two groups of microorganisms are the key players in sr-aom process: anaerobic methanotrophic archaea with three groups and sulphate reducing bacteria. all anme groups discovered so far are related clades of methanogens, while their srb partner was always found in the same environment with or without forming spatial closely related consortia. however, neither anme nor srb from sr-aom active spots has been obtained in pure culture yet. the main difficulty lies on the extremely long doubling time and low growth yield of anme and srb from in vitro incubations. to stimulate the in vitro sr-aom activity and to enrich the sr-aom community, different types of bioreactors, which can be operated at ambient/high pressure in continuous/batch mode, have been developed by different research groups. due to the extremely low affinity for methane and the low methane solubility at ambient pressure, high-pressure bioreactors have the advantage of permitting a higher sr-aom activity. nevertheless, it is still unknown if the high-pressure bioreactor also confers advantage on biomass enrichment, and if it has an effect on selective enrichment of certain groups of anme. moreover, the information is lacking on the community architecture inside the high-pressure bioreactor, meaning if the microbes live as single cells or form consortia. through high-pressure incubation, we have obtained an enrichment originating from a mud volcano from the gulf of cadiz, performing anaerobic oxidation of methane. the sr-aom activities at different incubation conditions have been described previously. in this study, the community structure and architecture of this enrichment were investigated. the potential growth of anme and srb under high pressure has been evaluated.  community architectural distribution to access the community architectural distribution, a dapi staining was applied on the samples s and s. based on dapi staining cell counts, both single cells and aggregates were commonly observed in s and s the aggregates had different sizes ranging from to μm in diameter. in both s and s single cells were 1- orders more abundant than the aggregates. among all the aggregates, the ones with diameter from to μm were the most abundant ones. few spherical aggregates bigger than μm were observed in s or s. for some aggregates we observed that it was dividing into two smaller spherical aggregates in both s and s. this was also reported in another enrichment from a semi-continuous bioreactor operated under mpa methane pressure. it is an indication that these large aggregates may have reached a ""critical size"" during growth, which then may disintegrate into smaller aggregates for further growth. cell aggregates accounted for the major part of the biovolume. the middle size aggregates contributed for about half of the total biovolume. although the big size aggregates had very low concentrations, they also contributed for large part of the biovolume. enrichment of total biomass the total biovolume concentration increased from * μm3/ml slurry in s to * μm3/ml slurry in s. since the reactor volume was fixed and the biomass washing out during reactor operation was negligible, the total biomass inside the reactor increased times within days. this reactor system was the first system that was able to accumulate total biomass while maintaining high sr-aom activity-- mmol sulfide production per day while the reactor was operated at batch mode under mpa methane pressure. in the systems previously reported by other authors, either only specific groups but not the total biomass was quantified or there was major loss of biomass due to sampling and decay. the biovolume data was converted into cell dry weight for a comparison with vss data. taken the same assumption as described by nauhaus et al., there was about g cell dry weight/ml biovolume in the sediment sample with sr-aom activity. therefore the biomass concentration in the high-pressure bioreactor increased from in s to in s however, this value was one order lower compared to the g/l of vss as reported by zhang et al.. one possibility is that the assumption g cell dry weight/ml biovolume was based on analysis of two strains of small marine microorganism, which could be not representative of the cells enriched in the reactor. another possibility would be the extracellular polymeric substances contributed large part of vss. for example, for granular microbial aggregates enriched in an oland reactor, as much as 50-80% of the space occupied by bacteria was constituted of eps. for the deep-sea sediment, the presence of eps has been reported both from in situ sediment and in vitro enrichments at different locations. however whether the production of eps was stimulated during high-pressure incubations and what was the mechanism behind still needs to be further investigated. community structure to identify the cells and aggregates observed under microscope, catalyzed reporter deposition fluorescence in situ hybridization with probes on anme- and srb was applied on s and s based on card-fish counts, anme- and srb were the most abundant ones compared to other types of anme, especially in the form of aggregates. among the free-living cells, only less than 10% belonged to anme- or srb. the number of anme- aggregates accounted for ± % of the total aggregates in s and ± % in s while srb accounted for ± % of the total aggregates in s and ± % in s however, it has to be taken into account that the card-fish in this study was performed with single probe hybridization. aggregates with anme- are most probably also containing srb as well, because they tend to live closely and form consortia. no anme- was detected in s and s about 2% of anme- was detected in the aggregates. the average value and standard error were calculated based on fields of view on each hybridization. no anme- cell or aggregate was observed based on our method. detection limit of × cells/ml slurry. detection limit of × cells/ml slurry the card-fish result showed that a large part of biomass in s and s especially single cells, did not belong to anme or srb. there was growth of other unknown microbes within a mixed community of anme/srb. therefore a clone library analysis was performed on s to approach to the complete archaeal and bacterial communities. archaeal community had extremely low diversity, where anme-2a and mbg-d were the only two groups of archaea detected. anme-2a was the dominant, which accounted for 88% of the archaeal community. no 16s rrna gene from anme- was detected. the absence of anme- in the archaeal clone library was contradictory to card-fish result. the size of the clone library was not large enough to detect the rare anme- or the hybridization experiment may have led to mis-hybridization, thus giving false positive signal. dissimilar from archaeal community, the bacterial community was highly diverse. gammaproteobacteria were the most dominant followed by the deltaproteobacteria, which includes the srb. among total bacteria population in s 8% was belonging to seep-srb1a subgroup of deltaproteobacteria, which were found to be specifically associated with anme-2a in other enrichments mediating sr-aom process. most of the gammaproteobacteria found in the community were closely related to methylophaga sp. and methylobacter sp., which are known to use reduced one-carbon compounds, such as methane, methanol or dimethylsulphide. the presence of such bacteria in our anaerobic reactor is intriguing since methane and sulphate were the only electron donor and acceptor supplied. the presence and even production of sulphide was an indication of anaerobic condition inside the reactor. however we cannot exclude the possibility of a limited amount of dissolved oxygen in the reactor influent, which could explain the presence of aerobic. further tests need to show if these gammaproteobacteria are playing an important active role in the reactor. enrichment of anme- and srb card-fish results showed that percentages of anme- and srb biovolume increased from ± % and ± % in s to ± % and ± % in s. by combining with the total biovolume data from dapi staining, the biovolume of anme- in s was: * % = * μm3/ml slurry the biovolume of anme- in s was: * % = * μm3/ml slurry therefore after days incubation, the anme- population increased for times. following the same method of calculation, the srb population increased for times after days incubation in this high-pressure bioreactor. the populations of anme- and srb both increased faster than the total biomass, which indicated that anme- and srb were selectively enriched in the system. this selective enrichment of anme- and srb was another proof that the incubation condition inside this high-pressure bioreactor was favourable for sr-aom community. to our knowledge, this is the first report on the enrichment of sr-aom community under high methane pressure, although potential growth of anme- anme- and srb has been reported in other engineered systems at ambient or low methane pressures. the different inocula showed different doubling times. when anme- and anme-2c were incubated in continuous flow bioreactors under ambient methane partial pressure, anme- had doubling time of months while anme-2c had doubling time of months. high methane partial pressure appeared to have advantage on stimulating the growth of anme. in the experiment of krüger et al., the methane-dependent uptake of 15n-nh by aom community dominated by anme- was higher at mpa methane pressure than at ambient methane pressure. if we assume the anme-2a cells in our system were following a logarithmic growth curve, a doubling time of months can be estimated based on anme- biovolume in s and s which is shorter than the result obtained by meulepas et al.. the increase of energy gained from sr-aom process by increasing methane pressure may favour the biomass growth. continuous flow also stimulated growth: anme-2a/2c had longer doubling time in a fed-batch bioreactor than in continuous flow bioreactors.  after days incubation in a simulated cold seep environment under high methane pressure, anme- and srb in the sediment from captain arutyunov mud volcano were enriched. based on biovolume calculation, the populations of anme- and srb increased for times and times. within total biomass volume, % was accounted from aggregates. therefore the incubation condition apparently favoured the cells to form aggregates, especially in small size, rather than to live as single cells. no aggregate bigger than μm in diameter was observed; they apparently divided after reaching a critical size. based on the 16s rrna gene clone library, the archaeal diversity was low, and contained only anme- and mbg-d. in contrast, the bacterial community was highly diverse. ",pubmed_generic,GPT 3.5,The process consumes more than 90% of the methane produced in marine sediments and fuels the deep-sea ecosystem by channelling thermal-generated and biogenetic methane into organic matter and carbonate.,non_factual,factual,minor,,intrinsic,,,,,
81,ee480fee-4489-42b6-9c5d-d16df6b2ccc8_flant5_gen,genomorama is a stand-alone tool for interactively displaying and analyzing multiple genomes.," with the rapid growth in the number of sequenced genomes has come a corresponding proliferation of computational tools for viewing, comparing and searching genome sequences and annotations. tools can be divided into two broad categories, database-client and stand-alone. in general, database-client tools offer static visualizations of small sets of predefined genomes, while stand-alone tools allow interactive visualizations of locally stored genomes. stand-alone tools can serve as graphical front ends for displaying the output of locally run calculations. a high level comparison of common features for these stand-alone tools is shown in table and reveals several trends and patterns. almost all of the tools are implemented in an interpreted language. while this provides for cross platform portability, the responsiveness of these applications is poor. while all of the tools can display genome annotations, additional functionalities vary widely between programs. aprograms that use java, tcl/tk and perl are expected to run on any operating system. bcommon file formats include the genbank flat file, embl flat file, nucleic acid sequence file, general feature format and protein table file. a complete list of genome annotation file formats can be found on the genomorama project webpage. cthe graphic output format labeled ""printer"" indicates direct output to an attached printer. not content with the performance or feature set of existing programs, we wrote genomorama, a stand-alone tool originally developed to assist in computational signature design for bacterial and viral pathogen detection. genomorama allows users designing dna-based hybridization assays, such as pcr or dna probes, to easily identify the regions of a genome targeted by a given assay. it is distinguished from existing tools by dna hybridization-based sequence searching, its rapid execution speed, and ability to read and export a diverse set of common file formats. despite its origins as a viewer for viral and bacterial genomes, genomorama can also visualize large eukaryotic genomes. implementation genomorama is a software program for interactively displaying and analyzing multiple genomes. it provides a powerful yet easy to use interface that leverages the visualization power of modern computers and the substantial bioinformatic infrastructure provided by the ncbi. genomorama is written in portable, highly optimized c++ and comes in three ""flavors"" that allow it to run natively on modern operating systems: os x, microsoft windows and linux. the motif version allows any x-windows client that supports opengl to remotely run genomorama. executables and source code are freely provided for all flavors.  to visualize and compare annotated genome features at all relevant size scales, genomes are displayed on the computer screen as linear, scale-dependent maps. the user interacts with a map using the mouse, keyboard and scroll bars. semantic zooming is used to display genomic features which occur at a wide range of scales, i.e. ~ bases for a mammalian gene, ~ bases for a pathogenicity island, ~ bases for a bacterial gene, ~ bases for a trna, ~ bases for a transcription factor binding site and for a single nucleotide polymorphism. optional 2d graphs, including %g+c, gc skew and external data sets, can be superimposed on genome maps. publication quality, wysiwyg images can be saved in either gif or postscript formats. genome annotations and sequences are available in a large number of file formats and genomorama can read a substantial subset of these formats, including genbank, european molecular biology laboratory, abstract syntax notation one, protein table and fasta. unlike existing programs, genomorama can read the multi-part gbk, embl and asn. files used to store annotations and sequence for partially assembled sequences for both prokaryotic and eukaryotic organisms. the ability to load multipart annotation files allows access to preliminary annotation information provided by sequencing centers during the whole genome shotgun sequencing of an organism. a screen shot of five contigs and associated sequencing quality scores from the genome sphingopyxis alaskensis rb is shown in figure genomorama can load large genomes. support for large genomes is crucial for visualizing entire eukaryotic chromosomes. a comparison between loading times for genomorama and two java-based visualization tools is shown in figure conservative memory usage and efficient c++ implementation enable genomorama to load the sequence and annotations for human chromosome substantially faster than either of the java-based programs on a range of desktop computers. to assist in experimental design and analysis, genomorama provides dna hybridization-based searches to identify probe binding locations and pcr amplification products. given a pair of pcr primers, genomorama will display all corresponding pcr amplicons from a target sequence. both traditional pcr primer and padlock probe queries are supported. these searches employ a sequence similarity criteria defined by dna melting temperature, which allows for non-watson and crick base pairing, and an optional number of exact matching bases at the 3' end of each primer. all possible combinations of the forward and reverse pcr primers are tested. in contrast, existing in-silico pcr tools are either inflexible or rely on heuristic similarity measures. genomorama also performs primer prediction by computing all potential forward and reverse pcr primers that satisfy primer length, melting temperature, %g+c and heuristic base composition requirements. an example of pcr primer based searching, using the b. anthracis specific primers, is shown in figure finally, sequence searching is sensitive to the topology of the target dna molecule and, as a result, can identify query matches that span the start/stop of circular genomes.  genomorama is an easy to use computational tool for a number of genome comparison tasks, including real time display of multiple genomes, high quality output and novel hybridization based sequence searching. availability and requirements • project name: genomorama • project homepage: • operating systems: os x, windows, linux • programming language: c++ • license: freely available • any restrictions on use by non-academics: no authors' contributions jg wrote the program and documentation. mw oversaw the development process. both authors prepared and approved the manuscript. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
82,ee480fee-4489-42b6-9c5d-d16df6b2ccc8_gpt3_gen,"The article discusses the two categories of computational tools available for viewing, comparing and searching genome sequences and annotations, namely database-client and stand-alone tools. Stand-alone tools allow interactive visualizations of locally stored genomes and can serve as graphical front ends for displaying the output of locally run calculations. The article introduces Genomorama, a stand-alone tool originally developed to assist in computational signature design for bacterial and viral pathogen detection. It allows users designing DNA-based hybridization assays to identify the regions of a genome targeted by a given assay. The article highlights the features of Genomorama, including its rapid execution speed, ability to read and export a diverse set of common file formats, and ability to load multipart annotation files that allow access to preliminary annotation information provided by sequencing centers. Genomorama also provides DNA hybridization-based searches to identify probe binding locations and PCR amplification products. Finally, the article concludes that Genomorama is an easy-to-use computational tool for a number of genome comparison tasks."," with the rapid growth in the number of sequenced genomes has come a corresponding proliferation of computational tools for viewing, comparing and searching genome sequences and annotations. tools can be divided into two broad categories, database-client and stand-alone. in general, database-client tools offer static visualizations of small sets of predefined genomes, while stand-alone tools allow interactive visualizations of locally stored genomes. stand-alone tools can serve as graphical front ends for displaying the output of locally run calculations. a high level comparison of common features for these stand-alone tools is shown in table and reveals several trends and patterns. almost all of the tools are implemented in an interpreted language. while this provides for cross platform portability, the responsiveness of these applications is poor. while all of the tools can display genome annotations, additional functionalities vary widely between programs. aprograms that use java, tcl/tk and perl are expected to run on any operating system. bcommon file formats include the genbank flat file, embl flat file, nucleic acid sequence file, general feature format and protein table file. a complete list of genome annotation file formats can be found on the genomorama project webpage. cthe graphic output format labeled ""printer"" indicates direct output to an attached printer. not content with the performance or feature set of existing programs, we wrote genomorama, a stand-alone tool originally developed to assist in computational signature design for bacterial and viral pathogen detection. genomorama allows users designing dna-based hybridization assays, such as pcr or dna probes, to easily identify the regions of a genome targeted by a given assay. it is distinguished from existing tools by dna hybridization-based sequence searching, its rapid execution speed, and ability to read and export a diverse set of common file formats. despite its origins as a viewer for viral and bacterial genomes, genomorama can also visualize large eukaryotic genomes. implementation genomorama is a software program for interactively displaying and analyzing multiple genomes. it provides a powerful yet easy to use interface that leverages the visualization power of modern computers and the substantial bioinformatic infrastructure provided by the ncbi. genomorama is written in portable, highly optimized c++ and comes in three ""flavors"" that allow it to run natively on modern operating systems: os x, microsoft windows and linux. the motif version allows any x-windows client that supports opengl to remotely run genomorama. executables and source code are freely provided for all flavors.  to visualize and compare annotated genome features at all relevant size scales, genomes are displayed on the computer screen as linear, scale-dependent maps. the user interacts with a map using the mouse, keyboard and scroll bars. semantic zooming is used to display genomic features which occur at a wide range of scales, i.e. ~ bases for a mammalian gene, ~ bases for a pathogenicity island, ~ bases for a bacterial gene, ~ bases for a trna, ~ bases for a transcription factor binding site and for a single nucleotide polymorphism. optional 2d graphs, including %g+c, gc skew and external data sets, can be superimposed on genome maps. publication quality, wysiwyg images can be saved in either gif or postscript formats. genome annotations and sequences are available in a large number of file formats and genomorama can read a substantial subset of these formats, including genbank, european molecular biology laboratory, abstract syntax notation one, protein table and fasta. unlike existing programs, genomorama can read the multi-part gbk, embl and asn. files used to store annotations and sequence for partially assembled sequences for both prokaryotic and eukaryotic organisms. the ability to load multipart annotation files allows access to preliminary annotation information provided by sequencing centers during the whole genome shotgun sequencing of an organism. a screen shot of five contigs and associated sequencing quality scores from the genome sphingopyxis alaskensis rb is shown in figure genomorama can load large genomes. support for large genomes is crucial for visualizing entire eukaryotic chromosomes. a comparison between loading times for genomorama and two java-based visualization tools is shown in figure conservative memory usage and efficient c++ implementation enable genomorama to load the sequence and annotations for human chromosome substantially faster than either of the java-based programs on a range of desktop computers. to assist in experimental design and analysis, genomorama provides dna hybridization-based searches to identify probe binding locations and pcr amplification products. given a pair of pcr primers, genomorama will display all corresponding pcr amplicons from a target sequence. both traditional pcr primer and padlock probe queries are supported. these searches employ a sequence similarity criteria defined by dna melting temperature, which allows for non-watson and crick base pairing, and an optional number of exact matching bases at the 3' end of each primer. all possible combinations of the forward and reverse pcr primers are tested. in contrast, existing in-silico pcr tools are either inflexible or rely on heuristic similarity measures. genomorama also performs primer prediction by computing all potential forward and reverse pcr primers that satisfy primer length, melting temperature, %g+c and heuristic base composition requirements. an example of pcr primer based searching, using the b. anthracis specific primers, is shown in figure finally, sequence searching is sensitive to the topology of the target dna molecule and, as a result, can identify query matches that span the start/stop of circular genomes.  genomorama is an easy to use computational tool for a number of genome comparison tasks, including real time display of multiple genomes, high quality output and novel hybridization based sequence searching. availability and requirements • project name: genomorama • project homepage: • operating systems: os x, windows, linux • programming language: c++ • license: freely available • any restrictions on use by non-academics: no authors' contributions jg wrote the program and documentation. mw oversaw the development process. both authors prepared and approved the manuscript. ",pubmed_generic,GPT 3.5,"The article discusses the two categories of computational tools available for viewing, comparing and searching genome sequences and annotations, namely database-client and stand-alone tools.",factual,factual,,,,,,,,THIS IS CORRECT
83,e2bd1717-7db8-4ac8-89e7-8bb290f19623_flant5_gen,"vaxijen is the first server for alignment-independent prediction of protective antigens of bacterial, viral and tumour origin. the server contains models derived by acc pre-processing of amino acids properties. the predictive ability of our models was tested by internal leave-one-out cross-validation on training sets and by external validation on test sets. acc matrices were imported into simca-p and were subject to a two-class discriminant analysis using the partial least squares technique. the models were validated using leave-one-out cross-validation on the whole sets and by external validation using test sets. the models were developed as a mean of the best five models, as assessed by loo-cv. the validation results were assessed in terms of aucroc, accuracy, sensitivity and specificity, as described in the methods section. additionally, five negative sets were compiled, and subsequently combined with the positive set to generate five new training sets. they also underwent da-pls and their aucroc, accuracy, sensitivity and specificity are given as mean values. the models were validated using leave-one-out cross-validation on the whole sets and by external validation using test sets. the models showed remarkable stability, as tested by combinations of the positive set and five different negative sets. thus, vaxijen is a reliable and consistent tool for the prediction of protective antigens."," vaccination is a highly effective approach to disease control in human and veterinary health care. a vaccine is a molecular or supramolecular agent which elicits specific, protective immunity; that is an enhanced adaptive immune response to re-infection by pathogenic microbes through the potentiation of immune memory. vaccination ultimately mitigates the effect of subsequent infection and disease. thus, the immune system recognizes vaccine agents as foreign, destroys them, and subsequently'remembers' them. when the pathogenic microorganism is encountered again, the immune system has been primed to respond, by neutralizing the target before it can enter cells, or/and by destroying infected cells before the microorganism can grow and cause damage. vaccines have contributed to the eradication of smallpox, the near eradication of polio, and the control of a variety of diseases, including rubella, measles, mumps, chickenpox, typhoid. vaccines from the pre-genomic era were based on killed or live, but attenuated, microorganisms, or subunits purified from them. subunit vaccines contain one or more pure or semi-pure antigens. in order to develop subunit vaccines, it is critical to identify those proteins which are important for inducing protection and to eliminate others. an antigen is said to be protective if it is able to induce protection from subsequent challenge by a disease-causing infective agent in an appropriate animal model following immunization. the empirical approach to sub-unit vaccine development, which includes several steps, begins with pathogen cultivation, followed by purification into components, and then testing of antigens for protection. apart from being time- and labour-consuming, this approach has several limitations that can lead to failure. vaccines can not be developed using this approach for microorganisms which can not easily be cultured and only allows for the identification of those antigens which can be obtained in sufficient quantities. in some cases, the most abundant proteins are not immunoprotective. in other cases, the antigen expressed during in vivo infection is not expressed during in vitro cultivation. genomics has revolutionized vaccine research. the ability to sequence the whole genome of a virulent microorganism has led some to screen in silico for the most probable protective antigens before undertaking confirmatory experiments. this approach, known as reverse vaccinology, was first used to identify antigens as potential candidate vaccines against serogroup b meningococcus. apart from obvious advantages – such as speed and low cost – the success of this approach is dependent on the accuracy of antigen prediction, and many bioinformatics tools are available to facilitate this process. they can identify surface-associated or outer membrane proteins, signal peptides, lipoproteins, or host-cell binding domains. most algorithms use sequence alignment to identify antigens. this is problematic for several reasons. some proteins formed through divergent or convergent evolution lack obvious sequence similarity, although they may share similar structures and biological properties. in such a situation, alignment-based approaches may produce ambiguous results or fail. moreover, antigenicity, as a property, may be encoded in a sequence in a subtle and recondite manner not amendable to direct identification by sequence alignment. likewise, the discovery of truly novel antigens will be frustrated by their lack of similarity to antigens of known provenance. to overcome the limitations of alignment-dependent sequence similarity methods, we propose a new alignment-independent method for antigen prediction based on auto cross covariance transformation of protein sequences into uniform equal-length vectors. acc is an protein sequence mining method developed by wold et al., which has been applied to quantitative structure-activity relationships studies of peptides with different length and for protein classification. the acc transformation accounts for neighbour effects, i.e. the lack of independence between different sequence positions. in the present study, we applied acc pre-processing to sets of known bacterial, viral and tumour antigens and developed alignment-independent models for antigen recognition based on the main chemical properties of amino acid sequences. the principal properties of the amino acids were represented by z descriptors, originally derived by hellberg et al. to describe amino acid hydrophobicity, molecular size and polarity. the models were implemented in a server for the prediction of protective antigens and subunit vaccines, which we call vaxijen. this is freely accessible via the world wide web. our method is the first alignment-free bioinformatics tool for the in silico identification of antigens.  three datasets were used in this study: one for bacteria, one for viruses, and one for tumours. each set consisted of known antigens and non-antigens, collected as described in the methods section. each amino acid in the protein sequence was represented by three z descriptors: z z and z each protein was transformed into a uniform vector, which consisted of acc terms, by applying acc pre-processing, as described in the methods section. the new matrices were imported into simca-p and were subject to a two-class discriminant analysis using the partial least squares technique. the models were validated using leave-one-out cross-validation on the whole sets and by external validation using test sets. the test sets were selected randomly to include 25% of the whole sets. then models were developed based on the remaining 75% and tested on the excluded proteins. the validation results were assessed in terms of aucroc, accuracy, sensitivity and specificity, as described in the methods section. additionally, five negative sets were compiled, and subsequently combined with the positive set to generate five new training sets. they also underwent da-pls and their aucroc, accuracy, sensitivity and specificity are given as mean values. within the server, the final model for each type was derived as a mean of the best five models, as assessed by loo-cv. vaxijen model for prediction of protective bacterial antigens the loo-cv of the bacterial model had 82% accuracy, 91% sensitivity and 72% specificity. as expected, the external validation showed a lower value but was still satisfactory. the roc curves are shown in figure the average values for the additional sets were very close to those derived for the initial model. athe area under the curve is a quantitative measure of the predictive ability and varies from for a random prediction to for a perfect prediction. bthe threshold of the highest accuracy. caccuracy = /total. dsensitivity = true antigens/all antigens. especificity = true non-antigens/all non-antigens. gmean values of five training sets. vaxijen model for prediction of protective viral antigens the viral model performed very well in the loo-cv; performance in the external validation was more moderate. roc curves of the viral model validation are shown in figure the additional training sets showed lower mean accuracy, sensitivity and specificity. vaxijen model for prediction of tumour antigens the tumour model had excellent performance both in the loo-cv and in the external validation, exhibiting more than 85% accuracy. the roc curves are shown in figure the additional models had lower sensitivity but similar specificity and accuracy. sequence similarity of training set potential similarity between sequences in the antigen and non-antigen sets was assessed as described. the viral and bacterial protective antigen sequence sets show very little sequence similarity. this reflects their diverse species origins. the tumour set, derived from a single proteome, exhibits a higher internal degree of self-similarity, but is still clearly highly diverse. vaxijen server the loo-cv bacterial, viral and tumour models were included in the vaxijen server. protein sequences can be submitted as single proteins or uploaded as a multiple sequence file in fasta format. a single target organism can be selected. additionally, acc coefficients can be output. this option makes the server useful for general acc calculations of proteins. the results page lists the selected target, the protein sequence, its prediction probability, and a statement of protective antigen or non-antigen, according to a predefined cutoff. since more of the models had their highest accuracy at a threshold of, this threshold value was chosen for all types. discussion vaxijen is the first server for alignment-independent prediction of protective antigens of bacterial, viral and tumour origin. the server contains models derived by acc pre-processing of amino acids properties. the predictive ability of our models was tested by internal leave-one-out cross-validation on training sets and by external validation on test sets. accuracies of internal and external validation for the three models lie in the range 70% to 89%. the models showed remarkable stability, as tested by combinations of the positive set and five different negative sets. thus, vaxijen is a reliable and consistent tool for the prediction of protective antigens. it can be used singly or in combination with other bioinformatics tools used for reverse vaccinology. the z descriptors are highly condensed descriptors, and are derived from a principal component analysis of experimental or calculated physicochemical properties of the twenty naturally occurring amino acids. they correspond to the first three principal components explaining the variance in the set: z represents hydrophobicity, z steric properties, and z polarity of the amino acids. since their creation, z descriptors have been widely used for the characterization and classification of proteins, and in qsar studies on peptides. recently, we have found that z descriptors are good predictors of mhc binding peptides. in the present study, z descriptors represent the main physicochemical properties important for the recognition of antigens. acc transformations were used to remove irrelevant information, such as sequence length, and to amplify the class-discriminating properties. sjostrom et al applied the acc transformation to z scale values in order to assign successfully the subcellular location of bacterial proteins. more recently, a similar method was applied to g-protein coupled receptors and succeeded in classifying them into their major classes. as antigenicity is not a simple, readily-interpreted linear property, it is unsurprising that acc pre-processing of the physicochemical properties of antigens and non-antigens allows for a good discrimination between them. the recognition of protective antigens arises synergistically from a combination of intermolecular interactions which involves a diverse variety of underlying features – steric, electrostatic and hydrophobic – which are explained well by the three z descriptors. the most important result of the present work is the ability of the models to predict whether a protein sequence will, or will not, be a protective antigen. such antigens form the basis of subunit vaccines. in order to facilitate the use of the derived models, a server, named vaxijen, was developed to allow users to assess a protein's ability to induce protection. the server deals with single proteins as well as whole proteomes submitted in fasta format. as the method is general, models for parasite and fungal antigens will be developed in the future and included in the vaxijen server.  vaxijen is the first server for alignment-independent prediction of protective antigens. it was developed to allow antigen classification based solely on the physicochemical properties of the protein irrespective of sequence length and the need for alignment. vaxijen is an open system: new models will be included in the future, old ones will be improved. the server can be used singly or in combination with alignment-dependent prediction methods. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
84,e2bd1717-7db8-4ac8-89e7-8bb290f19623_gpt3_gen,"The article discusses the importance of vaccination in disease control and the use of genomics in vaccine research. Traditional vaccine development methods have limitations such as time and labor and may not work for microorganisms that are difficult to culture. Reverse vaccinology, a method that uses in silico screening of virulent microorganisms for potential protective antigens, has been successful. However, traditional alignment-dependent methods for identifying antigens have limitations, so a new alignment-independent method called auto cross covariance transformation (ACC) was proposed. This method uses amino acid property descriptors and ACC to transform protein sequences into uniform vectors for antigen recognition. The resulting models were validated through internal and external testing sets and were incorporated into an open server for the prediction of protective antigens and subunit vaccines called Vaxijen. The server can be used for bacterial, viral, and tumor antigens and does not require sequence alignment, making it a reliable and consistent tool for predicting protective antigens."," vaccination is a highly effective approach to disease control in human and veterinary health care. a vaccine is a molecular or supramolecular agent which elicits specific, protective immunity; that is an enhanced adaptive immune response to re-infection by pathogenic microbes through the potentiation of immune memory. vaccination ultimately mitigates the effect of subsequent infection and disease. thus, the immune system recognizes vaccine agents as foreign, destroys them, and subsequently'remembers' them. when the pathogenic microorganism is encountered again, the immune system has been primed to respond, by neutralizing the target before it can enter cells, or/and by destroying infected cells before the microorganism can grow and cause damage. vaccines have contributed to the eradication of smallpox, the near eradication of polio, and the control of a variety of diseases, including rubella, measles, mumps, chickenpox, typhoid. vaccines from the pre-genomic era were based on killed or live, but attenuated, microorganisms, or subunits purified from them. subunit vaccines contain one or more pure or semi-pure antigens. in order to develop subunit vaccines, it is critical to identify those proteins which are important for inducing protection and to eliminate others. an antigen is said to be protective if it is able to induce protection from subsequent challenge by a disease-causing infective agent in an appropriate animal model following immunization. the empirical approach to sub-unit vaccine development, which includes several steps, begins with pathogen cultivation, followed by purification into components, and then testing of antigens for protection. apart from being time- and labour-consuming, this approach has several limitations that can lead to failure. vaccines can not be developed using this approach for microorganisms which can not easily be cultured and only allows for the identification of those antigens which can be obtained in sufficient quantities. in some cases, the most abundant proteins are not immunoprotective. in other cases, the antigen expressed during in vivo infection is not expressed during in vitro cultivation. genomics has revolutionized vaccine research. the ability to sequence the whole genome of a virulent microorganism has led some to screen in silico for the most probable protective antigens before undertaking confirmatory experiments. this approach, known as reverse vaccinology, was first used to identify antigens as potential candidate vaccines against serogroup b meningococcus. apart from obvious advantages – such as speed and low cost – the success of this approach is dependent on the accuracy of antigen prediction, and many bioinformatics tools are available to facilitate this process. they can identify surface-associated or outer membrane proteins, signal peptides, lipoproteins, or host-cell binding domains. most algorithms use sequence alignment to identify antigens. this is problematic for several reasons. some proteins formed through divergent or convergent evolution lack obvious sequence similarity, although they may share similar structures and biological properties. in such a situation, alignment-based approaches may produce ambiguous results or fail. moreover, antigenicity, as a property, may be encoded in a sequence in a subtle and recondite manner not amendable to direct identification by sequence alignment. likewise, the discovery of truly novel antigens will be frustrated by their lack of similarity to antigens of known provenance. to overcome the limitations of alignment-dependent sequence similarity methods, we propose a new alignment-independent method for antigen prediction based on auto cross covariance transformation of protein sequences into uniform equal-length vectors. acc is an protein sequence mining method developed by wold et al., which has been applied to quantitative structure-activity relationships studies of peptides with different length and for protein classification. the acc transformation accounts for neighbour effects, i.e. the lack of independence between different sequence positions. in the present study, we applied acc pre-processing to sets of known bacterial, viral and tumour antigens and developed alignment-independent models for antigen recognition based on the main chemical properties of amino acid sequences. the principal properties of the amino acids were represented by z descriptors, originally derived by hellberg et al. to describe amino acid hydrophobicity, molecular size and polarity. the models were implemented in a server for the prediction of protective antigens and subunit vaccines, which we call vaxijen. this is freely accessible via the world wide web. our method is the first alignment-free bioinformatics tool for the in silico identification of antigens.  three datasets were used in this study: one for bacteria, one for viruses, and one for tumours. each set consisted of known antigens and non-antigens, collected as described in the methods section. each amino acid in the protein sequence was represented by three z descriptors: z z and z each protein was transformed into a uniform vector, which consisted of acc terms, by applying acc pre-processing, as described in the methods section. the new matrices were imported into simca-p and were subject to a two-class discriminant analysis using the partial least squares technique. the models were validated using leave-one-out cross-validation on the whole sets and by external validation using test sets. the test sets were selected randomly to include 25% of the whole sets. then models were developed based on the remaining 75% and tested on the excluded proteins. the validation results were assessed in terms of aucroc, accuracy, sensitivity and specificity, as described in the methods section. additionally, five negative sets were compiled, and subsequently combined with the positive set to generate five new training sets. they also underwent da-pls and their aucroc, accuracy, sensitivity and specificity are given as mean values. within the server, the final model for each type was derived as a mean of the best five models, as assessed by loo-cv. vaxijen model for prediction of protective bacterial antigens the loo-cv of the bacterial model had 82% accuracy, 91% sensitivity and 72% specificity. as expected, the external validation showed a lower value but was still satisfactory. the roc curves are shown in figure the average values for the additional sets were very close to those derived for the initial model. athe area under the curve is a quantitative measure of the predictive ability and varies from for a random prediction to for a perfect prediction. bthe threshold of the highest accuracy. caccuracy = /total. dsensitivity = true antigens/all antigens. especificity = true non-antigens/all non-antigens. gmean values of five training sets. vaxijen model for prediction of protective viral antigens the viral model performed very well in the loo-cv; performance in the external validation was more moderate. roc curves of the viral model validation are shown in figure the additional training sets showed lower mean accuracy, sensitivity and specificity. vaxijen model for prediction of tumour antigens the tumour model had excellent performance both in the loo-cv and in the external validation, exhibiting more than 85% accuracy. the roc curves are shown in figure the additional models had lower sensitivity but similar specificity and accuracy. sequence similarity of training set potential similarity between sequences in the antigen and non-antigen sets was assessed as described. the viral and bacterial protective antigen sequence sets show very little sequence similarity. this reflects their diverse species origins. the tumour set, derived from a single proteome, exhibits a higher internal degree of self-similarity, but is still clearly highly diverse. vaxijen server the loo-cv bacterial, viral and tumour models were included in the vaxijen server. protein sequences can be submitted as single proteins or uploaded as a multiple sequence file in fasta format. a single target organism can be selected. additionally, acc coefficients can be output. this option makes the server useful for general acc calculations of proteins. the results page lists the selected target, the protein sequence, its prediction probability, and a statement of protective antigen or non-antigen, according to a predefined cutoff. since more of the models had their highest accuracy at a threshold of, this threshold value was chosen for all types. discussion vaxijen is the first server for alignment-independent prediction of protective antigens of bacterial, viral and tumour origin. the server contains models derived by acc pre-processing of amino acids properties. the predictive ability of our models was tested by internal leave-one-out cross-validation on training sets and by external validation on test sets. accuracies of internal and external validation for the three models lie in the range 70% to 89%. the models showed remarkable stability, as tested by combinations of the positive set and five different negative sets. thus, vaxijen is a reliable and consistent tool for the prediction of protective antigens. it can be used singly or in combination with other bioinformatics tools used for reverse vaccinology. the z descriptors are highly condensed descriptors, and are derived from a principal component analysis of experimental or calculated physicochemical properties of the twenty naturally occurring amino acids. they correspond to the first three principal components explaining the variance in the set: z represents hydrophobicity, z steric properties, and z polarity of the amino acids. since their creation, z descriptors have been widely used for the characterization and classification of proteins, and in qsar studies on peptides. recently, we have found that z descriptors are good predictors of mhc binding peptides. in the present study, z descriptors represent the main physicochemical properties important for the recognition of antigens. acc transformations were used to remove irrelevant information, such as sequence length, and to amplify the class-discriminating properties. sjostrom et al applied the acc transformation to z scale values in order to assign successfully the subcellular location of bacterial proteins. more recently, a similar method was applied to g-protein coupled receptors and succeeded in classifying them into their major classes. as antigenicity is not a simple, readily-interpreted linear property, it is unsurprising that acc pre-processing of the physicochemical properties of antigens and non-antigens allows for a good discrimination between them. the recognition of protective antigens arises synergistically from a combination of intermolecular interactions which involves a diverse variety of underlying features – steric, electrostatic and hydrophobic – which are explained well by the three z descriptors. the most important result of the present work is the ability of the models to predict whether a protein sequence will, or will not, be a protective antigen. such antigens form the basis of subunit vaccines. in order to facilitate the use of the derived models, a server, named vaxijen, was developed to allow users to assess a protein's ability to induce protection. the server deals with single proteins as well as whole proteomes submitted in fasta format. as the method is general, models for parasite and fungal antigens will be developed in the future and included in the vaxijen server.  vaxijen is the first server for alignment-independent prediction of protective antigens. it was developed to allow antigen classification based solely on the physicochemical properties of the protein irrespective of sequence length and the need for alignment. vaxijen is an open system: new models will be included in the future, old ones will be improved. the server can be used singly or in combination with alignment-dependent prediction methods. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
85,bd16ecf4-656d-4c53-84e2-b99023cfdf9c_gpt3_gen,"The article discusses the importance of proper reference gene selection for accurate evaluation of gene expression levels in human embryonic stem cell (hESC) differentiation experiments. Pluripotent hESCs have the potential to differentiate into all cell types of the adult body and are valuable for investigating cell differentiation and development mechanisms. Differentiation can be induced in vitro under specific culture conditions, such as the addition of retinoic acid. Reverse transcription quantitative polymerase chain reaction (RT-qPCR) is well-suited for monitoring pluripotency and differentiation, but proper normalization of gene expression levels is essential for data interpretation. The study used the genormplus algorithm to identify the most stable reference loci for differentiation induced by retinoic acid and found that β-2-microglobulin, ribosomal protein L13a, and Alu repeats were the most stable reference genes. The article also proposes a new normalization strategy based on measured Alu repeat expression for reliable RT-qPCR normalization in hESC differentiation experiments."," human embryonic stem cells, derived from the inner cell mass of a blastocyst stage embryo, are able to differentiate into all cell types of the adult body and have the potential for unlimited growth. as a consequence of their pluripotency and self-renewal capacity, hes cells are ideal for investigating the basic mechanisms of development and cell differentiation. in addition, they may be a source of differentiated cells of a particular cell type, to be used in toxicity screening, cell replacement therapies and many other applications. pluripotent cells are characterized by several features, such as the expression of pluripotency factors, nanog and sox ), the presence of specific cell surface antigens, and distinct chromatin signatures. to date, the molecular basic mechanisms of hes cell differentiation and development are largely unknown. differentiation can be induced in vitro under specific culture conditions, such as the addition of retinoic acid, a morphogen commonly used for multilineage differentiation of es cells in general and for specific development along the neural lineage. amongst other techniques, reverse transcription quantitative polymerase chain reaction is very well suited for monitoring pluripotency and differentiation, as it allows accurate messenger rna quantification of numerous samples at the same time. in the context of hes cell characterization, rt-qpcr is applied for evaluating the expression of the transcription factors oct and nanog, since the expression of these core pluripotency circuitry members decreases significantly within a few days after onset of differentiation. for proper rt-qpcr data evaluation, several variables need to be taken into account. these include sample handling and storage, starting material quantity and quality, efficiency of different enzymatic reaction steps and overall transcriptional activity differences between cells. to correct for these variables, different normalization methods have been reported. gene expression levels can be standardized to cell number, however, it is not always possible to obtain an accurate enumeration of cells. in addition, this strategy does not consider possible insufficient enzymatic reaction efficiencies. alternatively, data are normalized for rna mass quantity, although this is not always representative for the mrna content. ribosomal rna molecules make up the major part of the total rna mass and may be regulated, thus resulting in a variable rrna/mrna ratio. the most frequently utilized strategy is the inclusion of one or preferably more reference genes as an internal standard. the expression of these references should ideally not vary between cells of interest or as a consequence of experimental handling. selecting stable reference genes is critical for correct interpretation of rt-qpcr data. however, when studying differentiating hes cells, proper reference gene selection is not straightforward. differentiation does not only include various morphological changes, but also major alterations in gene expression levels of numerous genes. the regulation of some reference genes may be associated with these cellular changes, hence the stability of the used references has to be evaluated. the available differentiation protocols may induce distinct gene expression variability, which impedes finding stably expressed reference genes over the different samples and making protocol-dependent optimization required. in this study, we emphasize the importance of determining suitable reference genes by performing an expression stability analysis for retinoic acid induced differentiating hes cells, using the genormplus algorithm in the qbaseplus software. the possibility of co-regulation was reduced by opting for candidate reference genes from different functional categories. in addition to these candidates, a new normalization strategy was applied, based on the measurement of expressed alu repeats. alu insertions are repetitive dna sequences, approximately base pairs long and occurring generally at high copy number in introns, 3′ untranslated regions of genes and intergenic genomic regions. these short interspersed mobile elements are not equally spread throughout the human genome, since they preferentially accumulate in gene-rich regions. in total, alu elements comprise more than 10% of the genome mass, thus being the most abundant of all mobile elements and they are divided in several well-conserved subfamilies. alu repeats, named after a recognition site for the restriction enzyme alu i, are thought to be amplified by retrotransposition, a process in which the alu element is transcribed by rna polymerase iii, followed by reverse transcription and incorporation into the genome. because of their genome-wide distribution, including in the 3′ utr of protein coding genes, individual gene expression variability in the cells of interest will not substantially influence total alu element expression. this feature makes the alu repeats a valuable and interesting strategy for rt-qpcr normalization for biological systems such as differentiating stem cells.  human es cells were induced to differentiate for several days by addition of retinoic acid to the culture medium. the fading undifferentiated state of hes cells was assessed morphologically, using light microscopy. differentiation was initially visible at the colony periphery where cells start to pile-up, and in comparison to undifferentiated cells, differentiating colonies lost their round shape with well-defined borders, as illustrated in figure  to confirm differentiation, the expression levels of pluripotency genes pou5f and nanog can be followed over time using rt-qpcr. for this purpose, the most stable normalization references were determined by means of a stability analysis using the genormplus application in qbaseplus. the stability of candidate references was analyzed for a first series of samples, which were isolated every 24 hours during 8 days of differentiation. in the stability ranking, β-2-microglobulin, ribosomal protein l13a and alu repeats were found to be the most stable reference loci for this experimental set-up. the stability measure of these three references varied from to, which indicates a high stability in comparison to the other candidates, as m values up to are considered acceptably stable for homogenous samples. in the determination of the optimal reference number, two appeared to be sufficient for rt-qpcr normalization, as the pairwise variation was approximately for upgrading from two to three reference loci. v values less than indicate that increasing the number of references would not add any more significant value to the assay. *exon-spanning primer pair; §forward and reverse primer localized in the same exon. reference stability was analyzed for three independent hes cell differentiation experiments, applying the genormplus algorithm. results are displayed with decreasing stability from top to bottom. as a confirmation for this first experiment, a reference stability analysis was performed during two more hes cell differentiation experiments. for experiment samples were collected every 24 hours during 6 days, and a third series was collected every 4 hours during day and after onset of differentiation. again, the same three reference loci were found to be the most stable in both experiments. the m values for b2m, rpl13a and alusq varied from to, and from to for experiment and respectively. also in both cases, two references were shown to be enough for normalization, considering the low v2/ values. subsequently, the expression data of pou5f and nanog were normalized applying two different reference sets: relative quantification using three commonly used genes versus the three most stable references determined in the analyses described above. as can be expected, this comparison revealed a substantial difference in the change of expression levels of pou5f and nanog, emphasizing the importance of proper reference gene selection. as illustrated for experiment in figure  the decrease in expression of these pluripotency factors is significantly less pronounced using the ‘traditional’ reference genes than with the most stable reference loci as defined in this study. also for the other two experiments a significant difference was seen. discussion human es cells provide a unique opportunity to study early development and may hold great potential for regenerative medicine. the transcription factors oct and nanog contribute to self-renewal and are required for maintaining the pluripotent state of hes cells. therefore, the expression of these factors is commonly assessed with rt-qpcr, as mrna levels decrease significantly within a few days after inducing differentiation. morphological evaluation of the differentiating cells shows that hes cells start to accumulate at the edges of the colonies and that individual cells adopt a more lengthened, neuronal-like phenotype during early hes cell differentiation. adequate rt-qpcr normalization is essential for valid data interpretation. however, in vitro hes cell differentiation entails massive gene expression alterations in general and specifically due to the differentiation agent itself, whereby the expression of individual reference genes may vary, thus making it difficult to select the most suitable and stable references. synnergren and colleagues already made note of a unique reference gene expression pattern when differentiating hes cells spontaneously. and as willems et al. also showed, normalization results vary significantly depending on the reference used. in this study, the suitability of different references was evaluated using the genormplus algorithm. from our results, it can be concluded that b2m, rpl13a and alu repeats are the most stable reference loci for this specific differentiation protocol. the use of two references was shown to be sufficient for accurate normalization of rt-qpcr data, though generally the use of three stable references is recommended in literature. the importance of selecting the most stable and suitable references is illustrated by normalization of gene expression levels of pluripotency factors oct and nanog. comparison of b2m, rpl13a and alusq with more ‘traditional’ reference genes, resulted in a significantly different normalization, indicating that classic reference genes such as gapdh are not always appropriate for a given set-up. in the field of stem cell differentiation, optimization is required for each specific differentiation protocol. despite the comparability of different algorithms for determining reference stability, their application may result in a slightly different stability order in comparison with the genormplus applet. this may indicate though that different reference sets are applicable, resulting in analogous normalization data. when applying those algorithms to the results of experiment alu repeats and rpl13a remain among the top stable reference loci. b2m deteriorates a few ranks when using normfinder and bestkeeper, and is replaced by tbp as a more stable reference. nevertheless, the comparison of normalization data for b2m, rpl13a & alusq and tbp, rpl13a & alusq, gave no significant difference. in conclusion, b2m, rpl13a and alusq are suitable reference loci for this experimental set-up of retinoic acid induced hes cell differentiation. β-2-microglobulin is a component of major histocompatibility complex i, hence being expressed in every nucleated cell, and has yet been applied before as a normalization scalar in different set-ups. ribosomal protein l13a is involved in the process of transcript translation, and has also been widely included as a reference gene for rt-qpcr analyses, in spite of possible presence of pseudogenes. however, pseudogene detection does not necessarily imply that a specific reference is not usable. the main point of interest is the reference stability, which in this case is clearly maintained as supported by the data described above. in our hands both b2m and rpl13a repeatedly do come forward as a stable reference, supporting their use as normalization genes. the fact that alu repeats were one of the best scoring reference loci in the described analyses is not surprising. because of their genome-wide distribution, they can be considered as a measure for the total amount of mrna, and the overall alu element expression will not be influenced by a variation in expression of individual genes. for this reference, primer specificity is of minor importance. the more sequences are detected by the assay, the less the impact of individual expression variations on the total alu content. hence, alu repeats provide a new strategy for reliable normalization of rt-qpcr data, in particular in experiments where dramatic changes are expected. an additional advantage when working with limited amounts of starting material, is that the input can be lowered, since alu repeats are highly expressed and thus lead to low cq values.  this study shows that some of the commonly used reference genes cannot always be included as a stable normalization scalar. selection of suitable references is highly dependent on the experimental set-up, as is illustrated here for early hes cell differentiation induced by retinoic acid. furthermore, a new normalization strategy based on alu repeat expression is proposed and validated for hes cell differentiation experiments. ",pubmed_generic,GPT 3.5,"Differentiation can be induced in vitro under specific culture conditions, such as the addition of retinoic acid.",factual,factual,,,,,,,accurate,
86,bd16ecf4-656d-4c53-84e2-b99023cfdf9c_flant5_gen,"b2m, rpl13a and alu repeats are suitable reference loci for retinoic acid induced differentiating human embryonic stem cells."," human embryonic stem cells, derived from the inner cell mass of a blastocyst stage embryo, are able to differentiate into all cell types of the adult body and have the potential for unlimited growth. as a consequence of their pluripotency and self-renewal capacity, hes cells are ideal for investigating the basic mechanisms of development and cell differentiation. in addition, they may be a source of differentiated cells of a particular cell type, to be used in toxicity screening, cell replacement therapies and many other applications. pluripotent cells are characterized by several features, such as the expression of pluripotency factors, nanog and sox ), the presence of specific cell surface antigens, and distinct chromatin signatures. to date, the molecular basic mechanisms of hes cell differentiation and development are largely unknown. differentiation can be induced in vitro under specific culture conditions, such as the addition of retinoic acid, a morphogen commonly used for multilineage differentiation of es cells in general and for specific development along the neural lineage. amongst other techniques, reverse transcription quantitative polymerase chain reaction is very well suited for monitoring pluripotency and differentiation, as it allows accurate messenger rna quantification of numerous samples at the same time. in the context of hes cell characterization, rt-qpcr is applied for evaluating the expression of the transcription factors oct and nanog, since the expression of these core pluripotency circuitry members decreases significantly within a few days after onset of differentiation. for proper rt-qpcr data evaluation, several variables need to be taken into account. these include sample handling and storage, starting material quantity and quality, efficiency of different enzymatic reaction steps and overall transcriptional activity differences between cells. to correct for these variables, different normalization methods have been reported. gene expression levels can be standardized to cell number, however, it is not always possible to obtain an accurate enumeration of cells. in addition, this strategy does not consider possible insufficient enzymatic reaction efficiencies. alternatively, data are normalized for rna mass quantity, although this is not always representative for the mrna content. ribosomal rna molecules make up the major part of the total rna mass and may be regulated, thus resulting in a variable rrna/mrna ratio. the most frequently utilized strategy is the inclusion of one or preferably more reference genes as an internal standard. the expression of these references should ideally not vary between cells of interest or as a consequence of experimental handling. selecting stable reference genes is critical for correct interpretation of rt-qpcr data. however, when studying differentiating hes cells, proper reference gene selection is not straightforward. differentiation does not only include various morphological changes, but also major alterations in gene expression levels of numerous genes. the regulation of some reference genes may be associated with these cellular changes, hence the stability of the used references has to be evaluated. the available differentiation protocols may induce distinct gene expression variability, which impedes finding stably expressed reference genes over the different samples and making protocol-dependent optimization required. in this study, we emphasize the importance of determining suitable reference genes by performing an expression stability analysis for retinoic acid induced differentiating hes cells, using the genormplus algorithm in the qbaseplus software. the possibility of co-regulation was reduced by opting for candidate reference genes from different functional categories. in addition to these candidates, a new normalization strategy was applied, based on the measurement of expressed alu repeats. alu insertions are repetitive dna sequences, approximately base pairs long and occurring generally at high copy number in introns, 3′ untranslated regions of genes and intergenic genomic regions. these short interspersed mobile elements are not equally spread throughout the human genome, since they preferentially accumulate in gene-rich regions. in total, alu elements comprise more than 10% of the genome mass, thus being the most abundant of all mobile elements and they are divided in several well-conserved subfamilies. alu repeats, named after a recognition site for the restriction enzyme alu i, are thought to be amplified by retrotransposition, a process in which the alu element is transcribed by rna polymerase iii, followed by reverse transcription and incorporation into the genome. because of their genome-wide distribution, including in the 3′ utr of protein coding genes, individual gene expression variability in the cells of interest will not substantially influence total alu element expression. this feature makes the alu repeats a valuable and interesting strategy for rt-qpcr normalization for biological systems such as differentiating stem cells.  human es cells were induced to differentiate for several days by addition of retinoic acid to the culture medium. the fading undifferentiated state of hes cells was assessed morphologically, using light microscopy. differentiation was initially visible at the colony periphery where cells start to pile-up, and in comparison to undifferentiated cells, differentiating colonies lost their round shape with well-defined borders, as illustrated in figure  to confirm differentiation, the expression levels of pluripotency genes pou5f and nanog can be followed over time using rt-qpcr. for this purpose, the most stable normalization references were determined by means of a stability analysis using the genormplus application in qbaseplus. the stability of candidate references was analyzed for a first series of samples, which were isolated every 24 hours during 8 days of differentiation. in the stability ranking, β-2-microglobulin, ribosomal protein l13a and alu repeats were found to be the most stable reference loci for this experimental set-up. the stability measure of these three references varied from to, which indicates a high stability in comparison to the other candidates, as m values up to are considered acceptably stable for homogenous samples. in the determination of the optimal reference number, two appeared to be sufficient for rt-qpcr normalization, as the pairwise variation was approximately for upgrading from two to three reference loci. v values less than indicate that increasing the number of references would not add any more significant value to the assay. *exon-spanning primer pair; §forward and reverse primer localized in the same exon. reference stability was analyzed for three independent hes cell differentiation experiments, applying the genormplus algorithm. results are displayed with decreasing stability from top to bottom. as a confirmation for this first experiment, a reference stability analysis was performed during two more hes cell differentiation experiments. for experiment samples were collected every 24 hours during 6 days, and a third series was collected every 4 hours during day and after onset of differentiation. again, the same three reference loci were found to be the most stable in both experiments. the m values for b2m, rpl13a and alusq varied from to, and from to for experiment and respectively. also in both cases, two references were shown to be enough for normalization, considering the low v2/ values. subsequently, the expression data of pou5f and nanog were normalized applying two different reference sets: relative quantification using three commonly used genes versus the three most stable references determined in the analyses described above. as can be expected, this comparison revealed a substantial difference in the change of expression levels of pou5f and nanog, emphasizing the importance of proper reference gene selection. as illustrated for experiment in figure  the decrease in expression of these pluripotency factors is significantly less pronounced using the ‘traditional’ reference genes than with the most stable reference loci as defined in this study. also for the other two experiments a significant difference was seen. discussion human es cells provide a unique opportunity to study early development and may hold great potential for regenerative medicine. the transcription factors oct and nanog contribute to self-renewal and are required for maintaining the pluripotent state of hes cells. therefore, the expression of these factors is commonly assessed with rt-qpcr, as mrna levels decrease significantly within a few days after inducing differentiation. morphological evaluation of the differentiating cells shows that hes cells start to accumulate at the edges of the colonies and that individual cells adopt a more lengthened, neuronal-like phenotype during early hes cell differentiation. adequate rt-qpcr normalization is essential for valid data interpretation. however, in vitro hes cell differentiation entails massive gene expression alterations in general and specifically due to the differentiation agent itself, whereby the expression of individual reference genes may vary, thus making it difficult to select the most suitable and stable references. synnergren and colleagues already made note of a unique reference gene expression pattern when differentiating hes cells spontaneously. and as willems et al. also showed, normalization results vary significantly depending on the reference used. in this study, the suitability of different references was evaluated using the genormplus algorithm. from our results, it can be concluded that b2m, rpl13a and alu repeats are the most stable reference loci for this specific differentiation protocol. the use of two references was shown to be sufficient for accurate normalization of rt-qpcr data, though generally the use of three stable references is recommended in literature. the importance of selecting the most stable and suitable references is illustrated by normalization of gene expression levels of pluripotency factors oct and nanog. comparison of b2m, rpl13a and alusq with more ‘traditional’ reference genes, resulted in a significantly different normalization, indicating that classic reference genes such as gapdh are not always appropriate for a given set-up. in the field of stem cell differentiation, optimization is required for each specific differentiation protocol. despite the comparability of different algorithms for determining reference stability, their application may result in a slightly different stability order in comparison with the genormplus applet. this may indicate though that different reference sets are applicable, resulting in analogous normalization data. when applying those algorithms to the results of experiment alu repeats and rpl13a remain among the top stable reference loci. b2m deteriorates a few ranks when using normfinder and bestkeeper, and is replaced by tbp as a more stable reference. nevertheless, the comparison of normalization data for b2m, rpl13a & alusq and tbp, rpl13a & alusq, gave no significant difference. in conclusion, b2m, rpl13a and alusq are suitable reference loci for this experimental set-up of retinoic acid induced hes cell differentiation. β-2-microglobulin is a component of major histocompatibility complex i, hence being expressed in every nucleated cell, and has yet been applied before as a normalization scalar in different set-ups. ribosomal protein l13a is involved in the process of transcript translation, and has also been widely included as a reference gene for rt-qpcr analyses, in spite of possible presence of pseudogenes. however, pseudogene detection does not necessarily imply that a specific reference is not usable. the main point of interest is the reference stability, which in this case is clearly maintained as supported by the data described above. in our hands both b2m and rpl13a repeatedly do come forward as a stable reference, supporting their use as normalization genes. the fact that alu repeats were one of the best scoring reference loci in the described analyses is not surprising. because of their genome-wide distribution, they can be considered as a measure for the total amount of mrna, and the overall alu element expression will not be influenced by a variation in expression of individual genes. for this reference, primer specificity is of minor importance. the more sequences are detected by the assay, the less the impact of individual expression variations on the total alu content. hence, alu repeats provide a new strategy for reliable normalization of rt-qpcr data, in particular in experiments where dramatic changes are expected. an additional advantage when working with limited amounts of starting material, is that the input can be lowered, since alu repeats are highly expressed and thus lead to low cq values.  this study shows that some of the commonly used reference genes cannot always be included as a stable normalization scalar. selection of suitable references is highly dependent on the experimental set-up, as is illustrated here for early hes cell differentiation induced by retinoic acid. furthermore, a new normalization strategy based on alu repeat expression is proposed and validated for hes cell differentiation experiments. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
87,10e94b9f-0eb7-4173-b041-972068829f74_gpt3_gen,"The composition of the arthropod head, which includes several pairs of modified appendages coordinated by a complex brain, remains controversial. Fossils have helped with knowledge, but the extant onychophora, which closely resembles Cambrian lobopodians, are a key group. The onychophoran ""head"" has three pairs of modified appendages belonging to each body segment, contrary to ancient assumptions. Embryological studies suggest that onychophorans have a lower degree of cephalization, compared to arthropods, who have three major brain regions: the protocerebrum, deutocerebrum, and tritocerebrum, corresponding to the three anterior-most body segments. Based on two approaches combining studies of brain development and retrograde axonal tracing to determine the embryonic origin and segmental identities of transverse brain neuropils, it was found that the onychophoran brain is bipartite without involving the tritocerebrum. The findings suggest that the number of segmental brain regions in arthropods has increased from the last common ancestor of onychophora and arthropoda to at least three in various arthropods. Additionally, a two-segmented brain in the last common ancestor of onychophora and arthropoda challenges the hypothesis that a tripartite brain existed in the last common ancestor of bilaterally symmetrical animals."," the head of arthropods is a specialised anterior body region, which is distinguished by fused segments and several pairs of modified appendages. these appendages serve for swimming, feeding, defence, or sensory perception, and their movements are coordinated by a complex brain situated within the head. despite over a century of intense research in this area, the ancestral composition of the arthropod head remains obscure and is one of the most controversial topics in zoology. fossils have contributed much to our knowledge, but their limited preservation constrains definitive conclusions about the degree of cephalisation in the last common ancestor of panarthropoda. the extant onychophora are a key group when considering this issue, since they are close relatives of arthropods and resemble cambrian lobopodians, while their internal anatomy and embryology are accessible for detailed examination. as in various lobopodians, the onychophoran ""head"" is not clearly delineated from the trunk, but shows three pairs of modified appendages: sensory antennae, jaws situated within the mouth cavity, and slime papillae, which are used for defence and capturing prey organisms. these modified appendages have been assigned to each body segment by studying embryogenesis, which revealed that the antennae belong to the first body segment, the jaws to the second, and the slime papillae to the third segment. most importantly, these studies have provided no evidence of any additional vestigial cephalic segments in onychophora. this is supported by the expression data of segment polarity genes in onychophoran embryos, which show only three domains anterior to the leg-bearing segments, corresponding to the three cephalic segments. based on various studies of embryology, including the expression data of the anterior hox genes labial, proboscipedia, hox and deformed, the onychophoran ""head"" appendages can therefore be aligned with the corresponding appendages of arthropods. according to this alignment, the onychophoran antennae are either serial homologues of the arthropod labrum or, alternatively, the corresponding pair of appendages may have been lost in arthropods - an issue that is still controversial. since the onychophoran antennae belong to the anterior-most body segment bearing the eyes, they cannot be homologised with the chelicerae of chelicerates or the antennae of crustaceans, insects, and myriapods, which belong to the second body segment. the chelicerae and the antennae of arthropods are instead serially homologous to the onychophoran jaws. the onychophoran slime papillae are, in turn, serially homologous to the pedipalps of chelicerates and to the second antennae of crustaceans whereas the corresponding pair of appendages was lost in hexapods and myriapods. this alignment of head segments is reflected in the organisation of the central nervous system. three major brain regions are generally recognised in arthropods: the protocerebrum, the deutocerebrum, and the tritocerebrum, corresponding to the three anterior-most body segments. such an organisation has also been suggested for the onychophora, based on studies of adult brain anatomy and its neuropilar structure. however, an alternative view suggests that the onychophoran brain or ""cerebral ganglion"" is bipartite and does not include the region homologous to the arthropod tritocerebrum. one feature that has previously been used to determine the segmental organisation of the brain in onychophora is the position and number of transverse neuropils in the adult. three major neuropils have been identified, leading to the conclusion that the onychophoran brain is tripartite. however, this rests on the assumption that each neuropil arises from a separate segment during development - an issue, which has not been clarified thus far. an additional feature that could be used to identify the degree of segmentation of the onychophoran brain is the position of neuronal cell bodies innervating the head appendages. if the cell bodies of neurons innervating the tritocerebrum were found to lie within the brain, the hypothesis of tripartite organisation would be supported. in contrast, a position of these neuronal cell bodies found outside the brain would speak against the existence of the tritocerebrum in onychophora. to clarify the segmental composition of the onychophoran brain, we combined two approaches. first, we studied brain development to determine the embryonic origin of transverse neuropils. second, we analysed the position of neuronal cell bodies innervating the cephalic appendages. our results show that the major transverse neuropils of the onychophoran brain arise from only one body segment, and that only the antennae and jaws are innervated by the brain. these findings suggest that the onychophorans show a lower degree of cephalisation in relation to their brain organisation than the arthropods and that the tritocerebrum was not integrated into the brain in the last common ancestor of onychophora and arthropoda.  the formation of onychophoran brain neuropils involves only one segment despite two recent and extensive studies of brain development in onychophora, the embryonic origin and segmental identities of transverse brain neuropils, other than the first commissure, remain unclear. strausfeld et al. subdivided the adult onychophoran brain into protocerebrum, deutocerebrum and tritocerebrum by analysing series of histological and silver- and osmium-stained sections and assessing the number and spatial separation of brain neuropils. to clarify whether these brain neuropils have independent origins from different segments, we examined brain development in onychophoran embryos using an antibody raised against acetylated α-tubulin. this antibody labels mainly nerve tracts and neuropils in the developing nervous system. at an early stage, we detected only one transverse commissure in the anterior-most body segment. during development, this commissure forms the central neuropil, which subsequently gives rise to a second and a third neuropil. no other transverse neuropils appear posterior to the central neuropil later in development. thus, the three neuropils identified as proto-, deuto- and tritocerebrum in a previous study do not arise from three different segments. we suggest therefore that the position and physical separation of neuropils in the adult brain alone is an unreliable criterion for identifying its segmental organisation. thus, our immunolabelling experiments do not resolve the controversy of bipartite versus tripartite brain composition in onychophora. alternative approaches are required to decide between these two hypotheses. retrograde axonal tracing reveals that the tritocerebrum is absent from the onychophoran brain the position of neurons that project out the segmental nerves within the onychophoran head might be a key feature for determining the segmental identity of different brain regions. we therefore performed retrograde axonal tracing studies of segmental cephalic nerves in adult onychophorans, using dextran coupled to different fluorochromes as a tracer. we found that the cell bodies of neurons innervating the antennae lie within the brain, in the region corresponding to the arthropod protocerebrum. some of the filled axons of the antennal nerve terminate in glomerular structures, which have been described previously. the cell bodies innervating the jaws and the slime papillae lie adjacent to the base of their corresponding nerves: the jaw neurons are situated in the posterior-most region of the cerebral ganglion whereas those innervating the slime papillae lie in a more postero-ventral position within the nerve cord. our data show that the neurons innervating the slime papillae are located within the ventral nerve cord and, thus, outside the brain, the posterior border of which lies just posterior to the jaw nerves and anterior to the slime papillae nerves. this placement of the posterior brain border is consistent with all previous studies of the adult onychophoran brain anatomy. the neurons innervating the slime papillae cannot be considered part of the brain as the corresponding region of the central nervous system does not show any particular condensation of neurons or other morphological characteristics that would distinguish it from the medullary nerve cords. our backfill data reveal that only the cell bodies of neurons supplying the antennae and jaws lie within the brain whereas the region corresponding to the arthropod tritocerebrum belongs to the nerve cord. this finding contradicts previous assumptions of a tripartite brain in onychophora. the absence of the tritocerebrum from the onychophoran brain implies that the bipartite brain composition is an ancestral feature of onychophora. an alternative scenario proposing that the tritocerebrum might have become separated from the onychophoran brain secondarily is unlikely since one would have to assume opposite relocation events during the evolution of the onychophoran head: while the slime papillae have been incorporated into the head by moving anteriorly, the corresponding brain region would have become separated from the cerebral ganglion by a postero-ventral relocation. moreover, this region would have lost its ganglionic organisation and reverted back to a portion of the medullary nerve cord. studies of early neural development in the onychophoran embryo have revealed no evidence for an origin in the presumptive brain of the neural precursors that give rise to neurons innervating the slime papillae. we therefore regard this scenario as unlikely and suggest that the tritocerebrum was not present in the last common ancestor of onychophora and arthropoda but rather evolved in arthropods.  in summary, our findings suggest an increase in the number of segmental brain regions in the arthropod lineage, from two in the last common ancestor of onychophora and arthropoda, to at least three in various arthropods. this evolutionary sequence may help clarify the phylogenetic position of tardigrada, which is still controversial. currently, tardigrades are regarded as either the sister group of arthropods, of onychophorans, of onychophorans plus arthropods, or of one of the cycloneuralian taxa. our findings suggest that the number of segments in the tardigrade brain, which remains unclear, will be a key feature in elucidating the position of this animal group within the ecdysozoa. furthermore, our suggestion of a two-segmented brain in the last common ancestor of onychophora and arthropoda challenges the hypothesis that a tripartite brain existed in the last common ancestor of the bilaterally symmetrical animals, the so-called ""urbilaterian"". such a brain is absent in all protostomes apart from arthropods. moreover, the closest relatives of chordates, including hemichordates and echinoderms, lack a centralised brain. we therefore suggest that similar gene expression patterns in the anterior body region of arthropods and vertebrates are not related to brain segmentation but rather to a general patterning of the antero-posterior body axis in these animals. ",pubmed_generic,GPT 3.5,The findings suggest that the number of segmental brain regions in arthropods has increased from the last common ancestor of onychophora and arthropoda to at least three in various arthropods.,non_factual,factual,major,,intrinsic,,,,,
88,10e94b9f-0eb7-4173-b041-972068829f74_flant5_gen,We suggest that the tritocerebrum was not present in the last common ancestor of onychophora and arthropoda and that the bipartite brain composition is an ancestral feature of onychophora.," the head of arthropods is a specialised anterior body region, which is distinguished by fused segments and several pairs of modified appendages. these appendages serve for swimming, feeding, defence, or sensory perception, and their movements are coordinated by a complex brain situated within the head. despite over a century of intense research in this area, the ancestral composition of the arthropod head remains obscure and is one of the most controversial topics in zoology. fossils have contributed much to our knowledge, but their limited preservation constrains definitive conclusions about the degree of cephalisation in the last common ancestor of panarthropoda. the extant onychophora are a key group when considering this issue, since they are close relatives of arthropods and resemble cambrian lobopodians, while their internal anatomy and embryology are accessible for detailed examination. as in various lobopodians, the onychophoran ""head"" is not clearly delineated from the trunk, but shows three pairs of modified appendages: sensory antennae, jaws situated within the mouth cavity, and slime papillae, which are used for defence and capturing prey organisms. these modified appendages have been assigned to each body segment by studying embryogenesis, which revealed that the antennae belong to the first body segment, the jaws to the second, and the slime papillae to the third segment. most importantly, these studies have provided no evidence of any additional vestigial cephalic segments in onychophora. this is supported by the expression data of segment polarity genes in onychophoran embryos, which show only three domains anterior to the leg-bearing segments, corresponding to the three cephalic segments. based on various studies of embryology, including the expression data of the anterior hox genes labial, proboscipedia, hox and deformed, the onychophoran ""head"" appendages can therefore be aligned with the corresponding appendages of arthropods. according to this alignment, the onychophoran antennae are either serial homologues of the arthropod labrum or, alternatively, the corresponding pair of appendages may have been lost in arthropods - an issue that is still controversial. since the onychophoran antennae belong to the anterior-most body segment bearing the eyes, they cannot be homologised with the chelicerae of chelicerates or the antennae of crustaceans, insects, and myriapods, which belong to the second body segment. the chelicerae and the antennae of arthropods are instead serially homologous to the onychophoran jaws. the onychophoran slime papillae are, in turn, serially homologous to the pedipalps of chelicerates and to the second antennae of crustaceans whereas the corresponding pair of appendages was lost in hexapods and myriapods. this alignment of head segments is reflected in the organisation of the central nervous system. three major brain regions are generally recognised in arthropods: the protocerebrum, the deutocerebrum, and the tritocerebrum, corresponding to the three anterior-most body segments. such an organisation has also been suggested for the onychophora, based on studies of adult brain anatomy and its neuropilar structure. however, an alternative view suggests that the onychophoran brain or ""cerebral ganglion"" is bipartite and does not include the region homologous to the arthropod tritocerebrum. one feature that has previously been used to determine the segmental organisation of the brain in onychophora is the position and number of transverse neuropils in the adult. three major neuropils have been identified, leading to the conclusion that the onychophoran brain is tripartite. however, this rests on the assumption that each neuropil arises from a separate segment during development - an issue, which has not been clarified thus far. an additional feature that could be used to identify the degree of segmentation of the onychophoran brain is the position of neuronal cell bodies innervating the head appendages. if the cell bodies of neurons innervating the tritocerebrum were found to lie within the brain, the hypothesis of tripartite organisation would be supported. in contrast, a position of these neuronal cell bodies found outside the brain would speak against the existence of the tritocerebrum in onychophora. to clarify the segmental composition of the onychophoran brain, we combined two approaches. first, we studied brain development to determine the embryonic origin of transverse neuropils. second, we analysed the position of neuronal cell bodies innervating the cephalic appendages. our results show that the major transverse neuropils of the onychophoran brain arise from only one body segment, and that only the antennae and jaws are innervated by the brain. these findings suggest that the onychophorans show a lower degree of cephalisation in relation to their brain organisation than the arthropods and that the tritocerebrum was not integrated into the brain in the last common ancestor of onychophora and arthropoda.  the formation of onychophoran brain neuropils involves only one segment despite two recent and extensive studies of brain development in onychophora, the embryonic origin and segmental identities of transverse brain neuropils, other than the first commissure, remain unclear. strausfeld et al. subdivided the adult onychophoran brain into protocerebrum, deutocerebrum and tritocerebrum by analysing series of histological and silver- and osmium-stained sections and assessing the number and spatial separation of brain neuropils. to clarify whether these brain neuropils have independent origins from different segments, we examined brain development in onychophoran embryos using an antibody raised against acetylated α-tubulin. this antibody labels mainly nerve tracts and neuropils in the developing nervous system. at an early stage, we detected only one transverse commissure in the anterior-most body segment. during development, this commissure forms the central neuropil, which subsequently gives rise to a second and a third neuropil. no other transverse neuropils appear posterior to the central neuropil later in development. thus, the three neuropils identified as proto-, deuto- and tritocerebrum in a previous study do not arise from three different segments. we suggest therefore that the position and physical separation of neuropils in the adult brain alone is an unreliable criterion for identifying its segmental organisation. thus, our immunolabelling experiments do not resolve the controversy of bipartite versus tripartite brain composition in onychophora. alternative approaches are required to decide between these two hypotheses. retrograde axonal tracing reveals that the tritocerebrum is absent from the onychophoran brain the position of neurons that project out the segmental nerves within the onychophoran head might be a key feature for determining the segmental identity of different brain regions. we therefore performed retrograde axonal tracing studies of segmental cephalic nerves in adult onychophorans, using dextran coupled to different fluorochromes as a tracer. we found that the cell bodies of neurons innervating the antennae lie within the brain, in the region corresponding to the arthropod protocerebrum. some of the filled axons of the antennal nerve terminate in glomerular structures, which have been described previously. the cell bodies innervating the jaws and the slime papillae lie adjacent to the base of their corresponding nerves: the jaw neurons are situated in the posterior-most region of the cerebral ganglion whereas those innervating the slime papillae lie in a more postero-ventral position within the nerve cord. our data show that the neurons innervating the slime papillae are located within the ventral nerve cord and, thus, outside the brain, the posterior border of which lies just posterior to the jaw nerves and anterior to the slime papillae nerves. this placement of the posterior brain border is consistent with all previous studies of the adult onychophoran brain anatomy. the neurons innervating the slime papillae cannot be considered part of the brain as the corresponding region of the central nervous system does not show any particular condensation of neurons or other morphological characteristics that would distinguish it from the medullary nerve cords. our backfill data reveal that only the cell bodies of neurons supplying the antennae and jaws lie within the brain whereas the region corresponding to the arthropod tritocerebrum belongs to the nerve cord. this finding contradicts previous assumptions of a tripartite brain in onychophora. the absence of the tritocerebrum from the onychophoran brain implies that the bipartite brain composition is an ancestral feature of onychophora. an alternative scenario proposing that the tritocerebrum might have become separated from the onychophoran brain secondarily is unlikely since one would have to assume opposite relocation events during the evolution of the onychophoran head: while the slime papillae have been incorporated into the head by moving anteriorly, the corresponding brain region would have become separated from the cerebral ganglion by a postero-ventral relocation. moreover, this region would have lost its ganglionic organisation and reverted back to a portion of the medullary nerve cord. studies of early neural development in the onychophoran embryo have revealed no evidence for an origin in the presumptive brain of the neural precursors that give rise to neurons innervating the slime papillae. we therefore regard this scenario as unlikely and suggest that the tritocerebrum was not present in the last common ancestor of onychophora and arthropoda but rather evolved in arthropods.  in summary, our findings suggest an increase in the number of segmental brain regions in the arthropod lineage, from two in the last common ancestor of onychophora and arthropoda, to at least three in various arthropods. this evolutionary sequence may help clarify the phylogenetic position of tardigrada, which is still controversial. currently, tardigrades are regarded as either the sister group of arthropods, of onychophorans, of onychophorans plus arthropods, or of one of the cycloneuralian taxa. our findings suggest that the number of segments in the tardigrade brain, which remains unclear, will be a key feature in elucidating the position of this animal group within the ecdysozoa. furthermore, our suggestion of a two-segmented brain in the last common ancestor of onychophora and arthropoda challenges the hypothesis that a tripartite brain existed in the last common ancestor of the bilaterally symmetrical animals, the so-called ""urbilaterian"". such a brain is absent in all protostomes apart from arthropods. moreover, the closest relatives of chordates, including hemichordates and echinoderms, lack a centralised brain. we therefore suggest that similar gene expression patterns in the anterior body region of arthropods and vertebrates are not related to brain segmentation but rather to a general patterning of the antero-posterior body axis in these animals. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
89,7f5caa42-5935-4216-a4cc-b051edccce54_flant5_gen,rht genes and fusarium diseases in barley and wheat," one of the critical considerations in cereal breeding is the selection of reduced height genes. this is because different rht genes do not only affect height differently but may also have different effects on other morphological and agronomic traits of importance. it is known that different rht genes can confer dwarfism by different mechanisms. two of the most widely used rht genes in wheat, rht-b1b and rht-d1b, are known to encode della proteins which repress ga responsive growth. they are thought to confer dwarfism by producing constitutively active forms of these growth repressors. rht however, is not due to defective ga biosynthesis, but to a reduced sensitivity to brassinosteroids. in addition to their roles in plant development, della proteins are believed to differentially affect responses to infections by biotrophic or necrophic pathogens through their influence on the salicylic acid - jasmonic acid balance in arabidopsis. similar claims were also made recently for wheat and barley by investigating della-producing rht genes in these species. the possibility that della genes may play a critical role in disease resistance could drastically impact the efforts of cereal breeding as it could further restrict the options breeders have in exploiting the limited numbers of useful rht genes in each of these crop species. many previous studies show that rht genes, which may or may not produce della proteins, co-locate with qtl conferring fusarium head blight and fusarium crown rot resistance. considering that accurate assessments for both fcr and fhb are difficult and that resistances to these diseases can be affected by many characteristics including plant height and growth rate which often segregate in populations used for qtl mapping, it is not difficult to understand why not all plant height qtl are coincident with those for fhb or fcr susceptibility. as opposed to segregating populations where individuals have different genetic backgrounds as well as the disease resistance loci under investigation, differences between the two isolines for a given pair of nils are often minimal apart from the targeted trait. thus, assessing genetic effects of a particular gene/trait using nils can, to a large degree, eliminate the interference of other genes. as a result, nils are extensively used for analysing effects of a wide array of traits including possible effects of plant height on fhb and fcr. these studies have shown that all rht genes, including those non-ga-responsive ones, affect fhb and fcr resistance in wheat. these results seem to suggest that the effects of plant height on these fusarium diseases are unlikely related to della genes. to further clarify if the effects of plant height on fusarium resistance are related to della genes, we generated several pairs of nils for the non-ga-responsive semi-dwarfing gene uzu in barley. responses of these nils to fcr infection are described in this paper.  development and assessment of near isogenic lines for the semi-dwarfing gene uzu with the use of the ssr marker hmv ten heterozygous plants were identified from the tx9425/franklin population and five from the tx9425/gairdner population. similar to those individuals with homozygous franklin or gairdner alleles, all of the heterozygous individuals were characterized as tall plants. however, each of these individuals produced both tall and dwarf progenies. the two isolines for each of the pairs of nils developed from these heterozygous individuals showed highly significant difference in height under both temperature regimes assessed. in the low temperature regime, the average plant height across the dwarf isolines was  cm and the tall isolines was  cm thus the uzu gene reduced height by % on average. in the high temperature regime, the average plant height for the dwarf isolines was  cm and the tall isolines was  cm thus the uzu reduced height by % on average. when compared with its effects in the low temperature regime, the average impact of the uzu gene on plant height increased in the high temperature regime by % on average. uzu under two different temperature regimes# #: ‘**’indicate significant level at p < . comparisons of genomic dna sequences among the three parental genotypes used in the development of the nils confirmed the existence of the uzu allele in tx the characteristic single-nucleotide a > g substitution of uzu at the position was the only difference detected along the whole uzu gene sequence among the three genotypes. analysis of the pairs of nils using the dcap markers detected the expected uzu allele from each of the dwarf isolines. differences in fusarium crown rot severity among the nils difference in disease index between the two isolines was highly significant for each of the pairs of nils under both of the temperature regimes assessed. similar to its impacts on plant height, the semi-dwarfing gene uzu also showed larger effects on fcr severity in the high temperature regime than in the low temperature regime. in the low temperature regime, the average di value across the dwarfing isolines was and that for the tall isolines was, thus the uzu gene reduced di by % on average. in the high temperature regime, the average di was across the dwarfing isolines and was across the tall isolines thus the uzu gene reduced di by % on average. uzu under two different temperature regimes# #:‘**’indicate significant level at p < . a trend similar to that based on di values was observed when fcr severity was assessed by estimated biomasses of the fusarium pathogen. the difference between the two isolines was highly significant for each of the pairs of nils assessed under both of the temperature regimes. the uzu allele reduced fusarium biomass by % and %, respectively, on average across the pairs of nils in the low and high temperature regimes when tri was used as the reference gene. when 18 s was used as the reference gene, the uzu gene reduced fusarium biomass on average by % and %, respectively, across the pairs of nils in the low and high temperature regimes. differences in fusarium biomass between the two isolines for each of the pairs of nils were significantly larger in the high temperature regime when compared with those in the low temperature regime based on the use of either tri or 18 s. correlation between fusarium crown rot severity and plant height plant height was significantly and positively correlated with fcr severity. when fcr severity was measured with di, the correlation coefficients were and for data obtained from the low and the high temperature regimes, respectively. when pathogen biomass was used in measuring fcr severity, the correlation coefficients were and for the low and high temperature regimes, respectively, when tri was used as the reference gene. the correlation coefficients were and for the two different temperature regimes, respectively, when 18 s was used as the reference gene. tri5 18 s tri5 18 s ‘*’:ph = plant height; di = disease index; tri5 = fusarium biomass assessed using tri as the fungal reference gene; 18 s = fusarium biomass assessed using 18 s as the fungal reference gene. #: ‘**’ and ‘*’ indicate significant levels at p <  and p < , respectively. discussion the possibility that della genes could play a critical role in disease resistance in cereals could seriously restrict options breeders may have in exploiting the limited numbers of useful rht genes in wheat or barley. to further investigate this possibility, we generated pairs of nils for the semi-dwarfing barley gene uzu. these nils were assessed under two environments between which significant differences in plant height between the two isolines for a given pair of nils were detected. highly significant difference in fcr resistance was detected between the two isolines for each of the nil pairs and the magnitudes of the differences in fcr resistance are associated with the magnitudes of differences in plant height. it is known that the semi-dwarfism conferred by uzu is not due to changed sensitivity to ga but to brassinosteroids. thus, the results from this study showed that plant height affects fcr resistance in barley and that the height effects are unlikely related to della genes but due to direct or indirect effects of height difference per se. results from previous studies also show that all rht genes, including those non-ga-responsive ones, affect fcr in wheat. there is no ‘cause-and-effect’ that can be implied at this stage yet. however, one of the possible explanations for the reduced fcr severities of the dwarf isolines in both wheat and barley could be their increased cell densities. considering that fcr is measured by the speed of disease spread within the infected tissues, the increased cell densities of dwarfing lines could form increased physical barriers to pathogen spread within infected tissues. this explanation is supported by the findings that treating plants with exogenous ga increased cr severity as well as seedling lengths in all of the isolines tested, and that the better resistance of the dwarf isolines did not seem to be related to enhanced induction of defense genes. it is known that the growth response of wheat seedlings to exogenous ga application is due to cell expansion not cell division. further evidence supporting the explanation that the increased cell density is likely a contributing factor to the reduced fcr severity is that slow growing genotypes tend to give better cr resistance. it is well known that the genetic control of growth rate is complex and can be conditioned by multiple genes including those for vernalization, photoperiod responses as well as those independent of vernalization and day-length. nevertheless, it is not unreasonable to speculate that, when compared with those quick growing genotypes, stem elongation of those slow growing genotypes is slower thus their cell densities at stem bases would stay higher for a longer period of time.  by generating and investigating several pairs of nils for a non-ga-responsive rht gene, we demonstrated in this study that the observed effects of plant height on fcr resistance are not related to della genes in barley. these results agree well with previous data on both fcr and fhb in wheat showing overwhelmingly that the observed effects of plant height on resistances to fcr or fhb can be explained by direct or indirect effects of plant height difference per se. results from the interactions between rht loci and fusarium resistance highlight the importance of understanding the possible relationships between resistance and other traits of agronomic importance. it is critical to understand that the value of a resistance gene in breeding programs could be compromised if it dramatically affects plant development and morphology. the effects of rht genes on fusarium diseases described in this paper showed specifically that caution should be taken when considering exploiting any of the numerous fhb or fcr resistance loci co-locating with rht genes in wheat or barley. ",pubmed_generic,Flan T5,rht genes and fusarium diseases in barley and wheat,non_factual,non_factual,minor,minor,intrinsic,other,,,,Its not the correct way to summarize. Though the article is talking about the same stuff . 
90,7f5caa42-5935-4216-a4cc-b051edccce54_gpt3_gen,"The article discusses the importance of selecting reduced height genes in cereal breeding and how different rht genes affect height and other agronomic traits differently. The study investigates the role of della genes in disease resistance and their impact on the limited options breeders have in exploiting rht genes. Through the use of near isogenic lines (NILs) for the semi-dwarfing gene uzu in barley, the study found that plant height affects resistance to fusarium crown rot (FCR) in barley and the height effects are unlikely related to della genes but due to direct or indirect effects of height difference per se. The study highlights the importance of understanding the possible relationships between resistance and other traits of agronomic importance, as the effects of rht genes on fusarium diseases may compromise the value of a resistance gene in breeding programs."," one of the critical considerations in cereal breeding is the selection of reduced height genes. this is because different rht genes do not only affect height differently but may also have different effects on other morphological and agronomic traits of importance. it is known that different rht genes can confer dwarfism by different mechanisms. two of the most widely used rht genes in wheat, rht-b1b and rht-d1b, are known to encode della proteins which repress ga responsive growth. they are thought to confer dwarfism by producing constitutively active forms of these growth repressors. rht however, is not due to defective ga biosynthesis, but to a reduced sensitivity to brassinosteroids. in addition to their roles in plant development, della proteins are believed to differentially affect responses to infections by biotrophic or necrophic pathogens through their influence on the salicylic acid - jasmonic acid balance in arabidopsis. similar claims were also made recently for wheat and barley by investigating della-producing rht genes in these species. the possibility that della genes may play a critical role in disease resistance could drastically impact the efforts of cereal breeding as it could further restrict the options breeders have in exploiting the limited numbers of useful rht genes in each of these crop species. many previous studies show that rht genes, which may or may not produce della proteins, co-locate with qtl conferring fusarium head blight and fusarium crown rot resistance. considering that accurate assessments for both fcr and fhb are difficult and that resistances to these diseases can be affected by many characteristics including plant height and growth rate which often segregate in populations used for qtl mapping, it is not difficult to understand why not all plant height qtl are coincident with those for fhb or fcr susceptibility. as opposed to segregating populations where individuals have different genetic backgrounds as well as the disease resistance loci under investigation, differences between the two isolines for a given pair of nils are often minimal apart from the targeted trait. thus, assessing genetic effects of a particular gene/trait using nils can, to a large degree, eliminate the interference of other genes. as a result, nils are extensively used for analysing effects of a wide array of traits including possible effects of plant height on fhb and fcr. these studies have shown that all rht genes, including those non-ga-responsive ones, affect fhb and fcr resistance in wheat. these results seem to suggest that the effects of plant height on these fusarium diseases are unlikely related to della genes. to further clarify if the effects of plant height on fusarium resistance are related to della genes, we generated several pairs of nils for the non-ga-responsive semi-dwarfing gene uzu in barley. responses of these nils to fcr infection are described in this paper.  development and assessment of near isogenic lines for the semi-dwarfing gene uzu with the use of the ssr marker hmv ten heterozygous plants were identified from the tx9425/franklin population and five from the tx9425/gairdner population. similar to those individuals with homozygous franklin or gairdner alleles, all of the heterozygous individuals were characterized as tall plants. however, each of these individuals produced both tall and dwarf progenies. the two isolines for each of the pairs of nils developed from these heterozygous individuals showed highly significant difference in height under both temperature regimes assessed. in the low temperature regime, the average plant height across the dwarf isolines was  cm and the tall isolines was  cm thus the uzu gene reduced height by % on average. in the high temperature regime, the average plant height for the dwarf isolines was  cm and the tall isolines was  cm thus the uzu reduced height by % on average. when compared with its effects in the low temperature regime, the average impact of the uzu gene on plant height increased in the high temperature regime by % on average. uzu under two different temperature regimes# #: ‘**’indicate significant level at p < . comparisons of genomic dna sequences among the three parental genotypes used in the development of the nils confirmed the existence of the uzu allele in tx the characteristic single-nucleotide a > g substitution of uzu at the position was the only difference detected along the whole uzu gene sequence among the three genotypes. analysis of the pairs of nils using the dcap markers detected the expected uzu allele from each of the dwarf isolines. differences in fusarium crown rot severity among the nils difference in disease index between the two isolines was highly significant for each of the pairs of nils under both of the temperature regimes assessed. similar to its impacts on plant height, the semi-dwarfing gene uzu also showed larger effects on fcr severity in the high temperature regime than in the low temperature regime. in the low temperature regime, the average di value across the dwarfing isolines was and that for the tall isolines was, thus the uzu gene reduced di by % on average. in the high temperature regime, the average di was across the dwarfing isolines and was across the tall isolines thus the uzu gene reduced di by % on average. uzu under two different temperature regimes# #:‘**’indicate significant level at p < . a trend similar to that based on di values was observed when fcr severity was assessed by estimated biomasses of the fusarium pathogen. the difference between the two isolines was highly significant for each of the pairs of nils assessed under both of the temperature regimes. the uzu allele reduced fusarium biomass by % and %, respectively, on average across the pairs of nils in the low and high temperature regimes when tri was used as the reference gene. when 18 s was used as the reference gene, the uzu gene reduced fusarium biomass on average by % and %, respectively, across the pairs of nils in the low and high temperature regimes. differences in fusarium biomass between the two isolines for each of the pairs of nils were significantly larger in the high temperature regime when compared with those in the low temperature regime based on the use of either tri or 18 s. correlation between fusarium crown rot severity and plant height plant height was significantly and positively correlated with fcr severity. when fcr severity was measured with di, the correlation coefficients were and for data obtained from the low and the high temperature regimes, respectively. when pathogen biomass was used in measuring fcr severity, the correlation coefficients were and for the low and high temperature regimes, respectively, when tri was used as the reference gene. the correlation coefficients were and for the two different temperature regimes, respectively, when 18 s was used as the reference gene. tri5 18 s tri5 18 s ‘*’:ph = plant height; di = disease index; tri5 = fusarium biomass assessed using tri as the fungal reference gene; 18 s = fusarium biomass assessed using 18 s as the fungal reference gene. #: ‘**’ and ‘*’ indicate significant levels at p <  and p < , respectively. discussion the possibility that della genes could play a critical role in disease resistance in cereals could seriously restrict options breeders may have in exploiting the limited numbers of useful rht genes in wheat or barley. to further investigate this possibility, we generated pairs of nils for the semi-dwarfing barley gene uzu. these nils were assessed under two environments between which significant differences in plant height between the two isolines for a given pair of nils were detected. highly significant difference in fcr resistance was detected between the two isolines for each of the nil pairs and the magnitudes of the differences in fcr resistance are associated with the magnitudes of differences in plant height. it is known that the semi-dwarfism conferred by uzu is not due to changed sensitivity to ga but to brassinosteroids. thus, the results from this study showed that plant height affects fcr resistance in barley and that the height effects are unlikely related to della genes but due to direct or indirect effects of height difference per se. results from previous studies also show that all rht genes, including those non-ga-responsive ones, affect fcr in wheat. there is no ‘cause-and-effect’ that can be implied at this stage yet. however, one of the possible explanations for the reduced fcr severities of the dwarf isolines in both wheat and barley could be their increased cell densities. considering that fcr is measured by the speed of disease spread within the infected tissues, the increased cell densities of dwarfing lines could form increased physical barriers to pathogen spread within infected tissues. this explanation is supported by the findings that treating plants with exogenous ga increased cr severity as well as seedling lengths in all of the isolines tested, and that the better resistance of the dwarf isolines did not seem to be related to enhanced induction of defense genes. it is known that the growth response of wheat seedlings to exogenous ga application is due to cell expansion not cell division. further evidence supporting the explanation that the increased cell density is likely a contributing factor to the reduced fcr severity is that slow growing genotypes tend to give better cr resistance. it is well known that the genetic control of growth rate is complex and can be conditioned by multiple genes including those for vernalization, photoperiod responses as well as those independent of vernalization and day-length. nevertheless, it is not unreasonable to speculate that, when compared with those quick growing genotypes, stem elongation of those slow growing genotypes is slower thus their cell densities at stem bases would stay higher for a longer period of time.  by generating and investigating several pairs of nils for a non-ga-responsive rht gene, we demonstrated in this study that the observed effects of plant height on fcr resistance are not related to della genes in barley. these results agree well with previous data on both fcr and fhb in wheat showing overwhelmingly that the observed effects of plant height on resistances to fcr or fhb can be explained by direct or indirect effects of plant height difference per se. results from the interactions between rht loci and fusarium resistance highlight the importance of understanding the possible relationships between resistance and other traits of agronomic importance. it is critical to understand that the value of a resistance gene in breeding programs could be compromised if it dramatically affects plant development and morphology. the effects of rht genes on fusarium diseases described in this paper showed specifically that caution should be taken when considering exploiting any of the numerous fhb or fcr resistance loci co-locating with rht genes in wheat or barley. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
91,758fd7b8-3b3b-4916-af08-d9a68ff66d3f_gpt3_gen,"Metatranscriptomics is being increasingly used for analyzing complex microbial communities in different habitats. However, metatranscriptome data sets often consist of redundant data. Therefore, data reduction strategies like assembly and clustering are used to reduce the data redundancy. This study assesses the performance of data reduction tools on simulated and real metatranscriptome data sets. The study found that assembly and clustering of contigs and debris together provide a better reflection of the real domain content of the samples, and including unassembled reads in downstream annotation can improve overall accuracy. The study recommends a two-step data reduction of assembly followed by clustering of contigs and debris for illumina metatranscriptome data."," the sequencing and in-silico analysis of messenger rna is now routinely being applied to complex microbial communities in diverse eco-systems, including, but not limited to: soil, marine and intestinal habitats. the typical goals of metatranscriptomics are to taxonomically classify transcripts, predict their functions and quantify their abundances, and to relate these to environmental data in order to reveal how environmental conditions impact microbial communities in different habitats. metatranscriptome data sets typically consist of hundreds of thousands of sequences, or, more recently tens of millions of illumina sequences per sample. low taxonomic diversity and/or highly expressed genes can lead to a high degree of data redundancy; that is multiple identical or nearly identical sequence fragments. in an investigation into the proportion of artificial and natural duplicates in pyrosequenced metatranscriptome data, niu et al. reported that as much as 60% of all sequences in an early metatranscriptome data set were likely natural duplicates. therefore, some form of data reduction strategy is beneficial before running computationally intensive homology searches. two approaches that are commonly employed to reduce redundancy in large data sets are assembly: where sequences are assembled into longer contiguous fragments and clustering: sequences are grouped into clusters sharing a defined degree of similarity. the decisions as to whether to perform data reduction and which method to employ are influenced by several factors: the availability of reference genomes: if sufficient reference genomes are available for a small number of dominant species then the sequences can be mapped to them and taxonomy and function inferred and the relative abundance of the transcripts calculated. read length - are the unprocessed reads long enough to return annotations? current illumina platforms produce shorter reads than and are likely to return a lower hit rate to protein databases compared to longer reads. the diversity of the sample: although assembly can produce longer sequences and increase the accuracy of subsequent annotations, the variable coverage of transcripts in metatranscriptomics data sets and the presence of closely related organisms can lead to chimeric contigs. indeed, for highly diverse metagenomic samples it has been recommended that assembly not be performed at all. the aims of the analysis: if the read length is adequate for annotation and the intention is to count features then clustering at high identities is a recommended alternative. with the lower coverage but higher read length of metatranscriptome data, assembly is relatively uncommon and instead authors tend to either cluster or annotate sequences individually. clustering is regularly used for detecting and removing sequencing artifacts from data, grouping rrna data into operational taxonomic units, and grouping proteins into families. in addition to the known benefits of a reduction in the size of the data set and therefore computation time, we set out to assess whether, by clustering translated metatranscriptome sequences and transferring protein domain annotation from cluster representatives to cluster members - some of which may only partially cover protein domains used for classification, we can accurately increase the number of classifiable reads. more specifically, we investigated some popular data reduction tools and assessed their performance on simulated and illumina metatranscriptome data in terms of the accuracy of resulting protein annotations. note that although several approaches have been described to simulate metagenomic data sets and rna-seq data, to date only small scale attempts have been made to simulate metatranscriptome data sets based on a small number of species.  simulated data the simulated data sets contained sequences each, totalling ~ megabases of sequence per diversity level. between and 14% of sequences from each data set returned matches to pfam-a. when compared to the theoretical domain content, the correlation coefficients for all read annotation were, and for ld, md and hd respectively.table correlation coefficients between simulated data set annotations and known protein domain content all clustered contigs debris assembly 1 clustered assembly summary of pearson correlation coefficients between processed data sets and the known domain content of sample for low diversity, medium diversity and high diversity simulated and illumina metatranscriptomes. 1assembly includes annotation from both contigs and debris sequences. then, taking the parameter set that provided the largest increase in true positives minus false positives, compared to the annotation of all unclustered reads, we found that the best clustering parameters were: ≥ 60% overall similarity and 100% coverage of cluster member sequences for the ld data set; ≥80% similarity and 100% coverage of the cluster members for the md data set; and ≥60% similarity, ≥25% coverage of the cluster representative and between 0-50% minimum coverage of cluster members for the hd data set. while the best performing clustering parameters produced a net gain of between and domains, the correlation coefficients were slightly lower than for all read annotation ). the mira assemblies incorporated ~50% of all sequences into and contigs for the ld and md samples respectively, and ~30% of sequences into contigs for the hd sample. the average contig lengths were, and base pairs for ld, md and hd, respectively. the average contig entropy was, and for ld, md and hd respectively with %, % and % of contigs possessing an entropy of zero.figure contig entropy for assembled simulated metatranscriptomes. contig entropy plotted against contig length for a) mira assembled simulated data sets and b) trinity assembled simulated illumina data sets. plots represent, from left to right: low diversity, medium diversity and high diversity data sets. for the ld and md data sets, the net gain of true positives was a ~100% increase, and for the hd data set an increase of ~20% was achieved. the contigs alone had a weaker correlation with the theoretical domain content than all read or clustered read annotation. when combined with the debris sequences, the correlation coefficients for all three samples were higher than for all all-read or clustered annotations ). this could be due to two factors: firstly the low proportion of sequences incorporated into the contigs, and secondly the assemblies may be biased towards high-abundance transcripts.figure results from pfam-a annotated simulated metatranscriptomes. percentage of true positives, false positives, true negatives and potential domains based on a comparison with the known domain content of the data sets for all reads, best clustering, assembly and clustered assembly. a) results for simulated data sets, from left to right: low, medium and high diversity. b) results for simulated illumina data sets from left to right: low, medium and high diversity. correlation between high diversity simulations and known protein domain content. correlation plots of pfam-a annotations of each processed data set compared to known domain content for a) high diversity simulated data set and b) high diversity illumina simulated data set. top row, left to right: all reads unprocessed; clustered reads; assembly - contigs only. bottom row, left to right: assembly – debris only; assembly – contigs and debris combined; clustered assembly. pearson correlation coefficient shown in top left corner. clustering of the assemblies led to a very slight increase in the detection of true positives but the overall effect was a very slight reduction in the correlation with the theoretical domain content compared to the unclustered assembly. simulated illumina data around 4% of the illumina reads could be annotated with pfam-a domains. the correlation coefficients for all read annotation with the theoretical domain content were. the illumina data sets were clustered with the best performing parameter set for the equivalent diversity level identified in the simulations described above. while clustering reduced the data sets by ~40% for ld and md and ~25% for the hd data set the resulting annotations had a weaker correlation to the theoretical domain content of the sample.the trinity assemblies incorporated ~40% of sequences from the ld and md data sets into and contigs respectively with an average length of ~400 nt. for the hd data set, ~14% of reads from the hd data set into contigs with an average length of 328 nt. the average contig entropy was, and for ld, md and hd respectively with %, % and 92% of contigs possessing an entropy of zero. the number of domains correctly identified increased by ~ fold for the ld and md data sets and by ~ fold for the hd data set compared to individual sequence annotation. the correlation between the annotation of the contigs alone and the theoretical domain content of the sample were higher than for all read annotation. again it appears that the contigs capture the majority of the high-abundance transcripts and the unassembled debris capture the lower abundance transcripts, a combination of the two provides a stronger correlation with the known domain content of the samples than either individually. clustering of the illumina assemblies produced a net gain of between to extra domains, however this made only a relatively small improvement to the correlations with the known domain content of each sample. discussion the simulations show that the diversity of a metatranscriptome sample greatly impact the accuracy of protein domain annotations; with the high diversity simulations producing the weakest correlations with the known domain content of the sample. with a highly diverse population of organisms and transcripts, the average coverage of each transcript will decrease, thus clustering will result in many small clusters and fewer transcripts will be sequenced to sufficient depth to allow extension into longer contiguous fragments. however, regardless of the diversity level a better reflection of the domain content of the samples was achieved through applying data reduction techniques. the largest improvements in the correlation with the known domain content of the samples was achieved through assembly for the simulations and assembly followed by clustering the contigs and debris together for the illumina simulations. using near default parameters, highly homogeneous contigs were recreated from both and illumina data. it has been noted previously that assembly of'omics data is likely to favour highly abundant organisms, and it therefore follows that it would also favour highly abundant transcripts. the results of our simulations suggest that the annotations of contigs alone are insufficient, and we therefore recommend that they should be combined with those of the debris sequences to provide a better reflection of the real domain content of the samples. overall, the simulated illumina samples produced stronger correlations with the known protein domain content than the dollar cost-equivalent amount of sequence data. while we attempted to perform this analysis as consistently as possible, it was necessary to employ different assembly programs for the and illumina data –. however, the overall pattern of correlations from the different methods is fairly consistent and it seems likely that the stronger correlations of the illumina simulations are due to the greatly increased coverage provided rather than any biases introduced by the methods. while these simulations have their limitations, the results achieved were consistent with trials on real metatranscriptome data. we applied the data reduction methods previously employed on simulated data to two real metatranscriptome data sets: the mid-bloom, marine metatranscriptome from; and the 110 m marine metatranscriptome from an oxygen minimum zone. although the genuine domain content of a real microbial metatranscriptome is unknown, the results obtained from the gilbert and stewart metatranscriptomes were, in terms of data reduction and annotation rates, consistent with the medium and high diversity simulations. also, a recent study demonstrated that assembly of a simulated low diversity eukaryotic metatranscriptome could recreate a high number of contigs with low chimerism. in the future, these methods could be extended to exploit the increasing availability of microbial genomes and transcriptomes. for example, in real metatranscriptome data, the most abundant transcripts are often associated with fundamental processes such as biosynthesis. as more microbial transcriptome data become available ), it should be possible to refine these models of transcript abundance to reflect increased levels of transcripts involved in core processes and thereby produce more realistic simulations of metatranscriptome data.  based on our simulations, it appears that older recommendations to omit the assembly stage when dealing with high-diversity samples do not extend to metatranscriptome data. our results also show that including unassembled reads in downstream annotation can improve the overall accuracy and we would recommend that they should not be discarded after assembly. therefore, whether dealing with or illumina data, we recommend combining annotations from contigs and unassembled sequences for samples and employing a two-step data reduction of assembly followed by clustering of contigs and debris for illumina. the high coverage afforded by illumina sequencing has made it an increasingly popular choice for sequencing microbial communities. as more purpose built de-novo transcript assemblers become available there is a need for a systematic assessment of assembly tools and sequencing protocols for illumina metatranscriptome data. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
92,758fd7b8-3b3b-4916-af08-d9a68ff66d3f_flant5_gen,a comparison of assembly and clustering strategies for illumina metatranscriptome data," the sequencing and in-silico analysis of messenger rna is now routinely being applied to complex microbial communities in diverse eco-systems, including, but not limited to: soil, marine and intestinal habitats. the typical goals of metatranscriptomics are to taxonomically classify transcripts, predict their functions and quantify their abundances, and to relate these to environmental data in order to reveal how environmental conditions impact microbial communities in different habitats. metatranscriptome data sets typically consist of hundreds of thousands of sequences, or, more recently tens of millions of illumina sequences per sample. low taxonomic diversity and/or highly expressed genes can lead to a high degree of data redundancy; that is multiple identical or nearly identical sequence fragments. in an investigation into the proportion of artificial and natural duplicates in pyrosequenced metatranscriptome data, niu et al. reported that as much as 60% of all sequences in an early metatranscriptome data set were likely natural duplicates. therefore, some form of data reduction strategy is beneficial before running computationally intensive homology searches. two approaches that are commonly employed to reduce redundancy in large data sets are assembly: where sequences are assembled into longer contiguous fragments and clustering: sequences are grouped into clusters sharing a defined degree of similarity. the decisions as to whether to perform data reduction and which method to employ are influenced by several factors: the availability of reference genomes: if sufficient reference genomes are available for a small number of dominant species then the sequences can be mapped to them and taxonomy and function inferred and the relative abundance of the transcripts calculated. read length - are the unprocessed reads long enough to return annotations? current illumina platforms produce shorter reads than and are likely to return a lower hit rate to protein databases compared to longer reads. the diversity of the sample: although assembly can produce longer sequences and increase the accuracy of subsequent annotations, the variable coverage of transcripts in metatranscriptomics data sets and the presence of closely related organisms can lead to chimeric contigs. indeed, for highly diverse metagenomic samples it has been recommended that assembly not be performed at all. the aims of the analysis: if the read length is adequate for annotation and the intention is to count features then clustering at high identities is a recommended alternative. with the lower coverage but higher read length of metatranscriptome data, assembly is relatively uncommon and instead authors tend to either cluster or annotate sequences individually. clustering is regularly used for detecting and removing sequencing artifacts from data, grouping rrna data into operational taxonomic units, and grouping proteins into families. in addition to the known benefits of a reduction in the size of the data set and therefore computation time, we set out to assess whether, by clustering translated metatranscriptome sequences and transferring protein domain annotation from cluster representatives to cluster members - some of which may only partially cover protein domains used for classification, we can accurately increase the number of classifiable reads. more specifically, we investigated some popular data reduction tools and assessed their performance on simulated and illumina metatranscriptome data in terms of the accuracy of resulting protein annotations. note that although several approaches have been described to simulate metagenomic data sets and rna-seq data, to date only small scale attempts have been made to simulate metatranscriptome data sets based on a small number of species.  simulated data the simulated data sets contained sequences each, totalling ~ megabases of sequence per diversity level. between and 14% of sequences from each data set returned matches to pfam-a. when compared to the theoretical domain content, the correlation coefficients for all read annotation were, and for ld, md and hd respectively.table correlation coefficients between simulated data set annotations and known protein domain content all clustered contigs debris assembly 1 clustered assembly summary of pearson correlation coefficients between processed data sets and the known domain content of sample for low diversity, medium diversity and high diversity simulated and illumina metatranscriptomes. 1assembly includes annotation from both contigs and debris sequences. then, taking the parameter set that provided the largest increase in true positives minus false positives, compared to the annotation of all unclustered reads, we found that the best clustering parameters were: ≥ 60% overall similarity and 100% coverage of cluster member sequences for the ld data set; ≥80% similarity and 100% coverage of the cluster members for the md data set; and ≥60% similarity, ≥25% coverage of the cluster representative and between 0-50% minimum coverage of cluster members for the hd data set. while the best performing clustering parameters produced a net gain of between and domains, the correlation coefficients were slightly lower than for all read annotation ). the mira assemblies incorporated ~50% of all sequences into and contigs for the ld and md samples respectively, and ~30% of sequences into contigs for the hd sample. the average contig lengths were, and base pairs for ld, md and hd, respectively. the average contig entropy was, and for ld, md and hd respectively with %, % and % of contigs possessing an entropy of zero.figure contig entropy for assembled simulated metatranscriptomes. contig entropy plotted against contig length for a) mira assembled simulated data sets and b) trinity assembled simulated illumina data sets. plots represent, from left to right: low diversity, medium diversity and high diversity data sets. for the ld and md data sets, the net gain of true positives was a ~100% increase, and for the hd data set an increase of ~20% was achieved. the contigs alone had a weaker correlation with the theoretical domain content than all read or clustered read annotation. when combined with the debris sequences, the correlation coefficients for all three samples were higher than for all all-read or clustered annotations ). this could be due to two factors: firstly the low proportion of sequences incorporated into the contigs, and secondly the assemblies may be biased towards high-abundance transcripts.figure results from pfam-a annotated simulated metatranscriptomes. percentage of true positives, false positives, true negatives and potential domains based on a comparison with the known domain content of the data sets for all reads, best clustering, assembly and clustered assembly. a) results for simulated data sets, from left to right: low, medium and high diversity. b) results for simulated illumina data sets from left to right: low, medium and high diversity. correlation between high diversity simulations and known protein domain content. correlation plots of pfam-a annotations of each processed data set compared to known domain content for a) high diversity simulated data set and b) high diversity illumina simulated data set. top row, left to right: all reads unprocessed; clustered reads; assembly - contigs only. bottom row, left to right: assembly – debris only; assembly – contigs and debris combined; clustered assembly. pearson correlation coefficient shown in top left corner. clustering of the assemblies led to a very slight increase in the detection of true positives but the overall effect was a very slight reduction in the correlation with the theoretical domain content compared to the unclustered assembly. simulated illumina data around 4% of the illumina reads could be annotated with pfam-a domains. the correlation coefficients for all read annotation with the theoretical domain content were. the illumina data sets were clustered with the best performing parameter set for the equivalent diversity level identified in the simulations described above. while clustering reduced the data sets by ~40% for ld and md and ~25% for the hd data set the resulting annotations had a weaker correlation to the theoretical domain content of the sample.the trinity assemblies incorporated ~40% of sequences from the ld and md data sets into and contigs respectively with an average length of ~400 nt. for the hd data set, ~14% of reads from the hd data set into contigs with an average length of 328 nt. the average contig entropy was, and for ld, md and hd respectively with %, % and 92% of contigs possessing an entropy of zero. the number of domains correctly identified increased by ~ fold for the ld and md data sets and by ~ fold for the hd data set compared to individual sequence annotation. the correlation between the annotation of the contigs alone and the theoretical domain content of the sample were higher than for all read annotation. again it appears that the contigs capture the majority of the high-abundance transcripts and the unassembled debris capture the lower abundance transcripts, a combination of the two provides a stronger correlation with the known domain content of the samples than either individually. clustering of the illumina assemblies produced a net gain of between to extra domains, however this made only a relatively small improvement to the correlations with the known domain content of each sample. discussion the simulations show that the diversity of a metatranscriptome sample greatly impact the accuracy of protein domain annotations; with the high diversity simulations producing the weakest correlations with the known domain content of the sample. with a highly diverse population of organisms and transcripts, the average coverage of each transcript will decrease, thus clustering will result in many small clusters and fewer transcripts will be sequenced to sufficient depth to allow extension into longer contiguous fragments. however, regardless of the diversity level a better reflection of the domain content of the samples was achieved through applying data reduction techniques. the largest improvements in the correlation with the known domain content of the samples was achieved through assembly for the simulations and assembly followed by clustering the contigs and debris together for the illumina simulations. using near default parameters, highly homogeneous contigs were recreated from both and illumina data. it has been noted previously that assembly of'omics data is likely to favour highly abundant organisms, and it therefore follows that it would also favour highly abundant transcripts. the results of our simulations suggest that the annotations of contigs alone are insufficient, and we therefore recommend that they should be combined with those of the debris sequences to provide a better reflection of the real domain content of the samples. overall, the simulated illumina samples produced stronger correlations with the known protein domain content than the dollar cost-equivalent amount of sequence data. while we attempted to perform this analysis as consistently as possible, it was necessary to employ different assembly programs for the and illumina data –. however, the overall pattern of correlations from the different methods is fairly consistent and it seems likely that the stronger correlations of the illumina simulations are due to the greatly increased coverage provided rather than any biases introduced by the methods. while these simulations have their limitations, the results achieved were consistent with trials on real metatranscriptome data. we applied the data reduction methods previously employed on simulated data to two real metatranscriptome data sets: the mid-bloom, marine metatranscriptome from; and the 110 m marine metatranscriptome from an oxygen minimum zone. although the genuine domain content of a real microbial metatranscriptome is unknown, the results obtained from the gilbert and stewart metatranscriptomes were, in terms of data reduction and annotation rates, consistent with the medium and high diversity simulations. also, a recent study demonstrated that assembly of a simulated low diversity eukaryotic metatranscriptome could recreate a high number of contigs with low chimerism. in the future, these methods could be extended to exploit the increasing availability of microbial genomes and transcriptomes. for example, in real metatranscriptome data, the most abundant transcripts are often associated with fundamental processes such as biosynthesis. as more microbial transcriptome data become available ), it should be possible to refine these models of transcript abundance to reflect increased levels of transcripts involved in core processes and thereby produce more realistic simulations of metatranscriptome data.  based on our simulations, it appears that older recommendations to omit the assembly stage when dealing with high-diversity samples do not extend to metatranscriptome data. our results also show that including unassembled reads in downstream annotation can improve the overall accuracy and we would recommend that they should not be discarded after assembly. therefore, whether dealing with or illumina data, we recommend combining annotations from contigs and unassembled sequences for samples and employing a two-step data reduction of assembly followed by clustering of contigs and debris for illumina. the high coverage afforded by illumina sequencing has made it an increasingly popular choice for sequencing microbial communities. as more purpose built de-novo transcript assemblers become available there is a need for a systematic assessment of assembly tools and sequencing protocols for illumina metatranscriptome data. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
93,5849324e-2b8b-40a7-9a4d-9911b201b88f_gpt3_gen,"The article discusses the use of haplotypes to understand genomic inheritance patterns in recorded pedigrees, and the challenges in inferring haplotypes from genotypic data. The article explains the use of combinatorial optimization algorithms and simulated annealing in haplotype reconstruction and suggests the use of evolutionary algorithms for more efficient and parallelized computations. The article presents results comparing the efficiency of these different approaches in simulated and real data sets. The article concludes that evolutionary algorithms have advantages in convergence assessment and parallel computing, and can significantly outperform simulated annealing, especially when dealing with complex pedigrees with incomplete genotypic data. The article suggests that future research could explore further structural and parameterization strategies."," haplotypes can give useful information about patterns of inheritance for genomic regions. for each region, the probability of sharing founder genes through segregation in a recorded pedigree can be estimated based on the haplotypes, i.e. identity by descent probability based on linkage. the probability of sharing the genes from a common ancestor before the recorded pedigree can also be estimated based on the haplotypes, i.e. ibd probability based on linkage disequilibrium. those probabilities derived from the haplotypes are essential information for linkage mapping and association mapping. since haplotypes would not be directly observed from genotypic data, they need to be inferred based on observed pedigree information and marker genotypes. this would often result in a large state space of possible haplotype configurations especially with general pedigrees and incomplete genotypic data for multiple markers. exact likelihood methods using pedigree peeling, chromosome peeling or a combination of both algorithms often have problems dealing with the large state space and therefore have difficulties in finding the optimal haplotypes. alternatively, combinatorial optimization algorithms can be used. these are able to deal with problems that are hard to solve in polynomial time. one strategy used in such algorithms is to search for haplotype configurations that require a minimum number of recombination events or no recombination events. these approaches are rule-based and do not make any assumptions about genetic distances between markers. another approach is statistically based and would search for haplotype configurations with the highest likelihood, given all observed variables and known marker distances. a widely used statistical approach for haplotype reconstruction is simulated annealing which has been implemented in the linkage software, simwalk. simwalk uses a random walk approach to find candidates and an annealing process to develop the consecutive solutions to reach the optimal haplotypes. simwalk constitutes a flexible and efficient algorithm for haplotyping and probably the only one used for a general complex pedigree with incomplete genotypes. however, it needs a very large number of sequential evaluations and it is not always guaranteed that the most likely solutions are found within the arbitrarily determined number of evaluations. evolutionary algorithms constitute an efficient tool for solving combinatorial optimization problems. a number of parallel solutions are respectively updated by changing the variables within each solution, or recombining them from different solutions, and the most favorable solutions are selected. compared to sa, ea may be competitive in efficiently finding an optimal solution. an important advantage of ea is its potential to parallellise computations because the algorithm can be divided across multiple cpus. this would substantially reduce computing time. moreover, the search mechanism in ea can make it easier to diagnose convergence compared to that in simwalk it is well known that ea can be easily designed and parameterised for a specific problem, and standard values for ea-parameters usually give reasonably good results. in addition, jointly updating the set of dependent variables can increase the computational efficiency although not all sets of dependent variables may be found. it is noted that simwalk attempts to update multiple variables together, but the set that is updated is randomly chosen. because dependent variables are not necessarily within the same set, the acceptance rates are generally low. an evolutionary algorithm has not been implemented before in statistical approaches for haplotyping. the aim of this study is to investigate the use of an evolutionary algorithm and joint updating strategy for haplotyping, and compare its efficiency with simwalk  likelihood pattern with simulated data ‡number of evaluations of the likelihood function, * is from the default annealing schedule of simwalk2 ¶computing time for simwalk ea and ea when using incomplete genotypic data, the likelihood values are not yet converged after evaluations. after evaluations, the likelihood values appear to be fairly close to the global maximum where the value for ea is the highest among the three methods. after, evaluations, the likelihood reaches stable values with apparent convergence where the value for ea is the highest and the value for simwalk is the worst. it is noted that the convergence patterns and the evaluation numbers are different between complete and incomplete genotypes. likelihood pattern with real data ¶computing time for simwalk ea and ea computing time for a fixed number of evaluations with processors the relative computing time between simwalk ea and ea with processors varies depending on data structure. when using simulated data with complete genotypes, the computing time completing, evaluations for ea and ea was times and times faster than simwalk. however, when using simulated data with incomplete genotypes, the relative computing efficiency for ea was decreased; ea was times and ea was times faster than simwalk. when using the real data, the computing time completing, evaluations for ea and ea was times and times faster than simwalk. the larger advantage for ea for a larger data set is probably due to the fact that the proportion of transferring time over whole computing time increases when using a data set of small size with a few genotypes, e.g. simulated data with incomplete genotypes. convergence diagnosis and computational efficiency discussion the ea and ea reach the global or nearly global maximum quicker than simwalk both with simulated and real data. this was probably due to the fact that ea and ea used a number of parallel configurations which apparently is a more efficient searching mechanism, resulting in a wider range of variables updated during the cycles. using an efficient joint updating strategy combined with the random walk, ea significantly outperformed simwalk with a simultaneous use of multiple processors. convergence for ea or simwalk can be assessed by comparison of the likelihood values between different parts to check if the likelihood reaches a stable value. when the likelihood value is not converged, simwalk as currently implemented, requires another complete run with a new annealing schedule which would need to be longer than the previous run. therefore, simwalk may need multiple runs with a large number of evaluations. however, in the ea, the convergence of the likelihood value can be checked at any time and any point during the run without any rescheduling or rerun. for convergence diagnosis shown in figure simwalk needed to run more than times because of rescheduling of the annealing process for each point. however, ea and ea needed only a single run for the same convergence assessment. the ea population size was arbitrarily set at n = the chance of operating ea-recombination or ea-mutation was randomly equal, i.e. the probability of ea-recombination was ~. different ea-parameters did not dramatically affect the results unless the values were extreme, e.g. outside the range – for n or outside the range ~ for the probability of ea-recombination. if there are hundreds of cpus available, then n should not be less than the number of cpus used, to maximize the efficiency of parallel computing. such large values for n for large scale parallel computing should be tested with regard to optimal performance. however, it is possible to set n considerably higher than optimal, and computational efficiency is still increased. in the real data, we used microsatellites on the same chromosome positioned at cm intervals on average. however, a much larger number of markers is expected to be used soon, e.g. thousands of single nucleotide polymorphisms at << ~ cm intervals on a single chromosome. the ea with hundreds of cpus may be able to parallelize and solve the increased size of the problem within a reasonable time. haplotypes for dense markers might be resolved using population ld without pedigree information. however, when population ld is not significant over the average marker distance, the methods may perform poorly. therefore, when ld is not sufficient or one may not be sure whether there is enough ld, our approach will be an efficient tool for haplotyping for most types of data. when using multiple cpus and multiple machines, data transfer between machines took a large part of the overall computing time. therefore, the ea was slightly modified in order to save on transfer time. there were n nodes for ea-members parallelised between machines. we made each node have two ea-members. ea-mutation and ea-recombination were carried out in each node, and the solutions were evolved. one set of solutions in each node was moved to the next node every n cycles, therefore a complete evolutionary mechanism was performed with periodic isolation of islands. the number for n was chosen as n = total number of iterations/k, which resulted in k transfers between nodes in an analysis. it is noted that n should be a sufficient number for ea-mutation and ea-recombination within each node, and k should be a sufficient number for communicating between the nodes. in this study, we chose a large number k = which would be sufficient for n as well because we usually used the total number of iterations ≥ number of meiosis × number of markers × such a strategy becomes more important when using many different machines. we used data sets having complex relationships with incomplete genotypes. such data sets are quite common in natural and outbred populations. complex pedigrees with incomplete genotypes will generally generate a too large state space for haplotying, which cannot be handled by exact methods. however, simwalk has been successfully and widely used for such data sets although the size of data should be small or moderate. we showed that our approach could handle such data sets, and the computational efficiency for our approach was much higher than that for simwalk  the difference between ea and sa is mainly determined by the parameters used in their search mechanism, which affect the number of configurations considered in the cycles and updating strategies, and how information from different solutions is used to generate new candidate solutions. the ea algorithm has a substantial advantage in convergence assessment and parallel computing, which would much increase the efficiency of haplotype reconstruction. moreover, with the joint updating scheme, ea significantly outperformed simwalk. with more cpu, the computational efficiency of ea would be increased. in addition, our implementation of ea and ea for this application is likely to leave much room for increased performance, given the wide range of structural and parameterization strategies that could be invoked. further study would be required to investigate such potential. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
94,5849324e-2b8b-40a7-9a4d-9911b201b88f_flant5_gen,Evolutionary algorithms and joint updating strategy for haplotyping," haplotypes can give useful information about patterns of inheritance for genomic regions. for each region, the probability of sharing founder genes through segregation in a recorded pedigree can be estimated based on the haplotypes, i.e. identity by descent probability based on linkage. the probability of sharing the genes from a common ancestor before the recorded pedigree can also be estimated based on the haplotypes, i.e. ibd probability based on linkage disequilibrium. those probabilities derived from the haplotypes are essential information for linkage mapping and association mapping. since haplotypes would not be directly observed from genotypic data, they need to be inferred based on observed pedigree information and marker genotypes. this would often result in a large state space of possible haplotype configurations especially with general pedigrees and incomplete genotypic data for multiple markers. exact likelihood methods using pedigree peeling, chromosome peeling or a combination of both algorithms often have problems dealing with the large state space and therefore have difficulties in finding the optimal haplotypes. alternatively, combinatorial optimization algorithms can be used. these are able to deal with problems that are hard to solve in polynomial time. one strategy used in such algorithms is to search for haplotype configurations that require a minimum number of recombination events or no recombination events. these approaches are rule-based and do not make any assumptions about genetic distances between markers. another approach is statistically based and would search for haplotype configurations with the highest likelihood, given all observed variables and known marker distances. a widely used statistical approach for haplotype reconstruction is simulated annealing which has been implemented in the linkage software, simwalk. simwalk uses a random walk approach to find candidates and an annealing process to develop the consecutive solutions to reach the optimal haplotypes. simwalk constitutes a flexible and efficient algorithm for haplotyping and probably the only one used for a general complex pedigree with incomplete genotypes. however, it needs a very large number of sequential evaluations and it is not always guaranteed that the most likely solutions are found within the arbitrarily determined number of evaluations. evolutionary algorithms constitute an efficient tool for solving combinatorial optimization problems. a number of parallel solutions are respectively updated by changing the variables within each solution, or recombining them from different solutions, and the most favorable solutions are selected. compared to sa, ea may be competitive in efficiently finding an optimal solution. an important advantage of ea is its potential to parallellise computations because the algorithm can be divided across multiple cpus. this would substantially reduce computing time. moreover, the search mechanism in ea can make it easier to diagnose convergence compared to that in simwalk it is well known that ea can be easily designed and parameterised for a specific problem, and standard values for ea-parameters usually give reasonably good results. in addition, jointly updating the set of dependent variables can increase the computational efficiency although not all sets of dependent variables may be found. it is noted that simwalk attempts to update multiple variables together, but the set that is updated is randomly chosen. because dependent variables are not necessarily within the same set, the acceptance rates are generally low. an evolutionary algorithm has not been implemented before in statistical approaches for haplotyping. the aim of this study is to investigate the use of an evolutionary algorithm and joint updating strategy for haplotyping, and compare its efficiency with simwalk  likelihood pattern with simulated data ‡number of evaluations of the likelihood function, * is from the default annealing schedule of simwalk2 ¶computing time for simwalk ea and ea when using incomplete genotypic data, the likelihood values are not yet converged after evaluations. after evaluations, the likelihood values appear to be fairly close to the global maximum where the value for ea is the highest among the three methods. after, evaluations, the likelihood reaches stable values with apparent convergence where the value for ea is the highest and the value for simwalk is the worst. it is noted that the convergence patterns and the evaluation numbers are different between complete and incomplete genotypes. likelihood pattern with real data ¶computing time for simwalk ea and ea computing time for a fixed number of evaluations with processors the relative computing time between simwalk ea and ea with processors varies depending on data structure. when using simulated data with complete genotypes, the computing time completing, evaluations for ea and ea was times and times faster than simwalk. however, when using simulated data with incomplete genotypes, the relative computing efficiency for ea was decreased; ea was times and ea was times faster than simwalk. when using the real data, the computing time completing, evaluations for ea and ea was times and times faster than simwalk. the larger advantage for ea for a larger data set is probably due to the fact that the proportion of transferring time over whole computing time increases when using a data set of small size with a few genotypes, e.g. simulated data with incomplete genotypes. convergence diagnosis and computational efficiency discussion the ea and ea reach the global or nearly global maximum quicker than simwalk both with simulated and real data. this was probably due to the fact that ea and ea used a number of parallel configurations which apparently is a more efficient searching mechanism, resulting in a wider range of variables updated during the cycles. using an efficient joint updating strategy combined with the random walk, ea significantly outperformed simwalk with a simultaneous use of multiple processors. convergence for ea or simwalk can be assessed by comparison of the likelihood values between different parts to check if the likelihood reaches a stable value. when the likelihood value is not converged, simwalk as currently implemented, requires another complete run with a new annealing schedule which would need to be longer than the previous run. therefore, simwalk may need multiple runs with a large number of evaluations. however, in the ea, the convergence of the likelihood value can be checked at any time and any point during the run without any rescheduling or rerun. for convergence diagnosis shown in figure simwalk needed to run more than times because of rescheduling of the annealing process for each point. however, ea and ea needed only a single run for the same convergence assessment. the ea population size was arbitrarily set at n = the chance of operating ea-recombination or ea-mutation was randomly equal, i.e. the probability of ea-recombination was ~. different ea-parameters did not dramatically affect the results unless the values were extreme, e.g. outside the range – for n or outside the range ~ for the probability of ea-recombination. if there are hundreds of cpus available, then n should not be less than the number of cpus used, to maximize the efficiency of parallel computing. such large values for n for large scale parallel computing should be tested with regard to optimal performance. however, it is possible to set n considerably higher than optimal, and computational efficiency is still increased. in the real data, we used microsatellites on the same chromosome positioned at cm intervals on average. however, a much larger number of markers is expected to be used soon, e.g. thousands of single nucleotide polymorphisms at << ~ cm intervals on a single chromosome. the ea with hundreds of cpus may be able to parallelize and solve the increased size of the problem within a reasonable time. haplotypes for dense markers might be resolved using population ld without pedigree information. however, when population ld is not significant over the average marker distance, the methods may perform poorly. therefore, when ld is not sufficient or one may not be sure whether there is enough ld, our approach will be an efficient tool for haplotyping for most types of data. when using multiple cpus and multiple machines, data transfer between machines took a large part of the overall computing time. therefore, the ea was slightly modified in order to save on transfer time. there were n nodes for ea-members parallelised between machines. we made each node have two ea-members. ea-mutation and ea-recombination were carried out in each node, and the solutions were evolved. one set of solutions in each node was moved to the next node every n cycles, therefore a complete evolutionary mechanism was performed with periodic isolation of islands. the number for n was chosen as n = total number of iterations/k, which resulted in k transfers between nodes in an analysis. it is noted that n should be a sufficient number for ea-mutation and ea-recombination within each node, and k should be a sufficient number for communicating between the nodes. in this study, we chose a large number k = which would be sufficient for n as well because we usually used the total number of iterations ≥ number of meiosis × number of markers × such a strategy becomes more important when using many different machines. we used data sets having complex relationships with incomplete genotypes. such data sets are quite common in natural and outbred populations. complex pedigrees with incomplete genotypes will generally generate a too large state space for haplotying, which cannot be handled by exact methods. however, simwalk has been successfully and widely used for such data sets although the size of data should be small or moderate. we showed that our approach could handle such data sets, and the computational efficiency for our approach was much higher than that for simwalk  the difference between ea and sa is mainly determined by the parameters used in their search mechanism, which affect the number of configurations considered in the cycles and updating strategies, and how information from different solutions is used to generate new candidate solutions. the ea algorithm has a substantial advantage in convergence assessment and parallel computing, which would much increase the efficiency of haplotype reconstruction. moreover, with the joint updating scheme, ea significantly outperformed simwalk. with more cpu, the computational efficiency of ea would be increased. in addition, our implementation of ea and ea for this application is likely to leave much room for increased performance, given the wide range of structural and parameterization strategies that could be invoked. further study would be required to investigate such potential. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
95,2205acc2-794b-4853-b3f3-b7708cc5ff62_flant5_gen,pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a byproduct of the production of teflon-lined non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances. pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances.," it is well known that the teflon event involving the dupont company of usa drew serious international attention to perfluorooctanoic acid; pfoa is formed from the raw materials used in the production of teflon-lined non-stick cooking appliances. fluoropolymers such as teflon have very good performances e.g. as fire retardants and for oil and fat resistance; their byproducts such as pfoa can be formed by cooking, burning and environmental degradation. pfoa is still widely used in basic processes in the aviation, automobile, building materials, chemicals, electronic, semiconductor and textile industries. it is persistent and non-biodegradable and becomes widely distributed in nature, e.g. water, biological bodies, human tissues and foods. it can certainly enter the gastrointestinal tract via the intake of foods and water and then it is absorbed and permeates into the blood and various tissues. sampling studies have revealed the presence of pfoa in the bloods of over 90% of us residents. it may have serious effects on the endocrine, immune and nervous systems and it can be delivered to the fetus through the umbilical cord and can accumulate. it can also cause cancers of the liver, testis, pancreatic and mammary glands, and can lead to embryonic deformities and other diseases. in recent years, pfoa has become a significant issue in many aspects of environmental ecology, toxicology, pathology and life sciences. human serum albumin is a major protein component of blood plasma but is also found in the interstitial fluid of body tissues. in mammals, albumin is synthesized by the liver and has a half-life of days in the circulation. it is the major contributor to the oncotic pressure of the blood plasma. it is called a multifunctional plasma carrier protein because of its ability to bind an unusually broad spectrum of ligands e.g. inorganic ions, various drugs, amino acids, fatty acids, etc. binding to hsa facilitates their transport throughout the circulation. without doubt, interaction of any toxicant with hsa influences the transport of nutrients and drugs. recently, studies have been conducted on the binding of organic contaminants or toxins to hsa e.g. arazine, ochratoxin, methyl parathion and arsenic. bindings of pfoa to biomacromolecular such as rat and human plasma proteins, rat liver-form and kidney-form alpha 2u-globulins, have been investigated at room temperature. the interaction of organic contaminants and hsa is always affected by various environmental conditions such as ph, strength and temperature. in this work, we investigated the interaction of pfoa with hsa by equilibrium dialysis, fluorospectrometry, isothermal titration calorimetry and circular dichroism under normal physiological condition, ph and m electrolyte and 37°c. the object is to analyze the interaction forces, sites and type and then further understand the toxigenicity of pfoa.  equilibrium dialysis of pfoa the equilibrium dialysis method was used to investigate the interaction of pfoa with hsa. the pfoa concentration in the dialysis solution was measured at 37°c at various dialysis times with no protein in the membrane. the pfoa dialysis rate approaches 90% at h and exceeds 98% after h. pfoa passes freely through the semi-permeable membrane until equilibrium reached. hsa solution was put into the dialysis membrane as dialysate instead of pfoa, but it was found only in the dialysis bag. therefore, the equilibrium dialysis is suitable for investigating the interaction of pfoa with hsa. the dialysis solution was sampled and measured spectrophotometrically to determine the pfoa concentration after more than h of dialysis. characterization of the interactions of pfoa with hsa the interaction of pfoa with hsa is summarized as follows: both cl and cm are the initial mole concentrations of pfoa and hsa, cl is the equilibrium concentration of pfoa described above. n is the saturation binding number of pfoa. the effective fraction of pfoa bound to hsa and its molar binding ratio are calculated by the relations: f = 1-cl/cl and γ = fcl0/cm the γ value will approach n with increasing pfoa. in fact, ph varies widely among normal tissues in the human body. for example, less than ph in gastric fluid, ph in liver and saliva, ph – on the skin and around ph in blood and intestinal tract. normal human temperature is 37°c and the electrolyte concentration is between and %. in this present work, the experiments were conducted in m nacl at ph at 37°c. by measuring a series of pfoa solutions containing known concentrations of hsa at ph, the f and γ values were calculated according to the above equations. the f decreases linearly with increasing pfoa concentration from curve in fig. but γ increases from curve the binding of pfoa approaches to a constant maximum at when cl0/cm is more than from curve the number of amino acid residues positively charged e.g. lys, his and arg is in hsa, which is no correlation with such an n value. different from a sulfonic azo ligand, the pfoa binding to hsa doesn't results from ion-pair attraction. strong intermolecular forces e.g. hydrogen bond, van der waals forces and hydrophobic interaction may be involved. the temkin isothermal model, was used to fit the above experimental data. from curve, the interaction of pfoa with hsa corresponds to chemical monolayer adsorption. both Δq and ka were calculated to be - kj/mol and × m- the adsorption of pfoa on hsa is exothermic and non-covalent, i.e. no strong bond was formed between pfoa and hsa. in order to understand the mechanism of pfoa-hsa binding, some detailed thermodynamic data are needed. the itc measurement may provide information on thermodynamic quantities such as enthalpy and heat capacity changes during the molecular interaction directly from the heat produced by the reaction, and have been used to study, for example, protein interactions, dna triplex formation and hiv protease activity. fig. 3a depicts a typical isothermal titration profile obtained by injecting pfoa into the itc cell containing hsa. the resulting values were plotted as a function of cl0/cm and fitted to a two-step sequential binding model by a nonlinear least squares method. values for the equilibrium constant, enthalpy change and entropy change of the pfoa-hsa reaction were obtained and calculated by the gibbs free energy equation: Δg = -rtlnkb = Δh-tΔ s. the thermodynamic parameters derived from this curve are summarized in table because both Δhi values are much less than kcal/mol, the non-covalent binding of pfoa to hsa is confirmed. pfoa is more lipophilic in aqueous solution and it decreased obviously the aqueous surface intensity. fifteen electrophilic f-groups in pfoa can attract strongly the lone pair electrons of polar side groups of peptide chain, e.g. f⋯n and f⋯o halogen bonding. hsa is consisted of three homologous all α-helical domains, each divided into two subdomains. all the helixic subdomains are distributed round a hydrophobic intracavity and the hydrophilic side groups of hsa exposed on the outer surface. in the first step, only one pfoa molecule bound on hsa. the f of pfoa is always more than 90% from curve in fig. when the cl0/cm is less than therefore, the first step is complete at approximately of cl0/cm hsa binding pfoa caused the entropy decreasing in this step. the refolding of hsa occurred by resuming the released heat. from Δg value, the pfoa-hsa reaction is spontaneous. moreover, the higher kb, value indicated that the binding of the first pfoa molecule to hsa is firmer. from curve to in fig. the blue shift of peak emission wavelength from to nm indicated that the static quench of the hsa's intrinsic fluorescence occurred in the presence of pfoa, specially obviously when cl0/cm is less than thus, the first pfoa molecule may bind to the side group of tyr. as a result, the deformable linear pfoa may insert into the hydrophobic intracavity of hsa and bridge between subdomains iia and iib across trp by f⋯n and f⋯o halogen bonding with the polar side groups of asn, gln, asp, glu, arg, his, tyr and trp and hydrophobic interaction with the non-polar side groups, e.g. val, leu, met, ala and ile. the first step binding of pfoa to hsa is similar to that of long chain fatty acids to hsa. besides a long carbon chain, pfoa has strong extensibility on interface of water – particles so that it may spread on the exposed outer surface of hsa. when cl0/cm is more than pfoa began to bind on the hydrophilic surface of hsa till a saturation via the polar bonds e.g. ionic interaction, hydrogen bond and f⋯n and f⋯o halogen bonding. by comparison of n obtained by equilibrium dialysis and that obtained by itc, two methods achieves the same result. from the higher Δh value, the binding sites of pfoa may bridge between any two helixes all over the outer surface of hsa. from Δg value, the pfoa-hsa reaction is spontaneous. in the 2nd step, the binding of pfoa to hsa caused an obvious entropy decreasing, i.e. more negative Δs, the hsa structure changed refolding. by comparison of the emission spectra in fig. the obvious blue shift of peak wavelength was found when cl0/cm is more than this indicates an obvious change of hsa conformation, too. as a result, the interaction of pfoa with hsa is assignable under normal physiological condition. in addition, the β-pleated sheet content of hsa decreased obviously and its α-helix increased by 15% in the presence of pfoa from the change of cd spectra of hsa. thus, the second step in pfoa binding changed a substantial part of the β-pleated sheet of hsa into α-helix form. without doubt, such a binding would cause a great change of hsa structure and affect the function of hsa in blood.  the current work investigated the interaction of pfoa with hsa in the normal physiological acidities of blood and intestinal tract tissue where pfoa molecules may be present. the interaction of pfoa with hsa accorded with the langmuir isothermal model in two-step sequence, in which only one pfoa molecule entered the hydrophobic intracavity in the first step and pfoa molecules binding on the hydrophilic outer surface in the second step. the interaction of pfoa and hsa is spontaneous and the non-covalent bond results in change of hsa conformation. the possible binding sites were also speculated. the present work proposed a determination and characterization method for the intermolecular weak interaction. if combined further with the other experiments e.g. biomolecular function effect, cell membrane transport of contaminant and toxicological testing, it is more helpful for elucidating the toxigenicity of perfluorochemicals. ",pubmed_generic,Flan T5,pfoa is a persistent and non-biodegradable chemical that is widely used in the production of non-stick cooking appliances.,non_factual,factual,minor,,intrinsic,,,,,
96,2205acc2-794b-4853-b3f3-b7708cc5ff62_gpt3_gen,"The article discusses the interaction of perfluorooctanoic acid (PFOA) with human serum albumin (HSA), a major protein component of blood plasma. PFOA, a byproduct of fluoropolymers such as Teflon, is a persistent and non-biodegradable chemical that is widely distributed in nature and can have serious effects on the endocrine, immune, and nervous systems. The article investigates the interaction of PFOA with HSA through various methods and finds that the interaction follows a two-step sequential binding model in which PFOA binds to the hydrophobic intracavity and hydrophilic outer surface of HSA, causing changes in HSA conformation. The article proposes that this method of determining and characterizing weak intermolecular interactions can be combined with other experiments to better understand the toxigenicity of perfluorochemicals."," it is well known that the teflon event involving the dupont company of usa drew serious international attention to perfluorooctanoic acid; pfoa is formed from the raw materials used in the production of teflon-lined non-stick cooking appliances. fluoropolymers such as teflon have very good performances e.g. as fire retardants and for oil and fat resistance; their byproducts such as pfoa can be formed by cooking, burning and environmental degradation. pfoa is still widely used in basic processes in the aviation, automobile, building materials, chemicals, electronic, semiconductor and textile industries. it is persistent and non-biodegradable and becomes widely distributed in nature, e.g. water, biological bodies, human tissues and foods. it can certainly enter the gastrointestinal tract via the intake of foods and water and then it is absorbed and permeates into the blood and various tissues. sampling studies have revealed the presence of pfoa in the bloods of over 90% of us residents. it may have serious effects on the endocrine, immune and nervous systems and it can be delivered to the fetus through the umbilical cord and can accumulate. it can also cause cancers of the liver, testis, pancreatic and mammary glands, and can lead to embryonic deformities and other diseases. in recent years, pfoa has become a significant issue in many aspects of environmental ecology, toxicology, pathology and life sciences. human serum albumin is a major protein component of blood plasma but is also found in the interstitial fluid of body tissues. in mammals, albumin is synthesized by the liver and has a half-life of days in the circulation. it is the major contributor to the oncotic pressure of the blood plasma. it is called a multifunctional plasma carrier protein because of its ability to bind an unusually broad spectrum of ligands e.g. inorganic ions, various drugs, amino acids, fatty acids, etc. binding to hsa facilitates their transport throughout the circulation. without doubt, interaction of any toxicant with hsa influences the transport of nutrients and drugs. recently, studies have been conducted on the binding of organic contaminants or toxins to hsa e.g. arazine, ochratoxin, methyl parathion and arsenic. bindings of pfoa to biomacromolecular such as rat and human plasma proteins, rat liver-form and kidney-form alpha 2u-globulins, have been investigated at room temperature. the interaction of organic contaminants and hsa is always affected by various environmental conditions such as ph, strength and temperature. in this work, we investigated the interaction of pfoa with hsa by equilibrium dialysis, fluorospectrometry, isothermal titration calorimetry and circular dichroism under normal physiological condition, ph and m electrolyte and 37°c. the object is to analyze the interaction forces, sites and type and then further understand the toxigenicity of pfoa.  equilibrium dialysis of pfoa the equilibrium dialysis method was used to investigate the interaction of pfoa with hsa. the pfoa concentration in the dialysis solution was measured at 37°c at various dialysis times with no protein in the membrane. the pfoa dialysis rate approaches 90% at h and exceeds 98% after h. pfoa passes freely through the semi-permeable membrane until equilibrium reached. hsa solution was put into the dialysis membrane as dialysate instead of pfoa, but it was found only in the dialysis bag. therefore, the equilibrium dialysis is suitable for investigating the interaction of pfoa with hsa. the dialysis solution was sampled and measured spectrophotometrically to determine the pfoa concentration after more than h of dialysis. characterization of the interactions of pfoa with hsa the interaction of pfoa with hsa is summarized as follows: both cl and cm are the initial mole concentrations of pfoa and hsa, cl is the equilibrium concentration of pfoa described above. n is the saturation binding number of pfoa. the effective fraction of pfoa bound to hsa and its molar binding ratio are calculated by the relations: f = 1-cl/cl and γ = fcl0/cm the γ value will approach n with increasing pfoa. in fact, ph varies widely among normal tissues in the human body. for example, less than ph in gastric fluid, ph in liver and saliva, ph – on the skin and around ph in blood and intestinal tract. normal human temperature is 37°c and the electrolyte concentration is between and %. in this present work, the experiments were conducted in m nacl at ph at 37°c. by measuring a series of pfoa solutions containing known concentrations of hsa at ph, the f and γ values were calculated according to the above equations. the f decreases linearly with increasing pfoa concentration from curve in fig. but γ increases from curve the binding of pfoa approaches to a constant maximum at when cl0/cm is more than from curve the number of amino acid residues positively charged e.g. lys, his and arg is in hsa, which is no correlation with such an n value. different from a sulfonic azo ligand, the pfoa binding to hsa doesn't results from ion-pair attraction. strong intermolecular forces e.g. hydrogen bond, van der waals forces and hydrophobic interaction may be involved. the temkin isothermal model, was used to fit the above experimental data. from curve, the interaction of pfoa with hsa corresponds to chemical monolayer adsorption. both Δq and ka were calculated to be - kj/mol and × m- the adsorption of pfoa on hsa is exothermic and non-covalent, i.e. no strong bond was formed between pfoa and hsa. in order to understand the mechanism of pfoa-hsa binding, some detailed thermodynamic data are needed. the itc measurement may provide information on thermodynamic quantities such as enthalpy and heat capacity changes during the molecular interaction directly from the heat produced by the reaction, and have been used to study, for example, protein interactions, dna triplex formation and hiv protease activity. fig. 3a depicts a typical isothermal titration profile obtained by injecting pfoa into the itc cell containing hsa. the resulting values were plotted as a function of cl0/cm and fitted to a two-step sequential binding model by a nonlinear least squares method. values for the equilibrium constant, enthalpy change and entropy change of the pfoa-hsa reaction were obtained and calculated by the gibbs free energy equation: Δg = -rtlnkb = Δh-tΔ s. the thermodynamic parameters derived from this curve are summarized in table because both Δhi values are much less than kcal/mol, the non-covalent binding of pfoa to hsa is confirmed. pfoa is more lipophilic in aqueous solution and it decreased obviously the aqueous surface intensity. fifteen electrophilic f-groups in pfoa can attract strongly the lone pair electrons of polar side groups of peptide chain, e.g. f⋯n and f⋯o halogen bonding. hsa is consisted of three homologous all α-helical domains, each divided into two subdomains. all the helixic subdomains are distributed round a hydrophobic intracavity and the hydrophilic side groups of hsa exposed on the outer surface. in the first step, only one pfoa molecule bound on hsa. the f of pfoa is always more than 90% from curve in fig. when the cl0/cm is less than therefore, the first step is complete at approximately of cl0/cm hsa binding pfoa caused the entropy decreasing in this step. the refolding of hsa occurred by resuming the released heat. from Δg value, the pfoa-hsa reaction is spontaneous. moreover, the higher kb, value indicated that the binding of the first pfoa molecule to hsa is firmer. from curve to in fig. the blue shift of peak emission wavelength from to nm indicated that the static quench of the hsa's intrinsic fluorescence occurred in the presence of pfoa, specially obviously when cl0/cm is less than thus, the first pfoa molecule may bind to the side group of tyr. as a result, the deformable linear pfoa may insert into the hydrophobic intracavity of hsa and bridge between subdomains iia and iib across trp by f⋯n and f⋯o halogen bonding with the polar side groups of asn, gln, asp, glu, arg, his, tyr and trp and hydrophobic interaction with the non-polar side groups, e.g. val, leu, met, ala and ile. the first step binding of pfoa to hsa is similar to that of long chain fatty acids to hsa. besides a long carbon chain, pfoa has strong extensibility on interface of water – particles so that it may spread on the exposed outer surface of hsa. when cl0/cm is more than pfoa began to bind on the hydrophilic surface of hsa till a saturation via the polar bonds e.g. ionic interaction, hydrogen bond and f⋯n and f⋯o halogen bonding. by comparison of n obtained by equilibrium dialysis and that obtained by itc, two methods achieves the same result. from the higher Δh value, the binding sites of pfoa may bridge between any two helixes all over the outer surface of hsa. from Δg value, the pfoa-hsa reaction is spontaneous. in the 2nd step, the binding of pfoa to hsa caused an obvious entropy decreasing, i.e. more negative Δs, the hsa structure changed refolding. by comparison of the emission spectra in fig. the obvious blue shift of peak wavelength was found when cl0/cm is more than this indicates an obvious change of hsa conformation, too. as a result, the interaction of pfoa with hsa is assignable under normal physiological condition. in addition, the β-pleated sheet content of hsa decreased obviously and its α-helix increased by 15% in the presence of pfoa from the change of cd spectra of hsa. thus, the second step in pfoa binding changed a substantial part of the β-pleated sheet of hsa into α-helix form. without doubt, such a binding would cause a great change of hsa structure and affect the function of hsa in blood.  the current work investigated the interaction of pfoa with hsa in the normal physiological acidities of blood and intestinal tract tissue where pfoa molecules may be present. the interaction of pfoa with hsa accorded with the langmuir isothermal model in two-step sequence, in which only one pfoa molecule entered the hydrophobic intracavity in the first step and pfoa molecules binding on the hydrophilic outer surface in the second step. the interaction of pfoa and hsa is spontaneous and the non-covalent bond results in change of hsa conformation. the possible binding sites were also speculated. the present work proposed a determination and characterization method for the intermolecular weak interaction. if combined further with the other experiments e.g. biomolecular function effect, cell membrane transport of contaminant and toxicological testing, it is more helpful for elucidating the toxigenicity of perfluorochemicals. ",pubmed_generic,GPT 3.5,The article proposes that this method of determining and characterizing weak intermolecular interactions can be combined with other experiments to better understand the toxigenicity of perfluorochemicals.,non_factual,factual,minor,,intrinsic,,,,,
97,e6a6a5ec-b9f0-4e48-954f-1207f7750d64_gpt3_gen,"The article discusses the importance of anacystis nidulans, a prokaryotic cyanobacterium, in freshwater ecosystems as a primary producer and indicator of heavy metal toxicity. The article also explores the role of cyanophage, viruses that infect cyanobacteria, in modulating microbial populations and affecting water quality. The study focuses on the induction of temperate A. nidulans lysogenic phage by copper, and the results suggest that copper is a significant inducer for temperate as- released from an-t, with concentrations of × 10-4m to × 10-5m showing the highest level of viral induction. The study highlights the potential role of copper in triggering the cyanobacteria population in freshwater aquatic environments."," anacystis nidulans is a rod-shaped, unicellular prokaryotic cyanobacterium and plays an important role in aquatic ecosystems as a primary producer. it is often used as an indicator for studying the toxic metabolic levels of heavy metals. many heavy metal studies have been done using a. nidulans as the model system for the reaction of organisms to heavy metal stresses. in freshwater environments, dense algal blooms of cyanobacteria are usually caused by nutrient enrichment from sewage, agricultural fertilizers and industrial run-off into waterways. algal blooms are considered threat to the water system. cyanophage are viruses that infect cyanobacteria and are ubiquitous in both freshwater and marine environments. these phages play important roles in modulating cyanobacterial populations, affecting primary productivity, increasing water quality and may have a profound influence on global biogeochemical cycles. although the interaction between a cyanophage and its host organism is important in maintaining water quality in freshwater systems, little is known about how viruses regulate microbial mortality in natural waters. recently, it was found that lysogenic infection was common in marine synechococcus sp.. cyanophage infecting a single strain of marine synechococcus sp. can reach to per ml in seawater. suttle and chan have estimated that between 5– % of marine synechococcus cells were lysed by cyanophage daily. the discovery of a high abundance of viral particles in natural waters initiated the research on the ecological impact of the viral infection and lysis of marine microbes. they also provided evidence that viruses can affect microbial populations by either going through a lytic cycle, causing destruction of the host cell, or maintaining a lysogenic stage, in which the viral genome is inserted and maintained as the prophage in its host cell. there was also evidence to suggest that seasonal changes can cause the prophage to enter a lytic cycle thus leading to the disappearance of algae blooms. lysogeny can also be induced to a lytic cycle by pollutants. although extensive research has been done on the interaction between cyanophage and cyanbacteria in marine systems, there are no significant reports that have focused on freshwater cyanophage/cyanobacteria interactions. the possibility of temperate as- and lysogenic a. nidulans was suggested by bisen et al, but there was no direct evidence provided. it has been reported that uv, mitomycin c and heavy metals such as copper, cadmium can induce the release of cyanophage in marine water. in this study, different concentrations of copper sulfate were used to study a possible as- lysogenic life cycle in addition to the previously characterized lytic cycle. addition of copper sulfate led to a significant increase in phage production, a characteristic of an organism with a lysogenic life cycle. the study of lytic induction from temperate a. nidulans can provide a good model for studying the interaction between cyanophage and cyanobacteria in freshwater ecosystems.  in order to determine if heavy metals could cause induction of as- from temperate a. nidulans, cuso was added at concentrations of × 10- m, × 10- m, × 10- m and × 10- m at day post innoculation, the exponential growth stage of the culture. growth of an-t was severely inhibited at concentrations of × 10- m and × 10- m. growth was affected to a certain extent in × 10- m of cuso4; growth rate in × 10- m cuso was very similar to the control. as results seen in marine cyanobacteria, there is consistent release of virus through out the lysogenic cycle in the normal as-1/a. nidulans infective system. the viral release was monitored by plaque forming units. the representative pictures of the plaque forming units after cuso induction were obtained from different treated conditions and illustrated as no plaques and the proper number of plaques as showed in figure the results of as- pfu study, showed that hours after copper induction, ± pfus were observed from the control, ± pfus were observed from × 10- m of cuso4; ± pfus were formed from × 10- m of cuso ± pfus were formed from × 10- m of cuso hours after induction, ±, ±, ± and ± pfus were formed compared to the control, × 10- m, × 10- m and × 10- m of cuso respectively. hours after induction, ±, ±, ± and ± pfus were formed for the control, × 10- m, × 10- m and × 10- m of cuso induction respectively. pfus per a. nidulans was also calculated, hours after induction, they were ±, ±, ±, and ± respectively for the control, × 10- m, × 10- m and × 10- m of cuso hours after induction, they were ±, ±, ± and ± respectively for the control, × 10- m, × 10- m and × 10- m of cuso hours after induction, they were ±, ±, ± and ± respectively for the control, × 10- m, × 10-5m and × 10- m of cuso the comparison of the treated an-t with the control was summarized in table in the concentration of × 10- m, the pfus were obvious at hours after addition of copper; it induced ± times the control. at hours and hours after addition of copper, the pfus were significantly reduced, with only ± times and ± times of the control. the pfu per a. nidulans with copper of × 10- m was, and times of the control at and hours respectively. with concentrations of × 10- m, pfus were ± times, ± times and ± times of the control at and hours respectively after the addition of copper. the pfu per a. nidulans with copper of × 10- m was, and times of the control at and hours respectively after the addition of copper. with a concentration of × 10- m, the number of pfus was ± times, ± times and ± times of the control at and hours respectively after the addition of copper. the pfu per a. nidulans with copper of × 10- m was, and times of the control at and hours respectively after the addition of copper. concentrations of × 10- m may be too high to be inducers for releasing of temperate cyanophage as-. this concentration of copper may be toxic for the growth of the cells and induce lethality through different mechanisms. from this study, the percentage of increase of release was also calculated for different conditions. the results indicated that hours after addition of copper, ± %, ± % and ± % of increase of release were observed at × 10-4m, × 10- m and × 10- m of cuso respectively. hours after the addition of copper, the induction efficiency was not of major consequence with × 10- m of cuso the pir was negative with a value of - ± %. the pir was ± % and ± % at × 10- m and × 10- m of cuso respectively. hours after addition of copper, the pir for × 10- m of cuso was - ± %. the pir was ± % and ± % at × 10- m and × 10- m of cuso respectively. while there is no clear evidence to explain why induction decreases over time, it is possible that either the phage/host interaction stabilizes after the initial stress or the toxic effect of heavy metal on the host causes a disruption in phage production. although the heavy metal induction rates varied depending on the concentrations of the heavy metal, the overall induction of copper compared to control is clear. the results suggest that cu2+ is a significant inducer for temperate as- released from an-t. the results correlated well with the study of induction for marine cyanobacterial lysogen although as- release rate and induction rate by copper were much lower than the marine cyanophage/cyanobacterial lysogen studies. further study with other reported inducers mitomycin c and uv was also carried out to compare the pir of both mitomycin c and uv with copper studies. the maximum pir for different factors are showed in table it is indicated that copper, uv and mitomycin c are able to induce the release of phage with pir of ±, ±, and ± respectively.  these results suggest that as- lysogenic phage can be induced by copper with a concentration range from × 10- m to × 10- m. the best condition for phage induction occurred at hours after addition of all these concentrations. copper concentrations of × 10- m showed the highest level of viral induction. cu2+ is an important inducer for lysogenic cyanobacterial cells and consequently could be a potential trigger in the cyanobacteria population in freshwater aquatic environments. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
98,e6a6a5ec-b9f0-4e48-954f-1207f7750d64_flant5_gen,lysogenic phage induction from temperate cyanophage as-1/a. nidulans by copper sulfate," anacystis nidulans is a rod-shaped, unicellular prokaryotic cyanobacterium and plays an important role in aquatic ecosystems as a primary producer. it is often used as an indicator for studying the toxic metabolic levels of heavy metals. many heavy metal studies have been done using a. nidulans as the model system for the reaction of organisms to heavy metal stresses. in freshwater environments, dense algal blooms of cyanobacteria are usually caused by nutrient enrichment from sewage, agricultural fertilizers and industrial run-off into waterways. algal blooms are considered threat to the water system. cyanophage are viruses that infect cyanobacteria and are ubiquitous in both freshwater and marine environments. these phages play important roles in modulating cyanobacterial populations, affecting primary productivity, increasing water quality and may have a profound influence on global biogeochemical cycles. although the interaction between a cyanophage and its host organism is important in maintaining water quality in freshwater systems, little is known about how viruses regulate microbial mortality in natural waters. recently, it was found that lysogenic infection was common in marine synechococcus sp.. cyanophage infecting a single strain of marine synechococcus sp. can reach to per ml in seawater. suttle and chan have estimated that between 5– % of marine synechococcus cells were lysed by cyanophage daily. the discovery of a high abundance of viral particles in natural waters initiated the research on the ecological impact of the viral infection and lysis of marine microbes. they also provided evidence that viruses can affect microbial populations by either going through a lytic cycle, causing destruction of the host cell, or maintaining a lysogenic stage, in which the viral genome is inserted and maintained as the prophage in its host cell. there was also evidence to suggest that seasonal changes can cause the prophage to enter a lytic cycle thus leading to the disappearance of algae blooms. lysogeny can also be induced to a lytic cycle by pollutants. although extensive research has been done on the interaction between cyanophage and cyanbacteria in marine systems, there are no significant reports that have focused on freshwater cyanophage/cyanobacteria interactions. the possibility of temperate as- and lysogenic a. nidulans was suggested by bisen et al, but there was no direct evidence provided. it has been reported that uv, mitomycin c and heavy metals such as copper, cadmium can induce the release of cyanophage in marine water. in this study, different concentrations of copper sulfate were used to study a possible as- lysogenic life cycle in addition to the previously characterized lytic cycle. addition of copper sulfate led to a significant increase in phage production, a characteristic of an organism with a lysogenic life cycle. the study of lytic induction from temperate a. nidulans can provide a good model for studying the interaction between cyanophage and cyanobacteria in freshwater ecosystems.  in order to determine if heavy metals could cause induction of as- from temperate a. nidulans, cuso was added at concentrations of × 10- m, × 10- m, × 10- m and × 10- m at day post innoculation, the exponential growth stage of the culture. growth of an-t was severely inhibited at concentrations of × 10- m and × 10- m. growth was affected to a certain extent in × 10- m of cuso4; growth rate in × 10- m cuso was very similar to the control. as results seen in marine cyanobacteria, there is consistent release of virus through out the lysogenic cycle in the normal as-1/a. nidulans infective system. the viral release was monitored by plaque forming units. the representative pictures of the plaque forming units after cuso induction were obtained from different treated conditions and illustrated as no plaques and the proper number of plaques as showed in figure the results of as- pfu study, showed that hours after copper induction, ± pfus were observed from the control, ± pfus were observed from × 10- m of cuso4; ± pfus were formed from × 10- m of cuso ± pfus were formed from × 10- m of cuso hours after induction, ±, ±, ± and ± pfus were formed compared to the control, × 10- m, × 10- m and × 10- m of cuso respectively. hours after induction, ±, ±, ± and ± pfus were formed for the control, × 10- m, × 10- m and × 10- m of cuso induction respectively. pfus per a. nidulans was also calculated, hours after induction, they were ±, ±, ±, and ± respectively for the control, × 10- m, × 10- m and × 10- m of cuso hours after induction, they were ±, ±, ± and ± respectively for the control, × 10- m, × 10- m and × 10- m of cuso hours after induction, they were ±, ±, ± and ± respectively for the control, × 10- m, × 10-5m and × 10- m of cuso the comparison of the treated an-t with the control was summarized in table in the concentration of × 10- m, the pfus were obvious at hours after addition of copper; it induced ± times the control. at hours and hours after addition of copper, the pfus were significantly reduced, with only ± times and ± times of the control. the pfu per a. nidulans with copper of × 10- m was, and times of the control at and hours respectively. with concentrations of × 10- m, pfus were ± times, ± times and ± times of the control at and hours respectively after the addition of copper. the pfu per a. nidulans with copper of × 10- m was, and times of the control at and hours respectively after the addition of copper. with a concentration of × 10- m, the number of pfus was ± times, ± times and ± times of the control at and hours respectively after the addition of copper. the pfu per a. nidulans with copper of × 10- m was, and times of the control at and hours respectively after the addition of copper. concentrations of × 10- m may be too high to be inducers for releasing of temperate cyanophage as-. this concentration of copper may be toxic for the growth of the cells and induce lethality through different mechanisms. from this study, the percentage of increase of release was also calculated for different conditions. the results indicated that hours after addition of copper, ± %, ± % and ± % of increase of release were observed at × 10-4m, × 10- m and × 10- m of cuso respectively. hours after the addition of copper, the induction efficiency was not of major consequence with × 10- m of cuso the pir was negative with a value of - ± %. the pir was ± % and ± % at × 10- m and × 10- m of cuso respectively. hours after addition of copper, the pir for × 10- m of cuso was - ± %. the pir was ± % and ± % at × 10- m and × 10- m of cuso respectively. while there is no clear evidence to explain why induction decreases over time, it is possible that either the phage/host interaction stabilizes after the initial stress or the toxic effect of heavy metal on the host causes a disruption in phage production. although the heavy metal induction rates varied depending on the concentrations of the heavy metal, the overall induction of copper compared to control is clear. the results suggest that cu2+ is a significant inducer for temperate as- released from an-t. the results correlated well with the study of induction for marine cyanobacterial lysogen although as- release rate and induction rate by copper were much lower than the marine cyanophage/cyanobacterial lysogen studies. further study with other reported inducers mitomycin c and uv was also carried out to compare the pir of both mitomycin c and uv with copper studies. the maximum pir for different factors are showed in table it is indicated that copper, uv and mitomycin c are able to induce the release of phage with pir of ±, ±, and ± respectively.  these results suggest that as- lysogenic phage can be induced by copper with a concentration range from × 10- m to × 10- m. the best condition for phage induction occurred at hours after addition of all these concentrations. copper concentrations of × 10- m showed the highest level of viral induction. cu2+ is an important inducer for lysogenic cyanobacterial cells and consequently could be a potential trigger in the cyanobacteria population in freshwater aquatic environments. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
99,289f5d54-4e87-45af-a7e7-ae439305a0c9_flant5_gen,fMRI studies of the amygdala and fusiform gyrus response to schematic and human facial expressions.," human faces provide key social and emotional information via the expressions portrayed. in a single encounter, an individual's facial expressions change rapidly, requiring a quick deduction of meaning. this ability to process facial expressions quickly or automatically is particularly advantageous when the expressions predict threat. given the importance of processing social threat cues in facial expressions quickly, the meaning may be conveyed by several key features. schematic faces, simple line drawings or caricatures of faces, extract these features from a complex facial expression. a schematic face capturing the key components of a facial expression may be useful in studies of emotion because the prototype is relatively devoid of confounding characteristics. several studies have discovered that schematic faces still retain emotional meaning and schematic faces activate brain structures involved in processing human facial expressions, providing evidence that a simple representation of a facial expression can be used to study emotion. it is well-established that the amygdala response habituates to repeated presentations of human facial expressions; however, it is unclear whether the brain's response to schematic faces is maintained or habituates over time. amygdala single cell recordings show reduced activity to repeated human faces. additionally, neuroimaging studies have reported early vs. late within-block habituation in the amygdala and hippocampal formation in response to repeated fearful and neutral human faces. to our knowledge, only two studies have reported on habituation effects in response to schematic faces. in an event-related study involving both human and schematic faces, significant amygdala habituation was reported to schematic faces of anger relative to neutral in individuals with social phobia. in a block-design study of healthy individuals, the amgydala response to schematic faces was maintained across time; however, the presentation order may have inhibited habituation. in this fmri block-design study, we examined the brain responses to schematic and human facial expressions using a within-run facial expression and between-run face type counterbalanced design. this design allowed examination of habituation and of face type in a single experiment without potentially confounding influences of presentation order. we hypothesized within-run habituation effects would be detected in response to the alternating blocks of schematic facial expressions as well as the human facial expressions in the amygdala.  face recognition and emotion ratings during the post-scanning recognition task, participants identified the faces viewed with high accuracy rates. the negative faces were rated as being more arousing than the neutral faces. no differences in arousal ratings between face type were detected. no interaction effects were noted. the negative faces were rated as being more negative than the neutral faces. the human faces tended to be rated more negatively than the schematic faces. in addition, the valence rating difference between angry and neutral faces was greater for schematic faces than for human faces. this difference was due to greater negative valence ratings of the human neutral faces compared to more positive ratings of neutral schematic faces. bold activation a temporal effect of responses across blocks within the run were detected in amygdala and fusiform gyrus. a significant quadratic response was detected in both regions. post-hoc tests were conducted using a significance threshold of p < to correct for multiple comparisons and demonstrated a ""u"" pattern of activity. in the amygdala and fusiform, the response in the initial block was greater than the other blocks. contrary to the amygdala, the responses in the fusiform gyrus tend to progressively decline. in addition, a trend towards significant region x time interaction was detected in the left and the right hemispheres. responses to block were greater than block significantly in the right amygdala and bilateral fusiform gyrus and at trend-level significance in the left amygdala. in the right amygdala, a trend emotion x time effect was significant. because the initial block yielded the largest response and was subsequently followed by a habituated response, the responses in the first time block were investigated further for valence effects. greater responses were elicited to negative faces compared to neutral faces.. there were no other significant effects in the amygdala. no significant valence, face-type main effets or interactions were found in the fusiform gyrus.. discussion within each run, the amygdala and the fusiform gyrus showed a ""u"" response pattern with the initial and final blocks eliciting the greatest activation to a repeated facial expression. the amygdala profile may reflect an initial orienting response, then habituation, followed by recovery of activation in the final block. a similar ""u"" pattern was observed in skin conductance response and late-phase scr-associated left amygdala response to repeated fearful faces. like fear, anger is highly arousing and may prompt a similar orienting response and skin conductance response. the activation recovery may be due to emotional priming. alternatively, it may reflect spontaneous recovery or reinstatement. vigilance maintenance via a system reset, even in the absence of imminent threat, may be an important survival function. consistent with this notion, primate electrophysiological data demonstrate that neuronal populations within the amygdala respond maximally to novelty, show decreased activation with familiarity, and reset after limited number of repeated stimulus presentations. in this study, fusiform gyrus activation followed this ""u"" pattern in response as well; however, a trend towards different temporal patterns are observed in the amygdala and fusiform gyrus. in the amygdala, habituation occurs rapidly; whereas, in the fusiform gyrus, habituation occurs more gradually. this delayed recovery may be explained by enhanced modulation of the amygdala or a slower resetting system of the fusiform gyrus. negative faces are discriminated from neutral faces in the right amygdala. our findings replicate previous work showing that the right amygdala, responds to angry relative to neutral faces. in this study, the differential amygdala response to facial expressions was present only during the early time period, suggesting that it is related to the amygdala orienting response. although some studies report fusiform gyrus activation to emotional faces relative to neutral faces, we did not detect such an effect. it may be that differential fusiform gyrus activation to emotional faces is task-dependent. the fusiform gyrus responds more non-selectively to facial stimuli in the context of limited-attentional demands, yet exhibits a selective or differential pattern of activation when increased attention to face emotional content is required. in fact, the existence of projections from the amygdala to the fusiform cortex suggest that the amygdala may modulate the sensory processing stream according to the salience of the target visual stimulus. interestingly, no significant differences between schematic and human faces were detected in the amygdala and fusiform gyrus. in a recent study, the amygdala response to human and avatar was similar, yet the fusiform showed a greater response to human faces. for studying the amygdala, it appears that there is some utility to this response similarity between human and face representations. schematic and avatar faces may be useful to study emotion perception because the key facial features that underlie the neural activation are relatively isolated from stimulus features like race/ethnicity and gender, which may increase the variability in responses. it is also important to note that schematic and avatar faces may be useful in answering different questions concerning emotion that take advantage of the static or moveable representations. this study has some potential limitations. evaluating the temporal dynamics of neural responses is dependent on the time scale examined. in this study, within-run habituation effects were investigated; however, other time scales may show different effects. only angry faces were used to represent negative faces. future studies should examine the temporal dynamics of other expressions, including positive expressions. our findings suggest schematic and human faces elicit generally similar responses in the amygdala and fusiform gyrus; however, replication in a larger sample is needed. schematic faces reduce expressions to line drawings and a single exemplar was used in this study. while using a single exemplar may be problematic, it does diminish confounds due to variability in human facial expressions. finally, although using roi-based analysis is a more powerful approach for detecting differences in specific a priori regions, this approach does not allow the observation of other regions that may also respond to these stimuli.  in summary, it appears that both the amygdala and fusiform gyrus responses to facial expressions do habituate over time; however, the ""u"" pattern suggests that the responsivity of these structures resets, possibly to allow attentional reengagement with repeatedly presented stimuli. future studies with larger samples should investigate whether this pattern discriminates between emotions or stimulus type. ",pubmed_generic,Flan T5,,factual,factual,,,,,,,,
100,289f5d54-4e87-45af-a7e7-ae439305a0c9_gpt3_gen,"Facial expressions provide important social and emotional information, and schematic faces (simple line drawings or caricatures of faces) can be useful in studying emotions as they extract key features from a complex facial expression. This study used functional magnetic resonance imaging (fMRI) to examine the brain responses to schematic and human facial expressions and found that both the amygdala and fusiform gyrus show a ""u"" response pattern with initial and final blocks eliciting the greatest activation to a repeated facial expression, suggesting a reset in response and attentional reengagement with repeatedly presented stimuli. The study also found no significant differences between schematic and human faces in terms of eliciting similar responses in the amygdala and fusiform gyrus. Future studies with larger samples should investigate whether this pattern discriminates between emotions or stimulus type."," human faces provide key social and emotional information via the expressions portrayed. in a single encounter, an individual's facial expressions change rapidly, requiring a quick deduction of meaning. this ability to process facial expressions quickly or automatically is particularly advantageous when the expressions predict threat. given the importance of processing social threat cues in facial expressions quickly, the meaning may be conveyed by several key features. schematic faces, simple line drawings or caricatures of faces, extract these features from a complex facial expression. a schematic face capturing the key components of a facial expression may be useful in studies of emotion because the prototype is relatively devoid of confounding characteristics. several studies have discovered that schematic faces still retain emotional meaning and schematic faces activate brain structures involved in processing human facial expressions, providing evidence that a simple representation of a facial expression can be used to study emotion. it is well-established that the amygdala response habituates to repeated presentations of human facial expressions; however, it is unclear whether the brain's response to schematic faces is maintained or habituates over time. amygdala single cell recordings show reduced activity to repeated human faces. additionally, neuroimaging studies have reported early vs. late within-block habituation in the amygdala and hippocampal formation in response to repeated fearful and neutral human faces. to our knowledge, only two studies have reported on habituation effects in response to schematic faces. in an event-related study involving both human and schematic faces, significant amygdala habituation was reported to schematic faces of anger relative to neutral in individuals with social phobia. in a block-design study of healthy individuals, the amgydala response to schematic faces was maintained across time; however, the presentation order may have inhibited habituation. in this fmri block-design study, we examined the brain responses to schematic and human facial expressions using a within-run facial expression and between-run face type counterbalanced design. this design allowed examination of habituation and of face type in a single experiment without potentially confounding influences of presentation order. we hypothesized within-run habituation effects would be detected in response to the alternating blocks of schematic facial expressions as well as the human facial expressions in the amygdala.  face recognition and emotion ratings during the post-scanning recognition task, participants identified the faces viewed with high accuracy rates. the negative faces were rated as being more arousing than the neutral faces. no differences in arousal ratings between face type were detected. no interaction effects were noted. the negative faces were rated as being more negative than the neutral faces. the human faces tended to be rated more negatively than the schematic faces. in addition, the valence rating difference between angry and neutral faces was greater for schematic faces than for human faces. this difference was due to greater negative valence ratings of the human neutral faces compared to more positive ratings of neutral schematic faces. bold activation a temporal effect of responses across blocks within the run were detected in amygdala and fusiform gyrus. a significant quadratic response was detected in both regions. post-hoc tests were conducted using a significance threshold of p < to correct for multiple comparisons and demonstrated a ""u"" pattern of activity. in the amygdala and fusiform, the response in the initial block was greater than the other blocks. contrary to the amygdala, the responses in the fusiform gyrus tend to progressively decline. in addition, a trend towards significant region x time interaction was detected in the left and the right hemispheres. responses to block were greater than block significantly in the right amygdala and bilateral fusiform gyrus and at trend-level significance in the left amygdala. in the right amygdala, a trend emotion x time effect was significant. because the initial block yielded the largest response and was subsequently followed by a habituated response, the responses in the first time block were investigated further for valence effects. greater responses were elicited to negative faces compared to neutral faces.. there were no other significant effects in the amygdala. no significant valence, face-type main effets or interactions were found in the fusiform gyrus.. discussion within each run, the amygdala and the fusiform gyrus showed a ""u"" response pattern with the initial and final blocks eliciting the greatest activation to a repeated facial expression. the amygdala profile may reflect an initial orienting response, then habituation, followed by recovery of activation in the final block. a similar ""u"" pattern was observed in skin conductance response and late-phase scr-associated left amygdala response to repeated fearful faces. like fear, anger is highly arousing and may prompt a similar orienting response and skin conductance response. the activation recovery may be due to emotional priming. alternatively, it may reflect spontaneous recovery or reinstatement. vigilance maintenance via a system reset, even in the absence of imminent threat, may be an important survival function. consistent with this notion, primate electrophysiological data demonstrate that neuronal populations within the amygdala respond maximally to novelty, show decreased activation with familiarity, and reset after limited number of repeated stimulus presentations. in this study, fusiform gyrus activation followed this ""u"" pattern in response as well; however, a trend towards different temporal patterns are observed in the amygdala and fusiform gyrus. in the amygdala, habituation occurs rapidly; whereas, in the fusiform gyrus, habituation occurs more gradually. this delayed recovery may be explained by enhanced modulation of the amygdala or a slower resetting system of the fusiform gyrus. negative faces are discriminated from neutral faces in the right amygdala. our findings replicate previous work showing that the right amygdala, responds to angry relative to neutral faces. in this study, the differential amygdala response to facial expressions was present only during the early time period, suggesting that it is related to the amygdala orienting response. although some studies report fusiform gyrus activation to emotional faces relative to neutral faces, we did not detect such an effect. it may be that differential fusiform gyrus activation to emotional faces is task-dependent. the fusiform gyrus responds more non-selectively to facial stimuli in the context of limited-attentional demands, yet exhibits a selective or differential pattern of activation when increased attention to face emotional content is required. in fact, the existence of projections from the amygdala to the fusiform cortex suggest that the amygdala may modulate the sensory processing stream according to the salience of the target visual stimulus. interestingly, no significant differences between schematic and human faces were detected in the amygdala and fusiform gyrus. in a recent study, the amygdala response to human and avatar was similar, yet the fusiform showed a greater response to human faces. for studying the amygdala, it appears that there is some utility to this response similarity between human and face representations. schematic and avatar faces may be useful to study emotion perception because the key facial features that underlie the neural activation are relatively isolated from stimulus features like race/ethnicity and gender, which may increase the variability in responses. it is also important to note that schematic and avatar faces may be useful in answering different questions concerning emotion that take advantage of the static or moveable representations. this study has some potential limitations. evaluating the temporal dynamics of neural responses is dependent on the time scale examined. in this study, within-run habituation effects were investigated; however, other time scales may show different effects. only angry faces were used to represent negative faces. future studies should examine the temporal dynamics of other expressions, including positive expressions. our findings suggest schematic and human faces elicit generally similar responses in the amygdala and fusiform gyrus; however, replication in a larger sample is needed. schematic faces reduce expressions to line drawings and a single exemplar was used in this study. while using a single exemplar may be problematic, it does diminish confounds due to variability in human facial expressions. finally, although using roi-based analysis is a more powerful approach for detecting differences in specific a priori regions, this approach does not allow the observation of other regions that may also respond to these stimuli.  in summary, it appears that both the amygdala and fusiform gyrus responses to facial expressions do habituate over time; however, the ""u"" pattern suggests that the responsivity of these structures resets, possibly to allow attentional reengagement with repeatedly presented stimuli. future studies with larger samples should investigate whether this pattern discriminates between emotions or stimulus type. ",pubmed_generic,GPT 3.5,,factual,factual,,,,,,,,
